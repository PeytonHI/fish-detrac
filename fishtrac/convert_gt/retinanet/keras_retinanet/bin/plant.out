2019-06-14 13:42:51.639475: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2
2019-06-14 13:42:51.759904: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-06-14 13:42:51.760774: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 0 with properties: 
name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.7845
pciBusID: 0000:0c:00.0
totalMemory: 7.92GiB freeMemory: 7.75GiB
2019-06-14 13:42:51.760803: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0
2019-06-14 13:42:52.333740: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-06-14 13:42:52.333791: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 
2019-06-14 13:42:52.333805: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N 
2019-06-14 13:42:52.334224: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7482 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:0c:00.0, compute capability: 6.1)
Creating model, this may take a second...
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, None, None, 3 0                                            
__________________________________________________________________________________________________
conv1 (Conv2D)                  (None, None, None, 6 9408        input_1[0][0]                    
__________________________________________________________________________________________________
bn_conv1 (BatchNormalization)   (None, None, None, 6 256         conv1[0][0]                      
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, None, None, 6 0           bn_conv1[0][0]                   
__________________________________________________________________________________________________
pool1 (MaxPooling2D)            (None, None, None, 6 0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
res2a_branch2a (Conv2D)         (None, None, None, 6 4096        pool1[0][0]                      
__________________________________________________________________________________________________
bn2a_branch2a (BatchNormalizati (None, None, None, 6 256         res2a_branch2a[0][0]             
__________________________________________________________________________________________________
res2a_branch2a_relu (Activation (None, None, None, 6 0           bn2a_branch2a[0][0]              
__________________________________________________________________________________________________
padding2a_branch2b (ZeroPadding (None, None, None, 6 0           res2a_branch2a_relu[0][0]        
__________________________________________________________________________________________________
res2a_branch2b (Conv2D)         (None, None, None, 6 36864       padding2a_branch2b[0][0]         
__________________________________________________________________________________________________
bn2a_branch2b (BatchNormalizati (None, None, None, 6 256         res2a_branch2b[0][0]             
__________________________________________________________________________________________________
res2a_branch2b_relu (Activation (None, None, None, 6 0           bn2a_branch2b[0][0]              
__________________________________________________________________________________________________
res2a_branch2c (Conv2D)         (None, None, None, 2 16384       res2a_branch2b_relu[0][0]        
__________________________________________________________________________________________________
res2a_branch1 (Conv2D)          (None, None, None, 2 16384       pool1[0][0]                      
__________________________________________________________________________________________________
bn2a_branch2c (BatchNormalizati (None, None, None, 2 1024        res2a_branch2c[0][0]             
__________________________________________________________________________________________________
bn2a_branch1 (BatchNormalizatio (None, None, None, 2 1024        res2a_branch1[0][0]              
__________________________________________________________________________________________________
res2a (Add)                     (None, None, None, 2 0           bn2a_branch2c[0][0]              
                                                                 bn2a_branch1[0][0]               
__________________________________________________________________________________________________
res2a_relu (Activation)         (None, None, None, 2 0           res2a[0][0]                      
__________________________________________________________________________________________________
res2b_branch2a (Conv2D)         (None, None, None, 6 16384       res2a_relu[0][0]                 
__________________________________________________________________________________________________
bn2b_branch2a (BatchNormalizati (None, None, None, 6 256         res2b_branch2a[0][0]             
__________________________________________________________________________________________________
res2b_branch2a_relu (Activation (None, None, None, 6 0           bn2b_branch2a[0][0]              
__________________________________________________________________________________________________
padding2b_branch2b (ZeroPadding (None, None, None, 6 0           res2b_branch2a_relu[0][0]        
__________________________________________________________________________________________________
res2b_branch2b (Conv2D)         (None, None, None, 6 36864       padding2b_branch2b[0][0]         
__________________________________________________________________________________________________
bn2b_branch2b (BatchNormalizati (None, None, None, 6 256         res2b_branch2b[0][0]             
__________________________________________________________________________________________________
res2b_branch2b_relu (Activation (None, None, None, 6 0           bn2b_branch2b[0][0]              
__________________________________________________________________________________________________
res2b_branch2c (Conv2D)         (None, None, None, 2 16384       res2b_branch2b_relu[0][0]        
__________________________________________________________________________________________________
bn2b_branch2c (BatchNormalizati (None, None, None, 2 1024        res2b_branch2c[0][0]             
__________________________________________________________________________________________________
res2b (Add)                     (None, None, None, 2 0           bn2b_branch2c[0][0]              
                                                                 res2a_relu[0][0]                 
__________________________________________________________________________________________________
res2b_relu (Activation)         (None, None, None, 2 0           res2b[0][0]                      
__________________________________________________________________________________________________
res2c_branch2a (Conv2D)         (None, None, None, 6 16384       res2b_relu[0][0]                 
__________________________________________________________________________________________________
bn2c_branch2a (BatchNormalizati (None, None, None, 6 256         res2c_branch2a[0][0]             
__________________________________________________________________________________________________
res2c_branch2a_relu (Activation (None, None, None, 6 0           bn2c_branch2a[0][0]              
__________________________________________________________________________________________________
padding2c_branch2b (ZeroPadding (None, None, None, 6 0           res2c_branch2a_relu[0][0]        
__________________________________________________________________________________________________
res2c_branch2b (Conv2D)         (None, None, None, 6 36864       padding2c_branch2b[0][0]         
__________________________________________________________________________________________________
bn2c_branch2b (BatchNormalizati (None, None, None, 6 256         res2c_branch2b[0][0]             
__________________________________________________________________________________________________
res2c_branch2b_relu (Activation (None, None, None, 6 0           bn2c_branch2b[0][0]              
__________________________________________________________________________________________________
res2c_branch2c (Conv2D)         (None, None, None, 2 16384       res2c_branch2b_relu[0][0]        
__________________________________________________________________________________________________
bn2c_branch2c (BatchNormalizati (None, None, None, 2 1024        res2c_branch2c[0][0]             
__________________________________________________________________________________________________
res2c (Add)                     (None, None, None, 2 0           bn2c_branch2c[0][0]              
                                                                 res2b_relu[0][0]                 
__________________________________________________________________________________________________
res2c_relu (Activation)         (None, None, None, 2 0           res2c[0][0]                      
__________________________________________________________________________________________________
res3a_branch2a (Conv2D)         (None, None, None, 1 32768       res2c_relu[0][0]                 
__________________________________________________________________________________________________
bn3a_branch2a (BatchNormalizati (None, None, None, 1 512         res3a_branch2a[0][0]             
__________________________________________________________________________________________________
res3a_branch2a_relu (Activation (None, None, None, 1 0           bn3a_branch2a[0][0]              
__________________________________________________________________________________________________
padding3a_branch2b (ZeroPadding (None, None, None, 1 0           res3a_branch2a_relu[0][0]        
__________________________________________________________________________________________________
res3a_branch2b (Conv2D)         (None, None, None, 1 147456      padding3a_branch2b[0][0]         
__________________________________________________________________________________________________
bn3a_branch2b (BatchNormalizati (None, None, None, 1 512         res3a_branch2b[0][0]             
__________________________________________________________________________________________________
res3a_branch2b_relu (Activation (None, None, None, 1 0           bn3a_branch2b[0][0]              
__________________________________________________________________________________________________
res3a_branch2c (Conv2D)         (None, None, None, 5 65536       res3a_branch2b_relu[0][0]        
__________________________________________________________________________________________________
res3a_branch1 (Conv2D)          (None, None, None, 5 131072      res2c_relu[0][0]                 
__________________________________________________________________________________________________
bn3a_branch2c (BatchNormalizati (None, None, None, 5 2048        res3a_branch2c[0][0]             
__________________________________________________________________________________________________
bn3a_branch1 (BatchNormalizatio (None, None, None, 5 2048        res3a_branch1[0][0]              
__________________________________________________________________________________________________
res3a (Add)                     (None, None, None, 5 0           bn3a_branch2c[0][0]              
                                                                 bn3a_branch1[0][0]               
__________________________________________________________________________________________________
res3a_relu (Activation)         (None, None, None, 5 0           res3a[0][0]                      
__________________________________________________________________________________________________
res3b_branch2a (Conv2D)         (None, None, None, 1 65536       res3a_relu[0][0]                 
__________________________________________________________________________________________________
bn3b_branch2a (BatchNormalizati (None, None, None, 1 512         res3b_branch2a[0][0]             
__________________________________________________________________________________________________
res3b_branch2a_relu (Activation (None, None, None, 1 0           bn3b_branch2a[0][0]              
__________________________________________________________________________________________________
padding3b_branch2b (ZeroPadding (None, None, None, 1 0           res3b_branch2a_relu[0][0]        
__________________________________________________________________________________________________
res3b_branch2b (Conv2D)         (None, None, None, 1 147456      padding3b_branch2b[0][0]         
__________________________________________________________________________________________________
bn3b_branch2b (BatchNormalizati (None, None, None, 1 512         res3b_branch2b[0][0]             
__________________________________________________________________________________________________
res3b_branch2b_relu (Activation (None, None, None, 1 0           bn3b_branch2b[0][0]              
__________________________________________________________________________________________________
res3b_branch2c (Conv2D)         (None, None, None, 5 65536       res3b_branch2b_relu[0][0]        
__________________________________________________________________________________________________
bn3b_branch2c (BatchNormalizati (None, None, None, 5 2048        res3b_branch2c[0][0]             
__________________________________________________________________________________________________
res3b (Add)                     (None, None, None, 5 0           bn3b_branch2c[0][0]              
                                                                 res3a_relu[0][0]                 
__________________________________________________________________________________________________
res3b_relu (Activation)         (None, None, None, 5 0           res3b[0][0]                      
__________________________________________________________________________________________________
res3c_branch2a (Conv2D)         (None, None, None, 1 65536       res3b_relu[0][0]                 
__________________________________________________________________________________________________
bn3c_branch2a (BatchNormalizati (None, None, None, 1 512         res3c_branch2a[0][0]             
__________________________________________________________________________________________________
res3c_branch2a_relu (Activation (None, None, None, 1 0           bn3c_branch2a[0][0]              
__________________________________________________________________________________________________
padding3c_branch2b (ZeroPadding (None, None, None, 1 0           res3c_branch2a_relu[0][0]        
__________________________________________________________________________________________________
res3c_branch2b (Conv2D)         (None, None, None, 1 147456      padding3c_branch2b[0][0]         
__________________________________________________________________________________________________
bn3c_branch2b (BatchNormalizati (None, None, None, 1 512         res3c_branch2b[0][0]             
__________________________________________________________________________________________________
res3c_branch2b_relu (Activation (None, None, None, 1 0           bn3c_branch2b[0][0]              
__________________________________________________________________________________________________
res3c_branch2c (Conv2D)         (None, None, None, 5 65536       res3c_branch2b_relu[0][0]        
__________________________________________________________________________________________________
bn3c_branch2c (BatchNormalizati (None, None, None, 5 2048        res3c_branch2c[0][0]             
__________________________________________________________________________________________________
res3c (Add)                     (None, None, None, 5 0           bn3c_branch2c[0][0]              
                                                                 res3b_relu[0][0]                 
__________________________________________________________________________________________________
res3c_relu (Activation)         (None, None, None, 5 0           res3c[0][0]                      
__________________________________________________________________________________________________
res3d_branch2a (Conv2D)         (None, None, None, 1 65536       res3c_relu[0][0]                 
__________________________________________________________________________________________________
bn3d_branch2a (BatchNormalizati (None, None, None, 1 512         res3d_branch2a[0][0]             
__________________________________________________________________________________________________
res3d_branch2a_relu (Activation (None, None, None, 1 0           bn3d_branch2a[0][0]              
__________________________________________________________________________________________________
padding3d_branch2b (ZeroPadding (None, None, None, 1 0           res3d_branch2a_relu[0][0]        
__________________________________________________________________________________________________
res3d_branch2b (Conv2D)         (None, None, None, 1 147456      padding3d_branch2b[0][0]         
__________________________________________________________________________________________________
bn3d_branch2b (BatchNormalizati (None, None, None, 1 512         res3d_branch2b[0][0]             
__________________________________________________________________________________________________
res3d_branch2b_relu (Activation (None, None, None, 1 0           bn3d_branch2b[0][0]              
__________________________________________________________________________________________________
res3d_branch2c (Conv2D)         (None, None, None, 5 65536       res3d_branch2b_relu[0][0]        
__________________________________________________________________________________________________
bn3d_branch2c (BatchNormalizati (None, None, None, 5 2048        res3d_branch2c[0][0]             
__________________________________________________________________________________________________
res3d (Add)                     (None, None, None, 5 0           bn3d_branch2c[0][0]              
                                                                 res3c_relu[0][0]                 
__________________________________________________________________________________________________
res3d_relu (Activation)         (None, None, None, 5 0           res3d[0][0]                      
__________________________________________________________________________________________________
res4a_branch2a (Conv2D)         (None, None, None, 2 131072      res3d_relu[0][0]                 
__________________________________________________________________________________________________
bn4a_branch2a (BatchNormalizati (None, None, None, 2 1024        res4a_branch2a[0][0]             
__________________________________________________________________________________________________
res4a_branch2a_relu (Activation (None, None, None, 2 0           bn4a_branch2a[0][0]              
__________________________________________________________________________________________________
padding4a_branch2b (ZeroPadding (None, None, None, 2 0           res4a_branch2a_relu[0][0]        
__________________________________________________________________________________________________
res4a_branch2b (Conv2D)         (None, None, None, 2 589824      padding4a_branch2b[0][0]         
__________________________________________________________________________________________________
bn4a_branch2b (BatchNormalizati (None, None, None, 2 1024        res4a_branch2b[0][0]             
__________________________________________________________________________________________________
res4a_branch2b_relu (Activation (None, None, None, 2 0           bn4a_branch2b[0][0]              
__________________________________________________________________________________________________
res4a_branch2c (Conv2D)         (None, None, None, 1 262144      res4a_branch2b_relu[0][0]        
__________________________________________________________________________________________________
res4a_branch1 (Conv2D)          (None, None, None, 1 524288      res3d_relu[0][0]                 
__________________________________________________________________________________________________
bn4a_branch2c (BatchNormalizati (None, None, None, 1 4096        res4a_branch2c[0][0]             
__________________________________________________________________________________________________
bn4a_branch1 (BatchNormalizatio (None, None, None, 1 4096        res4a_branch1[0][0]              
__________________________________________________________________________________________________
res4a (Add)                     (None, None, None, 1 0           bn4a_branch2c[0][0]              
                                                                 bn4a_branch1[0][0]               
__________________________________________________________________________________________________
res4a_relu (Activation)         (None, None, None, 1 0           res4a[0][0]                      
__________________________________________________________________________________________________
res4b_branch2a (Conv2D)         (None, None, None, 2 262144      res4a_relu[0][0]                 
__________________________________________________________________________________________________
bn4b_branch2a (BatchNormalizati (None, None, None, 2 1024        res4b_branch2a[0][0]             
__________________________________________________________________________________________________
res4b_branch2a_relu (Activation (None, None, None, 2 0           bn4b_branch2a[0][0]              
__________________________________________________________________________________________________
padding4b_branch2b (ZeroPadding (None, None, None, 2 0           res4b_branch2a_relu[0][0]        
__________________________________________________________________________________________________
res4b_branch2b (Conv2D)         (None, None, None, 2 589824      padding4b_branch2b[0][0]         
__________________________________________________________________________________________________
bn4b_branch2b (BatchNormalizati (None, None, None, 2 1024        res4b_branch2b[0][0]             
__________________________________________________________________________________________________
res4b_branch2b_relu (Activation (None, None, None, 2 0           bn4b_branch2b[0][0]              
__________________________________________________________________________________________________
res4b_branch2c (Conv2D)         (None, None, None, 1 262144      res4b_branch2b_relu[0][0]        
__________________________________________________________________________________________________
bn4b_branch2c (BatchNormalizati (None, None, None, 1 4096        res4b_branch2c[0][0]             
__________________________________________________________________________________________________
res4b (Add)                     (None, None, None, 1 0           bn4b_branch2c[0][0]              
                                                                 res4a_relu[0][0]                 
__________________________________________________________________________________________________
res4b_relu (Activation)         (None, None, None, 1 0           res4b[0][0]                      
__________________________________________________________________________________________________
res4c_branch2a (Conv2D)         (None, None, None, 2 262144      res4b_relu[0][0]                 
__________________________________________________________________________________________________
bn4c_branch2a (BatchNormalizati (None, None, None, 2 1024        res4c_branch2a[0][0]             
__________________________________________________________________________________________________
res4c_branch2a_relu (Activation (None, None, None, 2 0           bn4c_branch2a[0][0]              
__________________________________________________________________________________________________
padding4c_branch2b (ZeroPadding (None, None, None, 2 0           res4c_branch2a_relu[0][0]        
__________________________________________________________________________________________________
res4c_branch2b (Conv2D)         (None, None, None, 2 589824      padding4c_branch2b[0][0]         
__________________________________________________________________________________________________
bn4c_branch2b (BatchNormalizati (None, None, None, 2 1024        res4c_branch2b[0][0]             
__________________________________________________________________________________________________
res4c_branch2b_relu (Activation (None, None, None, 2 0           bn4c_branch2b[0][0]              
__________________________________________________________________________________________________
res4c_branch2c (Conv2D)         (None, None, None, 1 262144      res4c_branch2b_relu[0][0]        
__________________________________________________________________________________________________
bn4c_branch2c (BatchNormalizati (None, None, None, 1 4096        res4c_branch2c[0][0]             
__________________________________________________________________________________________________
res4c (Add)                     (None, None, None, 1 0           bn4c_branch2c[0][0]              
                                                                 res4b_relu[0][0]                 
__________________________________________________________________________________________________
res4c_relu (Activation)         (None, None, None, 1 0           res4c[0][0]                      
__________________________________________________________________________________________________
res4d_branch2a (Conv2D)         (None, None, None, 2 262144      res4c_relu[0][0]                 
__________________________________________________________________________________________________
bn4d_branch2a (BatchNormalizati (None, None, None, 2 1024        res4d_branch2a[0][0]             
__________________________________________________________________________________________________
res4d_branch2a_relu (Activation (None, None, None, 2 0           bn4d_branch2a[0][0]              
__________________________________________________________________________________________________
padding4d_branch2b (ZeroPadding (None, None, None, 2 0           res4d_branch2a_relu[0][0]        
__________________________________________________________________________________________________
res4d_branch2b (Conv2D)         (None, None, None, 2 589824      padding4d_branch2b[0][0]         
__________________________________________________________________________________________________
bn4d_branch2b (BatchNormalizati (None, None, None, 2 1024        res4d_branch2b[0][0]             
__________________________________________________________________________________________________
res4d_branch2b_relu (Activation (None, None, None, 2 0           bn4d_branch2b[0][0]              
__________________________________________________________________________________________________
res4d_branch2c (Conv2D)         (None, None, None, 1 262144      res4d_branch2b_relu[0][0]        
__________________________________________________________________________________________________
bn4d_branch2c (BatchNormalizati (None, None, None, 1 4096        res4d_branch2c[0][0]             
__________________________________________________________________________________________________
res4d (Add)                     (None, None, None, 1 0           bn4d_branch2c[0][0]              
                                                                 res4c_relu[0][0]                 
__________________________________________________________________________________________________
res4d_relu (Activation)         (None, None, None, 1 0           res4d[0][0]                      
__________________________________________________________________________________________________
res4e_branch2a (Conv2D)         (None, None, None, 2 262144      res4d_relu[0][0]                 
__________________________________________________________________________________________________
bn4e_branch2a (BatchNormalizati (None, None, None, 2 1024        res4e_branch2a[0][0]             
__________________________________________________________________________________________________
res4e_branch2a_relu (Activation (None, None, None, 2 0           bn4e_branch2a[0][0]              
__________________________________________________________________________________________________
padding4e_branch2b (ZeroPadding (None, None, None, 2 0           res4e_branch2a_relu[0][0]        
__________________________________________________________________________________________________
res4e_branch2b (Conv2D)         (None, None, None, 2 589824      padding4e_branch2b[0][0]         
__________________________________________________________________________________________________
bn4e_branch2b (BatchNormalizati (None, None, None, 2 1024        res4e_branch2b[0][0]             
__________________________________________________________________________________________________
res4e_branch2b_relu (Activation (None, None, None, 2 0           bn4e_branch2b[0][0]              
__________________________________________________________________________________________________
res4e_branch2c (Conv2D)         (None, None, None, 1 262144      res4e_branch2b_relu[0][0]        
__________________________________________________________________________________________________
bn4e_branch2c (BatchNormalizati (None, None, None, 1 4096        res4e_branch2c[0][0]             
__________________________________________________________________________________________________
res4e (Add)                     (None, None, None, 1 0           bn4e_branch2c[0][0]              
                                                                 res4d_relu[0][0]                 
__________________________________________________________________________________________________
res4e_relu (Activation)         (None, None, None, 1 0           res4e[0][0]                      
__________________________________________________________________________________________________
res4f_branch2a (Conv2D)         (None, None, None, 2 262144      res4e_relu[0][0]                 
__________________________________________________________________________________________________
bn4f_branch2a (BatchNormalizati (None, None, None, 2 1024        res4f_branch2a[0][0]             
__________________________________________________________________________________________________
res4f_branch2a_relu (Activation (None, None, None, 2 0           bn4f_branch2a[0][0]              
__________________________________________________________________________________________________
padding4f_branch2b (ZeroPadding (None, None, None, 2 0           res4f_branch2a_relu[0][0]        
__________________________________________________________________________________________________
res4f_branch2b (Conv2D)         (None, None, None, 2 589824      padding4f_branch2b[0][0]         
__________________________________________________________________________________________________
bn4f_branch2b (BatchNormalizati (None, None, None, 2 1024        res4f_branch2b[0][0]             
__________________________________________________________________________________________________
res4f_branch2b_relu (Activation (None, None, None, 2 0           bn4f_branch2b[0][0]              
__________________________________________________________________________________________________
res4f_branch2c (Conv2D)         (None, None, None, 1 262144      res4f_branch2b_relu[0][0]        
__________________________________________________________________________________________________
bn4f_branch2c (BatchNormalizati (None, None, None, 1 4096        res4f_branch2c[0][0]             
__________________________________________________________________________________________________
res4f (Add)                     (None, None, None, 1 0           bn4f_branch2c[0][0]              
                                                                 res4e_relu[0][0]                 
__________________________________________________________________________________________________
res4f_relu (Activation)         (None, None, None, 1 0           res4f[0][0]                      
__________________________________________________________________________________________________
res5a_branch2a (Conv2D)         (None, None, None, 5 524288      res4f_relu[0][0]                 
__________________________________________________________________________________________________
bn5a_branch2a (BatchNormalizati (None, None, None, 5 2048        res5a_branch2a[0][0]             
__________________________________________________________________________________________________
res5a_branch2a_relu (Activation (None, None, None, 5 0           bn5a_branch2a[0][0]              
__________________________________________________________________________________________________
padding5a_branch2b (ZeroPadding (None, None, None, 5 0           res5a_branch2a_relu[0][0]        
__________________________________________________________________________________________________
res5a_branch2b (Conv2D)         (None, None, None, 5 2359296     padding5a_branch2b[0][0]         
__________________________________________________________________________________________________
bn5a_branch2b (BatchNormalizati (None, None, None, 5 2048        res5a_branch2b[0][0]             
__________________________________________________________________________________________________
res5a_branch2b_relu (Activation (None, None, None, 5 0           bn5a_branch2b[0][0]              
__________________________________________________________________________________________________
res5a_branch2c (Conv2D)         (None, None, None, 2 1048576     res5a_branch2b_relu[0][0]        
__________________________________________________________________________________________________
res5a_branch1 (Conv2D)          (None, None, None, 2 2097152     res4f_relu[0][0]                 
__________________________________________________________________________________________________
bn5a_branch2c (BatchNormalizati (None, None, None, 2 8192        res5a_branch2c[0][0]             
__________________________________________________________________________________________________
bn5a_branch1 (BatchNormalizatio (None, None, None, 2 8192        res5a_branch1[0][0]              
__________________________________________________________________________________________________
res5a (Add)                     (None, None, None, 2 0           bn5a_branch2c[0][0]              
                                                                 bn5a_branch1[0][0]               
__________________________________________________________________________________________________
res5a_relu (Activation)         (None, None, None, 2 0           res5a[0][0]                      
__________________________________________________________________________________________________
res5b_branch2a (Conv2D)         (None, None, None, 5 1048576     res5a_relu[0][0]                 
__________________________________________________________________________________________________
bn5b_branch2a (BatchNormalizati (None, None, None, 5 2048        res5b_branch2a[0][0]             
__________________________________________________________________________________________________
res5b_branch2a_relu (Activation (None, None, None, 5 0           bn5b_branch2a[0][0]              
__________________________________________________________________________________________________
padding5b_branch2b (ZeroPadding (None, None, None, 5 0           res5b_branch2a_relu[0][0]        
__________________________________________________________________________________________________
res5b_branch2b (Conv2D)         (None, None, None, 5 2359296     padding5b_branch2b[0][0]         
__________________________________________________________________________________________________
bn5b_branch2b (BatchNormalizati (None, None, None, 5 2048        res5b_branch2b[0][0]             
__________________________________________________________________________________________________
res5b_branch2b_relu (Activation (None, None, None, 5 0           bn5b_branch2b[0][0]              
__________________________________________________________________________________________________
res5b_branch2c (Conv2D)         (None, None, None, 2 1048576     res5b_branch2b_relu[0][0]        
__________________________________________________________________________________________________
bn5b_branch2c (BatchNormalizati (None, None, None, 2 8192        res5b_branch2c[0][0]             
__________________________________________________________________________________________________
res5b (Add)                     (None, None, None, 2 0           bn5b_branch2c[0][0]              
                                                                 res5a_relu[0][0]                 
__________________________________________________________________________________________________
res5b_relu (Activation)         (None, None, None, 2 0           res5b[0][0]                      
__________________________________________________________________________________________________
res5c_branch2a (Conv2D)         (None, None, None, 5 1048576     res5b_relu[0][0]                 
__________________________________________________________________________________________________
bn5c_branch2a (BatchNormalizati (None, None, None, 5 2048        res5c_branch2a[0][0]             
__________________________________________________________________________________________________
res5c_branch2a_relu (Activation (None, None, None, 5 0           bn5c_branch2a[0][0]              
__________________________________________________________________________________________________
padding5c_branch2b (ZeroPadding (None, None, None, 5 0           res5c_branch2a_relu[0][0]        
__________________________________________________________________________________________________
res5c_branch2b (Conv2D)         (None, None, None, 5 2359296     padding5c_branch2b[0][0]         
__________________________________________________________________________________________________
bn5c_branch2b (BatchNormalizati (None, None, None, 5 2048        res5c_branch2b[0][0]             
__________________________________________________________________________________________________
res5c_branch2b_relu (Activation (None, None, None, 5 0           bn5c_branch2b[0][0]              
__________________________________________________________________________________________________
res5c_branch2c (Conv2D)         (None, None, None, 2 1048576     res5c_branch2b_relu[0][0]        
__________________________________________________________________________________________________
bn5c_branch2c (BatchNormalizati (None, None, None, 2 8192        res5c_branch2c[0][0]             
__________________________________________________________________________________________________
res5c (Add)                     (None, None, None, 2 0           bn5c_branch2c[0][0]              
                                                                 res5b_relu[0][0]                 
__________________________________________________________________________________________________
res5c_relu (Activation)         (None, None, None, 2 0           res5c[0][0]                      
__________________________________________________________________________________________________
C5_reduced (Conv2D)             (None, None, None, 2 524544      res5c_relu[0][0]                 
__________________________________________________________________________________________________
P5_upsampled (UpsampleLike)     (None, None, None, 2 0           C5_reduced[0][0]                 
                                                                 res4f_relu[0][0]                 
__________________________________________________________________________________________________
C4_reduced (Conv2D)             (None, None, None, 2 262400      res4f_relu[0][0]                 
__________________________________________________________________________________________________
P4_merged (Add)                 (None, None, None, 2 0           P5_upsampled[0][0]               
                                                                 C4_reduced[0][0]                 
__________________________________________________________________________________________________
P4_upsampled (UpsampleLike)     (None, None, None, 2 0           P4_merged[0][0]                  
                                                                 res3d_relu[0][0]                 
__________________________________________________________________________________________________
C3_reduced (Conv2D)             (None, None, None, 2 131328      res3d_relu[0][0]                 
__________________________________________________________________________________________________
P6 (Conv2D)                     (None, None, None, 2 4718848     res5c_relu[0][0]                 
__________________________________________________________________________________________________
P3_merged (Add)                 (None, None, None, 2 0           P4_upsampled[0][0]               
                                                                 C3_reduced[0][0]                 
__________________________________________________________________________________________________
C6_relu (Activation)            (None, None, None, 2 0           P6[0][0]                         
__________________________________________________________________________________________________
P3 (Conv2D)                     (None, None, None, 2 590080      P3_merged[0][0]                  
__________________________________________________________________________________________________
P4 (Conv2D)                     (None, None, None, 2 590080      P4_merged[0][0]                  
__________________________________________________________________________________________________
P5 (Conv2D)                     (None, None, None, 2 590080      C5_reduced[0][0]                 
__________________________________________________________________________________________________
P7 (Conv2D)                     (None, None, None, 2 590080      C6_relu[0][0]                    
__________________________________________________________________________________________________
regression_submodel (Model)     (None, None, 4)      2443300     P3[0][0]                         
                                                                 P4[0][0]                         
                                                                 P5[0][0]                         
                                                                 P6[0][0]                         
                                                                 P7[0][0]                         
__________________________________________________________________________________________________
classification_submodel (Model) (None, None, 1)      2381065     P3[0][0]                         
                                                                 P4[0][0]                         
                                                                 P5[0][0]                         
                                                                 P6[0][0]                         
                                                                 P7[0][0]                         
__________________________________________________________________________________________________
regression (Concatenate)        (None, None, 4)      0           regression_submodel[1][0]        
                                                                 regression_submodel[2][0]        
                                                                 regression_submodel[3][0]        
                                                                 regression_submodel[4][0]        
                                                                 regression_submodel[5][0]        
__________________________________________________________________________________________________
classification (Concatenate)    (None, None, 1)      0           classification_submodel[1][0]    
                                                                 classification_submodel[2][0]    
                                                                 classification_submodel[3][0]    
                                                                 classification_submodel[4][0]    
                                                                 classification_submodel[5][0]    
==================================================================================================
Total params: 36,382,957
Trainable params: 36,276,717
Non-trainable params: 106,240
__________________________________________________________________________________________________
None
Epoch 1/10

   1/1000 [..............................] - ETA: 3:05:21 - loss: 3.8869 - regression_loss: 2.7570 - classification_loss: 1.1298
   2/1000 [..............................] - ETA: 1:34:53 - loss: 3.9000 - regression_loss: 2.7700 - classification_loss: 1.1300
   3/1000 [..............................] - ETA: 1:04:48 - loss: 3.8372 - regression_loss: 2.7069 - classification_loss: 1.1303
   4/1000 [..............................] - ETA: 49:43 - loss: 3.8897 - regression_loss: 2.7593 - classification_loss: 1.1304  
   5/1000 [..............................] - ETA: 40:40 - loss: 3.8537 - regression_loss: 2.7231 - classification_loss: 1.1306
   6/1000 [..............................] - ETA: 34:38 - loss: 3.8603 - regression_loss: 2.7298 - classification_loss: 1.1305
   7/1000 [..............................] - ETA: 30:19 - loss: 3.8404 - regression_loss: 2.7098 - classification_loss: 1.1306
   8/1000 [..............................] - ETA: 27:06 - loss: 3.9022 - regression_loss: 2.7717 - classification_loss: 1.1305
   9/1000 [..............................] - ETA: 24:34 - loss: 3.9294 - regression_loss: 2.7988 - classification_loss: 1.1307
  10/1000 [..............................] - ETA: 22:33 - loss: 3.9435 - regression_loss: 2.8132 - classification_loss: 1.1303
  11/1000 [..............................] - ETA: 20:55 - loss: 3.9552 - regression_loss: 2.8249 - classification_loss: 1.1303
  12/1000 [..............................] - ETA: 19:33 - loss: 3.9738 - regression_loss: 2.8437 - classification_loss: 1.1301
  13/1000 [..............................] - ETA: 18:23 - loss: 3.9668 - regression_loss: 2.8368 - classification_loss: 1.1300
  14/1000 [..............................] - ETA: 17:23 - loss: 3.9761 - regression_loss: 2.8462 - classification_loss: 1.1299
  15/1000 [..............................] - ETA: 16:32 - loss: 3.9795 - regression_loss: 2.8495 - classification_loss: 1.1300
  16/1000 [..............................] - ETA: 15:46 - loss: 3.9712 - regression_loss: 2.8411 - classification_loss: 1.1301
  17/1000 [..............................] - ETA: 15:06 - loss: 3.9610 - regression_loss: 2.8310 - classification_loss: 1.1300
  18/1000 [..............................] - ETA: 14:30 - loss: 3.9414 - regression_loss: 2.8114 - classification_loss: 1.1300
  19/1000 [..............................] - ETA: 13:58 - loss: 3.9399 - regression_loss: 2.8100 - classification_loss: 1.1300
  20/1000 [..............................] - ETA: 13:29 - loss: 3.9292 - regression_loss: 2.7993 - classification_loss: 1.1299
  21/1000 [..............................] - ETA: 13:03 - loss: 3.9157 - regression_loss: 2.7856 - classification_loss: 1.1300
  22/1000 [..............................] - ETA: 12:39 - loss: 3.9149 - regression_loss: 2.7849 - classification_loss: 1.1300
  23/1000 [..............................] - ETA: 12:17 - loss: 3.9104 - regression_loss: 2.7804 - classification_loss: 1.1300
  24/1000 [..............................] - ETA: 11:58 - loss: 3.9075 - regression_loss: 2.7776 - classification_loss: 1.1299
  25/1000 [..............................] - ETA: 11:39 - loss: 3.9174 - regression_loss: 2.7876 - classification_loss: 1.1298
  26/1000 [..............................] - ETA: 11:23 - loss: 3.9199 - regression_loss: 2.7901 - classification_loss: 1.1298
  27/1000 [..............................] - ETA: 11:07 - loss: 3.9214 - regression_loss: 2.7917 - classification_loss: 1.1297
  28/1000 [..............................] - ETA: 10:52 - loss: 3.9125 - regression_loss: 2.7828 - classification_loss: 1.1297
  29/1000 [..............................] - ETA: 10:39 - loss: 3.9218 - regression_loss: 2.7921 - classification_loss: 1.1297
  30/1000 [..............................] - ETA: 10:26 - loss: 3.9200 - regression_loss: 2.7904 - classification_loss: 1.1296
  31/1000 [..............................] - ETA: 10:14 - loss: 3.9041 - regression_loss: 2.7745 - classification_loss: 1.1296
  32/1000 [..............................] - ETA: 10:03 - loss: 3.9079 - regression_loss: 2.7783 - classification_loss: 1.1296
  33/1000 [..............................] - ETA: 9:52 - loss: 3.9084 - regression_loss: 2.7787 - classification_loss: 1.1297 
  34/1000 [>.............................] - ETA: 9:42 - loss: 3.9069 - regression_loss: 2.7773 - classification_loss: 1.1296
  35/1000 [>.............................] - ETA: 9:33 - loss: 3.9093 - regression_loss: 2.7797 - classification_loss: 1.1295
  36/1000 [>.............................] - ETA: 9:25 - loss: 3.9189 - regression_loss: 2.7895 - classification_loss: 1.1294
  37/1000 [>.............................] - ETA: 9:16 - loss: 3.9260 - regression_loss: 2.7966 - classification_loss: 1.1294
  38/1000 [>.............................] - ETA: 9:08 - loss: 3.9195 - regression_loss: 2.7901 - classification_loss: 1.1294
  39/1000 [>.............................] - ETA: 9:01 - loss: 3.9189 - regression_loss: 2.7896 - classification_loss: 1.1293
  40/1000 [>.............................] - ETA: 8:53 - loss: 3.9213 - regression_loss: 2.7921 - classification_loss: 1.1292
  41/1000 [>.............................] - ETA: 8:47 - loss: 3.9282 - regression_loss: 2.7990 - classification_loss: 1.1292
  42/1000 [>.............................] - ETA: 8:40 - loss: 3.9230 - regression_loss: 2.7938 - classification_loss: 1.1292
  43/1000 [>.............................] - ETA: 8:34 - loss: 3.9217 - regression_loss: 2.7926 - classification_loss: 1.1291
  44/1000 [>.............................] - ETA: 8:28 - loss: 3.9206 - regression_loss: 2.7916 - classification_loss: 1.1290
  45/1000 [>.............................] - ETA: 8:22 - loss: 3.9193 - regression_loss: 2.7903 - classification_loss: 1.1290
  46/1000 [>.............................] - ETA: 8:16 - loss: 3.9157 - regression_loss: 2.7867 - classification_loss: 1.1290
  47/1000 [>.............................] - ETA: 8:11 - loss: 3.9132 - regression_loss: 2.7843 - classification_loss: 1.1289
  48/1000 [>.............................] - ETA: 8:06 - loss: 3.9131 - regression_loss: 2.7842 - classification_loss: 1.1289
  49/1000 [>.............................] - ETA: 8:01 - loss: 3.9180 - regression_loss: 2.7891 - classification_loss: 1.1289
  50/1000 [>.............................] - ETA: 7:57 - loss: 3.9187 - regression_loss: 2.7900 - classification_loss: 1.1288
  51/1000 [>.............................] - ETA: 7:52 - loss: 3.9195 - regression_loss: 2.7909 - classification_loss: 1.1286
  52/1000 [>.............................] - ETA: 7:48 - loss: 3.9239 - regression_loss: 2.7952 - classification_loss: 1.1287
  53/1000 [>.............................] - ETA: 7:44 - loss: 3.9245 - regression_loss: 2.7960 - classification_loss: 1.1285
  54/1000 [>.............................] - ETA: 7:40 - loss: 3.9244 - regression_loss: 2.7960 - classification_loss: 1.1283
  55/1000 [>.............................] - ETA: 7:36 - loss: 3.9311 - regression_loss: 2.8029 - classification_loss: 1.1282
  56/1000 [>.............................] - ETA: 7:32 - loss: 3.9304 - regression_loss: 2.8024 - classification_loss: 1.1281
  57/1000 [>.............................] - ETA: 7:28 - loss: 3.9332 - regression_loss: 2.8053 - classification_loss: 1.1280
  58/1000 [>.............................] - ETA: 7:24 - loss: 3.9380 - regression_loss: 2.8101 - classification_loss: 1.1279
  59/1000 [>.............................] - ETA: 7:21 - loss: 3.9374 - regression_loss: 2.8096 - classification_loss: 1.1278
  60/1000 [>.............................] - ETA: 7:18 - loss: 3.9355 - regression_loss: 2.8079 - classification_loss: 1.1276
  61/1000 [>.............................] - ETA: 7:14 - loss: 3.9360 - regression_loss: 2.8085 - classification_loss: 1.1275
  62/1000 [>.............................] - ETA: 7:11 - loss: 3.9353 - regression_loss: 2.8079 - classification_loss: 1.1274
  63/1000 [>.............................] - ETA: 7:08 - loss: 3.9380 - regression_loss: 2.8108 - classification_loss: 1.1272
  64/1000 [>.............................] - ETA: 7:05 - loss: 3.9358 - regression_loss: 2.8090 - classification_loss: 1.1268
  65/1000 [>.............................] - ETA: 7:02 - loss: 3.9303 - regression_loss: 2.8037 - classification_loss: 1.1266
  66/1000 [>.............................] - ETA: 6:59 - loss: 3.9283 - regression_loss: 2.8018 - classification_loss: 1.1265
  67/1000 [=>............................] - ETA: 6:57 - loss: 3.9269 - regression_loss: 2.8008 - classification_loss: 1.1262
  68/1000 [=>............................] - ETA: 6:54 - loss: 3.9276 - regression_loss: 2.8017 - classification_loss: 1.1260
  69/1000 [=>............................] - ETA: 6:52 - loss: 3.9260 - regression_loss: 2.8003 - classification_loss: 1.1257
  70/1000 [=>............................] - ETA: 6:49 - loss: 3.9285 - regression_loss: 2.8030 - classification_loss: 1.1254
  71/1000 [=>............................] - ETA: 6:46 - loss: 3.9296 - regression_loss: 2.8043 - classification_loss: 1.1252
  72/1000 [=>............................] - ETA: 6:44 - loss: 3.9282 - regression_loss: 2.8032 - classification_loss: 1.1250
  73/1000 [=>............................] - ETA: 6:42 - loss: 3.9250 - regression_loss: 2.8000 - classification_loss: 1.1251
  74/1000 [=>............................] - ETA: 6:40 - loss: 3.9219 - regression_loss: 2.7972 - classification_loss: 1.1246
  75/1000 [=>............................] - ETA: 6:37 - loss: 3.9169 - regression_loss: 2.7926 - classification_loss: 1.1244
  76/1000 [=>............................] - ETA: 6:35 - loss: 3.9158 - regression_loss: 2.7918 - classification_loss: 1.1240
  77/1000 [=>............................] - ETA: 6:33 - loss: 3.9172 - regression_loss: 2.7937 - classification_loss: 1.1235
  78/1000 [=>............................] - ETA: 6:31 - loss: 3.9158 - regression_loss: 2.7927 - classification_loss: 1.1230
  79/1000 [=>............................] - ETA: 6:29 - loss: 3.9119 - regression_loss: 2.7892 - classification_loss: 1.1227
  80/1000 [=>............................] - ETA: 6:27 - loss: 3.9141 - regression_loss: 2.7918 - classification_loss: 1.1223
  81/1000 [=>............................] - ETA: 6:25 - loss: 3.9120 - regression_loss: 2.7902 - classification_loss: 1.1218
  82/1000 [=>............................] - ETA: 6:23 - loss: 3.9137 - regression_loss: 2.7924 - classification_loss: 1.1213
  83/1000 [=>............................] - ETA: 6:21 - loss: 3.9143 - regression_loss: 2.7930 - classification_loss: 1.1213
  84/1000 [=>............................] - ETA: 6:19 - loss: 3.9111 - regression_loss: 2.7904 - classification_loss: 1.1207
  85/1000 [=>............................] - ETA: 6:17 - loss: 3.9102 - regression_loss: 2.7901 - classification_loss: 1.1201
  86/1000 [=>............................] - ETA: 6:15 - loss: 3.9066 - regression_loss: 2.7871 - classification_loss: 1.1196
  87/1000 [=>............................] - ETA: 6:14 - loss: 3.9043 - regression_loss: 2.7853 - classification_loss: 1.1190
  88/1000 [=>............................] - ETA: 6:12 - loss: 3.9067 - regression_loss: 2.7881 - classification_loss: 1.1186
  89/1000 [=>............................] - ETA: 6:10 - loss: 3.9061 - regression_loss: 2.7882 - classification_loss: 1.1178
  90/1000 [=>............................] - ETA: 6:08 - loss: 3.9052 - regression_loss: 2.7880 - classification_loss: 1.1172
  91/1000 [=>............................] - ETA: 6:07 - loss: 3.9019 - regression_loss: 2.7854 - classification_loss: 1.1165
  92/1000 [=>............................] - ETA: 6:05 - loss: 3.9009 - regression_loss: 2.7856 - classification_loss: 1.1153
  93/1000 [=>............................] - ETA: 6:04 - loss: 3.9039 - regression_loss: 2.7898 - classification_loss: 1.1142
  94/1000 [=>............................] - ETA: 6:02 - loss: 3.9006 - regression_loss: 2.7872 - classification_loss: 1.1134
  95/1000 [=>............................] - ETA: 6:01 - loss: 3.9000 - regression_loss: 2.7880 - classification_loss: 1.1121
  96/1000 [=>............................] - ETA: 5:59 - loss: 3.8969 - regression_loss: 2.7864 - classification_loss: 1.1106
  97/1000 [=>............................] - ETA: 5:58 - loss: 3.8929 - regression_loss: 2.7837 - classification_loss: 1.1093
  98/1000 [=>............................] - ETA: 5:56 - loss: 3.8895 - regression_loss: 2.7819 - classification_loss: 1.1076
  99/1000 [=>............................] - ETA: 5:55 - loss: 3.8883 - regression_loss: 2.7820 - classification_loss: 1.1062
 100/1000 [==>...........................] - ETA: 5:53 - loss: 3.8860 - regression_loss: 2.7823 - classification_loss: 1.1037
 101/1000 [==>...........................] - ETA: 5:52 - loss: 3.8840 - regression_loss: 2.7820 - classification_loss: 1.1020
 102/1000 [==>...........................] - ETA: 5:51 - loss: 3.8827 - regression_loss: 2.7820 - classification_loss: 1.1007
 103/1000 [==>...........................] - ETA: 5:49 - loss: 3.8828 - regression_loss: 2.7843 - classification_loss: 1.0985
 104/1000 [==>...........................] - ETA: 5:48 - loss: 3.8814 - regression_loss: 2.7847 - classification_loss: 1.0967
 105/1000 [==>...........................] - ETA: 5:47 - loss: 3.8767 - regression_loss: 2.7820 - classification_loss: 1.0948
 106/1000 [==>...........................] - ETA: 5:46 - loss: 3.8769 - regression_loss: 2.7839 - classification_loss: 1.0930
 107/1000 [==>...........................] - ETA: 5:44 - loss: 3.8725 - regression_loss: 2.7830 - classification_loss: 1.0895
 108/1000 [==>...........................] - ETA: 5:43 - loss: 3.8687 - regression_loss: 2.7819 - classification_loss: 1.0868
 109/1000 [==>...........................] - ETA: 5:42 - loss: 3.8692 - regression_loss: 2.7854 - classification_loss: 1.0838
 110/1000 [==>...........................] - ETA: 5:41 - loss: 3.8652 - regression_loss: 2.7826 - classification_loss: 1.0826
 111/1000 [==>...........................] - ETA: 5:40 - loss: 3.8589 - regression_loss: 2.7800 - classification_loss: 1.0789
 112/1000 [==>...........................] - ETA: 5:39 - loss: 3.8561 - regression_loss: 2.7797 - classification_loss: 1.0765
 113/1000 [==>...........................] - ETA: 5:37 - loss: 3.8536 - regression_loss: 2.7781 - classification_loss: 1.0756
 114/1000 [==>...........................] - ETA: 5:36 - loss: 3.8498 - regression_loss: 2.7769 - classification_loss: 1.0729
 115/1000 [==>...........................] - ETA: 5:35 - loss: 3.8565 - regression_loss: 2.7824 - classification_loss: 1.0741
 116/1000 [==>...........................] - ETA: 5:34 - loss: 3.8537 - regression_loss: 2.7823 - classification_loss: 1.0714
 117/1000 [==>...........................] - ETA: 5:33 - loss: 3.8470 - regression_loss: 2.7789 - classification_loss: 1.0681
 118/1000 [==>...........................] - ETA: 5:32 - loss: 3.8406 - regression_loss: 2.7750 - classification_loss: 1.0657
 119/1000 [==>...........................] - ETA: 5:31 - loss: 3.8385 - regression_loss: 2.7743 - classification_loss: 1.0642
 120/1000 [==>...........................] - ETA: 5:30 - loss: 3.8361 - regression_loss: 2.7738 - classification_loss: 1.0623
 121/1000 [==>...........................] - ETA: 5:29 - loss: 3.8332 - regression_loss: 2.7724 - classification_loss: 1.0608
 122/1000 [==>...........................] - ETA: 5:28 - loss: 3.8328 - regression_loss: 2.7741 - classification_loss: 1.0587
 123/1000 [==>...........................] - ETA: 5:27 - loss: 3.8302 - regression_loss: 2.7731 - classification_loss: 1.0571
 124/1000 [==>...........................] - ETA: 5:26 - loss: 3.8281 - regression_loss: 2.7725 - classification_loss: 1.0556
 125/1000 [==>...........................] - ETA: 5:25 - loss: 3.8257 - regression_loss: 2.7715 - classification_loss: 1.0542
 126/1000 [==>...........................] - ETA: 5:24 - loss: 3.8218 - regression_loss: 2.7702 - classification_loss: 1.0516
 127/1000 [==>...........................] - ETA: 5:23 - loss: 3.8178 - regression_loss: 2.7680 - classification_loss: 1.0498
 128/1000 [==>...........................] - ETA: 5:22 - loss: 3.8125 - regression_loss: 2.7658 - classification_loss: 1.0467
 129/1000 [==>...........................] - ETA: 5:21 - loss: 3.8124 - regression_loss: 2.7668 - classification_loss: 1.0456
 130/1000 [==>...........................] - ETA: 5:20 - loss: 3.8077 - regression_loss: 2.7650 - classification_loss: 1.0428
 131/1000 [==>...........................] - ETA: 5:19 - loss: 3.8068 - regression_loss: 2.7664 - classification_loss: 1.0404
 132/1000 [==>...........................] - ETA: 5:18 - loss: 3.8046 - regression_loss: 2.7670 - classification_loss: 1.0377
 133/1000 [==>...........................] - ETA: 5:17 - loss: 3.8015 - regression_loss: 2.7662 - classification_loss: 1.0353
 134/1000 [===>..........................] - ETA: 5:16 - loss: 3.7965 - regression_loss: 2.7639 - classification_loss: 1.0326
 135/1000 [===>..........................] - ETA: 5:15 - loss: 3.7970 - regression_loss: 2.7628 - classification_loss: 1.0342
 136/1000 [===>..........................] - ETA: 5:14 - loss: 3.7968 - regression_loss: 2.7651 - classification_loss: 1.0317
 137/1000 [===>..........................] - ETA: 5:14 - loss: 3.7976 - regression_loss: 2.7656 - classification_loss: 1.0321
 138/1000 [===>..........................] - ETA: 5:13 - loss: 3.7939 - regression_loss: 2.7642 - classification_loss: 1.0296
 139/1000 [===>..........................] - ETA: 5:12 - loss: 3.7898 - regression_loss: 2.7622 - classification_loss: 1.0275
 140/1000 [===>..........................] - ETA: 5:11 - loss: 3.7867 - regression_loss: 2.7618 - classification_loss: 1.0249
 141/1000 [===>..........................] - ETA: 5:10 - loss: 3.7811 - regression_loss: 2.7585 - classification_loss: 1.0227
 142/1000 [===>..........................] - ETA: 5:10 - loss: 3.7779 - regression_loss: 2.7582 - classification_loss: 1.0197
 143/1000 [===>..........................] - ETA: 5:09 - loss: 3.7749 - regression_loss: 2.7572 - classification_loss: 1.0177
 144/1000 [===>..........................] - ETA: 5:08 - loss: 3.7720 - regression_loss: 2.7564 - classification_loss: 1.0156
 145/1000 [===>..........................] - ETA: 5:07 - loss: 3.7769 - regression_loss: 2.7588 - classification_loss: 1.0181
 146/1000 [===>..........................] - ETA: 5:06 - loss: 3.7733 - regression_loss: 2.7580 - classification_loss: 1.0152
 147/1000 [===>..........................] - ETA: 5:05 - loss: 3.7693 - regression_loss: 2.7555 - classification_loss: 1.0138
 148/1000 [===>..........................] - ETA: 5:05 - loss: 3.7701 - regression_loss: 2.7574 - classification_loss: 1.0126
 149/1000 [===>..........................] - ETA: 5:04 - loss: 3.7673 - regression_loss: 2.7570 - classification_loss: 1.0104
 150/1000 [===>..........................] - ETA: 5:03 - loss: 3.7647 - regression_loss: 2.7565 - classification_loss: 1.0082
 151/1000 [===>..........................] - ETA: 5:02 - loss: 3.7606 - regression_loss: 2.7554 - classification_loss: 1.0052
 152/1000 [===>..........................] - ETA: 5:02 - loss: 3.7553 - regression_loss: 2.7536 - classification_loss: 1.0017
 153/1000 [===>..........................] - ETA: 5:01 - loss: 3.7561 - regression_loss: 2.7549 - classification_loss: 1.0011
 154/1000 [===>..........................] - ETA: 5:00 - loss: 3.7556 - regression_loss: 2.7571 - classification_loss: 0.9985
 155/1000 [===>..........................] - ETA: 4:59 - loss: 3.7576 - regression_loss: 2.7594 - classification_loss: 0.9982
 156/1000 [===>..........................] - ETA: 4:59 - loss: 3.7572 - regression_loss: 2.7603 - classification_loss: 0.9969
 157/1000 [===>..........................] - ETA: 4:58 - loss: 3.7550 - regression_loss: 2.7593 - classification_loss: 0.9956
 158/1000 [===>..........................] - ETA: 4:57 - loss: 3.7496 - regression_loss: 2.7575 - classification_loss: 0.9922
 159/1000 [===>..........................] - ETA: 4:57 - loss: 3.7456 - regression_loss: 2.7566 - classification_loss: 0.9890
 160/1000 [===>..........................] - ETA: 4:56 - loss: 3.7438 - regression_loss: 2.7570 - classification_loss: 0.9867
 161/1000 [===>..........................] - ETA: 4:55 - loss: 3.7427 - regression_loss: 2.7569 - classification_loss: 0.9858
 162/1000 [===>..........................] - ETA: 4:54 - loss: 3.7421 - regression_loss: 2.7579 - classification_loss: 0.9842
 163/1000 [===>..........................] - ETA: 4:54 - loss: 3.7396 - regression_loss: 2.7578 - classification_loss: 0.9818
 164/1000 [===>..........................] - ETA: 4:53 - loss: 3.7340 - regression_loss: 2.7556 - classification_loss: 0.9783
 165/1000 [===>..........................] - ETA: 4:52 - loss: 3.7365 - regression_loss: 2.7586 - classification_loss: 0.9779
 166/1000 [===>..........................] - ETA: 4:52 - loss: 3.7358 - regression_loss: 2.7579 - classification_loss: 0.9779
 167/1000 [====>.........................] - ETA: 4:51 - loss: 3.7311 - regression_loss: 2.7557 - classification_loss: 0.9754
 168/1000 [====>.........................] - ETA: 4:50 - loss: 3.7290 - regression_loss: 2.7550 - classification_loss: 0.9740
 169/1000 [====>.........................] - ETA: 4:50 - loss: 3.7258 - regression_loss: 2.7545 - classification_loss: 0.9714
 170/1000 [====>.........................] - ETA: 4:49 - loss: 3.7216 - regression_loss: 2.7529 - classification_loss: 0.9687
 171/1000 [====>.........................] - ETA: 4:48 - loss: 3.7193 - regression_loss: 2.7523 - classification_loss: 0.9670
 172/1000 [====>.........................] - ETA: 4:48 - loss: 3.7159 - regression_loss: 2.7515 - classification_loss: 0.9644
 173/1000 [====>.........................] - ETA: 4:47 - loss: 3.7131 - regression_loss: 2.7508 - classification_loss: 0.9623
 174/1000 [====>.........................] - ETA: 4:46 - loss: 3.7101 - regression_loss: 2.7499 - classification_loss: 0.9602
 175/1000 [====>.........................] - ETA: 4:46 - loss: 3.7066 - regression_loss: 2.7489 - classification_loss: 0.9577
 176/1000 [====>.........................] - ETA: 4:45 - loss: 3.7064 - regression_loss: 2.7483 - classification_loss: 0.9582
 177/1000 [====>.........................] - ETA: 4:44 - loss: 3.7026 - regression_loss: 2.7473 - classification_loss: 0.9553
 178/1000 [====>.........................] - ETA: 4:44 - loss: 3.7011 - regression_loss: 2.7479 - classification_loss: 0.9532
 179/1000 [====>.........................] - ETA: 4:43 - loss: 3.6982 - regression_loss: 2.7458 - classification_loss: 0.9524
 180/1000 [====>.........................] - ETA: 4:43 - loss: 3.6948 - regression_loss: 2.7441 - classification_loss: 0.9507
 181/1000 [====>.........................] - ETA: 4:42 - loss: 3.6897 - regression_loss: 2.7422 - classification_loss: 0.9475
 182/1000 [====>.........................] - ETA: 4:41 - loss: 3.6874 - regression_loss: 2.7415 - classification_loss: 0.9459
 183/1000 [====>.........................] - ETA: 4:41 - loss: 3.6842 - regression_loss: 2.7409 - classification_loss: 0.9433
 184/1000 [====>.........................] - ETA: 4:40 - loss: 3.6823 - regression_loss: 2.7399 - classification_loss: 0.9424
 185/1000 [====>.........................] - ETA: 4:39 - loss: 3.6797 - regression_loss: 2.7397 - classification_loss: 0.9400
 186/1000 [====>.........................] - ETA: 4:39 - loss: 3.6768 - regression_loss: 2.7397 - classification_loss: 0.9372
 187/1000 [====>.........................] - ETA: 4:38 - loss: 3.6749 - regression_loss: 2.7389 - classification_loss: 0.9360
 188/1000 [====>.........................] - ETA: 4:38 - loss: 3.6729 - regression_loss: 2.7386 - classification_loss: 0.9342
 189/1000 [====>.........................] - ETA: 4:37 - loss: 3.6720 - regression_loss: 2.7381 - classification_loss: 0.9339
 190/1000 [====>.........................] - ETA: 4:37 - loss: 3.6697 - regression_loss: 2.7380 - classification_loss: 0.9317
 191/1000 [====>.........................] - ETA: 4:36 - loss: 3.6665 - regression_loss: 2.7363 - classification_loss: 0.9301
 192/1000 [====>.........................] - ETA: 4:35 - loss: 3.6657 - regression_loss: 2.7365 - classification_loss: 0.9293
 193/1000 [====>.........................] - ETA: 4:35 - loss: 3.6637 - regression_loss: 2.7360 - classification_loss: 0.9277
 194/1000 [====>.........................] - ETA: 4:34 - loss: 3.6596 - regression_loss: 2.7349 - classification_loss: 0.9247
 195/1000 [====>.........................] - ETA: 4:34 - loss: 3.6560 - regression_loss: 2.7337 - classification_loss: 0.9223
 196/1000 [====>.........................] - ETA: 4:33 - loss: 3.6522 - regression_loss: 2.7321 - classification_loss: 0.9201
 197/1000 [====>.........................] - ETA: 4:33 - loss: 3.6491 - regression_loss: 2.7309 - classification_loss: 0.9182
 198/1000 [====>.........................] - ETA: 4:32 - loss: 3.6480 - regression_loss: 2.7305 - classification_loss: 0.9176
 199/1000 [====>.........................] - ETA: 4:31 - loss: 3.6439 - regression_loss: 2.7281 - classification_loss: 0.9158
 200/1000 [=====>........................] - ETA: 4:31 - loss: 3.6396 - regression_loss: 2.7259 - classification_loss: 0.9137
 201/1000 [=====>........................] - ETA: 4:30 - loss: 3.6399 - regression_loss: 2.7278 - classification_loss: 0.9120
 202/1000 [=====>........................] - ETA: 4:30 - loss: 3.6370 - regression_loss: 2.7271 - classification_loss: 0.9099
 203/1000 [=====>........................] - ETA: 4:29 - loss: 3.6380 - regression_loss: 2.7284 - classification_loss: 0.9097
 204/1000 [=====>........................] - ETA: 4:29 - loss: 3.6348 - regression_loss: 2.7272 - classification_loss: 0.9076
 205/1000 [=====>........................] - ETA: 4:28 - loss: 3.6324 - regression_loss: 2.7262 - classification_loss: 0.9061
 206/1000 [=====>........................] - ETA: 4:28 - loss: 3.6307 - regression_loss: 2.7253 - classification_loss: 0.9054
 207/1000 [=====>........................] - ETA: 4:27 - loss: 3.6257 - regression_loss: 2.7229 - classification_loss: 0.9029
 208/1000 [=====>........................] - ETA: 4:27 - loss: 3.6254 - regression_loss: 2.7236 - classification_loss: 0.9017
 209/1000 [=====>........................] - ETA: 4:26 - loss: 3.6219 - regression_loss: 2.7222 - classification_loss: 0.8997
 210/1000 [=====>........................] - ETA: 4:26 - loss: 3.6217 - regression_loss: 2.7234 - classification_loss: 0.8983
 211/1000 [=====>........................] - ETA: 4:25 - loss: 3.6215 - regression_loss: 2.7243 - classification_loss: 0.8972
 212/1000 [=====>........................] - ETA: 4:24 - loss: 3.6183 - regression_loss: 2.7230 - classification_loss: 0.8953
 213/1000 [=====>........................] - ETA: 4:24 - loss: 3.6147 - regression_loss: 2.7213 - classification_loss: 0.8934
 214/1000 [=====>........................] - ETA: 4:23 - loss: 3.6142 - regression_loss: 2.7212 - classification_loss: 0.8930
 215/1000 [=====>........................] - ETA: 4:23 - loss: 3.6154 - regression_loss: 2.7194 - classification_loss: 0.8960
 216/1000 [=====>........................] - ETA: 4:22 - loss: 3.6151 - regression_loss: 2.7195 - classification_loss: 0.8956
 217/1000 [=====>........................] - ETA: 4:22 - loss: 3.6164 - regression_loss: 2.7204 - classification_loss: 0.8960
 218/1000 [=====>........................] - ETA: 4:21 - loss: 3.6155 - regression_loss: 2.7203 - classification_loss: 0.8953
 219/1000 [=====>........................] - ETA: 4:21 - loss: 3.6133 - regression_loss: 2.7195 - classification_loss: 0.8938
 220/1000 [=====>........................] - ETA: 4:21 - loss: 3.6121 - regression_loss: 2.7200 - classification_loss: 0.8921
 221/1000 [=====>........................] - ETA: 4:20 - loss: 3.6102 - regression_loss: 2.7187 - classification_loss: 0.8914
 222/1000 [=====>........................] - ETA: 4:19 - loss: 3.6075 - regression_loss: 2.7183 - classification_loss: 0.8892
 223/1000 [=====>........................] - ETA: 4:19 - loss: 3.6060 - regression_loss: 2.7172 - classification_loss: 0.8888
 224/1000 [=====>........................] - ETA: 4:18 - loss: 3.6052 - regression_loss: 2.7173 - classification_loss: 0.8879
 225/1000 [=====>........................] - ETA: 4:18 - loss: 3.6033 - regression_loss: 2.7168 - classification_loss: 0.8865
 226/1000 [=====>........................] - ETA: 4:18 - loss: 3.5998 - regression_loss: 2.7157 - classification_loss: 0.8841
 227/1000 [=====>........................] - ETA: 4:17 - loss: 3.5997 - regression_loss: 2.7160 - classification_loss: 0.8837
 228/1000 [=====>........................] - ETA: 4:17 - loss: 3.5988 - regression_loss: 2.7162 - classification_loss: 0.8825
 229/1000 [=====>........................] - ETA: 4:16 - loss: 3.5993 - regression_loss: 2.7173 - classification_loss: 0.8820
 230/1000 [=====>........................] - ETA: 4:16 - loss: 3.5980 - regression_loss: 2.7174 - classification_loss: 0.8806
 231/1000 [=====>........................] - ETA: 4:15 - loss: 3.5948 - regression_loss: 2.7165 - classification_loss: 0.8783
 232/1000 [=====>........................] - ETA: 4:15 - loss: 3.5941 - regression_loss: 2.7166 - classification_loss: 0.8775
 233/1000 [=====>........................] - ETA: 4:14 - loss: 3.5922 - regression_loss: 2.7163 - classification_loss: 0.8759
 234/1000 [======>.......................] - ETA: 4:14 - loss: 3.5916 - regression_loss: 2.7167 - classification_loss: 0.8749
 235/1000 [======>.......................] - ETA: 4:13 - loss: 3.5896 - regression_loss: 2.7161 - classification_loss: 0.8735
 236/1000 [======>.......................] - ETA: 4:13 - loss: 3.5902 - regression_loss: 2.7176 - classification_loss: 0.8725
 237/1000 [======>.......................] - ETA: 4:12 - loss: 3.5896 - regression_loss: 2.7175 - classification_loss: 0.8721
 238/1000 [======>.......................] - ETA: 4:12 - loss: 3.5899 - regression_loss: 2.7189 - classification_loss: 0.8710
 239/1000 [======>.......................] - ETA: 4:11 - loss: 3.5988 - regression_loss: 2.7267 - classification_loss: 0.8722
 240/1000 [======>.......................] - ETA: 4:11 - loss: 3.5962 - regression_loss: 2.7256 - classification_loss: 0.8706
 241/1000 [======>.......................] - ETA: 4:10 - loss: 3.5954 - regression_loss: 2.7259 - classification_loss: 0.8695
 242/1000 [======>.......................] - ETA: 4:10 - loss: 3.5942 - regression_loss: 2.7254 - classification_loss: 0.8688
 243/1000 [======>.......................] - ETA: 4:09 - loss: 3.5924 - regression_loss: 2.7253 - classification_loss: 0.8672
 244/1000 [======>.......................] - ETA: 4:09 - loss: 3.5916 - regression_loss: 2.7246 - classification_loss: 0.8670
 245/1000 [======>.......................] - ETA: 4:08 - loss: 3.5899 - regression_loss: 2.7242 - classification_loss: 0.8657
 246/1000 [======>.......................] - ETA: 4:08 - loss: 3.5889 - regression_loss: 2.7244 - classification_loss: 0.8645
 247/1000 [======>.......................] - ETA: 4:08 - loss: 3.5881 - regression_loss: 2.7248 - classification_loss: 0.8632
 248/1000 [======>.......................] - ETA: 4:07 - loss: 3.5876 - regression_loss: 2.7256 - classification_loss: 0.8620
 249/1000 [======>.......................] - ETA: 4:07 - loss: 3.5854 - regression_loss: 2.7246 - classification_loss: 0.8608
 250/1000 [======>.......................] - ETA: 4:06 - loss: 3.5851 - regression_loss: 2.7246 - classification_loss: 0.8605
 251/1000 [======>.......................] - ETA: 4:06 - loss: 3.5823 - regression_loss: 2.7235 - classification_loss: 0.8588
 252/1000 [======>.......................] - ETA: 4:05 - loss: 3.5831 - regression_loss: 2.7251 - classification_loss: 0.8580
 253/1000 [======>.......................] - ETA: 4:05 - loss: 3.5810 - regression_loss: 2.7241 - classification_loss: 0.8570
 254/1000 [======>.......................] - ETA: 4:04 - loss: 3.5783 - regression_loss: 2.7230 - classification_loss: 0.8552
 255/1000 [======>.......................] - ETA: 4:04 - loss: 3.5757 - regression_loss: 2.7219 - classification_loss: 0.8538
 256/1000 [======>.......................] - ETA: 4:03 - loss: 3.5770 - regression_loss: 2.7226 - classification_loss: 0.8544
 257/1000 [======>.......................] - ETA: 4:03 - loss: 3.5743 - regression_loss: 2.7213 - classification_loss: 0.8530
 258/1000 [======>.......................] - ETA: 4:02 - loss: 3.5733 - regression_loss: 2.7212 - classification_loss: 0.8522
 259/1000 [======>.......................] - ETA: 4:02 - loss: 3.5735 - regression_loss: 2.7213 - classification_loss: 0.8521
 260/1000 [======>.......................] - ETA: 4:02 - loss: 3.5730 - regression_loss: 2.7218 - classification_loss: 0.8512
 261/1000 [======>.......................] - ETA: 4:01 - loss: 3.5718 - regression_loss: 2.7216 - classification_loss: 0.8503
 262/1000 [======>.......................] - ETA: 4:01 - loss: 3.5703 - regression_loss: 2.7212 - classification_loss: 0.8492
 263/1000 [======>.......................] - ETA: 4:00 - loss: 3.5674 - regression_loss: 2.7204 - classification_loss: 0.8470
 264/1000 [======>.......................] - ETA: 4:00 - loss: 3.5665 - regression_loss: 2.7208 - classification_loss: 0.8457
 265/1000 [======>.......................] - ETA: 3:59 - loss: 3.5659 - regression_loss: 2.7209 - classification_loss: 0.8451
 266/1000 [======>.......................] - ETA: 3:59 - loss: 3.5629 - regression_loss: 2.7196 - classification_loss: 0.8433
 267/1000 [=======>......................] - ETA: 3:58 - loss: 3.5609 - regression_loss: 2.7190 - classification_loss: 0.8419
 268/1000 [=======>......................] - ETA: 3:58 - loss: 3.5598 - regression_loss: 2.7187 - classification_loss: 0.8411
 269/1000 [=======>......................] - ETA: 3:58 - loss: 3.5560 - regression_loss: 2.7167 - classification_loss: 0.8393
 270/1000 [=======>......................] - ETA: 3:57 - loss: 3.5585 - regression_loss: 2.7180 - classification_loss: 0.8405
 271/1000 [=======>......................] - ETA: 3:57 - loss: 3.5553 - regression_loss: 2.7167 - classification_loss: 0.8385
 272/1000 [=======>......................] - ETA: 3:56 - loss: 3.5549 - regression_loss: 2.7173 - classification_loss: 0.8376
 273/1000 [=======>......................] - ETA: 3:56 - loss: 3.5537 - regression_loss: 2.7169 - classification_loss: 0.8369
 274/1000 [=======>......................] - ETA: 3:55 - loss: 3.5517 - regression_loss: 2.7161 - classification_loss: 0.8355
 275/1000 [=======>......................] - ETA: 3:55 - loss: 3.5497 - regression_loss: 2.7153 - classification_loss: 0.8344
 276/1000 [=======>......................] - ETA: 3:55 - loss: 3.5484 - regression_loss: 2.7148 - classification_loss: 0.8336
 277/1000 [=======>......................] - ETA: 3:54 - loss: 3.5484 - regression_loss: 2.7152 - classification_loss: 0.8332
 278/1000 [=======>......................] - ETA: 3:54 - loss: 3.5478 - regression_loss: 2.7155 - classification_loss: 0.8323
 279/1000 [=======>......................] - ETA: 3:53 - loss: 3.5454 - regression_loss: 2.7141 - classification_loss: 0.8313
 280/1000 [=======>......................] - ETA: 3:53 - loss: 3.5457 - regression_loss: 2.7152 - classification_loss: 0.8305
 281/1000 [=======>......................] - ETA: 3:52 - loss: 3.5494 - regression_loss: 2.7196 - classification_loss: 0.8298
 282/1000 [=======>......................] - ETA: 3:52 - loss: 3.5479 - regression_loss: 2.7193 - classification_loss: 0.8286
 283/1000 [=======>......................] - ETA: 3:52 - loss: 3.5460 - regression_loss: 2.7184 - classification_loss: 0.8276
 284/1000 [=======>......................] - ETA: 3:51 - loss: 3.5434 - regression_loss: 2.7171 - classification_loss: 0.8262
 285/1000 [=======>......................] - ETA: 3:51 - loss: 3.5420 - regression_loss: 2.7171 - classification_loss: 0.8250
 286/1000 [=======>......................] - ETA: 3:50 - loss: 3.5407 - regression_loss: 2.7166 - classification_loss: 0.8241
 287/1000 [=======>......................] - ETA: 3:50 - loss: 3.5378 - regression_loss: 2.7154 - classification_loss: 0.8223
 288/1000 [=======>......................] - ETA: 3:49 - loss: 3.5371 - regression_loss: 2.7152 - classification_loss: 0.8219
 289/1000 [=======>......................] - ETA: 3:49 - loss: 3.5385 - regression_loss: 2.7155 - classification_loss: 0.8231
 290/1000 [=======>......................] - ETA: 3:49 - loss: 3.5347 - regression_loss: 2.7134 - classification_loss: 0.8213
 291/1000 [=======>......................] - ETA: 3:48 - loss: 3.5322 - regression_loss: 2.7124 - classification_loss: 0.8198
 292/1000 [=======>......................] - ETA: 3:48 - loss: 3.5307 - regression_loss: 2.7119 - classification_loss: 0.8187
 293/1000 [=======>......................] - ETA: 3:47 - loss: 3.5284 - regression_loss: 2.7111 - classification_loss: 0.8174
 294/1000 [=======>......................] - ETA: 3:47 - loss: 3.5257 - regression_loss: 2.7098 - classification_loss: 0.8160
 295/1000 [=======>......................] - ETA: 3:46 - loss: 3.5233 - regression_loss: 2.7092 - classification_loss: 0.8142
 296/1000 [=======>......................] - ETA: 3:46 - loss: 3.5258 - regression_loss: 2.7113 - classification_loss: 0.8145
 297/1000 [=======>......................] - ETA: 3:46 - loss: 3.5274 - regression_loss: 2.7133 - classification_loss: 0.8141
 298/1000 [=======>......................] - ETA: 3:45 - loss: 3.5250 - regression_loss: 2.7123 - classification_loss: 0.8127
 299/1000 [=======>......................] - ETA: 3:45 - loss: 3.5241 - regression_loss: 2.7120 - classification_loss: 0.8122
 300/1000 [========>.....................] - ETA: 3:44 - loss: 3.5231 - regression_loss: 2.7120 - classification_loss: 0.8111
 301/1000 [========>.....................] - ETA: 3:44 - loss: 3.5199 - regression_loss: 2.7107 - classification_loss: 0.8092
 302/1000 [========>.....................] - ETA: 3:44 - loss: 3.5174 - regression_loss: 2.7098 - classification_loss: 0.8076
 303/1000 [========>.....................] - ETA: 3:43 - loss: 3.5168 - regression_loss: 2.7097 - classification_loss: 0.8071
 304/1000 [========>.....................] - ETA: 3:43 - loss: 3.5157 - regression_loss: 2.7090 - classification_loss: 0.8067
 305/1000 [========>.....................] - ETA: 3:42 - loss: 3.5179 - regression_loss: 2.7094 - classification_loss: 0.8085
 306/1000 [========>.....................] - ETA: 3:42 - loss: 3.5185 - regression_loss: 2.7088 - classification_loss: 0.8097
 307/1000 [========>.....................] - ETA: 3:42 - loss: 3.5192 - regression_loss: 2.7085 - classification_loss: 0.8107
 308/1000 [========>.....................] - ETA: 3:41 - loss: 3.5174 - regression_loss: 2.7080 - classification_loss: 0.8094
 309/1000 [========>.....................] - ETA: 3:41 - loss: 3.5149 - regression_loss: 2.7070 - classification_loss: 0.8079
 310/1000 [========>.....................] - ETA: 3:40 - loss: 3.5132 - regression_loss: 2.7063 - classification_loss: 0.8069
 311/1000 [========>.....................] - ETA: 3:40 - loss: 3.5127 - regression_loss: 2.7058 - classification_loss: 0.8069
 312/1000 [========>.....................] - ETA: 3:40 - loss: 3.5128 - regression_loss: 2.7064 - classification_loss: 0.8064
 313/1000 [========>.....................] - ETA: 3:39 - loss: 3.5122 - regression_loss: 2.7059 - classification_loss: 0.8063
 314/1000 [========>.....................] - ETA: 3:39 - loss: 3.5089 - regression_loss: 2.7041 - classification_loss: 0.8048
 315/1000 [========>.....................] - ETA: 3:38 - loss: 3.5073 - regression_loss: 2.7041 - classification_loss: 0.8032
 316/1000 [========>.....................] - ETA: 3:38 - loss: 3.5072 - regression_loss: 2.7046 - classification_loss: 0.8026
 317/1000 [========>.....................] - ETA: 3:38 - loss: 3.5050 - regression_loss: 2.7038 - classification_loss: 0.8011
 318/1000 [========>.....................] - ETA: 3:37 - loss: 3.5061 - regression_loss: 2.7048 - classification_loss: 0.8013
 319/1000 [========>.....................] - ETA: 3:37 - loss: 3.5046 - regression_loss: 2.7045 - classification_loss: 0.8001
 320/1000 [========>.....................] - ETA: 3:36 - loss: 3.5020 - regression_loss: 2.7029 - classification_loss: 0.7991
 321/1000 [========>.....................] - ETA: 3:36 - loss: 3.5003 - regression_loss: 2.7023 - classification_loss: 0.7980
 322/1000 [========>.....................] - ETA: 3:36 - loss: 3.5020 - regression_loss: 2.7041 - classification_loss: 0.7980
 323/1000 [========>.....................] - ETA: 3:35 - loss: 3.4991 - regression_loss: 2.7026 - classification_loss: 0.7964
 324/1000 [========>.....................] - ETA: 3:35 - loss: 3.5037 - regression_loss: 2.7070 - classification_loss: 0.7967
 325/1000 [========>.....................] - ETA: 3:34 - loss: 3.5031 - regression_loss: 2.7070 - classification_loss: 0.7961
 326/1000 [========>.....................] - ETA: 3:34 - loss: 3.5015 - regression_loss: 2.7055 - classification_loss: 0.7960
 327/1000 [========>.....................] - ETA: 3:34 - loss: 3.5023 - regression_loss: 2.7063 - classification_loss: 0.7960
 328/1000 [========>.....................] - ETA: 3:33 - loss: 3.5011 - regression_loss: 2.7060 - classification_loss: 0.7951
 329/1000 [========>.....................] - ETA: 3:33 - loss: 3.4991 - regression_loss: 2.7052 - classification_loss: 0.7939
 330/1000 [========>.....................] - ETA: 3:33 - loss: 3.4979 - regression_loss: 2.7045 - classification_loss: 0.7934
 331/1000 [========>.....................] - ETA: 3:32 - loss: 3.4964 - regression_loss: 2.7039 - classification_loss: 0.7925
 332/1000 [========>.....................] - ETA: 3:32 - loss: 3.4952 - regression_loss: 2.7035 - classification_loss: 0.7917
 333/1000 [========>.....................] - ETA: 3:32 - loss: 3.4933 - regression_loss: 2.7021 - classification_loss: 0.7912
 334/1000 [=========>....................] - ETA: 3:31 - loss: 3.4940 - regression_loss: 2.7023 - classification_loss: 0.7917
 335/1000 [=========>....................] - ETA: 3:31 - loss: 3.4924 - regression_loss: 2.7019 - classification_loss: 0.7905
 336/1000 [=========>....................] - ETA: 3:30 - loss: 3.4896 - regression_loss: 2.7006 - classification_loss: 0.7890
 337/1000 [=========>....................] - ETA: 3:30 - loss: 3.4884 - regression_loss: 2.7003 - classification_loss: 0.7881
 338/1000 [=========>....................] - ETA: 3:30 - loss: 3.4874 - regression_loss: 2.6998 - classification_loss: 0.7876
 339/1000 [=========>....................] - ETA: 3:29 - loss: 3.4847 - regression_loss: 2.6986 - classification_loss: 0.7862
 340/1000 [=========>....................] - ETA: 3:29 - loss: 3.4834 - regression_loss: 2.6981 - classification_loss: 0.7854
 341/1000 [=========>....................] - ETA: 3:29 - loss: 3.4851 - regression_loss: 2.7001 - classification_loss: 0.7850
 342/1000 [=========>....................] - ETA: 3:28 - loss: 3.4830 - regression_loss: 2.6996 - classification_loss: 0.7834
 343/1000 [=========>....................] - ETA: 3:28 - loss: 3.4813 - regression_loss: 2.6989 - classification_loss: 0.7824
 344/1000 [=========>....................] - ETA: 3:27 - loss: 3.4784 - regression_loss: 2.6977 - classification_loss: 0.7807
 345/1000 [=========>....................] - ETA: 3:27 - loss: 3.4780 - regression_loss: 2.6986 - classification_loss: 0.7794
 346/1000 [=========>....................] - ETA: 3:27 - loss: 3.4759 - regression_loss: 2.6980 - classification_loss: 0.7779
 347/1000 [=========>....................] - ETA: 3:26 - loss: 3.4752 - regression_loss: 2.6976 - classification_loss: 0.7776
 348/1000 [=========>....................] - ETA: 3:26 - loss: 3.4727 - regression_loss: 2.6965 - classification_loss: 0.7762
 349/1000 [=========>....................] - ETA: 3:26 - loss: 3.4699 - regression_loss: 2.6952 - classification_loss: 0.7747
 350/1000 [=========>....................] - ETA: 3:25 - loss: 3.4685 - regression_loss: 2.6943 - classification_loss: 0.7742
 351/1000 [=========>....................] - ETA: 3:25 - loss: 3.4684 - regression_loss: 2.6944 - classification_loss: 0.7740
 352/1000 [=========>....................] - ETA: 3:24 - loss: 3.4680 - regression_loss: 2.6943 - classification_loss: 0.7737
 353/1000 [=========>....................] - ETA: 3:24 - loss: 3.4666 - regression_loss: 2.6931 - classification_loss: 0.7735
 354/1000 [=========>....................] - ETA: 3:24 - loss: 3.4634 - regression_loss: 2.6913 - classification_loss: 0.7720
 355/1000 [=========>....................] - ETA: 3:23 - loss: 3.4624 - regression_loss: 2.6905 - classification_loss: 0.7719
 356/1000 [=========>....................] - ETA: 3:23 - loss: 3.4652 - regression_loss: 2.6926 - classification_loss: 0.7726
 357/1000 [=========>....................] - ETA: 3:23 - loss: 3.4637 - regression_loss: 2.6923 - classification_loss: 0.7714
 358/1000 [=========>....................] - ETA: 3:22 - loss: 3.4623 - regression_loss: 2.6920 - classification_loss: 0.7703
 359/1000 [=========>....................] - ETA: 3:22 - loss: 3.4602 - regression_loss: 2.6912 - classification_loss: 0.7690
 360/1000 [=========>....................] - ETA: 3:21 - loss: 3.4567 - regression_loss: 2.6892 - classification_loss: 0.7675
 361/1000 [=========>....................] - ETA: 3:21 - loss: 3.4537 - regression_loss: 2.6874 - classification_loss: 0.7663
 362/1000 [=========>....................] - ETA: 3:21 - loss: 3.4519 - regression_loss: 2.6868 - classification_loss: 0.7651
 363/1000 [=========>....................] - ETA: 3:20 - loss: 3.4507 - regression_loss: 2.6858 - classification_loss: 0.7648
 364/1000 [=========>....................] - ETA: 3:20 - loss: 3.4470 - regression_loss: 2.6834 - classification_loss: 0.7636
 365/1000 [=========>....................] - ETA: 3:20 - loss: 3.4467 - regression_loss: 2.6835 - classification_loss: 0.7631
 366/1000 [=========>....................] - ETA: 3:19 - loss: 3.4442 - regression_loss: 2.6822 - classification_loss: 0.7620
 367/1000 [==========>...................] - ETA: 3:19 - loss: 3.4424 - regression_loss: 2.6811 - classification_loss: 0.7613
 368/1000 [==========>...................] - ETA: 3:19 - loss: 3.4433 - regression_loss: 2.6821 - classification_loss: 0.7612
 369/1000 [==========>...................] - ETA: 3:18 - loss: 3.4419 - regression_loss: 2.6817 - classification_loss: 0.7602
 370/1000 [==========>...................] - ETA: 3:18 - loss: 3.4400 - regression_loss: 2.6808 - classification_loss: 0.7592
 371/1000 [==========>...................] - ETA: 3:17 - loss: 3.4396 - regression_loss: 2.6805 - classification_loss: 0.7591
 372/1000 [==========>...................] - ETA: 3:17 - loss: 3.4402 - regression_loss: 2.6817 - classification_loss: 0.7585
 373/1000 [==========>...................] - ETA: 3:17 - loss: 3.4393 - regression_loss: 2.6812 - classification_loss: 0.7581
 374/1000 [==========>...................] - ETA: 3:16 - loss: 3.4413 - regression_loss: 2.6829 - classification_loss: 0.7584
 375/1000 [==========>...................] - ETA: 3:16 - loss: 3.4382 - regression_loss: 2.6809 - classification_loss: 0.7573
 376/1000 [==========>...................] - ETA: 3:16 - loss: 3.4353 - regression_loss: 2.6793 - classification_loss: 0.7561
 377/1000 [==========>...................] - ETA: 3:15 - loss: 3.4325 - regression_loss: 2.6772 - classification_loss: 0.7553
 378/1000 [==========>...................] - ETA: 3:15 - loss: 3.4313 - regression_loss: 2.6768 - classification_loss: 0.7545
 379/1000 [==========>...................] - ETA: 3:15 - loss: 3.4329 - regression_loss: 2.6772 - classification_loss: 0.7556
 380/1000 [==========>...................] - ETA: 3:14 - loss: 3.4309 - regression_loss: 2.6763 - classification_loss: 0.7546
 381/1000 [==========>...................] - ETA: 3:14 - loss: 3.4293 - regression_loss: 2.6755 - classification_loss: 0.7538
 382/1000 [==========>...................] - ETA: 3:14 - loss: 3.4267 - regression_loss: 2.6736 - classification_loss: 0.7531
 383/1000 [==========>...................] - ETA: 3:13 - loss: 3.4264 - regression_loss: 2.6734 - classification_loss: 0.7530
 384/1000 [==========>...................] - ETA: 3:13 - loss: 3.4235 - regression_loss: 2.6715 - classification_loss: 0.7520
 385/1000 [==========>...................] - ETA: 3:12 - loss: 3.4239 - regression_loss: 2.6720 - classification_loss: 0.7520
 386/1000 [==========>...................] - ETA: 3:12 - loss: 3.4229 - regression_loss: 2.6719 - classification_loss: 0.7510
 387/1000 [==========>...................] - ETA: 3:12 - loss: 3.4211 - regression_loss: 2.6710 - classification_loss: 0.7500
 388/1000 [==========>...................] - ETA: 3:11 - loss: 3.4201 - regression_loss: 2.6703 - classification_loss: 0.7498
 389/1000 [==========>...................] - ETA: 3:11 - loss: 3.4181 - regression_loss: 2.6693 - classification_loss: 0.7488
 390/1000 [==========>...................] - ETA: 3:11 - loss: 3.4181 - regression_loss: 2.6692 - classification_loss: 0.7489
 391/1000 [==========>...................] - ETA: 3:10 - loss: 3.4167 - regression_loss: 2.6688 - classification_loss: 0.7479
 392/1000 [==========>...................] - ETA: 3:10 - loss: 3.4157 - regression_loss: 2.6682 - classification_loss: 0.7475
 393/1000 [==========>...................] - ETA: 3:10 - loss: 3.4120 - regression_loss: 2.6657 - classification_loss: 0.7463
 394/1000 [==========>...................] - ETA: 3:09 - loss: 3.4101 - regression_loss: 2.6646 - classification_loss: 0.7455
 395/1000 [==========>...................] - ETA: 3:09 - loss: 3.4084 - regression_loss: 2.6640 - classification_loss: 0.7444
 396/1000 [==========>...................] - ETA: 3:08 - loss: 3.4076 - regression_loss: 2.6631 - classification_loss: 0.7446
 397/1000 [==========>...................] - ETA: 3:08 - loss: 3.4071 - regression_loss: 2.6629 - classification_loss: 0.7442
 398/1000 [==========>...................] - ETA: 3:08 - loss: 3.4050 - regression_loss: 2.6617 - classification_loss: 0.7433
 399/1000 [==========>...................] - ETA: 3:07 - loss: 3.4037 - regression_loss: 2.6610 - classification_loss: 0.7426
 400/1000 [===========>..................] - ETA: 3:07 - loss: 3.4027 - regression_loss: 2.6610 - classification_loss: 0.7417
 401/1000 [===========>..................] - ETA: 3:07 - loss: 3.4011 - regression_loss: 2.6600 - classification_loss: 0.7411
 402/1000 [===========>..................] - ETA: 3:06 - loss: 3.4025 - regression_loss: 2.6600 - classification_loss: 0.7425
 403/1000 [===========>..................] - ETA: 3:06 - loss: 3.4005 - regression_loss: 2.6588 - classification_loss: 0.7417
 404/1000 [===========>..................] - ETA: 3:06 - loss: 3.3995 - regression_loss: 2.6585 - classification_loss: 0.7410
 405/1000 [===========>..................] - ETA: 3:05 - loss: 3.3975 - regression_loss: 2.6572 - classification_loss: 0.7402
 406/1000 [===========>..................] - ETA: 3:05 - loss: 3.3941 - regression_loss: 2.6551 - classification_loss: 0.7390
 407/1000 [===========>..................] - ETA: 3:05 - loss: 3.3926 - regression_loss: 2.6539 - classification_loss: 0.7388
 408/1000 [===========>..................] - ETA: 3:04 - loss: 3.3929 - regression_loss: 2.6550 - classification_loss: 0.7378
 409/1000 [===========>..................] - ETA: 3:04 - loss: 3.3910 - regression_loss: 2.6537 - classification_loss: 0.7373
 410/1000 [===========>..................] - ETA: 3:04 - loss: 3.3900 - regression_loss: 2.6530 - classification_loss: 0.7369
 411/1000 [===========>..................] - ETA: 3:03 - loss: 3.3875 - regression_loss: 2.6514 - classification_loss: 0.7361
 412/1000 [===========>..................] - ETA: 3:03 - loss: 3.3844 - regression_loss: 2.6493 - classification_loss: 0.7351
 413/1000 [===========>..................] - ETA: 3:03 - loss: 3.3822 - regression_loss: 2.6480 - classification_loss: 0.7342
 414/1000 [===========>..................] - ETA: 3:02 - loss: 3.3828 - regression_loss: 2.6490 - classification_loss: 0.7338
 415/1000 [===========>..................] - ETA: 3:02 - loss: 3.3810 - regression_loss: 2.6479 - classification_loss: 0.7331
 416/1000 [===========>..................] - ETA: 3:01 - loss: 3.3804 - regression_loss: 2.6476 - classification_loss: 0.7327
 417/1000 [===========>..................] - ETA: 3:01 - loss: 3.3787 - regression_loss: 2.6465 - classification_loss: 0.7322
 418/1000 [===========>..................] - ETA: 3:01 - loss: 3.3770 - regression_loss: 2.6454 - classification_loss: 0.7316
 419/1000 [===========>..................] - ETA: 3:00 - loss: 3.3745 - regression_loss: 2.6438 - classification_loss: 0.7306
 420/1000 [===========>..................] - ETA: 3:00 - loss: 3.3759 - regression_loss: 2.6452 - classification_loss: 0.7307
 421/1000 [===========>..................] - ETA: 3:00 - loss: 3.3742 - regression_loss: 2.6438 - classification_loss: 0.7304
 422/1000 [===========>..................] - ETA: 2:59 - loss: 3.3721 - regression_loss: 2.6423 - classification_loss: 0.7298
 423/1000 [===========>..................] - ETA: 2:59 - loss: 3.3695 - regression_loss: 2.6402 - classification_loss: 0.7293
 424/1000 [===========>..................] - ETA: 2:59 - loss: 3.3695 - regression_loss: 2.6407 - classification_loss: 0.7288
 425/1000 [===========>..................] - ETA: 2:58 - loss: 3.3671 - regression_loss: 2.6390 - classification_loss: 0.7281
 426/1000 [===========>..................] - ETA: 2:58 - loss: 3.3659 - regression_loss: 2.6386 - classification_loss: 0.7273
 427/1000 [===========>..................] - ETA: 2:58 - loss: 3.3666 - regression_loss: 2.6392 - classification_loss: 0.7274
 428/1000 [===========>..................] - ETA: 2:57 - loss: 3.3642 - regression_loss: 2.6376 - classification_loss: 0.7266
 429/1000 [===========>..................] - ETA: 2:57 - loss: 3.3650 - regression_loss: 2.6389 - classification_loss: 0.7261
 430/1000 [===========>..................] - ETA: 2:57 - loss: 3.3631 - regression_loss: 2.6378 - classification_loss: 0.7253
 431/1000 [===========>..................] - ETA: 2:56 - loss: 3.3614 - regression_loss: 2.6369 - classification_loss: 0.7246
 432/1000 [===========>..................] - ETA: 2:56 - loss: 3.3599 - regression_loss: 2.6360 - classification_loss: 0.7239
 433/1000 [===========>..................] - ETA: 2:56 - loss: 3.3621 - regression_loss: 2.6380 - classification_loss: 0.7241
 434/1000 [============>.................] - ETA: 2:55 - loss: 3.3603 - regression_loss: 2.6366 - classification_loss: 0.7236
 435/1000 [============>.................] - ETA: 2:55 - loss: 3.3606 - regression_loss: 2.6368 - classification_loss: 0.7238
 436/1000 [============>.................] - ETA: 2:55 - loss: 3.3585 - regression_loss: 2.6354 - classification_loss: 0.7231
 437/1000 [============>.................] - ETA: 2:54 - loss: 3.3585 - regression_loss: 2.6360 - classification_loss: 0.7225
 438/1000 [============>.................] - ETA: 2:54 - loss: 3.3583 - regression_loss: 2.6361 - classification_loss: 0.7222
 439/1000 [============>.................] - ETA: 2:54 - loss: 3.3574 - regression_loss: 2.6355 - classification_loss: 0.7218
 440/1000 [============>.................] - ETA: 2:53 - loss: 3.3539 - regression_loss: 2.6332 - classification_loss: 0.7207
 441/1000 [============>.................] - ETA: 2:53 - loss: 3.3522 - regression_loss: 2.6321 - classification_loss: 0.7201
 442/1000 [============>.................] - ETA: 2:53 - loss: 3.3488 - regression_loss: 2.6298 - classification_loss: 0.7190
 443/1000 [============>.................] - ETA: 2:52 - loss: 3.3469 - regression_loss: 2.6285 - classification_loss: 0.7184
 444/1000 [============>.................] - ETA: 2:52 - loss: 3.3467 - regression_loss: 2.6289 - classification_loss: 0.7178
 445/1000 [============>.................] - ETA: 2:51 - loss: 3.3465 - regression_loss: 2.6291 - classification_loss: 0.7174
 446/1000 [============>.................] - ETA: 2:51 - loss: 3.3446 - regression_loss: 2.6280 - classification_loss: 0.7166
 447/1000 [============>.................] - ETA: 2:51 - loss: 3.3422 - regression_loss: 2.6263 - classification_loss: 0.7159
 448/1000 [============>.................] - ETA: 2:50 - loss: 3.3406 - regression_loss: 2.6249 - classification_loss: 0.7156
 449/1000 [============>.................] - ETA: 2:50 - loss: 3.3384 - regression_loss: 2.6237 - classification_loss: 0.7146
 450/1000 [============>.................] - ETA: 2:50 - loss: 3.3362 - regression_loss: 2.6226 - classification_loss: 0.7136
 451/1000 [============>.................] - ETA: 2:49 - loss: 3.3347 - regression_loss: 2.6220 - classification_loss: 0.7126
 452/1000 [============>.................] - ETA: 2:49 - loss: 3.3338 - regression_loss: 2.6215 - classification_loss: 0.7124
 453/1000 [============>.................] - ETA: 2:49 - loss: 3.3337 - regression_loss: 2.6215 - classification_loss: 0.7122
 454/1000 [============>.................] - ETA: 2:48 - loss: 3.3331 - regression_loss: 2.6214 - classification_loss: 0.7117
 455/1000 [============>.................] - ETA: 2:48 - loss: 3.3324 - regression_loss: 2.6208 - classification_loss: 0.7116
 456/1000 [============>.................] - ETA: 2:48 - loss: 3.3316 - regression_loss: 2.6203 - classification_loss: 0.7112
 457/1000 [============>.................] - ETA: 2:47 - loss: 3.3284 - regression_loss: 2.6181 - classification_loss: 0.7103
 458/1000 [============>.................] - ETA: 2:47 - loss: 3.3286 - regression_loss: 2.6185 - classification_loss: 0.7101
 459/1000 [============>.................] - ETA: 2:47 - loss: 3.3270 - regression_loss: 2.6173 - classification_loss: 0.7097
 460/1000 [============>.................] - ETA: 2:46 - loss: 3.3256 - regression_loss: 2.6169 - classification_loss: 0.7087
 461/1000 [============>.................] - ETA: 2:46 - loss: 3.3233 - regression_loss: 2.6151 - classification_loss: 0.7082
 462/1000 [============>.................] - ETA: 2:46 - loss: 3.3205 - regression_loss: 2.6132 - classification_loss: 0.7074
 463/1000 [============>.................] - ETA: 2:45 - loss: 3.3140 - regression_loss: 2.6075 - classification_loss: 0.7064
 464/1000 [============>.................] - ETA: 2:45 - loss: 3.3128 - regression_loss: 2.6068 - classification_loss: 0.7060
 465/1000 [============>.................] - ETA: 2:45 - loss: 3.3117 - regression_loss: 2.6061 - classification_loss: 0.7055
 466/1000 [============>.................] - ETA: 2:44 - loss: 3.3116 - regression_loss: 2.6060 - classification_loss: 0.7055
 467/1000 [=============>................] - ETA: 2:44 - loss: 3.3091 - regression_loss: 2.6042 - classification_loss: 0.7049
 468/1000 [=============>................] - ETA: 2:44 - loss: 3.3084 - regression_loss: 2.6039 - classification_loss: 0.7044
 469/1000 [=============>................] - ETA: 2:43 - loss: 3.3059 - regression_loss: 2.6022 - classification_loss: 0.7037
 470/1000 [=============>................] - ETA: 2:43 - loss: 3.3057 - regression_loss: 2.6018 - classification_loss: 0.7039
 471/1000 [=============>................] - ETA: 2:43 - loss: 3.3036 - regression_loss: 2.6004 - classification_loss: 0.7032
 472/1000 [=============>................] - ETA: 2:42 - loss: 3.3015 - regression_loss: 2.5990 - classification_loss: 0.7025
 473/1000 [=============>................] - ETA: 2:42 - loss: 3.2979 - regression_loss: 2.5964 - classification_loss: 0.7015
 474/1000 [=============>................] - ETA: 2:42 - loss: 3.2946 - regression_loss: 2.5941 - classification_loss: 0.7005
 475/1000 [=============>................] - ETA: 2:41 - loss: 3.2932 - regression_loss: 2.5933 - classification_loss: 0.6999
 476/1000 [=============>................] - ETA: 2:41 - loss: 3.2911 - regression_loss: 2.5918 - classification_loss: 0.6993
 477/1000 [=============>................] - ETA: 2:41 - loss: 3.2924 - regression_loss: 2.5931 - classification_loss: 0.6994
 478/1000 [=============>................] - ETA: 2:40 - loss: 3.2926 - regression_loss: 2.5929 - classification_loss: 0.6996
 479/1000 [=============>................] - ETA: 2:40 - loss: 3.2897 - regression_loss: 2.5902 - classification_loss: 0.6995
 480/1000 [=============>................] - ETA: 2:40 - loss: 3.2880 - regression_loss: 2.5888 - classification_loss: 0.6992
 481/1000 [=============>................] - ETA: 2:39 - loss: 3.2875 - regression_loss: 2.5882 - classification_loss: 0.6993
 482/1000 [=============>................] - ETA: 2:39 - loss: 3.2876 - regression_loss: 2.5891 - classification_loss: 0.6984
 483/1000 [=============>................] - ETA: 2:39 - loss: 3.2861 - regression_loss: 2.5880 - classification_loss: 0.6981
 484/1000 [=============>................] - ETA: 2:38 - loss: 3.2872 - regression_loss: 2.5888 - classification_loss: 0.6984
 485/1000 [=============>................] - ETA: 2:38 - loss: 3.2871 - regression_loss: 2.5888 - classification_loss: 0.6983
 486/1000 [=============>................] - ETA: 2:38 - loss: 3.2844 - regression_loss: 2.5867 - classification_loss: 0.6977
 487/1000 [=============>................] - ETA: 2:37 - loss: 3.2829 - regression_loss: 2.5860 - classification_loss: 0.6969
 488/1000 [=============>................] - ETA: 2:37 - loss: 3.2823 - regression_loss: 2.5856 - classification_loss: 0.6967
 489/1000 [=============>................] - ETA: 2:37 - loss: 3.2818 - regression_loss: 2.5855 - classification_loss: 0.6963
 490/1000 [=============>................] - ETA: 2:36 - loss: 3.2810 - regression_loss: 2.5850 - classification_loss: 0.6959
 491/1000 [=============>................] - ETA: 2:36 - loss: 3.2785 - regression_loss: 2.5833 - classification_loss: 0.6952
 492/1000 [=============>................] - ETA: 2:36 - loss: 3.2760 - regression_loss: 2.5813 - classification_loss: 0.6947
 493/1000 [=============>................] - ETA: 2:35 - loss: 3.2744 - regression_loss: 2.5802 - classification_loss: 0.6942
 494/1000 [=============>................] - ETA: 2:35 - loss: 3.2754 - regression_loss: 2.5806 - classification_loss: 0.6947
 495/1000 [=============>................] - ETA: 2:35 - loss: 3.2739 - regression_loss: 2.5797 - classification_loss: 0.6941
 496/1000 [=============>................] - ETA: 2:34 - loss: 3.2721 - regression_loss: 2.5787 - classification_loss: 0.6934
 497/1000 [=============>................] - ETA: 2:34 - loss: 3.2713 - regression_loss: 2.5783 - classification_loss: 0.6930
 498/1000 [=============>................] - ETA: 2:34 - loss: 3.2683 - regression_loss: 2.5762 - classification_loss: 0.6922
 499/1000 [=============>................] - ETA: 2:33 - loss: 3.2669 - regression_loss: 2.5753 - classification_loss: 0.6916
 500/1000 [==============>...............] - ETA: 2:33 - loss: 3.2649 - regression_loss: 2.5738 - classification_loss: 0.6911
 501/1000 [==============>...............] - ETA: 2:33 - loss: 3.2651 - regression_loss: 2.5736 - classification_loss: 0.6914
 502/1000 [==============>...............] - ETA: 2:33 - loss: 3.2667 - regression_loss: 2.5757 - classification_loss: 0.6910
 503/1000 [==============>...............] - ETA: 2:32 - loss: 3.2659 - regression_loss: 2.5749 - classification_loss: 0.6910
 504/1000 [==============>...............] - ETA: 2:32 - loss: 3.2633 - regression_loss: 2.5731 - classification_loss: 0.6902
 505/1000 [==============>...............] - ETA: 2:32 - loss: 3.2641 - regression_loss: 2.5742 - classification_loss: 0.6899
 506/1000 [==============>...............] - ETA: 2:31 - loss: 3.2631 - regression_loss: 2.5738 - classification_loss: 0.6892
 507/1000 [==============>...............] - ETA: 2:31 - loss: 3.2601 - regression_loss: 2.5716 - classification_loss: 0.6885
 508/1000 [==============>...............] - ETA: 2:31 - loss: 3.2596 - regression_loss: 2.5717 - classification_loss: 0.6879
 509/1000 [==============>...............] - ETA: 2:30 - loss: 3.2580 - regression_loss: 2.5708 - classification_loss: 0.6872
 510/1000 [==============>...............] - ETA: 2:30 - loss: 3.2585 - regression_loss: 2.5711 - classification_loss: 0.6873
 511/1000 [==============>...............] - ETA: 2:30 - loss: 3.2570 - regression_loss: 2.5702 - classification_loss: 0.6868
 512/1000 [==============>...............] - ETA: 2:29 - loss: 3.2550 - regression_loss: 2.5690 - classification_loss: 0.6861
 513/1000 [==============>...............] - ETA: 2:29 - loss: 3.2525 - regression_loss: 2.5673 - classification_loss: 0.6853
 514/1000 [==============>...............] - ETA: 2:29 - loss: 3.2494 - regression_loss: 2.5650 - classification_loss: 0.6844
 515/1000 [==============>...............] - ETA: 2:28 - loss: 3.2480 - regression_loss: 2.5643 - classification_loss: 0.6836
 516/1000 [==============>...............] - ETA: 2:28 - loss: 3.2475 - regression_loss: 2.5644 - classification_loss: 0.6831
 517/1000 [==============>...............] - ETA: 2:28 - loss: 3.2461 - regression_loss: 2.5630 - classification_loss: 0.6831
 518/1000 [==============>...............] - ETA: 2:27 - loss: 3.2439 - regression_loss: 2.5615 - classification_loss: 0.6823
 519/1000 [==============>...............] - ETA: 2:27 - loss: 3.2414 - regression_loss: 2.5599 - classification_loss: 0.6815
 520/1000 [==============>...............] - ETA: 2:27 - loss: 3.2409 - regression_loss: 2.5596 - classification_loss: 0.6813
 521/1000 [==============>...............] - ETA: 2:26 - loss: 3.2448 - regression_loss: 2.5595 - classification_loss: 0.6853
 522/1000 [==============>...............] - ETA: 2:26 - loss: 3.2427 - regression_loss: 2.5581 - classification_loss: 0.6846
 523/1000 [==============>...............] - ETA: 2:26 - loss: 3.2401 - regression_loss: 2.5564 - classification_loss: 0.6837
 524/1000 [==============>...............] - ETA: 2:25 - loss: 3.2391 - regression_loss: 2.5557 - classification_loss: 0.6834
 525/1000 [==============>...............] - ETA: 2:25 - loss: 3.2379 - regression_loss: 2.5552 - classification_loss: 0.6827
 526/1000 [==============>...............] - ETA: 2:25 - loss: 3.2375 - regression_loss: 2.5549 - classification_loss: 0.6826
 527/1000 [==============>...............] - ETA: 2:24 - loss: 3.2373 - regression_loss: 2.5552 - classification_loss: 0.6821
 528/1000 [==============>...............] - ETA: 2:24 - loss: 3.2358 - regression_loss: 2.5542 - classification_loss: 0.6816
 529/1000 [==============>...............] - ETA: 2:24 - loss: 3.2334 - regression_loss: 2.5525 - classification_loss: 0.6809
 530/1000 [==============>...............] - ETA: 2:23 - loss: 3.2319 - regression_loss: 2.5516 - classification_loss: 0.6803
 531/1000 [==============>...............] - ETA: 2:23 - loss: 3.2310 - regression_loss: 2.5511 - classification_loss: 0.6799
 532/1000 [==============>...............] - ETA: 2:23 - loss: 3.2291 - regression_loss: 2.5496 - classification_loss: 0.6795
 533/1000 [==============>...............] - ETA: 2:22 - loss: 3.2270 - regression_loss: 2.5483 - classification_loss: 0.6787
 534/1000 [===============>..............] - ETA: 2:22 - loss: 3.2242 - regression_loss: 2.5464 - classification_loss: 0.6778
 535/1000 [===============>..............] - ETA: 2:22 - loss: 3.2232 - regression_loss: 2.5456 - classification_loss: 0.6775
 536/1000 [===============>..............] - ETA: 2:21 - loss: 3.2233 - regression_loss: 2.5462 - classification_loss: 0.6771
 537/1000 [===============>..............] - ETA: 2:21 - loss: 3.2225 - regression_loss: 2.5456 - classification_loss: 0.6769
 538/1000 [===============>..............] - ETA: 2:21 - loss: 3.2207 - regression_loss: 2.5444 - classification_loss: 0.6763
 539/1000 [===============>..............] - ETA: 2:20 - loss: 3.2196 - regression_loss: 2.5440 - classification_loss: 0.6756
 540/1000 [===============>..............] - ETA: 2:20 - loss: 3.2191 - regression_loss: 2.5434 - classification_loss: 0.6757
 541/1000 [===============>..............] - ETA: 2:20 - loss: 3.2174 - regression_loss: 2.5420 - classification_loss: 0.6754
 542/1000 [===============>..............] - ETA: 2:20 - loss: 3.2150 - regression_loss: 2.5402 - classification_loss: 0.6748
 543/1000 [===============>..............] - ETA: 2:19 - loss: 3.2136 - regression_loss: 2.5395 - classification_loss: 0.6741
 544/1000 [===============>..............] - ETA: 2:19 - loss: 3.2122 - regression_loss: 2.5386 - classification_loss: 0.6736
 545/1000 [===============>..............] - ETA: 2:19 - loss: 3.2107 - regression_loss: 2.5375 - classification_loss: 0.6732
 546/1000 [===============>..............] - ETA: 2:18 - loss: 3.2080 - regression_loss: 2.5356 - classification_loss: 0.6724
 547/1000 [===============>..............] - ETA: 2:18 - loss: 3.2059 - regression_loss: 2.5341 - classification_loss: 0.6718
 548/1000 [===============>..............] - ETA: 2:18 - loss: 3.2045 - regression_loss: 2.5333 - classification_loss: 0.6712
 549/1000 [===============>..............] - ETA: 2:17 - loss: 3.2056 - regression_loss: 2.5343 - classification_loss: 0.6713
 550/1000 [===============>..............] - ETA: 2:17 - loss: 3.2048 - regression_loss: 2.5338 - classification_loss: 0.6710
 551/1000 [===============>..............] - ETA: 2:17 - loss: 3.2029 - regression_loss: 2.5325 - classification_loss: 0.6704
 552/1000 [===============>..............] - ETA: 2:16 - loss: 3.2010 - regression_loss: 2.5311 - classification_loss: 0.6699
 553/1000 [===============>..............] - ETA: 2:16 - loss: 3.2006 - regression_loss: 2.5308 - classification_loss: 0.6698
 554/1000 [===============>..............] - ETA: 2:16 - loss: 3.2004 - regression_loss: 2.5308 - classification_loss: 0.6696
 555/1000 [===============>..............] - ETA: 2:15 - loss: 3.1990 - regression_loss: 2.5300 - classification_loss: 0.6690
 556/1000 [===============>..............] - ETA: 2:15 - loss: 3.1980 - regression_loss: 2.5296 - classification_loss: 0.6684
 557/1000 [===============>..............] - ETA: 2:15 - loss: 3.1972 - regression_loss: 2.5290 - classification_loss: 0.6682
 558/1000 [===============>..............] - ETA: 2:14 - loss: 3.1957 - regression_loss: 2.5281 - classification_loss: 0.6676
 559/1000 [===============>..............] - ETA: 2:14 - loss: 3.1940 - regression_loss: 2.5270 - classification_loss: 0.6670
 560/1000 [===============>..............] - ETA: 2:14 - loss: 3.1922 - regression_loss: 2.5259 - classification_loss: 0.6663
 561/1000 [===============>..............] - ETA: 2:13 - loss: 3.1932 - regression_loss: 2.5272 - classification_loss: 0.6660
 562/1000 [===============>..............] - ETA: 2:13 - loss: 3.1911 - regression_loss: 2.5257 - classification_loss: 0.6655
 563/1000 [===============>..............] - ETA: 2:13 - loss: 3.1900 - regression_loss: 2.5250 - classification_loss: 0.6650
 564/1000 [===============>..............] - ETA: 2:12 - loss: 3.1880 - regression_loss: 2.5233 - classification_loss: 0.6647
 565/1000 [===============>..............] - ETA: 2:12 - loss: 3.1864 - regression_loss: 2.5222 - classification_loss: 0.6642
 566/1000 [===============>..............] - ETA: 2:12 - loss: 3.1896 - regression_loss: 2.5254 - classification_loss: 0.6642
 567/1000 [================>.............] - ETA: 2:12 - loss: 3.1893 - regression_loss: 2.5254 - classification_loss: 0.6639
 568/1000 [================>.............] - ETA: 2:11 - loss: 3.1874 - regression_loss: 2.5240 - classification_loss: 0.6633
 569/1000 [================>.............] - ETA: 2:11 - loss: 3.1862 - regression_loss: 2.5233 - classification_loss: 0.6629
 570/1000 [================>.............] - ETA: 2:11 - loss: 3.1851 - regression_loss: 2.5225 - classification_loss: 0.6626
 571/1000 [================>.............] - ETA: 2:10 - loss: 3.1838 - regression_loss: 2.5217 - classification_loss: 0.6621
 572/1000 [================>.............] - ETA: 2:10 - loss: 3.1836 - regression_loss: 2.5221 - classification_loss: 0.6615
 573/1000 [================>.............] - ETA: 2:10 - loss: 3.1827 - regression_loss: 2.5219 - classification_loss: 0.6608
 574/1000 [================>.............] - ETA: 2:09 - loss: 3.1835 - regression_loss: 2.5221 - classification_loss: 0.6613
 575/1000 [================>.............] - ETA: 2:09 - loss: 3.1841 - regression_loss: 2.5225 - classification_loss: 0.6616
 576/1000 [================>.............] - ETA: 2:09 - loss: 3.1828 - regression_loss: 2.5216 - classification_loss: 0.6612
 577/1000 [================>.............] - ETA: 2:08 - loss: 3.1827 - regression_loss: 2.5214 - classification_loss: 0.6613
 578/1000 [================>.............] - ETA: 2:08 - loss: 3.1810 - regression_loss: 2.5204 - classification_loss: 0.6607
 579/1000 [================>.............] - ETA: 2:08 - loss: 3.1799 - regression_loss: 2.5195 - classification_loss: 0.6604
 580/1000 [================>.............] - ETA: 2:07 - loss: 3.1786 - regression_loss: 2.5186 - classification_loss: 0.6600
 581/1000 [================>.............] - ETA: 2:07 - loss: 3.1789 - regression_loss: 2.5187 - classification_loss: 0.6603
 582/1000 [================>.............] - ETA: 2:07 - loss: 3.1779 - regression_loss: 2.5179 - classification_loss: 0.6600
 583/1000 [================>.............] - ETA: 2:06 - loss: 3.1775 - regression_loss: 2.5176 - classification_loss: 0.6600
 584/1000 [================>.............] - ETA: 2:06 - loss: 3.1772 - regression_loss: 2.5175 - classification_loss: 0.6597
 585/1000 [================>.............] - ETA: 2:06 - loss: 3.1768 - regression_loss: 2.5171 - classification_loss: 0.6597
 586/1000 [================>.............] - ETA: 2:05 - loss: 3.1753 - regression_loss: 2.5162 - classification_loss: 0.6591
 587/1000 [================>.............] - ETA: 2:05 - loss: 3.1737 - regression_loss: 2.5153 - classification_loss: 0.6584
 588/1000 [================>.............] - ETA: 2:05 - loss: 3.1717 - regression_loss: 2.5139 - classification_loss: 0.6578
 589/1000 [================>.............] - ETA: 2:05 - loss: 3.1693 - regression_loss: 2.5121 - classification_loss: 0.6572
 590/1000 [================>.............] - ETA: 2:04 - loss: 3.1671 - regression_loss: 2.5105 - classification_loss: 0.6565
 591/1000 [================>.............] - ETA: 2:04 - loss: 3.1660 - regression_loss: 2.5097 - classification_loss: 0.6563
 592/1000 [================>.............] - ETA: 2:04 - loss: 3.1664 - regression_loss: 2.5101 - classification_loss: 0.6563
 593/1000 [================>.............] - ETA: 2:03 - loss: 3.1665 - regression_loss: 2.5091 - classification_loss: 0.6574
 594/1000 [================>.............] - ETA: 2:03 - loss: 3.1661 - regression_loss: 2.5087 - classification_loss: 0.6573
 595/1000 [================>.............] - ETA: 2:03 - loss: 3.1667 - regression_loss: 2.5091 - classification_loss: 0.6576
 596/1000 [================>.............] - ETA: 2:02 - loss: 3.1651 - regression_loss: 2.5078 - classification_loss: 0.6573
 597/1000 [================>.............] - ETA: 2:02 - loss: 3.1640 - regression_loss: 2.5071 - classification_loss: 0.6570
 598/1000 [================>.............] - ETA: 2:02 - loss: 3.1627 - regression_loss: 2.5061 - classification_loss: 0.6565
 599/1000 [================>.............] - ETA: 2:01 - loss: 3.1622 - regression_loss: 2.5061 - classification_loss: 0.6562
 600/1000 [=================>............] - ETA: 2:01 - loss: 3.1604 - regression_loss: 2.5048 - classification_loss: 0.6556
 601/1000 [=================>............] - ETA: 2:01 - loss: 3.1602 - regression_loss: 2.5048 - classification_loss: 0.6553
 602/1000 [=================>............] - ETA: 2:00 - loss: 3.1590 - regression_loss: 2.5039 - classification_loss: 0.6551
 603/1000 [=================>............] - ETA: 2:00 - loss: 3.1577 - regression_loss: 2.5033 - classification_loss: 0.6545
 604/1000 [=================>............] - ETA: 2:00 - loss: 3.1548 - regression_loss: 2.5008 - classification_loss: 0.6540
 605/1000 [=================>............] - ETA: 1:59 - loss: 3.1543 - regression_loss: 2.5007 - classification_loss: 0.6536
 606/1000 [=================>............] - ETA: 1:59 - loss: 3.1539 - regression_loss: 2.5007 - classification_loss: 0.6532
 607/1000 [=================>............] - ETA: 1:59 - loss: 3.1516 - regression_loss: 2.4991 - classification_loss: 0.6526
 608/1000 [=================>............] - ETA: 1:59 - loss: 3.1495 - regression_loss: 2.4975 - classification_loss: 0.6520
 609/1000 [=================>............] - ETA: 1:58 - loss: 3.1481 - regression_loss: 2.4966 - classification_loss: 0.6516
 610/1000 [=================>............] - ETA: 1:58 - loss: 3.1457 - regression_loss: 2.4945 - classification_loss: 0.6512
 611/1000 [=================>............] - ETA: 1:58 - loss: 3.1442 - regression_loss: 2.4931 - classification_loss: 0.6511
 612/1000 [=================>............] - ETA: 1:57 - loss: 3.1432 - regression_loss: 2.4926 - classification_loss: 0.6506
 613/1000 [=================>............] - ETA: 1:57 - loss: 3.1423 - regression_loss: 2.4924 - classification_loss: 0.6499
 614/1000 [=================>............] - ETA: 1:57 - loss: 3.1401 - regression_loss: 2.4907 - classification_loss: 0.6494
 615/1000 [=================>............] - ETA: 1:56 - loss: 3.1389 - regression_loss: 2.4899 - classification_loss: 0.6490
 616/1000 [=================>............] - ETA: 1:56 - loss: 3.1373 - regression_loss: 2.4890 - classification_loss: 0.6483
 617/1000 [=================>............] - ETA: 1:56 - loss: 3.1368 - regression_loss: 2.4890 - classification_loss: 0.6478
 618/1000 [=================>............] - ETA: 1:55 - loss: 3.1359 - regression_loss: 2.4885 - classification_loss: 0.6473
 619/1000 [=================>............] - ETA: 1:55 - loss: 3.1352 - regression_loss: 2.4881 - classification_loss: 0.6472
 620/1000 [=================>............] - ETA: 1:55 - loss: 3.1336 - regression_loss: 2.4870 - classification_loss: 0.6466
 621/1000 [=================>............] - ETA: 1:54 - loss: 3.1337 - regression_loss: 2.4876 - classification_loss: 0.6461
 622/1000 [=================>............] - ETA: 1:54 - loss: 3.1332 - regression_loss: 2.4867 - classification_loss: 0.6465
 623/1000 [=================>............] - ETA: 1:54 - loss: 3.1321 - regression_loss: 2.4858 - classification_loss: 0.6463
 624/1000 [=================>............] - ETA: 1:53 - loss: 3.1315 - regression_loss: 2.4855 - classification_loss: 0.6459
 625/1000 [=================>............] - ETA: 1:53 - loss: 3.1360 - regression_loss: 2.4892 - classification_loss: 0.6468
 626/1000 [=================>............] - ETA: 1:53 - loss: 3.1355 - regression_loss: 2.4891 - classification_loss: 0.6464
 627/1000 [=================>............] - ETA: 1:53 - loss: 3.1342 - regression_loss: 2.4881 - classification_loss: 0.6461
 628/1000 [=================>............] - ETA: 1:52 - loss: 3.1334 - regression_loss: 2.4876 - classification_loss: 0.6458
 629/1000 [=================>............] - ETA: 1:52 - loss: 3.1316 - regression_loss: 2.4863 - classification_loss: 0.6453
 630/1000 [=================>............] - ETA: 1:52 - loss: 3.1314 - regression_loss: 2.4861 - classification_loss: 0.6453
 631/1000 [=================>............] - ETA: 1:51 - loss: 3.1295 - regression_loss: 2.4848 - classification_loss: 0.6447
 632/1000 [=================>............] - ETA: 1:51 - loss: 3.1284 - regression_loss: 2.4841 - classification_loss: 0.6443
 633/1000 [=================>............] - ETA: 1:51 - loss: 3.1269 - regression_loss: 2.4831 - classification_loss: 0.6438
 634/1000 [==================>...........] - ETA: 1:50 - loss: 3.1267 - regression_loss: 2.4832 - classification_loss: 0.6435
 635/1000 [==================>...........] - ETA: 1:50 - loss: 3.1264 - regression_loss: 2.4828 - classification_loss: 0.6436
 636/1000 [==================>...........] - ETA: 1:50 - loss: 3.1246 - regression_loss: 2.4816 - classification_loss: 0.6430
 637/1000 [==================>...........] - ETA: 1:49 - loss: 3.1244 - regression_loss: 2.4817 - classification_loss: 0.6427
 638/1000 [==================>...........] - ETA: 1:49 - loss: 3.1230 - regression_loss: 2.4806 - classification_loss: 0.6423
 639/1000 [==================>...........] - ETA: 1:49 - loss: 3.1222 - regression_loss: 2.4803 - classification_loss: 0.6419
 640/1000 [==================>...........] - ETA: 1:48 - loss: 3.1197 - regression_loss: 2.4785 - classification_loss: 0.6412
 641/1000 [==================>...........] - ETA: 1:48 - loss: 3.1201 - regression_loss: 2.4790 - classification_loss: 0.6412
 642/1000 [==================>...........] - ETA: 1:48 - loss: 3.1190 - regression_loss: 2.4782 - classification_loss: 0.6408
 643/1000 [==================>...........] - ETA: 1:48 - loss: 3.1169 - regression_loss: 2.4767 - classification_loss: 0.6402
 644/1000 [==================>...........] - ETA: 1:47 - loss: 3.1158 - regression_loss: 2.4759 - classification_loss: 0.6399
 645/1000 [==================>...........] - ETA: 1:47 - loss: 3.1155 - regression_loss: 2.4756 - classification_loss: 0.6399
 646/1000 [==================>...........] - ETA: 1:47 - loss: 3.1138 - regression_loss: 2.4744 - classification_loss: 0.6394
 647/1000 [==================>...........] - ETA: 1:46 - loss: 3.1132 - regression_loss: 2.4738 - classification_loss: 0.6394
 648/1000 [==================>...........] - ETA: 1:46 - loss: 3.1140 - regression_loss: 2.4743 - classification_loss: 0.6397
 649/1000 [==================>...........] - ETA: 1:46 - loss: 3.1124 - regression_loss: 2.4733 - classification_loss: 0.6391
 650/1000 [==================>...........] - ETA: 1:45 - loss: 3.1110 - regression_loss: 2.4723 - classification_loss: 0.6386
 651/1000 [==================>...........] - ETA: 1:45 - loss: 3.1105 - regression_loss: 2.4723 - classification_loss: 0.6382
 652/1000 [==================>...........] - ETA: 1:45 - loss: 3.1089 - regression_loss: 2.4712 - classification_loss: 0.6378
 653/1000 [==================>...........] - ETA: 1:44 - loss: 3.1073 - regression_loss: 2.4699 - classification_loss: 0.6374
 654/1000 [==================>...........] - ETA: 1:44 - loss: 3.1064 - regression_loss: 2.4694 - classification_loss: 0.6370
 655/1000 [==================>...........] - ETA: 1:44 - loss: 3.1050 - regression_loss: 2.4686 - classification_loss: 0.6365
 656/1000 [==================>...........] - ETA: 1:43 - loss: 3.1029 - regression_loss: 2.4670 - classification_loss: 0.6360
 657/1000 [==================>...........] - ETA: 1:43 - loss: 3.1017 - regression_loss: 2.4661 - classification_loss: 0.6356
 658/1000 [==================>...........] - ETA: 1:43 - loss: 3.1022 - regression_loss: 2.4667 - classification_loss: 0.6355
 659/1000 [==================>...........] - ETA: 1:43 - loss: 3.1001 - regression_loss: 2.4652 - classification_loss: 0.6349
 660/1000 [==================>...........] - ETA: 1:42 - loss: 3.0997 - regression_loss: 2.4652 - classification_loss: 0.6345
 661/1000 [==================>...........] - ETA: 1:42 - loss: 3.0992 - regression_loss: 2.4650 - classification_loss: 0.6341
 662/1000 [==================>...........] - ETA: 1:42 - loss: 3.0979 - regression_loss: 2.4643 - classification_loss: 0.6336
 663/1000 [==================>...........] - ETA: 1:41 - loss: 3.0960 - regression_loss: 2.4630 - classification_loss: 0.6331
 664/1000 [==================>...........] - ETA: 1:41 - loss: 3.0937 - regression_loss: 2.4612 - classification_loss: 0.6325
 665/1000 [==================>...........] - ETA: 1:41 - loss: 3.0925 - regression_loss: 2.4605 - classification_loss: 0.6321
 666/1000 [==================>...........] - ETA: 1:40 - loss: 3.0950 - regression_loss: 2.4627 - classification_loss: 0.6323
 667/1000 [===================>..........] - ETA: 1:40 - loss: 3.0937 - regression_loss: 2.4618 - classification_loss: 0.6318
 668/1000 [===================>..........] - ETA: 1:40 - loss: 3.0922 - regression_loss: 2.4607 - classification_loss: 0.6315
 669/1000 [===================>..........] - ETA: 1:39 - loss: 3.0896 - regression_loss: 2.4588 - classification_loss: 0.6308
 670/1000 [===================>..........] - ETA: 1:39 - loss: 3.0889 - regression_loss: 2.4584 - classification_loss: 0.6305
 671/1000 [===================>..........] - ETA: 1:39 - loss: 3.0874 - regression_loss: 2.4573 - classification_loss: 0.6301
 672/1000 [===================>..........] - ETA: 1:39 - loss: 3.0868 - regression_loss: 2.4571 - classification_loss: 0.6296
 673/1000 [===================>..........] - ETA: 1:38 - loss: 3.0851 - regression_loss: 2.4559 - classification_loss: 0.6292
 674/1000 [===================>..........] - ETA: 1:38 - loss: 3.0835 - regression_loss: 2.4547 - classification_loss: 0.6288
 675/1000 [===================>..........] - ETA: 1:38 - loss: 3.0846 - regression_loss: 2.4553 - classification_loss: 0.6293
 676/1000 [===================>..........] - ETA: 1:37 - loss: 3.0832 - regression_loss: 2.4543 - classification_loss: 0.6288
 677/1000 [===================>..........] - ETA: 1:37 - loss: 3.0805 - regression_loss: 2.4523 - classification_loss: 0.6282
 678/1000 [===================>..........] - ETA: 1:37 - loss: 3.0790 - regression_loss: 2.4511 - classification_loss: 0.6279
 679/1000 [===================>..........] - ETA: 1:36 - loss: 3.0774 - regression_loss: 2.4501 - classification_loss: 0.6273
 680/1000 [===================>..........] - ETA: 1:36 - loss: 3.0746 - regression_loss: 2.4478 - classification_loss: 0.6268
 681/1000 [===================>..........] - ETA: 1:36 - loss: 3.0724 - regression_loss: 2.4463 - classification_loss: 0.6261
 682/1000 [===================>..........] - ETA: 1:35 - loss: 3.0703 - regression_loss: 2.4448 - classification_loss: 0.6255
 683/1000 [===================>..........] - ETA: 1:35 - loss: 3.0696 - regression_loss: 2.4445 - classification_loss: 0.6251
 684/1000 [===================>..........] - ETA: 1:35 - loss: 3.0698 - regression_loss: 2.4447 - classification_loss: 0.6251
 685/1000 [===================>..........] - ETA: 1:35 - loss: 3.0687 - regression_loss: 2.4440 - classification_loss: 0.6247
 686/1000 [===================>..........] - ETA: 1:34 - loss: 3.0690 - regression_loss: 2.4443 - classification_loss: 0.6247
 687/1000 [===================>..........] - ETA: 1:34 - loss: 3.0689 - regression_loss: 2.4447 - classification_loss: 0.6242
 688/1000 [===================>..........] - ETA: 1:34 - loss: 3.0691 - regression_loss: 2.4449 - classification_loss: 0.6242
 689/1000 [===================>..........] - ETA: 1:33 - loss: 3.0707 - regression_loss: 2.4461 - classification_loss: 0.6246
 690/1000 [===================>..........] - ETA: 1:33 - loss: 3.0698 - regression_loss: 2.4456 - classification_loss: 0.6242
 691/1000 [===================>..........] - ETA: 1:33 - loss: 3.0690 - regression_loss: 2.4451 - classification_loss: 0.6239
 692/1000 [===================>..........] - ETA: 1:32 - loss: 3.0680 - regression_loss: 2.4443 - classification_loss: 0.6236
 693/1000 [===================>..........] - ETA: 1:32 - loss: 3.0681 - regression_loss: 2.4444 - classification_loss: 0.6237
 694/1000 [===================>..........] - ETA: 1:32 - loss: 3.0674 - regression_loss: 2.4441 - classification_loss: 0.6233
 695/1000 [===================>..........] - ETA: 1:31 - loss: 3.0657 - regression_loss: 2.4427 - classification_loss: 0.6230
 696/1000 [===================>..........] - ETA: 1:31 - loss: 3.0657 - regression_loss: 2.4428 - classification_loss: 0.6229
 697/1000 [===================>..........] - ETA: 1:31 - loss: 3.0648 - regression_loss: 2.4424 - classification_loss: 0.6224
 698/1000 [===================>..........] - ETA: 1:31 - loss: 3.0638 - regression_loss: 2.4415 - classification_loss: 0.6223
 699/1000 [===================>..........] - ETA: 1:30 - loss: 3.0619 - regression_loss: 2.4403 - classification_loss: 0.6217
 700/1000 [====================>.........] - ETA: 1:30 - loss: 3.0617 - regression_loss: 2.4396 - classification_loss: 0.6221
 701/1000 [====================>.........] - ETA: 1:30 - loss: 3.0613 - regression_loss: 2.4396 - classification_loss: 0.6217
 702/1000 [====================>.........] - ETA: 1:29 - loss: 3.0605 - regression_loss: 2.4390 - classification_loss: 0.6215
 703/1000 [====================>.........] - ETA: 1:29 - loss: 3.0595 - regression_loss: 2.4384 - classification_loss: 0.6210
 704/1000 [====================>.........] - ETA: 1:29 - loss: 3.0588 - regression_loss: 2.4380 - classification_loss: 0.6207
 705/1000 [====================>.........] - ETA: 1:28 - loss: 3.0566 - regression_loss: 2.4364 - classification_loss: 0.6202
 706/1000 [====================>.........] - ETA: 1:28 - loss: 3.0552 - regression_loss: 2.4353 - classification_loss: 0.6198
 707/1000 [====================>.........] - ETA: 1:28 - loss: 3.0554 - regression_loss: 2.4351 - classification_loss: 0.6204
 708/1000 [====================>.........] - ETA: 1:27 - loss: 3.0544 - regression_loss: 2.4343 - classification_loss: 0.6201
 709/1000 [====================>.........] - ETA: 1:27 - loss: 3.0530 - regression_loss: 2.4333 - classification_loss: 0.6197
 710/1000 [====================>.........] - ETA: 1:27 - loss: 3.0531 - regression_loss: 2.4333 - classification_loss: 0.6199
 711/1000 [====================>.........] - ETA: 1:27 - loss: 3.0517 - regression_loss: 2.4322 - classification_loss: 0.6195
 712/1000 [====================>.........] - ETA: 1:26 - loss: 3.0514 - regression_loss: 2.4319 - classification_loss: 0.6194
 713/1000 [====================>.........] - ETA: 1:26 - loss: 3.0513 - regression_loss: 2.4321 - classification_loss: 0.6192
 714/1000 [====================>.........] - ETA: 1:26 - loss: 3.0495 - regression_loss: 2.4307 - classification_loss: 0.6188
 715/1000 [====================>.........] - ETA: 1:25 - loss: 3.0489 - regression_loss: 2.4304 - classification_loss: 0.6185
 716/1000 [====================>.........] - ETA: 1:25 - loss: 3.0480 - regression_loss: 2.4300 - classification_loss: 0.6180
 717/1000 [====================>.........] - ETA: 1:25 - loss: 3.0471 - regression_loss: 2.4296 - classification_loss: 0.6176
 718/1000 [====================>.........] - ETA: 1:24 - loss: 3.0461 - regression_loss: 2.4290 - classification_loss: 0.6171
 719/1000 [====================>.........] - ETA: 1:24 - loss: 3.0453 - regression_loss: 2.4285 - classification_loss: 0.6168
 720/1000 [====================>.........] - ETA: 1:24 - loss: 3.0454 - regression_loss: 2.4288 - classification_loss: 0.6166
 721/1000 [====================>.........] - ETA: 1:23 - loss: 3.0456 - regression_loss: 2.4286 - classification_loss: 0.6170
 722/1000 [====================>.........] - ETA: 1:23 - loss: 3.0447 - regression_loss: 2.4281 - classification_loss: 0.6167
 723/1000 [====================>.........] - ETA: 1:23 - loss: 3.0430 - regression_loss: 2.4268 - classification_loss: 0.6162
 724/1000 [====================>.........] - ETA: 1:23 - loss: 3.0415 - regression_loss: 2.4257 - classification_loss: 0.6159
 725/1000 [====================>.........] - ETA: 1:22 - loss: 3.0404 - regression_loss: 2.4245 - classification_loss: 0.6159
 726/1000 [====================>.........] - ETA: 1:22 - loss: 3.0388 - regression_loss: 2.4234 - classification_loss: 0.6154
 727/1000 [====================>.........] - ETA: 1:22 - loss: 3.0373 - regression_loss: 2.4223 - classification_loss: 0.6150
 728/1000 [====================>.........] - ETA: 1:21 - loss: 3.0364 - regression_loss: 2.4217 - classification_loss: 0.6147
 729/1000 [====================>.........] - ETA: 1:21 - loss: 3.0347 - regression_loss: 2.4204 - classification_loss: 0.6143
 730/1000 [====================>.........] - ETA: 1:21 - loss: 3.0337 - regression_loss: 2.4198 - classification_loss: 0.6139
 731/1000 [====================>.........] - ETA: 1:20 - loss: 3.0333 - regression_loss: 2.4195 - classification_loss: 0.6138
 732/1000 [====================>.........] - ETA: 1:20 - loss: 3.0312 - regression_loss: 2.4179 - classification_loss: 0.6134
 733/1000 [====================>.........] - ETA: 1:20 - loss: 3.0293 - regression_loss: 2.4164 - classification_loss: 0.6129
 734/1000 [=====================>........] - ETA: 1:19 - loss: 3.0281 - regression_loss: 2.4155 - classification_loss: 0.6126
 735/1000 [=====================>........] - ETA: 1:19 - loss: 3.0269 - regression_loss: 2.4147 - classification_loss: 0.6122
 736/1000 [=====================>........] - ETA: 1:19 - loss: 3.0258 - regression_loss: 2.4140 - classification_loss: 0.6118
 737/1000 [=====================>........] - ETA: 1:19 - loss: 3.0241 - regression_loss: 2.4129 - classification_loss: 0.6112
 738/1000 [=====================>........] - ETA: 1:18 - loss: 3.0238 - regression_loss: 2.4128 - classification_loss: 0.6110
 739/1000 [=====================>........] - ETA: 1:18 - loss: 3.0229 - regression_loss: 2.4120 - classification_loss: 0.6109
 740/1000 [=====================>........] - ETA: 1:18 - loss: 3.0221 - regression_loss: 2.4114 - classification_loss: 0.6107
 741/1000 [=====================>........] - ETA: 1:17 - loss: 3.0214 - regression_loss: 2.4108 - classification_loss: 0.6106
 742/1000 [=====================>........] - ETA: 1:17 - loss: 3.0201 - regression_loss: 2.4101 - classification_loss: 0.6100
 743/1000 [=====================>........] - ETA: 1:17 - loss: 3.0188 - regression_loss: 2.4092 - classification_loss: 0.6096
 744/1000 [=====================>........] - ETA: 1:16 - loss: 3.0179 - regression_loss: 2.4088 - classification_loss: 0.6091
 745/1000 [=====================>........] - ETA: 1:16 - loss: 3.0174 - regression_loss: 2.4084 - classification_loss: 0.6090
 746/1000 [=====================>........] - ETA: 1:16 - loss: 3.0168 - regression_loss: 2.4082 - classification_loss: 0.6086
 747/1000 [=====================>........] - ETA: 1:15 - loss: 3.0149 - regression_loss: 2.4068 - classification_loss: 0.6081
 748/1000 [=====================>........] - ETA: 1:15 - loss: 3.0137 - regression_loss: 2.4060 - classification_loss: 0.6077
 749/1000 [=====================>........] - ETA: 1:15 - loss: 3.0120 - regression_loss: 2.4046 - classification_loss: 0.6073
 750/1000 [=====================>........] - ETA: 1:15 - loss: 3.0101 - regression_loss: 2.4033 - classification_loss: 0.6068
 751/1000 [=====================>........] - ETA: 1:14 - loss: 3.0081 - regression_loss: 2.4018 - classification_loss: 0.6063
 752/1000 [=====================>........] - ETA: 1:14 - loss: 3.0080 - regression_loss: 2.4020 - classification_loss: 0.6060
 753/1000 [=====================>........] - ETA: 1:14 - loss: 3.0077 - regression_loss: 2.4019 - classification_loss: 0.6058
 754/1000 [=====================>........] - ETA: 1:13 - loss: 3.0070 - regression_loss: 2.4016 - classification_loss: 0.6054
 755/1000 [=====================>........] - ETA: 1:13 - loss: 3.0061 - regression_loss: 2.4008 - classification_loss: 0.6053
 756/1000 [=====================>........] - ETA: 1:13 - loss: 3.0053 - regression_loss: 2.4003 - classification_loss: 0.6050
 757/1000 [=====================>........] - ETA: 1:12 - loss: 3.0036 - regression_loss: 2.3991 - classification_loss: 0.6045
 758/1000 [=====================>........] - ETA: 1:12 - loss: 3.0033 - regression_loss: 2.3989 - classification_loss: 0.6044
 759/1000 [=====================>........] - ETA: 1:12 - loss: 3.0018 - regression_loss: 2.3977 - classification_loss: 0.6042
 760/1000 [=====================>........] - ETA: 1:12 - loss: 3.0006 - regression_loss: 2.3967 - classification_loss: 0.6039
 761/1000 [=====================>........] - ETA: 1:11 - loss: 2.9996 - regression_loss: 2.3961 - classification_loss: 0.6035
 762/1000 [=====================>........] - ETA: 1:11 - loss: 2.9974 - regression_loss: 2.3944 - classification_loss: 0.6030
 763/1000 [=====================>........] - ETA: 1:11 - loss: 2.9963 - regression_loss: 2.3937 - classification_loss: 0.6026
 764/1000 [=====================>........] - ETA: 1:10 - loss: 2.9952 - regression_loss: 2.3928 - classification_loss: 0.6024
 765/1000 [=====================>........] - ETA: 1:10 - loss: 2.9937 - regression_loss: 2.3916 - classification_loss: 0.6020
 766/1000 [=====================>........] - ETA: 1:10 - loss: 2.9931 - regression_loss: 2.3912 - classification_loss: 0.6019
 767/1000 [======================>.......] - ETA: 1:09 - loss: 2.9927 - regression_loss: 2.3912 - classification_loss: 0.6016
 768/1000 [======================>.......] - ETA: 1:09 - loss: 2.9910 - regression_loss: 2.3899 - classification_loss: 0.6012
 769/1000 [======================>.......] - ETA: 1:09 - loss: 2.9904 - regression_loss: 2.3892 - classification_loss: 0.6012
 770/1000 [======================>.......] - ETA: 1:08 - loss: 2.9892 - regression_loss: 2.3883 - classification_loss: 0.6009
 771/1000 [======================>.......] - ETA: 1:08 - loss: 2.9884 - regression_loss: 2.3878 - classification_loss: 0.6005
 772/1000 [======================>.......] - ETA: 1:08 - loss: 2.9875 - regression_loss: 2.3873 - classification_loss: 0.6001
 773/1000 [======================>.......] - ETA: 1:08 - loss: 2.9873 - regression_loss: 2.3872 - classification_loss: 0.6002
 774/1000 [======================>.......] - ETA: 1:07 - loss: 2.9852 - regression_loss: 2.3854 - classification_loss: 0.5998
 775/1000 [======================>.......] - ETA: 1:07 - loss: 2.9841 - regression_loss: 2.3847 - classification_loss: 0.5993
 776/1000 [======================>.......] - ETA: 1:07 - loss: 2.9837 - regression_loss: 2.3843 - classification_loss: 0.5993
 777/1000 [======================>.......] - ETA: 1:06 - loss: 2.9836 - regression_loss: 2.3844 - classification_loss: 0.5992
 778/1000 [======================>.......] - ETA: 1:06 - loss: 2.9837 - regression_loss: 2.3846 - classification_loss: 0.5991
 779/1000 [======================>.......] - ETA: 1:06 - loss: 2.9829 - regression_loss: 2.3837 - classification_loss: 0.5992
 780/1000 [======================>.......] - ETA: 1:05 - loss: 2.9817 - regression_loss: 2.3828 - classification_loss: 0.5989
 781/1000 [======================>.......] - ETA: 1:05 - loss: 2.9811 - regression_loss: 2.3823 - classification_loss: 0.5988
 782/1000 [======================>.......] - ETA: 1:05 - loss: 2.9814 - regression_loss: 2.3826 - classification_loss: 0.5989
 783/1000 [======================>.......] - ETA: 1:05 - loss: 2.9808 - regression_loss: 2.3823 - classification_loss: 0.5985
 784/1000 [======================>.......] - ETA: 1:04 - loss: 2.9807 - regression_loss: 2.3824 - classification_loss: 0.5983
 785/1000 [======================>.......] - ETA: 1:04 - loss: 2.9797 - regression_loss: 2.3816 - classification_loss: 0.5982
 786/1000 [======================>.......] - ETA: 1:04 - loss: 2.9787 - regression_loss: 2.3808 - classification_loss: 0.5979
 787/1000 [======================>.......] - ETA: 1:03 - loss: 2.9772 - regression_loss: 2.3798 - classification_loss: 0.5975
 788/1000 [======================>.......] - ETA: 1:03 - loss: 2.9770 - regression_loss: 2.3797 - classification_loss: 0.5973
 789/1000 [======================>.......] - ETA: 1:03 - loss: 2.9760 - regression_loss: 2.3790 - classification_loss: 0.5970
 790/1000 [======================>.......] - ETA: 1:02 - loss: 2.9742 - regression_loss: 2.3777 - classification_loss: 0.5965
 791/1000 [======================>.......] - ETA: 1:02 - loss: 2.9736 - regression_loss: 2.3774 - classification_loss: 0.5962
 792/1000 [======================>.......] - ETA: 1:02 - loss: 2.9719 - regression_loss: 2.3762 - classification_loss: 0.5957
 793/1000 [======================>.......] - ETA: 1:01 - loss: 2.9704 - regression_loss: 2.3752 - classification_loss: 0.5952
 794/1000 [======================>.......] - ETA: 1:01 - loss: 2.9685 - regression_loss: 2.3737 - classification_loss: 0.5948
 795/1000 [======================>.......] - ETA: 1:01 - loss: 2.9680 - regression_loss: 2.3735 - classification_loss: 0.5946
 796/1000 [======================>.......] - ETA: 1:01 - loss: 2.9669 - regression_loss: 2.3720 - classification_loss: 0.5948
 797/1000 [======================>.......] - ETA: 1:00 - loss: 2.9662 - regression_loss: 2.3717 - classification_loss: 0.5946
 798/1000 [======================>.......] - ETA: 1:00 - loss: 2.9648 - regression_loss: 2.3707 - classification_loss: 0.5941
 799/1000 [======================>.......] - ETA: 1:00 - loss: 2.9644 - regression_loss: 2.3705 - classification_loss: 0.5939
 800/1000 [=======================>......] - ETA: 59s - loss: 2.9634 - regression_loss: 2.3698 - classification_loss: 0.5936 
 801/1000 [=======================>......] - ETA: 59s - loss: 2.9627 - regression_loss: 2.3692 - classification_loss: 0.5934
 802/1000 [=======================>......] - ETA: 59s - loss: 2.9611 - regression_loss: 2.3681 - classification_loss: 0.5930
 803/1000 [=======================>......] - ETA: 58s - loss: 2.9596 - regression_loss: 2.3671 - classification_loss: 0.5925
 804/1000 [=======================>......] - ETA: 58s - loss: 2.9584 - regression_loss: 2.3662 - classification_loss: 0.5922
 805/1000 [=======================>......] - ETA: 58s - loss: 2.9572 - regression_loss: 2.3654 - classification_loss: 0.5919
 806/1000 [=======================>......] - ETA: 58s - loss: 2.9564 - regression_loss: 2.3649 - classification_loss: 0.5914
 807/1000 [=======================>......] - ETA: 57s - loss: 2.9545 - regression_loss: 2.3635 - classification_loss: 0.5910
 808/1000 [=======================>......] - ETA: 57s - loss: 2.9529 - regression_loss: 2.3625 - classification_loss: 0.5905
 809/1000 [=======================>......] - ETA: 57s - loss: 2.9514 - regression_loss: 2.3614 - classification_loss: 0.5900
 810/1000 [=======================>......] - ETA: 56s - loss: 2.9515 - regression_loss: 2.3618 - classification_loss: 0.5897
 811/1000 [=======================>......] - ETA: 56s - loss: 2.9498 - regression_loss: 2.3605 - classification_loss: 0.5893
 812/1000 [=======================>......] - ETA: 56s - loss: 2.9480 - regression_loss: 2.3591 - classification_loss: 0.5889
 813/1000 [=======================>......] - ETA: 55s - loss: 2.9461 - regression_loss: 2.3577 - classification_loss: 0.5884
 814/1000 [=======================>......] - ETA: 55s - loss: 2.9447 - regression_loss: 2.3567 - classification_loss: 0.5880
 815/1000 [=======================>......] - ETA: 55s - loss: 2.9447 - regression_loss: 2.3569 - classification_loss: 0.5878
 816/1000 [=======================>......] - ETA: 55s - loss: 2.9437 - regression_loss: 2.3562 - classification_loss: 0.5876
 817/1000 [=======================>......] - ETA: 54s - loss: 2.9431 - regression_loss: 2.3559 - classification_loss: 0.5872
 818/1000 [=======================>......] - ETA: 54s - loss: 2.9422 - regression_loss: 2.3554 - classification_loss: 0.5869
 819/1000 [=======================>......] - ETA: 54s - loss: 2.9432 - regression_loss: 2.3547 - classification_loss: 0.5885
 820/1000 [=======================>......] - ETA: 53s - loss: 2.9424 - regression_loss: 2.3538 - classification_loss: 0.5886
 821/1000 [=======================>......] - ETA: 53s - loss: 2.9435 - regression_loss: 2.3545 - classification_loss: 0.5890
 822/1000 [=======================>......] - ETA: 53s - loss: 2.9420 - regression_loss: 2.3533 - classification_loss: 0.5887
 823/1000 [=======================>......] - ETA: 52s - loss: 2.9420 - regression_loss: 2.3534 - classification_loss: 0.5885
 824/1000 [=======================>......] - ETA: 52s - loss: 2.9413 - regression_loss: 2.3531 - classification_loss: 0.5883
 825/1000 [=======================>......] - ETA: 52s - loss: 2.9417 - regression_loss: 2.3536 - classification_loss: 0.5881
 826/1000 [=======================>......] - ETA: 52s - loss: 2.9405 - regression_loss: 2.3527 - classification_loss: 0.5878
 827/1000 [=======================>......] - ETA: 51s - loss: 2.9398 - regression_loss: 2.3522 - classification_loss: 0.5876
 828/1000 [=======================>......] - ETA: 51s - loss: 2.9398 - regression_loss: 2.3524 - classification_loss: 0.5875
 829/1000 [=======================>......] - ETA: 51s - loss: 2.9391 - regression_loss: 2.3518 - classification_loss: 0.5873
 830/1000 [=======================>......] - ETA: 50s - loss: 2.9383 - regression_loss: 2.3512 - classification_loss: 0.5871
 831/1000 [=======================>......] - ETA: 50s - loss: 2.9380 - regression_loss: 2.3510 - classification_loss: 0.5869
 832/1000 [=======================>......] - ETA: 50s - loss: 2.9382 - regression_loss: 2.3512 - classification_loss: 0.5870
 833/1000 [=======================>......] - ETA: 49s - loss: 2.9380 - regression_loss: 2.3510 - classification_loss: 0.5870
 834/1000 [========================>.....] - ETA: 49s - loss: 2.9380 - regression_loss: 2.3512 - classification_loss: 0.5868
 835/1000 [========================>.....] - ETA: 49s - loss: 2.9376 - regression_loss: 2.3510 - classification_loss: 0.5866
 836/1000 [========================>.....] - ETA: 49s - loss: 2.9380 - regression_loss: 2.3513 - classification_loss: 0.5867
 837/1000 [========================>.....] - ETA: 48s - loss: 2.9370 - regression_loss: 2.3507 - classification_loss: 0.5863
 838/1000 [========================>.....] - ETA: 48s - loss: 2.9353 - regression_loss: 2.3493 - classification_loss: 0.5860
 839/1000 [========================>.....] - ETA: 48s - loss: 2.9335 - regression_loss: 2.3480 - classification_loss: 0.5855
 840/1000 [========================>.....] - ETA: 47s - loss: 2.9314 - regression_loss: 2.3464 - classification_loss: 0.5850
 841/1000 [========================>.....] - ETA: 47s - loss: 2.9305 - regression_loss: 2.3458 - classification_loss: 0.5846
 842/1000 [========================>.....] - ETA: 47s - loss: 2.9299 - regression_loss: 2.3455 - classification_loss: 0.5843
 843/1000 [========================>.....] - ETA: 46s - loss: 2.9313 - regression_loss: 2.3466 - classification_loss: 0.5847
 844/1000 [========================>.....] - ETA: 46s - loss: 2.9303 - regression_loss: 2.3460 - classification_loss: 0.5843
 845/1000 [========================>.....] - ETA: 46s - loss: 2.9295 - regression_loss: 2.3454 - classification_loss: 0.5841
 846/1000 [========================>.....] - ETA: 45s - loss: 2.9285 - regression_loss: 2.3448 - classification_loss: 0.5837
 847/1000 [========================>.....] - ETA: 45s - loss: 2.9283 - regression_loss: 2.3448 - classification_loss: 0.5835
 848/1000 [========================>.....] - ETA: 45s - loss: 2.9282 - regression_loss: 2.3447 - classification_loss: 0.5835
 849/1000 [========================>.....] - ETA: 45s - loss: 2.9273 - regression_loss: 2.3440 - classification_loss: 0.5833
 850/1000 [========================>.....] - ETA: 44s - loss: 2.9271 - regression_loss: 2.3438 - classification_loss: 0.5833
 851/1000 [========================>.....] - ETA: 44s - loss: 2.9277 - regression_loss: 2.3441 - classification_loss: 0.5835
 852/1000 [========================>.....] - ETA: 44s - loss: 2.9266 - regression_loss: 2.3435 - classification_loss: 0.5832
 853/1000 [========================>.....] - ETA: 43s - loss: 2.9261 - regression_loss: 2.3433 - classification_loss: 0.5828
 854/1000 [========================>.....] - ETA: 43s - loss: 2.9255 - regression_loss: 2.3429 - classification_loss: 0.5826
 855/1000 [========================>.....] - ETA: 43s - loss: 2.9251 - regression_loss: 2.3426 - classification_loss: 0.5825
 856/1000 [========================>.....] - ETA: 42s - loss: 2.9239 - regression_loss: 2.3417 - classification_loss: 0.5822
 857/1000 [========================>.....] - ETA: 42s - loss: 2.9242 - regression_loss: 2.3421 - classification_loss: 0.5822
 858/1000 [========================>.....] - ETA: 42s - loss: 2.9233 - regression_loss: 2.3413 - classification_loss: 0.5819
 859/1000 [========================>.....] - ETA: 42s - loss: 2.9224 - regression_loss: 2.3408 - classification_loss: 0.5816
 860/1000 [========================>.....] - ETA: 41s - loss: 2.9216 - regression_loss: 2.3402 - classification_loss: 0.5814
 861/1000 [========================>.....] - ETA: 41s - loss: 2.9212 - regression_loss: 2.3401 - classification_loss: 0.5811
 862/1000 [========================>.....] - ETA: 41s - loss: 2.9206 - regression_loss: 2.3398 - classification_loss: 0.5809
 863/1000 [========================>.....] - ETA: 40s - loss: 2.9192 - regression_loss: 2.3387 - classification_loss: 0.5804
 864/1000 [========================>.....] - ETA: 40s - loss: 2.9182 - regression_loss: 2.3381 - classification_loss: 0.5801
 865/1000 [========================>.....] - ETA: 40s - loss: 2.9174 - regression_loss: 2.3372 - classification_loss: 0.5802
 866/1000 [========================>.....] - ETA: 39s - loss: 2.9171 - regression_loss: 2.3372 - classification_loss: 0.5799
 867/1000 [=========================>....] - ETA: 39s - loss: 2.9168 - regression_loss: 2.3372 - classification_loss: 0.5796
 868/1000 [=========================>....] - ETA: 39s - loss: 2.9154 - regression_loss: 2.3361 - classification_loss: 0.5792
 869/1000 [=========================>....] - ETA: 39s - loss: 2.9151 - regression_loss: 2.3356 - classification_loss: 0.5794
 870/1000 [=========================>....] - ETA: 38s - loss: 2.9137 - regression_loss: 2.3346 - classification_loss: 0.5791
 871/1000 [=========================>....] - ETA: 38s - loss: 2.9125 - regression_loss: 2.3338 - classification_loss: 0.5788
 872/1000 [=========================>....] - ETA: 38s - loss: 2.9117 - regression_loss: 2.3332 - classification_loss: 0.5784
 873/1000 [=========================>....] - ETA: 37s - loss: 2.9122 - regression_loss: 2.3338 - classification_loss: 0.5785
 874/1000 [=========================>....] - ETA: 37s - loss: 2.9111 - regression_loss: 2.3329 - classification_loss: 0.5782
 875/1000 [=========================>....] - ETA: 37s - loss: 2.9100 - regression_loss: 2.3322 - classification_loss: 0.5778
 876/1000 [=========================>....] - ETA: 36s - loss: 2.9097 - regression_loss: 2.3320 - classification_loss: 0.5777
 877/1000 [=========================>....] - ETA: 36s - loss: 2.9067 - regression_loss: 2.3293 - classification_loss: 0.5774
 878/1000 [=========================>....] - ETA: 36s - loss: 2.9067 - regression_loss: 2.3292 - classification_loss: 0.5775
 879/1000 [=========================>....] - ETA: 36s - loss: 2.9066 - regression_loss: 2.3295 - classification_loss: 0.5771
 880/1000 [=========================>....] - ETA: 35s - loss: 2.9066 - regression_loss: 2.3295 - classification_loss: 0.5771
 881/1000 [=========================>....] - ETA: 35s - loss: 2.9065 - regression_loss: 2.3294 - classification_loss: 0.5771
 882/1000 [=========================>....] - ETA: 35s - loss: 2.9049 - regression_loss: 2.3283 - classification_loss: 0.5767
 883/1000 [=========================>....] - ETA: 34s - loss: 2.9040 - regression_loss: 2.3276 - classification_loss: 0.5764
 884/1000 [=========================>....] - ETA: 34s - loss: 2.9028 - regression_loss: 2.3267 - classification_loss: 0.5761
 885/1000 [=========================>....] - ETA: 34s - loss: 2.9034 - regression_loss: 2.3271 - classification_loss: 0.5763
 886/1000 [=========================>....] - ETA: 33s - loss: 2.9029 - regression_loss: 2.3269 - classification_loss: 0.5761
 887/1000 [=========================>....] - ETA: 33s - loss: 2.9021 - regression_loss: 2.3262 - classification_loss: 0.5758
 888/1000 [=========================>....] - ETA: 33s - loss: 2.9011 - regression_loss: 2.3255 - classification_loss: 0.5755
 889/1000 [=========================>....] - ETA: 33s - loss: 2.9005 - regression_loss: 2.3253 - classification_loss: 0.5752
 890/1000 [=========================>....] - ETA: 32s - loss: 2.8995 - regression_loss: 2.3245 - classification_loss: 0.5750
 891/1000 [=========================>....] - ETA: 32s - loss: 2.8983 - regression_loss: 2.3238 - classification_loss: 0.5746
 892/1000 [=========================>....] - ETA: 32s - loss: 2.8974 - regression_loss: 2.3231 - classification_loss: 0.5743
 893/1000 [=========================>....] - ETA: 31s - loss: 2.8969 - regression_loss: 2.3229 - classification_loss: 0.5740
 894/1000 [=========================>....] - ETA: 31s - loss: 2.8962 - regression_loss: 2.3226 - classification_loss: 0.5737
 895/1000 [=========================>....] - ETA: 31s - loss: 2.8954 - regression_loss: 2.3220 - classification_loss: 0.5734
 896/1000 [=========================>....] - ETA: 30s - loss: 2.8938 - regression_loss: 2.3207 - classification_loss: 0.5731
 897/1000 [=========================>....] - ETA: 30s - loss: 2.8931 - regression_loss: 2.3201 - classification_loss: 0.5729
 898/1000 [=========================>....] - ETA: 30s - loss: 2.8923 - regression_loss: 2.3196 - classification_loss: 0.5727
 899/1000 [=========================>....] - ETA: 30s - loss: 2.8903 - regression_loss: 2.3181 - classification_loss: 0.5722
 900/1000 [==========================>...] - ETA: 29s - loss: 2.8898 - regression_loss: 2.3177 - classification_loss: 0.5721
 901/1000 [==========================>...] - ETA: 29s - loss: 2.8908 - regression_loss: 2.3189 - classification_loss: 0.5719
 902/1000 [==========================>...] - ETA: 29s - loss: 2.8897 - regression_loss: 2.3164 - classification_loss: 0.5733
 903/1000 [==========================>...] - ETA: 28s - loss: 2.8889 - regression_loss: 2.3158 - classification_loss: 0.5730
 904/1000 [==========================>...] - ETA: 28s - loss: 2.8883 - regression_loss: 2.3155 - classification_loss: 0.5728
 905/1000 [==========================>...] - ETA: 28s - loss: 2.8868 - regression_loss: 2.3143 - classification_loss: 0.5725
 906/1000 [==========================>...] - ETA: 27s - loss: 2.8861 - regression_loss: 2.3137 - classification_loss: 0.5724
 907/1000 [==========================>...] - ETA: 27s - loss: 2.8852 - regression_loss: 2.3132 - classification_loss: 0.5720
 908/1000 [==========================>...] - ETA: 27s - loss: 2.8839 - regression_loss: 2.3122 - classification_loss: 0.5716
 909/1000 [==========================>...] - ETA: 27s - loss: 2.8837 - regression_loss: 2.3121 - classification_loss: 0.5716
 910/1000 [==========================>...] - ETA: 26s - loss: 2.8819 - regression_loss: 2.3108 - classification_loss: 0.5711
 911/1000 [==========================>...] - ETA: 26s - loss: 2.8804 - regression_loss: 2.3097 - classification_loss: 0.5708
 912/1000 [==========================>...] - ETA: 26s - loss: 2.8790 - regression_loss: 2.3085 - classification_loss: 0.5705
 913/1000 [==========================>...] - ETA: 25s - loss: 2.8775 - regression_loss: 2.3074 - classification_loss: 0.5701
 914/1000 [==========================>...] - ETA: 25s - loss: 2.8778 - regression_loss: 2.3077 - classification_loss: 0.5701
 915/1000 [==========================>...] - ETA: 25s - loss: 2.8786 - regression_loss: 2.3082 - classification_loss: 0.5704
 916/1000 [==========================>...] - ETA: 25s - loss: 2.8786 - regression_loss: 2.3082 - classification_loss: 0.5704
 917/1000 [==========================>...] - ETA: 24s - loss: 2.8774 - regression_loss: 2.3074 - classification_loss: 0.5701
 918/1000 [==========================>...] - ETA: 24s - loss: 2.8759 - regression_loss: 2.3063 - classification_loss: 0.5697
 919/1000 [==========================>...] - ETA: 24s - loss: 2.8761 - regression_loss: 2.3065 - classification_loss: 0.5696
 920/1000 [==========================>...] - ETA: 23s - loss: 2.8748 - regression_loss: 2.3056 - classification_loss: 0.5692
 921/1000 [==========================>...] - ETA: 23s - loss: 2.8747 - regression_loss: 2.3057 - classification_loss: 0.5691
 922/1000 [==========================>...] - ETA: 23s - loss: 2.8757 - regression_loss: 2.3060 - classification_loss: 0.5697
 923/1000 [==========================>...] - ETA: 22s - loss: 2.8755 - regression_loss: 2.3059 - classification_loss: 0.5696
 924/1000 [==========================>...] - ETA: 22s - loss: 2.8762 - regression_loss: 2.3064 - classification_loss: 0.5698
 925/1000 [==========================>...] - ETA: 22s - loss: 2.8761 - regression_loss: 2.3062 - classification_loss: 0.5699
 926/1000 [==========================>...] - ETA: 22s - loss: 2.8750 - regression_loss: 2.3054 - classification_loss: 0.5696
 927/1000 [==========================>...] - ETA: 21s - loss: 2.8745 - regression_loss: 2.3050 - classification_loss: 0.5694
 928/1000 [==========================>...] - ETA: 21s - loss: 2.8740 - regression_loss: 2.3048 - classification_loss: 0.5692
 929/1000 [==========================>...] - ETA: 21s - loss: 2.8735 - regression_loss: 2.3044 - classification_loss: 0.5691
 930/1000 [==========================>...] - ETA: 20s - loss: 2.8726 - regression_loss: 2.3038 - classification_loss: 0.5688
 931/1000 [==========================>...] - ETA: 20s - loss: 2.8721 - regression_loss: 2.3035 - classification_loss: 0.5686
 932/1000 [==========================>...] - ETA: 20s - loss: 2.8717 - regression_loss: 2.3033 - classification_loss: 0.5684
 933/1000 [==========================>...] - ETA: 19s - loss: 2.8705 - regression_loss: 2.3026 - classification_loss: 0.5680
 934/1000 [===========================>..] - ETA: 19s - loss: 2.8703 - regression_loss: 2.3025 - classification_loss: 0.5678
 935/1000 [===========================>..] - ETA: 19s - loss: 2.8689 - regression_loss: 2.3015 - classification_loss: 0.5673
 936/1000 [===========================>..] - ETA: 19s - loss: 2.8688 - regression_loss: 2.3016 - classification_loss: 0.5671
 937/1000 [===========================>..] - ETA: 18s - loss: 2.8690 - regression_loss: 2.3016 - classification_loss: 0.5674
 938/1000 [===========================>..] - ETA: 18s - loss: 2.8677 - regression_loss: 2.3006 - classification_loss: 0.5671
 939/1000 [===========================>..] - ETA: 18s - loss: 2.8671 - regression_loss: 2.3000 - classification_loss: 0.5671
 940/1000 [===========================>..] - ETA: 17s - loss: 2.8657 - regression_loss: 2.2989 - classification_loss: 0.5668
 941/1000 [===========================>..] - ETA: 17s - loss: 2.8648 - regression_loss: 2.2983 - classification_loss: 0.5665
 942/1000 [===========================>..] - ETA: 17s - loss: 2.8637 - regression_loss: 2.2975 - classification_loss: 0.5662
 943/1000 [===========================>..] - ETA: 16s - loss: 2.8632 - regression_loss: 2.2973 - classification_loss: 0.5659
 944/1000 [===========================>..] - ETA: 16s - loss: 2.8674 - regression_loss: 2.3010 - classification_loss: 0.5665
 945/1000 [===========================>..] - ETA: 16s - loss: 2.8685 - regression_loss: 2.3018 - classification_loss: 0.5667
 946/1000 [===========================>..] - ETA: 16s - loss: 2.8691 - regression_loss: 2.3024 - classification_loss: 0.5667
 947/1000 [===========================>..] - ETA: 15s - loss: 2.8683 - regression_loss: 2.3018 - classification_loss: 0.5665
 948/1000 [===========================>..] - ETA: 15s - loss: 2.8675 - regression_loss: 2.3013 - classification_loss: 0.5662
 949/1000 [===========================>..] - ETA: 15s - loss: 2.8669 - regression_loss: 2.3008 - classification_loss: 0.5661
 950/1000 [===========================>..] - ETA: 14s - loss: 2.8671 - regression_loss: 2.3011 - classification_loss: 0.5660
 951/1000 [===========================>..] - ETA: 14s - loss: 2.8663 - regression_loss: 2.3005 - classification_loss: 0.5658
 952/1000 [===========================>..] - ETA: 14s - loss: 2.8648 - regression_loss: 2.2994 - classification_loss: 0.5654
 953/1000 [===========================>..] - ETA: 13s - loss: 2.8643 - regression_loss: 2.2990 - classification_loss: 0.5654
 954/1000 [===========================>..] - ETA: 13s - loss: 2.8634 - regression_loss: 2.2983 - classification_loss: 0.5651
 955/1000 [===========================>..] - ETA: 13s - loss: 2.8626 - regression_loss: 2.2977 - classification_loss: 0.5648
 956/1000 [===========================>..] - ETA: 13s - loss: 2.8616 - regression_loss: 2.2970 - classification_loss: 0.5645
 957/1000 [===========================>..] - ETA: 12s - loss: 2.8617 - regression_loss: 2.2972 - classification_loss: 0.5645
 958/1000 [===========================>..] - ETA: 12s - loss: 2.8612 - regression_loss: 2.2970 - classification_loss: 0.5642
 959/1000 [===========================>..] - ETA: 12s - loss: 2.8596 - regression_loss: 2.2956 - classification_loss: 0.5640
 960/1000 [===========================>..] - ETA: 11s - loss: 2.8588 - regression_loss: 2.2950 - classification_loss: 0.5639
 961/1000 [===========================>..] - ETA: 11s - loss: 2.8588 - regression_loss: 2.2950 - classification_loss: 0.5639
 962/1000 [===========================>..] - ETA: 11s - loss: 2.8583 - regression_loss: 2.2947 - classification_loss: 0.5636
 963/1000 [===========================>..] - ETA: 10s - loss: 2.8574 - regression_loss: 2.2941 - classification_loss: 0.5633
 964/1000 [===========================>..] - ETA: 10s - loss: 2.8580 - regression_loss: 2.2944 - classification_loss: 0.5636
 965/1000 [===========================>..] - ETA: 10s - loss: 2.8564 - regression_loss: 2.2932 - classification_loss: 0.5632
 966/1000 [===========================>..] - ETA: 10s - loss: 2.8551 - regression_loss: 2.2922 - classification_loss: 0.5630
 967/1000 [============================>.] - ETA: 9s - loss: 2.8537 - regression_loss: 2.2911 - classification_loss: 0.5626 
 968/1000 [============================>.] - ETA: 9s - loss: 2.8530 - regression_loss: 2.2906 - classification_loss: 0.5624
 969/1000 [============================>.] - ETA: 9s - loss: 2.8519 - regression_loss: 2.2899 - classification_loss: 0.5620
 970/1000 [============================>.] - ETA: 8s - loss: 2.8508 - regression_loss: 2.2890 - classification_loss: 0.5618
 971/1000 [============================>.] - ETA: 8s - loss: 2.8498 - regression_loss: 2.2882 - classification_loss: 0.5616
 972/1000 [============================>.] - ETA: 8s - loss: 2.8487 - regression_loss: 2.2873 - classification_loss: 0.5614
 973/1000 [============================>.] - ETA: 8s - loss: 2.8491 - regression_loss: 2.2875 - classification_loss: 0.5616
 974/1000 [============================>.] - ETA: 7s - loss: 2.8489 - regression_loss: 2.2876 - classification_loss: 0.5613
 975/1000 [============================>.] - ETA: 7s - loss: 2.8481 - regression_loss: 2.2871 - classification_loss: 0.5610
 976/1000 [============================>.] - ETA: 7s - loss: 2.8469 - regression_loss: 2.2863 - classification_loss: 0.5606
 977/1000 [============================>.] - ETA: 6s - loss: 2.8463 - regression_loss: 2.2860 - classification_loss: 0.5604
 978/1000 [============================>.] - ETA: 6s - loss: 2.8466 - regression_loss: 2.2861 - classification_loss: 0.5604
 979/1000 [============================>.] - ETA: 6s - loss: 2.8467 - regression_loss: 2.2863 - classification_loss: 0.5604
 980/1000 [============================>.] - ETA: 5s - loss: 2.8455 - regression_loss: 2.2854 - classification_loss: 0.5601
 981/1000 [============================>.] - ETA: 5s - loss: 2.8445 - regression_loss: 2.2847 - classification_loss: 0.5598
 982/1000 [============================>.] - ETA: 5s - loss: 2.8431 - regression_loss: 2.2836 - classification_loss: 0.5595
 983/1000 [============================>.] - ETA: 5s - loss: 2.8437 - regression_loss: 2.2839 - classification_loss: 0.5598
 984/1000 [============================>.] - ETA: 4s - loss: 2.8424 - regression_loss: 2.2831 - classification_loss: 0.5594
 985/1000 [============================>.] - ETA: 4s - loss: 2.8412 - regression_loss: 2.2822 - classification_loss: 0.5591
 986/1000 [============================>.] - ETA: 4s - loss: 2.8412 - regression_loss: 2.2822 - classification_loss: 0.5590
 987/1000 [============================>.] - ETA: 3s - loss: 2.8403 - regression_loss: 2.2815 - classification_loss: 0.5588
 988/1000 [============================>.] - ETA: 3s - loss: 2.8401 - regression_loss: 2.2814 - classification_loss: 0.5587
 989/1000 [============================>.] - ETA: 3s - loss: 2.8404 - regression_loss: 2.2817 - classification_loss: 0.5587
 990/1000 [============================>.] - ETA: 2s - loss: 2.8392 - regression_loss: 2.2808 - classification_loss: 0.5584
 991/1000 [============================>.] - ETA: 2s - loss: 2.8379 - regression_loss: 2.2797 - classification_loss: 0.5581
 992/1000 [============================>.] - ETA: 2s - loss: 2.8366 - regression_loss: 2.2788 - classification_loss: 0.5578
 993/1000 [============================>.] - ETA: 2s - loss: 2.8361 - regression_loss: 2.2784 - classification_loss: 0.5576
 994/1000 [============================>.] - ETA: 1s - loss: 2.8358 - regression_loss: 2.2783 - classification_loss: 0.5575
 995/1000 [============================>.] - ETA: 1s - loss: 2.8351 - regression_loss: 2.2778 - classification_loss: 0.5574
 996/1000 [============================>.] - ETA: 1s - loss: 2.8348 - regression_loss: 2.2774 - classification_loss: 0.5573
 997/1000 [============================>.] - ETA: 0s - loss: 2.8336 - regression_loss: 2.2765 - classification_loss: 0.5571
 998/1000 [============================>.] - ETA: 0s - loss: 2.8332 - regression_loss: 2.2762 - classification_loss: 0.5570
 999/1000 [============================>.] - ETA: 0s - loss: 2.8319 - regression_loss: 2.2752 - classification_loss: 0.5567
1000/1000 [==============================] - 297s 297ms/step - loss: 2.8316 - regression_loss: 2.2750 - classification_loss: 0.5566

Epoch 00001: saving model to ./snapshots/resnet50_csv_01.h5
Epoch 2/10

   1/1000 [..............................] - ETA: 4:47 - loss: 2.3082 - regression_loss: 2.0268 - classification_loss: 0.2814
   2/1000 [..............................] - ETA: 4:46 - loss: 1.9516 - regression_loss: 1.7011 - classification_loss: 0.2505
   3/1000 [..............................] - ETA: 4:46 - loss: 1.9724 - regression_loss: 1.7107 - classification_loss: 0.2618
   4/1000 [..............................] - ETA: 4:44 - loss: 2.1652 - regression_loss: 1.8526 - classification_loss: 0.3126
   5/1000 [..............................] - ETA: 4:43 - loss: 2.2796 - regression_loss: 1.9379 - classification_loss: 0.3416
   6/1000 [..............................] - ETA: 4:42 - loss: 2.3019 - regression_loss: 1.9560 - classification_loss: 0.3459
   7/1000 [..............................] - ETA: 4:44 - loss: 2.3095 - regression_loss: 1.9652 - classification_loss: 0.3443
   8/1000 [..............................] - ETA: 4:43 - loss: 2.2650 - regression_loss: 1.9328 - classification_loss: 0.3322
   9/1000 [..............................] - ETA: 4:42 - loss: 2.4067 - regression_loss: 2.0122 - classification_loss: 0.3945
  10/1000 [..............................] - ETA: 4:42 - loss: 2.3873 - regression_loss: 2.0048 - classification_loss: 0.3825
  11/1000 [..............................] - ETA: 4:41 - loss: 2.3918 - regression_loss: 2.0151 - classification_loss: 0.3766
  12/1000 [..............................] - ETA: 4:41 - loss: 2.3808 - regression_loss: 2.0064 - classification_loss: 0.3744
  13/1000 [..............................] - ETA: 4:40 - loss: 2.3407 - regression_loss: 1.9742 - classification_loss: 0.3665
  14/1000 [..............................] - ETA: 4:40 - loss: 2.2920 - regression_loss: 1.9377 - classification_loss: 0.3543
  15/1000 [..............................] - ETA: 4:39 - loss: 2.3366 - regression_loss: 1.9665 - classification_loss: 0.3700
  16/1000 [..............................] - ETA: 4:39 - loss: 2.2949 - regression_loss: 1.9197 - classification_loss: 0.3752
  17/1000 [..............................] - ETA: 4:38 - loss: 2.2881 - regression_loss: 1.9166 - classification_loss: 0.3715
  18/1000 [..............................] - ETA: 4:39 - loss: 2.2737 - regression_loss: 1.8954 - classification_loss: 0.3783
  19/1000 [..............................] - ETA: 4:39 - loss: 2.2768 - regression_loss: 1.8944 - classification_loss: 0.3824
  20/1000 [..............................] - ETA: 4:39 - loss: 2.3010 - regression_loss: 1.9130 - classification_loss: 0.3880
  21/1000 [..............................] - ETA: 4:38 - loss: 2.3008 - regression_loss: 1.9131 - classification_loss: 0.3877
  22/1000 [..............................] - ETA: 4:38 - loss: 2.2982 - regression_loss: 1.9123 - classification_loss: 0.3860
  23/1000 [..............................] - ETA: 4:38 - loss: 2.2980 - regression_loss: 1.9157 - classification_loss: 0.3823
  24/1000 [..............................] - ETA: 4:37 - loss: 2.3276 - regression_loss: 1.9386 - classification_loss: 0.3890
  25/1000 [..............................] - ETA: 4:37 - loss: 2.3290 - regression_loss: 1.9415 - classification_loss: 0.3875
  26/1000 [..............................] - ETA: 4:37 - loss: 2.3213 - regression_loss: 1.9378 - classification_loss: 0.3835
  27/1000 [..............................] - ETA: 4:36 - loss: 2.3081 - regression_loss: 1.9279 - classification_loss: 0.3802
  28/1000 [..............................] - ETA: 4:36 - loss: 2.3636 - regression_loss: 1.9776 - classification_loss: 0.3860
  29/1000 [..............................] - ETA: 4:36 - loss: 2.3314 - regression_loss: 1.9517 - classification_loss: 0.3797
  30/1000 [..............................] - ETA: 4:35 - loss: 2.3286 - regression_loss: 1.9495 - classification_loss: 0.3791
  31/1000 [..............................] - ETA: 4:35 - loss: 2.3261 - regression_loss: 1.9461 - classification_loss: 0.3799
  32/1000 [..............................] - ETA: 4:35 - loss: 2.3247 - regression_loss: 1.9444 - classification_loss: 0.3803
  33/1000 [..............................] - ETA: 4:35 - loss: 2.3227 - regression_loss: 1.9438 - classification_loss: 0.3789
  34/1000 [>.............................] - ETA: 4:35 - loss: 2.3449 - regression_loss: 1.9618 - classification_loss: 0.3831
  35/1000 [>.............................] - ETA: 4:34 - loss: 2.3669 - regression_loss: 1.9796 - classification_loss: 0.3873
  36/1000 [>.............................] - ETA: 4:34 - loss: 2.3835 - regression_loss: 1.9930 - classification_loss: 0.3905
  37/1000 [>.............................] - ETA: 4:34 - loss: 2.3745 - regression_loss: 1.9852 - classification_loss: 0.3893
  38/1000 [>.............................] - ETA: 4:33 - loss: 2.3709 - regression_loss: 1.9816 - classification_loss: 0.3893
  39/1000 [>.............................] - ETA: 4:33 - loss: 2.3968 - regression_loss: 1.9959 - classification_loss: 0.4009
  40/1000 [>.............................] - ETA: 4:33 - loss: 2.3746 - regression_loss: 1.9740 - classification_loss: 0.4005
  41/1000 [>.............................] - ETA: 4:33 - loss: 2.3828 - regression_loss: 1.9811 - classification_loss: 0.4017
  42/1000 [>.............................] - ETA: 4:32 - loss: 2.3808 - regression_loss: 1.9816 - classification_loss: 0.3991
  43/1000 [>.............................] - ETA: 4:32 - loss: 2.3826 - regression_loss: 1.9849 - classification_loss: 0.3977
  44/1000 [>.............................] - ETA: 4:35 - loss: 2.3850 - regression_loss: 1.9872 - classification_loss: 0.3978
  45/1000 [>.............................] - ETA: 4:35 - loss: 2.3910 - regression_loss: 1.9922 - classification_loss: 0.3987
  46/1000 [>.............................] - ETA: 4:34 - loss: 2.3860 - regression_loss: 1.9884 - classification_loss: 0.3976
  47/1000 [>.............................] - ETA: 4:34 - loss: 2.3877 - regression_loss: 1.9918 - classification_loss: 0.3959
  48/1000 [>.............................] - ETA: 4:34 - loss: 2.4073 - regression_loss: 2.0072 - classification_loss: 0.4000
  49/1000 [>.............................] - ETA: 4:33 - loss: 2.3971 - regression_loss: 1.9997 - classification_loss: 0.3974
  50/1000 [>.............................] - ETA: 4:33 - loss: 2.3798 - regression_loss: 1.9866 - classification_loss: 0.3932
  51/1000 [>.............................] - ETA: 4:33 - loss: 2.3742 - regression_loss: 1.9839 - classification_loss: 0.3903
  52/1000 [>.............................] - ETA: 4:32 - loss: 2.3836 - regression_loss: 1.9891 - classification_loss: 0.3945
  53/1000 [>.............................] - ETA: 4:32 - loss: 2.4032 - regression_loss: 2.0018 - classification_loss: 0.4015
  54/1000 [>.............................] - ETA: 4:32 - loss: 2.4171 - regression_loss: 2.0120 - classification_loss: 0.4052
  55/1000 [>.............................] - ETA: 4:31 - loss: 2.4255 - regression_loss: 2.0127 - classification_loss: 0.4128
  56/1000 [>.............................] - ETA: 4:31 - loss: 2.4376 - regression_loss: 2.0116 - classification_loss: 0.4260
  57/1000 [>.............................] - ETA: 4:31 - loss: 2.4541 - regression_loss: 2.0169 - classification_loss: 0.4372
  58/1000 [>.............................] - ETA: 4:30 - loss: 2.4401 - regression_loss: 2.0071 - classification_loss: 0.4330
  59/1000 [>.............................] - ETA: 4:30 - loss: 2.4271 - regression_loss: 1.9975 - classification_loss: 0.4296
  60/1000 [>.............................] - ETA: 4:29 - loss: 2.4363 - regression_loss: 2.0045 - classification_loss: 0.4318
  61/1000 [>.............................] - ETA: 4:29 - loss: 2.4300 - regression_loss: 2.0007 - classification_loss: 0.4293
  62/1000 [>.............................] - ETA: 4:29 - loss: 2.4293 - regression_loss: 1.9995 - classification_loss: 0.4298
  63/1000 [>.............................] - ETA: 4:29 - loss: 2.4102 - regression_loss: 1.9828 - classification_loss: 0.4275
  64/1000 [>.............................] - ETA: 4:28 - loss: 2.4130 - regression_loss: 1.9841 - classification_loss: 0.4289
  65/1000 [>.............................] - ETA: 4:28 - loss: 2.4093 - regression_loss: 1.9808 - classification_loss: 0.4285
  66/1000 [>.............................] - ETA: 4:28 - loss: 2.4024 - regression_loss: 1.9753 - classification_loss: 0.4272
  67/1000 [=>............................] - ETA: 4:28 - loss: 2.3905 - regression_loss: 1.9637 - classification_loss: 0.4268
  68/1000 [=>............................] - ETA: 4:27 - loss: 2.3896 - regression_loss: 1.9628 - classification_loss: 0.4268
  69/1000 [=>............................] - ETA: 4:27 - loss: 2.4011 - regression_loss: 1.9703 - classification_loss: 0.4309
  70/1000 [=>............................] - ETA: 4:27 - loss: 2.4109 - regression_loss: 1.9787 - classification_loss: 0.4322
  71/1000 [=>............................] - ETA: 4:27 - loss: 2.4037 - regression_loss: 1.9741 - classification_loss: 0.4296
  72/1000 [=>............................] - ETA: 4:26 - loss: 2.3969 - regression_loss: 1.9699 - classification_loss: 0.4271
  73/1000 [=>............................] - ETA: 4:26 - loss: 2.3886 - regression_loss: 1.9644 - classification_loss: 0.4242
  74/1000 [=>............................] - ETA: 4:25 - loss: 2.3779 - regression_loss: 1.9565 - classification_loss: 0.4213
  75/1000 [=>............................] - ETA: 4:25 - loss: 2.3815 - regression_loss: 1.9604 - classification_loss: 0.4211
  76/1000 [=>............................] - ETA: 4:25 - loss: 2.3776 - regression_loss: 1.9583 - classification_loss: 0.4193
  77/1000 [=>............................] - ETA: 4:25 - loss: 2.3679 - regression_loss: 1.9507 - classification_loss: 0.4172
  78/1000 [=>............................] - ETA: 4:24 - loss: 2.3693 - regression_loss: 1.9526 - classification_loss: 0.4167
  79/1000 [=>............................] - ETA: 4:24 - loss: 2.3752 - regression_loss: 1.9578 - classification_loss: 0.4174
  80/1000 [=>............................] - ETA: 4:24 - loss: 2.3794 - regression_loss: 1.9596 - classification_loss: 0.4197
  81/1000 [=>............................] - ETA: 4:24 - loss: 2.3803 - regression_loss: 1.9611 - classification_loss: 0.4192
  82/1000 [=>............................] - ETA: 4:23 - loss: 2.3736 - regression_loss: 1.9545 - classification_loss: 0.4191
  83/1000 [=>............................] - ETA: 4:23 - loss: 2.3684 - regression_loss: 1.9501 - classification_loss: 0.4183
  84/1000 [=>............................] - ETA: 4:23 - loss: 2.3747 - regression_loss: 1.9552 - classification_loss: 0.4195
  85/1000 [=>............................] - ETA: 4:22 - loss: 2.3730 - regression_loss: 1.9548 - classification_loss: 0.4181
  86/1000 [=>............................] - ETA: 4:22 - loss: 2.3680 - regression_loss: 1.9514 - classification_loss: 0.4166
  87/1000 [=>............................] - ETA: 4:22 - loss: 2.3565 - regression_loss: 1.9426 - classification_loss: 0.4139
  88/1000 [=>............................] - ETA: 4:21 - loss: 2.3585 - regression_loss: 1.9413 - classification_loss: 0.4172
  89/1000 [=>............................] - ETA: 4:21 - loss: 2.3559 - regression_loss: 1.9393 - classification_loss: 0.4166
  90/1000 [=>............................] - ETA: 4:21 - loss: 2.3512 - regression_loss: 1.9353 - classification_loss: 0.4159
  91/1000 [=>............................] - ETA: 4:21 - loss: 2.3680 - regression_loss: 1.9493 - classification_loss: 0.4187
  92/1000 [=>............................] - ETA: 4:20 - loss: 2.3753 - regression_loss: 1.9529 - classification_loss: 0.4224
  93/1000 [=>............................] - ETA: 4:20 - loss: 2.3652 - regression_loss: 1.9450 - classification_loss: 0.4201
  94/1000 [=>............................] - ETA: 4:20 - loss: 2.3567 - regression_loss: 1.9381 - classification_loss: 0.4186
  95/1000 [=>............................] - ETA: 4:19 - loss: 2.3571 - regression_loss: 1.9382 - classification_loss: 0.4189
  96/1000 [=>............................] - ETA: 4:19 - loss: 2.3545 - regression_loss: 1.9355 - classification_loss: 0.4190
  97/1000 [=>............................] - ETA: 4:19 - loss: 2.3478 - regression_loss: 1.9301 - classification_loss: 0.4177
  98/1000 [=>............................] - ETA: 4:18 - loss: 2.3505 - regression_loss: 1.9340 - classification_loss: 0.4164
  99/1000 [=>............................] - ETA: 4:18 - loss: 2.3554 - regression_loss: 1.9385 - classification_loss: 0.4169
 100/1000 [==>...........................] - ETA: 4:18 - loss: 2.3633 - regression_loss: 1.9432 - classification_loss: 0.4202
 101/1000 [==>...........................] - ETA: 4:18 - loss: 2.3651 - regression_loss: 1.9448 - classification_loss: 0.4203
 102/1000 [==>...........................] - ETA: 4:17 - loss: 2.3640 - regression_loss: 1.9446 - classification_loss: 0.4194
 103/1000 [==>...........................] - ETA: 4:17 - loss: 2.3737 - regression_loss: 1.9504 - classification_loss: 0.4233
 104/1000 [==>...........................] - ETA: 4:17 - loss: 2.3672 - regression_loss: 1.9455 - classification_loss: 0.4217
 105/1000 [==>...........................] - ETA: 4:17 - loss: 2.3757 - regression_loss: 1.9504 - classification_loss: 0.4253
 106/1000 [==>...........................] - ETA: 4:16 - loss: 2.3756 - regression_loss: 1.9503 - classification_loss: 0.4253
 107/1000 [==>...........................] - ETA: 4:16 - loss: 2.3789 - regression_loss: 1.9539 - classification_loss: 0.4251
 108/1000 [==>...........................] - ETA: 4:16 - loss: 2.3789 - regression_loss: 1.9547 - classification_loss: 0.4242
 109/1000 [==>...........................] - ETA: 4:15 - loss: 2.3781 - regression_loss: 1.9555 - classification_loss: 0.4226
 110/1000 [==>...........................] - ETA: 4:15 - loss: 2.3755 - regression_loss: 1.9543 - classification_loss: 0.4212
 111/1000 [==>...........................] - ETA: 4:15 - loss: 2.3791 - regression_loss: 1.9565 - classification_loss: 0.4226
 112/1000 [==>...........................] - ETA: 4:14 - loss: 2.3880 - regression_loss: 1.9639 - classification_loss: 0.4241
 113/1000 [==>...........................] - ETA: 4:14 - loss: 2.3852 - regression_loss: 1.9619 - classification_loss: 0.4233
 114/1000 [==>...........................] - ETA: 4:14 - loss: 2.3796 - regression_loss: 1.9578 - classification_loss: 0.4217
 115/1000 [==>...........................] - ETA: 4:13 - loss: 2.3756 - regression_loss: 1.9542 - classification_loss: 0.4215
 116/1000 [==>...........................] - ETA: 4:13 - loss: 2.3696 - regression_loss: 1.9494 - classification_loss: 0.4203
 117/1000 [==>...........................] - ETA: 4:13 - loss: 2.3669 - regression_loss: 1.9480 - classification_loss: 0.4189
 118/1000 [==>...........................] - ETA: 4:13 - loss: 2.3604 - regression_loss: 1.9426 - classification_loss: 0.4178
 119/1000 [==>...........................] - ETA: 4:12 - loss: 2.3656 - regression_loss: 1.9458 - classification_loss: 0.4198
 120/1000 [==>...........................] - ETA: 4:12 - loss: 2.3653 - regression_loss: 1.9468 - classification_loss: 0.4185
 121/1000 [==>...........................] - ETA: 4:12 - loss: 2.3574 - regression_loss: 1.9404 - classification_loss: 0.4169
 122/1000 [==>...........................] - ETA: 4:12 - loss: 2.3547 - regression_loss: 1.9387 - classification_loss: 0.4159
 123/1000 [==>...........................] - ETA: 4:11 - loss: 2.3500 - regression_loss: 1.9354 - classification_loss: 0.4146
 124/1000 [==>...........................] - ETA: 4:11 - loss: 2.3471 - regression_loss: 1.9343 - classification_loss: 0.4129
 125/1000 [==>...........................] - ETA: 4:11 - loss: 2.3441 - regression_loss: 1.9327 - classification_loss: 0.4114
 126/1000 [==>...........................] - ETA: 4:10 - loss: 2.3435 - regression_loss: 1.9321 - classification_loss: 0.4114
 127/1000 [==>...........................] - ETA: 4:10 - loss: 2.3423 - regression_loss: 1.9312 - classification_loss: 0.4111
 128/1000 [==>...........................] - ETA: 4:10 - loss: 2.3415 - regression_loss: 1.9311 - classification_loss: 0.4104
 129/1000 [==>...........................] - ETA: 4:10 - loss: 2.3367 - regression_loss: 1.9275 - classification_loss: 0.4092
 130/1000 [==>...........................] - ETA: 4:09 - loss: 2.3398 - regression_loss: 1.9306 - classification_loss: 0.4092
 131/1000 [==>...........................] - ETA: 4:09 - loss: 2.3387 - regression_loss: 1.9291 - classification_loss: 0.4096
 132/1000 [==>...........................] - ETA: 4:09 - loss: 2.3388 - regression_loss: 1.9289 - classification_loss: 0.4099
 133/1000 [==>...........................] - ETA: 4:08 - loss: 2.3348 - regression_loss: 1.9259 - classification_loss: 0.4089
 134/1000 [===>..........................] - ETA: 4:08 - loss: 2.3403 - regression_loss: 1.9293 - classification_loss: 0.4110
 135/1000 [===>..........................] - ETA: 4:08 - loss: 2.3391 - regression_loss: 1.9285 - classification_loss: 0.4106
 136/1000 [===>..........................] - ETA: 4:07 - loss: 2.3382 - regression_loss: 1.9281 - classification_loss: 0.4101
 137/1000 [===>..........................] - ETA: 4:07 - loss: 2.3389 - regression_loss: 1.9295 - classification_loss: 0.4094
 138/1000 [===>..........................] - ETA: 4:07 - loss: 2.3421 - regression_loss: 1.9324 - classification_loss: 0.4097
 139/1000 [===>..........................] - ETA: 4:06 - loss: 2.3434 - regression_loss: 1.9342 - classification_loss: 0.4093
 140/1000 [===>..........................] - ETA: 4:06 - loss: 2.3394 - regression_loss: 1.9315 - classification_loss: 0.4079
 141/1000 [===>..........................] - ETA: 4:06 - loss: 2.3400 - regression_loss: 1.9313 - classification_loss: 0.4087
 142/1000 [===>..........................] - ETA: 4:06 - loss: 2.3316 - regression_loss: 1.9249 - classification_loss: 0.4068
 143/1000 [===>..........................] - ETA: 4:05 - loss: 2.3257 - regression_loss: 1.9200 - classification_loss: 0.4057
 144/1000 [===>..........................] - ETA: 4:05 - loss: 2.3281 - regression_loss: 1.9215 - classification_loss: 0.4066
 145/1000 [===>..........................] - ETA: 4:05 - loss: 2.3302 - regression_loss: 1.9239 - classification_loss: 0.4063
 146/1000 [===>..........................] - ETA: 4:04 - loss: 2.3307 - regression_loss: 1.9246 - classification_loss: 0.4061
 147/1000 [===>..........................] - ETA: 4:04 - loss: 2.3324 - regression_loss: 1.9259 - classification_loss: 0.4064
 148/1000 [===>..........................] - ETA: 4:04 - loss: 2.3304 - regression_loss: 1.9247 - classification_loss: 0.4057
 149/1000 [===>..........................] - ETA: 4:04 - loss: 2.3275 - regression_loss: 1.9223 - classification_loss: 0.4051
 150/1000 [===>..........................] - ETA: 4:03 - loss: 2.3218 - regression_loss: 1.9182 - classification_loss: 0.4036
 151/1000 [===>..........................] - ETA: 4:03 - loss: 2.3218 - regression_loss: 1.9190 - classification_loss: 0.4028
 152/1000 [===>..........................] - ETA: 4:03 - loss: 2.3221 - regression_loss: 1.9194 - classification_loss: 0.4027
 153/1000 [===>..........................] - ETA: 4:02 - loss: 2.3208 - regression_loss: 1.9187 - classification_loss: 0.4021
 154/1000 [===>..........................] - ETA: 4:02 - loss: 2.3241 - regression_loss: 1.9215 - classification_loss: 0.4026
 155/1000 [===>..........................] - ETA: 4:02 - loss: 2.3168 - regression_loss: 1.9155 - classification_loss: 0.4013
 156/1000 [===>..........................] - ETA: 4:02 - loss: 2.3131 - regression_loss: 1.9126 - classification_loss: 0.4004
 157/1000 [===>..........................] - ETA: 4:01 - loss: 2.3150 - regression_loss: 1.9135 - classification_loss: 0.4015
 158/1000 [===>..........................] - ETA: 4:01 - loss: 2.3148 - regression_loss: 1.9136 - classification_loss: 0.4012
 159/1000 [===>..........................] - ETA: 4:01 - loss: 2.3099 - regression_loss: 1.9100 - classification_loss: 0.4000
 160/1000 [===>..........................] - ETA: 4:00 - loss: 2.3082 - regression_loss: 1.9088 - classification_loss: 0.3994
 161/1000 [===>..........................] - ETA: 4:00 - loss: 2.3119 - regression_loss: 1.9116 - classification_loss: 0.4003
 162/1000 [===>..........................] - ETA: 4:00 - loss: 2.3159 - regression_loss: 1.9146 - classification_loss: 0.4013
 163/1000 [===>..........................] - ETA: 4:00 - loss: 2.3164 - regression_loss: 1.9156 - classification_loss: 0.4008
 164/1000 [===>..........................] - ETA: 3:59 - loss: 2.3158 - regression_loss: 1.9155 - classification_loss: 0.4003
 165/1000 [===>..........................] - ETA: 3:59 - loss: 2.3102 - regression_loss: 1.9114 - classification_loss: 0.3988
 166/1000 [===>..........................] - ETA: 3:59 - loss: 2.3063 - regression_loss: 1.9085 - classification_loss: 0.3978
 167/1000 [====>.........................] - ETA: 3:58 - loss: 2.3052 - regression_loss: 1.9082 - classification_loss: 0.3970
 168/1000 [====>.........................] - ETA: 3:58 - loss: 2.3036 - regression_loss: 1.9075 - classification_loss: 0.3961
 169/1000 [====>.........................] - ETA: 3:58 - loss: 2.3028 - regression_loss: 1.9070 - classification_loss: 0.3958
 170/1000 [====>.........................] - ETA: 3:58 - loss: 2.3047 - regression_loss: 1.9084 - classification_loss: 0.3962
 171/1000 [====>.........................] - ETA: 3:57 - loss: 2.2990 - regression_loss: 1.9042 - classification_loss: 0.3948
 172/1000 [====>.........................] - ETA: 3:57 - loss: 2.2955 - regression_loss: 1.9007 - classification_loss: 0.3947
 173/1000 [====>.........................] - ETA: 3:57 - loss: 2.2918 - regression_loss: 1.8980 - classification_loss: 0.3938
 174/1000 [====>.........................] - ETA: 3:56 - loss: 2.2880 - regression_loss: 1.8955 - classification_loss: 0.3926
 175/1000 [====>.........................] - ETA: 3:56 - loss: 2.2891 - regression_loss: 1.8961 - classification_loss: 0.3930
 176/1000 [====>.........................] - ETA: 3:56 - loss: 2.2828 - regression_loss: 1.8907 - classification_loss: 0.3921
 177/1000 [====>.........................] - ETA: 3:55 - loss: 2.2791 - regression_loss: 1.8879 - classification_loss: 0.3912
 178/1000 [====>.........................] - ETA: 3:55 - loss: 2.2758 - regression_loss: 1.8856 - classification_loss: 0.3902
 179/1000 [====>.........................] - ETA: 3:55 - loss: 2.2715 - regression_loss: 1.8820 - classification_loss: 0.3894
 180/1000 [====>.........................] - ETA: 3:55 - loss: 2.2697 - regression_loss: 1.8808 - classification_loss: 0.3889
 181/1000 [====>.........................] - ETA: 3:54 - loss: 2.2660 - regression_loss: 1.8775 - classification_loss: 0.3885
 182/1000 [====>.........................] - ETA: 3:54 - loss: 2.2644 - regression_loss: 1.8764 - classification_loss: 0.3880
 183/1000 [====>.........................] - ETA: 3:54 - loss: 2.2619 - regression_loss: 1.8747 - classification_loss: 0.3872
 184/1000 [====>.........................] - ETA: 3:53 - loss: 2.2613 - regression_loss: 1.8738 - classification_loss: 0.3875
 185/1000 [====>.........................] - ETA: 3:53 - loss: 2.2628 - regression_loss: 1.8752 - classification_loss: 0.3876
 186/1000 [====>.........................] - ETA: 3:53 - loss: 2.2617 - regression_loss: 1.8748 - classification_loss: 0.3868
 187/1000 [====>.........................] - ETA: 3:52 - loss: 2.2694 - regression_loss: 1.8803 - classification_loss: 0.3892
 188/1000 [====>.........................] - ETA: 3:52 - loss: 2.2662 - regression_loss: 1.8783 - classification_loss: 0.3879
 189/1000 [====>.........................] - ETA: 3:52 - loss: 2.2637 - regression_loss: 1.8768 - classification_loss: 0.3870
 190/1000 [====>.........................] - ETA: 3:52 - loss: 2.2585 - regression_loss: 1.8728 - classification_loss: 0.3857
 191/1000 [====>.........................] - ETA: 3:51 - loss: 2.2548 - regression_loss: 1.8699 - classification_loss: 0.3849
 192/1000 [====>.........................] - ETA: 3:51 - loss: 2.2561 - regression_loss: 1.8720 - classification_loss: 0.3841
 193/1000 [====>.........................] - ETA: 3:51 - loss: 2.2535 - regression_loss: 1.8702 - classification_loss: 0.3833
 194/1000 [====>.........................] - ETA: 3:50 - loss: 2.2541 - regression_loss: 1.8702 - classification_loss: 0.3839
 195/1000 [====>.........................] - ETA: 3:50 - loss: 2.2510 - regression_loss: 1.8682 - classification_loss: 0.3829
 196/1000 [====>.........................] - ETA: 3:50 - loss: 2.2523 - regression_loss: 1.8687 - classification_loss: 0.3836
 197/1000 [====>.........................] - ETA: 3:50 - loss: 2.2515 - regression_loss: 1.8686 - classification_loss: 0.3829
 198/1000 [====>.........................] - ETA: 3:49 - loss: 2.2550 - regression_loss: 1.8713 - classification_loss: 0.3837
 199/1000 [====>.........................] - ETA: 3:49 - loss: 2.2593 - regression_loss: 1.8747 - classification_loss: 0.3847
 200/1000 [=====>........................] - ETA: 3:49 - loss: 2.2569 - regression_loss: 1.8728 - classification_loss: 0.3841
 201/1000 [=====>........................] - ETA: 3:48 - loss: 2.2535 - regression_loss: 1.8702 - classification_loss: 0.3834
 202/1000 [=====>........................] - ETA: 3:48 - loss: 2.2553 - regression_loss: 1.8718 - classification_loss: 0.3835
 203/1000 [=====>........................] - ETA: 3:48 - loss: 2.2593 - regression_loss: 1.8744 - classification_loss: 0.3849
 204/1000 [=====>........................] - ETA: 3:48 - loss: 2.2599 - regression_loss: 1.8753 - classification_loss: 0.3846
 205/1000 [=====>........................] - ETA: 3:47 - loss: 2.2572 - regression_loss: 1.8729 - classification_loss: 0.3843
 206/1000 [=====>........................] - ETA: 3:47 - loss: 2.2568 - regression_loss: 1.8728 - classification_loss: 0.3840
 207/1000 [=====>........................] - ETA: 3:47 - loss: 2.2541 - regression_loss: 1.8709 - classification_loss: 0.3832
 208/1000 [=====>........................] - ETA: 3:46 - loss: 2.2603 - regression_loss: 1.8757 - classification_loss: 0.3846
 209/1000 [=====>........................] - ETA: 3:46 - loss: 2.2593 - regression_loss: 1.8750 - classification_loss: 0.3843
 210/1000 [=====>........................] - ETA: 3:46 - loss: 2.2566 - regression_loss: 1.8721 - classification_loss: 0.3845
 211/1000 [=====>........................] - ETA: 3:46 - loss: 2.2581 - regression_loss: 1.8736 - classification_loss: 0.3845
 212/1000 [=====>........................] - ETA: 3:45 - loss: 2.2597 - regression_loss: 1.8749 - classification_loss: 0.3847
 213/1000 [=====>........................] - ETA: 3:45 - loss: 2.2596 - regression_loss: 1.8756 - classification_loss: 0.3841
 214/1000 [=====>........................] - ETA: 3:45 - loss: 2.2558 - regression_loss: 1.8728 - classification_loss: 0.3831
 215/1000 [=====>........................] - ETA: 3:45 - loss: 2.2540 - regression_loss: 1.8714 - classification_loss: 0.3826
 216/1000 [=====>........................] - ETA: 3:44 - loss: 2.2505 - regression_loss: 1.8687 - classification_loss: 0.3818
 217/1000 [=====>........................] - ETA: 3:44 - loss: 2.2533 - regression_loss: 1.8709 - classification_loss: 0.3823
 218/1000 [=====>........................] - ETA: 3:44 - loss: 2.2508 - regression_loss: 1.8690 - classification_loss: 0.3817
 219/1000 [=====>........................] - ETA: 3:43 - loss: 2.2479 - regression_loss: 1.8662 - classification_loss: 0.3817
 220/1000 [=====>........................] - ETA: 3:43 - loss: 2.2538 - regression_loss: 1.8722 - classification_loss: 0.3816
 221/1000 [=====>........................] - ETA: 3:43 - loss: 2.2585 - regression_loss: 1.8762 - classification_loss: 0.3823
 222/1000 [=====>........................] - ETA: 3:43 - loss: 2.2555 - regression_loss: 1.8735 - classification_loss: 0.3819
 223/1000 [=====>........................] - ETA: 3:42 - loss: 2.2590 - regression_loss: 1.8757 - classification_loss: 0.3833
 224/1000 [=====>........................] - ETA: 3:42 - loss: 2.2597 - regression_loss: 1.8765 - classification_loss: 0.3832
 225/1000 [=====>........................] - ETA: 3:42 - loss: 2.2580 - regression_loss: 1.8752 - classification_loss: 0.3828
 226/1000 [=====>........................] - ETA: 3:41 - loss: 2.2559 - regression_loss: 1.8737 - classification_loss: 0.3823
 227/1000 [=====>........................] - ETA: 3:41 - loss: 2.2540 - regression_loss: 1.8713 - classification_loss: 0.3827
 228/1000 [=====>........................] - ETA: 3:41 - loss: 2.2562 - regression_loss: 1.8730 - classification_loss: 0.3832
 229/1000 [=====>........................] - ETA: 3:41 - loss: 2.2587 - regression_loss: 1.8750 - classification_loss: 0.3838
 230/1000 [=====>........................] - ETA: 3:40 - loss: 2.2570 - regression_loss: 1.8736 - classification_loss: 0.3834
 231/1000 [=====>........................] - ETA: 3:40 - loss: 2.2554 - regression_loss: 1.8725 - classification_loss: 0.3828
 232/1000 [=====>........................] - ETA: 3:40 - loss: 2.2578 - regression_loss: 1.8745 - classification_loss: 0.3833
 233/1000 [=====>........................] - ETA: 3:39 - loss: 2.2588 - regression_loss: 1.8751 - classification_loss: 0.3837
 234/1000 [======>.......................] - ETA: 3:39 - loss: 2.2589 - regression_loss: 1.8755 - classification_loss: 0.3834
 235/1000 [======>.......................] - ETA: 3:39 - loss: 2.2566 - regression_loss: 1.8732 - classification_loss: 0.3833
 236/1000 [======>.......................] - ETA: 3:39 - loss: 2.2564 - regression_loss: 1.8735 - classification_loss: 0.3829
 237/1000 [======>.......................] - ETA: 3:38 - loss: 2.2575 - regression_loss: 1.8749 - classification_loss: 0.3826
 238/1000 [======>.......................] - ETA: 3:38 - loss: 2.2539 - regression_loss: 1.8720 - classification_loss: 0.3819
 239/1000 [======>.......................] - ETA: 3:38 - loss: 2.2572 - regression_loss: 1.8732 - classification_loss: 0.3840
 240/1000 [======>.......................] - ETA: 3:37 - loss: 2.2561 - regression_loss: 1.8726 - classification_loss: 0.3834
 241/1000 [======>.......................] - ETA: 3:37 - loss: 2.2548 - regression_loss: 1.8713 - classification_loss: 0.3835
 242/1000 [======>.......................] - ETA: 3:37 - loss: 2.2546 - regression_loss: 1.8716 - classification_loss: 0.3831
 243/1000 [======>.......................] - ETA: 3:36 - loss: 2.2557 - regression_loss: 1.8725 - classification_loss: 0.3832
 244/1000 [======>.......................] - ETA: 3:36 - loss: 2.2560 - regression_loss: 1.8728 - classification_loss: 0.3832
 245/1000 [======>.......................] - ETA: 3:36 - loss: 2.2528 - regression_loss: 1.8703 - classification_loss: 0.3825
 246/1000 [======>.......................] - ETA: 3:36 - loss: 2.2537 - regression_loss: 1.8703 - classification_loss: 0.3834
 247/1000 [======>.......................] - ETA: 3:35 - loss: 2.2529 - regression_loss: 1.8696 - classification_loss: 0.3833
 248/1000 [======>.......................] - ETA: 3:35 - loss: 2.2494 - regression_loss: 1.8666 - classification_loss: 0.3828
 249/1000 [======>.......................] - ETA: 3:35 - loss: 2.2522 - regression_loss: 1.8690 - classification_loss: 0.3832
 250/1000 [======>.......................] - ETA: 3:34 - loss: 2.2540 - regression_loss: 1.8706 - classification_loss: 0.3834
 251/1000 [======>.......................] - ETA: 3:34 - loss: 2.2540 - regression_loss: 1.8709 - classification_loss: 0.3831
 252/1000 [======>.......................] - ETA: 3:34 - loss: 2.2535 - regression_loss: 1.8704 - classification_loss: 0.3831
 253/1000 [======>.......................] - ETA: 3:34 - loss: 2.2509 - regression_loss: 1.8684 - classification_loss: 0.3825
 254/1000 [======>.......................] - ETA: 3:33 - loss: 2.2469 - regression_loss: 1.8650 - classification_loss: 0.3818
 255/1000 [======>.......................] - ETA: 3:33 - loss: 2.2413 - regression_loss: 1.8606 - classification_loss: 0.3807
 256/1000 [======>.......................] - ETA: 3:33 - loss: 2.2423 - regression_loss: 1.8619 - classification_loss: 0.3804
 257/1000 [======>.......................] - ETA: 3:32 - loss: 2.2391 - regression_loss: 1.8592 - classification_loss: 0.3799
 258/1000 [======>.......................] - ETA: 3:32 - loss: 2.2390 - regression_loss: 1.8592 - classification_loss: 0.3798
 259/1000 [======>.......................] - ETA: 3:32 - loss: 2.2367 - regression_loss: 1.8577 - classification_loss: 0.3791
 260/1000 [======>.......................] - ETA: 3:32 - loss: 2.2399 - regression_loss: 1.8601 - classification_loss: 0.3798
 261/1000 [======>.......................] - ETA: 3:31 - loss: 2.2377 - regression_loss: 1.8585 - classification_loss: 0.3792
 262/1000 [======>.......................] - ETA: 3:31 - loss: 2.2379 - regression_loss: 1.8589 - classification_loss: 0.3790
 263/1000 [======>.......................] - ETA: 3:31 - loss: 2.2377 - regression_loss: 1.8575 - classification_loss: 0.3801
 264/1000 [======>.......................] - ETA: 3:30 - loss: 2.2345 - regression_loss: 1.8551 - classification_loss: 0.3794
 265/1000 [======>.......................] - ETA: 3:30 - loss: 2.2344 - regression_loss: 1.8547 - classification_loss: 0.3797
 266/1000 [======>.......................] - ETA: 3:30 - loss: 2.2351 - regression_loss: 1.8551 - classification_loss: 0.3800
 267/1000 [=======>......................] - ETA: 3:30 - loss: 2.2337 - regression_loss: 1.8540 - classification_loss: 0.3797
 268/1000 [=======>......................] - ETA: 3:29 - loss: 2.2353 - regression_loss: 1.8552 - classification_loss: 0.3801
 269/1000 [=======>......................] - ETA: 3:29 - loss: 2.2329 - regression_loss: 1.8531 - classification_loss: 0.3798
 270/1000 [=======>......................] - ETA: 3:29 - loss: 2.2336 - regression_loss: 1.8542 - classification_loss: 0.3794
 271/1000 [=======>......................] - ETA: 3:29 - loss: 2.2323 - regression_loss: 1.8534 - classification_loss: 0.3789
 272/1000 [=======>......................] - ETA: 3:28 - loss: 2.2319 - regression_loss: 1.8534 - classification_loss: 0.3785
 273/1000 [=======>......................] - ETA: 3:28 - loss: 2.2295 - regression_loss: 1.8517 - classification_loss: 0.3778
 274/1000 [=======>......................] - ETA: 3:28 - loss: 2.2302 - regression_loss: 1.8523 - classification_loss: 0.3779
 275/1000 [=======>......................] - ETA: 3:27 - loss: 2.2302 - regression_loss: 1.8528 - classification_loss: 0.3774
 276/1000 [=======>......................] - ETA: 3:27 - loss: 2.2305 - regression_loss: 1.8531 - classification_loss: 0.3774
 277/1000 [=======>......................] - ETA: 3:27 - loss: 2.2304 - regression_loss: 1.8533 - classification_loss: 0.3771
 278/1000 [=======>......................] - ETA: 3:27 - loss: 2.2315 - regression_loss: 1.8543 - classification_loss: 0.3772
 279/1000 [=======>......................] - ETA: 3:26 - loss: 2.2296 - regression_loss: 1.8528 - classification_loss: 0.3768
 280/1000 [=======>......................] - ETA: 3:26 - loss: 2.2290 - regression_loss: 1.8521 - classification_loss: 0.3769
 281/1000 [=======>......................] - ETA: 3:26 - loss: 2.2287 - regression_loss: 1.8518 - classification_loss: 0.3769
 282/1000 [=======>......................] - ETA: 3:25 - loss: 2.2311 - regression_loss: 1.8543 - classification_loss: 0.3768
 283/1000 [=======>......................] - ETA: 3:25 - loss: 2.2309 - regression_loss: 1.8544 - classification_loss: 0.3765
 284/1000 [=======>......................] - ETA: 3:25 - loss: 2.2300 - regression_loss: 1.8540 - classification_loss: 0.3759
 285/1000 [=======>......................] - ETA: 3:24 - loss: 2.2330 - regression_loss: 1.8561 - classification_loss: 0.3769
 286/1000 [=======>......................] - ETA: 3:24 - loss: 2.2299 - regression_loss: 1.8528 - classification_loss: 0.3772
 287/1000 [=======>......................] - ETA: 3:24 - loss: 2.2297 - regression_loss: 1.8528 - classification_loss: 0.3769
 288/1000 [=======>......................] - ETA: 3:24 - loss: 2.2296 - regression_loss: 1.8523 - classification_loss: 0.3773
 289/1000 [=======>......................] - ETA: 3:23 - loss: 2.2266 - regression_loss: 1.8498 - classification_loss: 0.3767
 290/1000 [=======>......................] - ETA: 3:23 - loss: 2.2236 - regression_loss: 1.8472 - classification_loss: 0.3764
 291/1000 [=======>......................] - ETA: 3:23 - loss: 2.2275 - regression_loss: 1.8502 - classification_loss: 0.3773
 292/1000 [=======>......................] - ETA: 3:22 - loss: 2.2265 - regression_loss: 1.8496 - classification_loss: 0.3769
 293/1000 [=======>......................] - ETA: 3:22 - loss: 2.2259 - regression_loss: 1.8493 - classification_loss: 0.3766
 294/1000 [=======>......................] - ETA: 3:22 - loss: 2.2235 - regression_loss: 1.8476 - classification_loss: 0.3760
 295/1000 [=======>......................] - ETA: 3:22 - loss: 2.2219 - regression_loss: 1.8464 - classification_loss: 0.3755
 296/1000 [=======>......................] - ETA: 3:21 - loss: 2.2211 - regression_loss: 1.8457 - classification_loss: 0.3753
 297/1000 [=======>......................] - ETA: 3:21 - loss: 2.2200 - regression_loss: 1.8452 - classification_loss: 0.3748
 298/1000 [=======>......................] - ETA: 3:21 - loss: 2.2189 - regression_loss: 1.8442 - classification_loss: 0.3748
 299/1000 [=======>......................] - ETA: 3:20 - loss: 2.2220 - regression_loss: 1.8460 - classification_loss: 0.3760
 300/1000 [========>.....................] - ETA: 3:20 - loss: 2.2371 - regression_loss: 1.8575 - classification_loss: 0.3797
 301/1000 [========>.....................] - ETA: 3:20 - loss: 2.2351 - regression_loss: 1.8561 - classification_loss: 0.3790
 302/1000 [========>.....................] - ETA: 3:20 - loss: 2.2324 - regression_loss: 1.8539 - classification_loss: 0.3785
 303/1000 [========>.....................] - ETA: 3:19 - loss: 2.2318 - regression_loss: 1.8534 - classification_loss: 0.3784
 304/1000 [========>.....................] - ETA: 3:19 - loss: 2.2298 - regression_loss: 1.8514 - classification_loss: 0.3784
 305/1000 [========>.....................] - ETA: 3:19 - loss: 2.2296 - regression_loss: 1.8511 - classification_loss: 0.3785
 306/1000 [========>.....................] - ETA: 3:18 - loss: 2.2289 - regression_loss: 1.8506 - classification_loss: 0.3783
 307/1000 [========>.....................] - ETA: 3:18 - loss: 2.2261 - regression_loss: 1.8484 - classification_loss: 0.3777
 308/1000 [========>.....................] - ETA: 3:18 - loss: 2.2281 - regression_loss: 1.8498 - classification_loss: 0.3783
 309/1000 [========>.....................] - ETA: 3:18 - loss: 2.2273 - regression_loss: 1.8492 - classification_loss: 0.3781
 310/1000 [========>.....................] - ETA: 3:17 - loss: 2.2266 - regression_loss: 1.8489 - classification_loss: 0.3777
 311/1000 [========>.....................] - ETA: 3:17 - loss: 2.2258 - regression_loss: 1.8484 - classification_loss: 0.3775
 312/1000 [========>.....................] - ETA: 3:17 - loss: 2.2280 - regression_loss: 1.8498 - classification_loss: 0.3782
 313/1000 [========>.....................] - ETA: 3:16 - loss: 2.2313 - regression_loss: 1.8524 - classification_loss: 0.3789
 314/1000 [========>.....................] - ETA: 3:16 - loss: 2.2337 - regression_loss: 1.8543 - classification_loss: 0.3794
 315/1000 [========>.....................] - ETA: 3:16 - loss: 2.2322 - regression_loss: 1.8531 - classification_loss: 0.3791
 316/1000 [========>.....................] - ETA: 3:16 - loss: 2.2317 - regression_loss: 1.8527 - classification_loss: 0.3790
 317/1000 [========>.....................] - ETA: 3:15 - loss: 2.2295 - regression_loss: 1.8508 - classification_loss: 0.3787
 318/1000 [========>.....................] - ETA: 3:15 - loss: 2.2265 - regression_loss: 1.8484 - classification_loss: 0.3781
 319/1000 [========>.....................] - ETA: 3:15 - loss: 2.2253 - regression_loss: 1.8475 - classification_loss: 0.3778
 320/1000 [========>.....................] - ETA: 3:14 - loss: 2.2250 - regression_loss: 1.8474 - classification_loss: 0.3776
 321/1000 [========>.....................] - ETA: 3:14 - loss: 2.2249 - regression_loss: 1.8477 - classification_loss: 0.3772
 322/1000 [========>.....................] - ETA: 3:14 - loss: 2.2238 - regression_loss: 1.8461 - classification_loss: 0.3777
 323/1000 [========>.....................] - ETA: 3:14 - loss: 2.2239 - regression_loss: 1.8464 - classification_loss: 0.3774
 324/1000 [========>.....................] - ETA: 3:13 - loss: 2.2213 - regression_loss: 1.8444 - classification_loss: 0.3769
 325/1000 [========>.....................] - ETA: 3:13 - loss: 2.2204 - regression_loss: 1.8436 - classification_loss: 0.3768
 326/1000 [========>.....................] - ETA: 3:13 - loss: 2.2235 - regression_loss: 1.8462 - classification_loss: 0.3773
 327/1000 [========>.....................] - ETA: 3:12 - loss: 2.2228 - regression_loss: 1.8456 - classification_loss: 0.3772
 328/1000 [========>.....................] - ETA: 3:12 - loss: 2.2241 - regression_loss: 1.8472 - classification_loss: 0.3769
 329/1000 [========>.....................] - ETA: 3:12 - loss: 2.2219 - regression_loss: 1.8456 - classification_loss: 0.3763
 330/1000 [========>.....................] - ETA: 3:12 - loss: 2.2227 - regression_loss: 1.8466 - classification_loss: 0.3761
 331/1000 [========>.....................] - ETA: 3:11 - loss: 2.2201 - regression_loss: 1.8445 - classification_loss: 0.3756
 332/1000 [========>.....................] - ETA: 3:11 - loss: 2.2216 - regression_loss: 1.8454 - classification_loss: 0.3762
 333/1000 [========>.....................] - ETA: 3:11 - loss: 2.2182 - regression_loss: 1.8426 - classification_loss: 0.3757
 334/1000 [=========>....................] - ETA: 3:10 - loss: 2.2152 - regression_loss: 1.8402 - classification_loss: 0.3750
 335/1000 [=========>....................] - ETA: 3:10 - loss: 2.2143 - regression_loss: 1.8393 - classification_loss: 0.3750
 336/1000 [=========>....................] - ETA: 3:10 - loss: 2.2154 - regression_loss: 1.8403 - classification_loss: 0.3752
 337/1000 [=========>....................] - ETA: 3:10 - loss: 2.2172 - regression_loss: 1.8421 - classification_loss: 0.3751
 338/1000 [=========>....................] - ETA: 3:09 - loss: 2.2186 - regression_loss: 1.8432 - classification_loss: 0.3754
 339/1000 [=========>....................] - ETA: 3:09 - loss: 2.2173 - regression_loss: 1.8424 - classification_loss: 0.3749
 340/1000 [=========>....................] - ETA: 3:09 - loss: 2.2158 - regression_loss: 1.8412 - classification_loss: 0.3745
 341/1000 [=========>....................] - ETA: 3:08 - loss: 2.2152 - regression_loss: 1.8406 - classification_loss: 0.3747
 342/1000 [=========>....................] - ETA: 3:08 - loss: 2.2163 - regression_loss: 1.8413 - classification_loss: 0.3750
 343/1000 [=========>....................] - ETA: 3:08 - loss: 2.2154 - regression_loss: 1.8408 - classification_loss: 0.3745
 344/1000 [=========>....................] - ETA: 3:08 - loss: 2.2143 - regression_loss: 1.8401 - classification_loss: 0.3742
 345/1000 [=========>....................] - ETA: 3:07 - loss: 2.2118 - regression_loss: 1.8380 - classification_loss: 0.3738
 346/1000 [=========>....................] - ETA: 3:07 - loss: 2.2106 - regression_loss: 1.8372 - classification_loss: 0.3734
 347/1000 [=========>....................] - ETA: 3:07 - loss: 2.2092 - regression_loss: 1.8360 - classification_loss: 0.3732
 348/1000 [=========>....................] - ETA: 3:06 - loss: 2.2082 - regression_loss: 1.8354 - classification_loss: 0.3728
 349/1000 [=========>....................] - ETA: 3:06 - loss: 2.2091 - regression_loss: 1.8365 - classification_loss: 0.3726
 350/1000 [=========>....................] - ETA: 3:06 - loss: 2.2085 - regression_loss: 1.8361 - classification_loss: 0.3723
 351/1000 [=========>....................] - ETA: 3:06 - loss: 2.2086 - regression_loss: 1.8364 - classification_loss: 0.3722
 352/1000 [=========>....................] - ETA: 3:05 - loss: 2.2100 - regression_loss: 1.8375 - classification_loss: 0.3725
 353/1000 [=========>....................] - ETA: 3:05 - loss: 2.2100 - regression_loss: 1.8373 - classification_loss: 0.3726
 354/1000 [=========>....................] - ETA: 3:05 - loss: 2.2099 - regression_loss: 1.8374 - classification_loss: 0.3725
 355/1000 [=========>....................] - ETA: 3:04 - loss: 2.2079 - regression_loss: 1.8359 - classification_loss: 0.3720
 356/1000 [=========>....................] - ETA: 3:04 - loss: 2.2076 - regression_loss: 1.8359 - classification_loss: 0.3717
 357/1000 [=========>....................] - ETA: 3:04 - loss: 2.2087 - regression_loss: 1.8367 - classification_loss: 0.3719
 358/1000 [=========>....................] - ETA: 3:04 - loss: 2.2077 - regression_loss: 1.8361 - classification_loss: 0.3716
 359/1000 [=========>....................] - ETA: 3:03 - loss: 2.2057 - regression_loss: 1.8347 - classification_loss: 0.3711
 360/1000 [=========>....................] - ETA: 3:03 - loss: 2.2047 - regression_loss: 1.8340 - classification_loss: 0.3707
 361/1000 [=========>....................] - ETA: 3:03 - loss: 2.2067 - regression_loss: 1.8354 - classification_loss: 0.3713
 362/1000 [=========>....................] - ETA: 3:02 - loss: 2.2054 - regression_loss: 1.8343 - classification_loss: 0.3710
 363/1000 [=========>....................] - ETA: 3:02 - loss: 2.2061 - regression_loss: 1.8347 - classification_loss: 0.3714
 364/1000 [=========>....................] - ETA: 3:02 - loss: 2.2034 - regression_loss: 1.8327 - classification_loss: 0.3707
 365/1000 [=========>....................] - ETA: 3:01 - loss: 2.1999 - regression_loss: 1.8297 - classification_loss: 0.3702
 366/1000 [=========>....................] - ETA: 3:01 - loss: 2.1989 - regression_loss: 1.8291 - classification_loss: 0.3698
 367/1000 [==========>...................] - ETA: 3:01 - loss: 2.1985 - regression_loss: 1.8291 - classification_loss: 0.3694
 368/1000 [==========>...................] - ETA: 3:01 - loss: 2.1966 - regression_loss: 1.8277 - classification_loss: 0.3689
 369/1000 [==========>...................] - ETA: 3:00 - loss: 2.1980 - regression_loss: 1.8281 - classification_loss: 0.3698
 370/1000 [==========>...................] - ETA: 3:00 - loss: 2.1962 - regression_loss: 1.8269 - classification_loss: 0.3693
 371/1000 [==========>...................] - ETA: 3:00 - loss: 2.1958 - regression_loss: 1.8264 - classification_loss: 0.3693
 372/1000 [==========>...................] - ETA: 2:59 - loss: 2.1973 - regression_loss: 1.8272 - classification_loss: 0.3701
 373/1000 [==========>...................] - ETA: 2:59 - loss: 2.1969 - regression_loss: 1.8271 - classification_loss: 0.3698
 374/1000 [==========>...................] - ETA: 2:59 - loss: 2.1951 - regression_loss: 1.8253 - classification_loss: 0.3698
 375/1000 [==========>...................] - ETA: 2:59 - loss: 2.1930 - regression_loss: 1.8238 - classification_loss: 0.3691
 376/1000 [==========>...................] - ETA: 2:58 - loss: 2.1901 - regression_loss: 1.8215 - classification_loss: 0.3686
 377/1000 [==========>...................] - ETA: 2:58 - loss: 2.1918 - regression_loss: 1.8230 - classification_loss: 0.3688
 378/1000 [==========>...................] - ETA: 2:58 - loss: 2.1921 - regression_loss: 1.8232 - classification_loss: 0.3689
 379/1000 [==========>...................] - ETA: 2:57 - loss: 2.1899 - regression_loss: 1.8215 - classification_loss: 0.3685
 380/1000 [==========>...................] - ETA: 2:57 - loss: 2.1873 - regression_loss: 1.8192 - classification_loss: 0.3681
 381/1000 [==========>...................] - ETA: 2:57 - loss: 2.1850 - regression_loss: 1.8174 - classification_loss: 0.3676
 382/1000 [==========>...................] - ETA: 2:57 - loss: 2.1853 - regression_loss: 1.8179 - classification_loss: 0.3674
 383/1000 [==========>...................] - ETA: 2:56 - loss: 2.1841 - regression_loss: 1.8170 - classification_loss: 0.3671
 384/1000 [==========>...................] - ETA: 2:56 - loss: 2.1834 - regression_loss: 1.8164 - classification_loss: 0.3670
 385/1000 [==========>...................] - ETA: 2:56 - loss: 2.1822 - regression_loss: 1.8154 - classification_loss: 0.3667
 386/1000 [==========>...................] - ETA: 2:55 - loss: 2.1790 - regression_loss: 1.8126 - classification_loss: 0.3664
 387/1000 [==========>...................] - ETA: 2:55 - loss: 2.1777 - regression_loss: 1.8113 - classification_loss: 0.3664
 388/1000 [==========>...................] - ETA: 2:55 - loss: 2.1767 - regression_loss: 1.8104 - classification_loss: 0.3663
 389/1000 [==========>...................] - ETA: 2:55 - loss: 2.1779 - regression_loss: 1.8112 - classification_loss: 0.3667
 390/1000 [==========>...................] - ETA: 2:54 - loss: 2.1763 - regression_loss: 1.8100 - classification_loss: 0.3663
 391/1000 [==========>...................] - ETA: 2:54 - loss: 2.1781 - regression_loss: 1.8117 - classification_loss: 0.3664
 392/1000 [==========>...................] - ETA: 2:54 - loss: 2.1782 - regression_loss: 1.8118 - classification_loss: 0.3664
 393/1000 [==========>...................] - ETA: 2:53 - loss: 2.1761 - regression_loss: 1.8097 - classification_loss: 0.3664
 394/1000 [==========>...................] - ETA: 2:53 - loss: 2.1739 - regression_loss: 1.8081 - classification_loss: 0.3658
 395/1000 [==========>...................] - ETA: 2:53 - loss: 2.1727 - regression_loss: 1.8072 - classification_loss: 0.3655
 396/1000 [==========>...................] - ETA: 2:53 - loss: 2.1717 - regression_loss: 1.8065 - classification_loss: 0.3652
 397/1000 [==========>...................] - ETA: 2:52 - loss: 2.1707 - regression_loss: 1.8058 - classification_loss: 0.3650
 398/1000 [==========>...................] - ETA: 2:52 - loss: 2.1694 - regression_loss: 1.8048 - classification_loss: 0.3645
 399/1000 [==========>...................] - ETA: 2:52 - loss: 2.1678 - regression_loss: 1.8035 - classification_loss: 0.3643
 400/1000 [===========>..................] - ETA: 2:51 - loss: 2.1679 - regression_loss: 1.8037 - classification_loss: 0.3641
 401/1000 [===========>..................] - ETA: 2:51 - loss: 2.1691 - regression_loss: 1.8048 - classification_loss: 0.3643
 402/1000 [===========>..................] - ETA: 2:51 - loss: 2.1668 - regression_loss: 1.8030 - classification_loss: 0.3638
 403/1000 [===========>..................] - ETA: 2:51 - loss: 2.1656 - regression_loss: 1.8022 - classification_loss: 0.3634
 404/1000 [===========>..................] - ETA: 2:50 - loss: 2.1647 - regression_loss: 1.8018 - classification_loss: 0.3629
 405/1000 [===========>..................] - ETA: 2:50 - loss: 2.1650 - regression_loss: 1.8021 - classification_loss: 0.3629
 406/1000 [===========>..................] - ETA: 2:50 - loss: 2.1672 - regression_loss: 1.8043 - classification_loss: 0.3629
 407/1000 [===========>..................] - ETA: 2:49 - loss: 2.1666 - regression_loss: 1.8038 - classification_loss: 0.3628
 408/1000 [===========>..................] - ETA: 2:49 - loss: 2.1671 - regression_loss: 1.8043 - classification_loss: 0.3628
 409/1000 [===========>..................] - ETA: 2:49 - loss: 2.1658 - regression_loss: 1.8032 - classification_loss: 0.3626
 410/1000 [===========>..................] - ETA: 2:49 - loss: 2.1648 - regression_loss: 1.8024 - classification_loss: 0.3624
 411/1000 [===========>..................] - ETA: 2:48 - loss: 2.1636 - regression_loss: 1.8015 - classification_loss: 0.3620
 412/1000 [===========>..................] - ETA: 2:48 - loss: 2.1648 - regression_loss: 1.8024 - classification_loss: 0.3624
 413/1000 [===========>..................] - ETA: 2:48 - loss: 2.1637 - regression_loss: 1.8016 - classification_loss: 0.3621
 414/1000 [===========>..................] - ETA: 2:47 - loss: 2.1633 - regression_loss: 1.8014 - classification_loss: 0.3619
 415/1000 [===========>..................] - ETA: 2:47 - loss: 2.1607 - regression_loss: 1.7994 - classification_loss: 0.3613
 416/1000 [===========>..................] - ETA: 2:47 - loss: 2.1607 - regression_loss: 1.7988 - classification_loss: 0.3620
 417/1000 [===========>..................] - ETA: 2:47 - loss: 2.1615 - regression_loss: 1.7994 - classification_loss: 0.3621
 418/1000 [===========>..................] - ETA: 2:46 - loss: 2.1631 - regression_loss: 1.8005 - classification_loss: 0.3627
 419/1000 [===========>..................] - ETA: 2:46 - loss: 2.1623 - regression_loss: 1.8000 - classification_loss: 0.3623
 420/1000 [===========>..................] - ETA: 2:46 - loss: 2.1641 - regression_loss: 1.8019 - classification_loss: 0.3622
 421/1000 [===========>..................] - ETA: 2:45 - loss: 2.1638 - regression_loss: 1.8014 - classification_loss: 0.3624
 422/1000 [===========>..................] - ETA: 2:45 - loss: 2.1638 - regression_loss: 1.8016 - classification_loss: 0.3622
 423/1000 [===========>..................] - ETA: 2:45 - loss: 2.1632 - regression_loss: 1.8015 - classification_loss: 0.3618
 424/1000 [===========>..................] - ETA: 2:45 - loss: 2.1626 - regression_loss: 1.8013 - classification_loss: 0.3613
 425/1000 [===========>..................] - ETA: 2:44 - loss: 2.1637 - regression_loss: 1.8023 - classification_loss: 0.3615
 426/1000 [===========>..................] - ETA: 2:44 - loss: 2.1617 - regression_loss: 1.8007 - classification_loss: 0.3610
 427/1000 [===========>..................] - ETA: 2:44 - loss: 2.1598 - regression_loss: 1.7992 - classification_loss: 0.3606
 428/1000 [===========>..................] - ETA: 2:43 - loss: 2.1609 - regression_loss: 1.8006 - classification_loss: 0.3603
 429/1000 [===========>..................] - ETA: 2:43 - loss: 2.1602 - regression_loss: 1.8001 - classification_loss: 0.3601
 430/1000 [===========>..................] - ETA: 2:43 - loss: 2.1607 - regression_loss: 1.8008 - classification_loss: 0.3599
 431/1000 [===========>..................] - ETA: 2:43 - loss: 2.1594 - regression_loss: 1.7998 - classification_loss: 0.3596
 432/1000 [===========>..................] - ETA: 2:42 - loss: 2.1597 - regression_loss: 1.8002 - classification_loss: 0.3594
 433/1000 [===========>..................] - ETA: 2:42 - loss: 2.1592 - regression_loss: 1.8000 - classification_loss: 0.3593
 434/1000 [============>.................] - ETA: 2:42 - loss: 2.1593 - regression_loss: 1.7999 - classification_loss: 0.3594
 435/1000 [============>.................] - ETA: 2:41 - loss: 2.1594 - regression_loss: 1.8003 - classification_loss: 0.3591
 436/1000 [============>.................] - ETA: 2:41 - loss: 2.1572 - regression_loss: 1.7984 - classification_loss: 0.3588
 437/1000 [============>.................] - ETA: 2:41 - loss: 2.1579 - regression_loss: 1.7991 - classification_loss: 0.3588
 438/1000 [============>.................] - ETA: 2:41 - loss: 2.1573 - regression_loss: 1.7983 - classification_loss: 0.3590
 439/1000 [============>.................] - ETA: 2:40 - loss: 2.1552 - regression_loss: 1.7966 - classification_loss: 0.3586
 440/1000 [============>.................] - ETA: 2:40 - loss: 2.1571 - regression_loss: 1.7983 - classification_loss: 0.3589
 441/1000 [============>.................] - ETA: 2:40 - loss: 2.1549 - regression_loss: 1.7963 - classification_loss: 0.3586
 442/1000 [============>.................] - ETA: 2:39 - loss: 2.1552 - regression_loss: 1.7967 - classification_loss: 0.3586
 443/1000 [============>.................] - ETA: 2:39 - loss: 2.1525 - regression_loss: 1.7942 - classification_loss: 0.3583
 444/1000 [============>.................] - ETA: 2:39 - loss: 2.1521 - regression_loss: 1.7934 - classification_loss: 0.3587
 445/1000 [============>.................] - ETA: 2:39 - loss: 2.1499 - regression_loss: 1.7916 - classification_loss: 0.3584
 446/1000 [============>.................] - ETA: 2:38 - loss: 2.1501 - regression_loss: 1.7917 - classification_loss: 0.3584
 447/1000 [============>.................] - ETA: 2:38 - loss: 2.1472 - regression_loss: 1.7893 - classification_loss: 0.3579
 448/1000 [============>.................] - ETA: 2:38 - loss: 2.1487 - regression_loss: 1.7900 - classification_loss: 0.3587
 449/1000 [============>.................] - ETA: 2:37 - loss: 2.1476 - regression_loss: 1.7890 - classification_loss: 0.3586
 450/1000 [============>.................] - ETA: 2:37 - loss: 2.1475 - regression_loss: 1.7888 - classification_loss: 0.3586
 451/1000 [============>.................] - ETA: 2:37 - loss: 2.1479 - regression_loss: 1.7892 - classification_loss: 0.3587
 452/1000 [============>.................] - ETA: 2:37 - loss: 2.1460 - regression_loss: 1.7877 - classification_loss: 0.3583
 453/1000 [============>.................] - ETA: 2:36 - loss: 2.1438 - regression_loss: 1.7859 - classification_loss: 0.3578
 454/1000 [============>.................] - ETA: 2:36 - loss: 2.1434 - regression_loss: 1.7856 - classification_loss: 0.3578
 455/1000 [============>.................] - ETA: 2:36 - loss: 2.1420 - regression_loss: 1.7844 - classification_loss: 0.3576
 456/1000 [============>.................] - ETA: 2:35 - loss: 2.1429 - regression_loss: 1.7850 - classification_loss: 0.3579
 457/1000 [============>.................] - ETA: 2:35 - loss: 2.1417 - regression_loss: 1.7840 - classification_loss: 0.3577
 458/1000 [============>.................] - ETA: 2:35 - loss: 2.1405 - regression_loss: 1.7832 - classification_loss: 0.3573
 459/1000 [============>.................] - ETA: 2:35 - loss: 2.1403 - regression_loss: 1.7831 - classification_loss: 0.3572
 460/1000 [============>.................] - ETA: 2:34 - loss: 2.1400 - regression_loss: 1.7829 - classification_loss: 0.3571
 461/1000 [============>.................] - ETA: 2:34 - loss: 2.1382 - regression_loss: 1.7815 - classification_loss: 0.3567
 462/1000 [============>.................] - ETA: 2:34 - loss: 2.1405 - regression_loss: 1.7828 - classification_loss: 0.3577
 463/1000 [============>.................] - ETA: 2:33 - loss: 2.1408 - regression_loss: 1.7832 - classification_loss: 0.3577
 464/1000 [============>.................] - ETA: 2:33 - loss: 2.1407 - regression_loss: 1.7827 - classification_loss: 0.3580
 465/1000 [============>.................] - ETA: 2:33 - loss: 2.1395 - regression_loss: 1.7819 - classification_loss: 0.3577
 466/1000 [============>.................] - ETA: 2:33 - loss: 2.1396 - regression_loss: 1.7819 - classification_loss: 0.3577
 467/1000 [=============>................] - ETA: 2:32 - loss: 2.1389 - regression_loss: 1.7812 - classification_loss: 0.3577
 468/1000 [=============>................] - ETA: 2:32 - loss: 2.1397 - regression_loss: 1.7819 - classification_loss: 0.3579
 469/1000 [=============>................] - ETA: 2:32 - loss: 2.1427 - regression_loss: 1.7836 - classification_loss: 0.3590
 470/1000 [=============>................] - ETA: 2:31 - loss: 2.1429 - regression_loss: 1.7838 - classification_loss: 0.3591
 471/1000 [=============>................] - ETA: 2:31 - loss: 2.1423 - regression_loss: 1.7833 - classification_loss: 0.3590
 472/1000 [=============>................] - ETA: 2:31 - loss: 2.1412 - regression_loss: 1.7824 - classification_loss: 0.3588
 473/1000 [=============>................] - ETA: 2:31 - loss: 2.1427 - regression_loss: 1.7838 - classification_loss: 0.3589
 474/1000 [=============>................] - ETA: 2:30 - loss: 2.1411 - regression_loss: 1.7824 - classification_loss: 0.3588
 475/1000 [=============>................] - ETA: 2:30 - loss: 2.1393 - regression_loss: 1.7807 - classification_loss: 0.3586
 476/1000 [=============>................] - ETA: 2:30 - loss: 2.1381 - regression_loss: 1.7797 - classification_loss: 0.3584
 477/1000 [=============>................] - ETA: 2:29 - loss: 2.1364 - regression_loss: 1.7782 - classification_loss: 0.3581
 478/1000 [=============>................] - ETA: 2:29 - loss: 2.1374 - regression_loss: 1.7788 - classification_loss: 0.3585
 479/1000 [=============>................] - ETA: 2:29 - loss: 2.1375 - regression_loss: 1.7790 - classification_loss: 0.3585
 480/1000 [=============>................] - ETA: 2:29 - loss: 2.1371 - regression_loss: 1.7788 - classification_loss: 0.3582
 481/1000 [=============>................] - ETA: 2:28 - loss: 2.1383 - regression_loss: 1.7799 - classification_loss: 0.3584
 482/1000 [=============>................] - ETA: 2:28 - loss: 2.1402 - regression_loss: 1.7812 - classification_loss: 0.3591
 483/1000 [=============>................] - ETA: 2:28 - loss: 2.1408 - regression_loss: 1.7817 - classification_loss: 0.3591
 484/1000 [=============>................] - ETA: 2:27 - loss: 2.1408 - regression_loss: 1.7820 - classification_loss: 0.3589
 485/1000 [=============>................] - ETA: 2:27 - loss: 2.1402 - regression_loss: 1.7814 - classification_loss: 0.3588
 486/1000 [=============>................] - ETA: 2:27 - loss: 2.1387 - regression_loss: 1.7802 - classification_loss: 0.3584
 487/1000 [=============>................] - ETA: 2:27 - loss: 2.1383 - regression_loss: 1.7800 - classification_loss: 0.3582
 488/1000 [=============>................] - ETA: 2:26 - loss: 2.1390 - regression_loss: 1.7803 - classification_loss: 0.3587
 489/1000 [=============>................] - ETA: 2:26 - loss: 2.1363 - regression_loss: 1.7780 - classification_loss: 0.3583
 490/1000 [=============>................] - ETA: 2:26 - loss: 2.1346 - regression_loss: 1.7766 - classification_loss: 0.3580
 491/1000 [=============>................] - ETA: 2:25 - loss: 2.1341 - regression_loss: 1.7764 - classification_loss: 0.3577
 492/1000 [=============>................] - ETA: 2:25 - loss: 2.1345 - regression_loss: 1.7769 - classification_loss: 0.3576
 493/1000 [=============>................] - ETA: 2:25 - loss: 2.1330 - regression_loss: 1.7758 - classification_loss: 0.3572
 494/1000 [=============>................] - ETA: 2:24 - loss: 2.1347 - regression_loss: 1.7770 - classification_loss: 0.3577
 495/1000 [=============>................] - ETA: 2:24 - loss: 2.1334 - regression_loss: 1.7761 - classification_loss: 0.3573
 496/1000 [=============>................] - ETA: 2:24 - loss: 2.1324 - regression_loss: 1.7753 - classification_loss: 0.3571
 497/1000 [=============>................] - ETA: 2:24 - loss: 2.1329 - regression_loss: 1.7756 - classification_loss: 0.3573
 498/1000 [=============>................] - ETA: 2:23 - loss: 2.1312 - regression_loss: 1.7742 - classification_loss: 0.3570
 499/1000 [=============>................] - ETA: 2:23 - loss: 2.1304 - regression_loss: 1.7733 - classification_loss: 0.3571
 500/1000 [==============>...............] - ETA: 2:23 - loss: 2.1303 - regression_loss: 1.7730 - classification_loss: 0.3573
 501/1000 [==============>...............] - ETA: 2:22 - loss: 2.1286 - regression_loss: 1.7717 - classification_loss: 0.3570
 502/1000 [==============>...............] - ETA: 2:22 - loss: 2.1273 - regression_loss: 1.7706 - classification_loss: 0.3567
 503/1000 [==============>...............] - ETA: 2:22 - loss: 2.1304 - regression_loss: 1.7732 - classification_loss: 0.3572
 504/1000 [==============>...............] - ETA: 2:22 - loss: 2.1293 - regression_loss: 1.7724 - classification_loss: 0.3569
 505/1000 [==============>...............] - ETA: 2:21 - loss: 2.1292 - regression_loss: 1.7723 - classification_loss: 0.3568
 506/1000 [==============>...............] - ETA: 2:21 - loss: 2.1299 - regression_loss: 1.7728 - classification_loss: 0.3571
 507/1000 [==============>...............] - ETA: 2:21 - loss: 2.1289 - regression_loss: 1.7720 - classification_loss: 0.3568
 508/1000 [==============>...............] - ETA: 2:20 - loss: 2.1301 - regression_loss: 1.7730 - classification_loss: 0.3572
 509/1000 [==============>...............] - ETA: 2:20 - loss: 2.1291 - regression_loss: 1.7719 - classification_loss: 0.3573
 510/1000 [==============>...............] - ETA: 2:20 - loss: 2.1304 - regression_loss: 1.7731 - classification_loss: 0.3573
 511/1000 [==============>...............] - ETA: 2:20 - loss: 2.1318 - regression_loss: 1.7741 - classification_loss: 0.3576
 512/1000 [==============>...............] - ETA: 2:19 - loss: 2.1314 - regression_loss: 1.7738 - classification_loss: 0.3575
 513/1000 [==============>...............] - ETA: 2:19 - loss: 2.1324 - regression_loss: 1.7747 - classification_loss: 0.3577
 514/1000 [==============>...............] - ETA: 2:19 - loss: 2.1312 - regression_loss: 1.7738 - classification_loss: 0.3574
 515/1000 [==============>...............] - ETA: 2:18 - loss: 2.1311 - regression_loss: 1.7737 - classification_loss: 0.3574
 516/1000 [==============>...............] - ETA: 2:18 - loss: 2.1300 - regression_loss: 1.7728 - classification_loss: 0.3572
 517/1000 [==============>...............] - ETA: 2:18 - loss: 2.1299 - regression_loss: 1.7727 - classification_loss: 0.3572
 518/1000 [==============>...............] - ETA: 2:18 - loss: 2.1287 - regression_loss: 1.7720 - classification_loss: 0.3567
 519/1000 [==============>...............] - ETA: 2:17 - loss: 2.1291 - regression_loss: 1.7724 - classification_loss: 0.3567
 520/1000 [==============>...............] - ETA: 2:17 - loss: 2.1286 - regression_loss: 1.7722 - classification_loss: 0.3564
 521/1000 [==============>...............] - ETA: 2:17 - loss: 2.1281 - regression_loss: 1.7717 - classification_loss: 0.3564
 522/1000 [==============>...............] - ETA: 2:16 - loss: 2.1288 - regression_loss: 1.7722 - classification_loss: 0.3566
 523/1000 [==============>...............] - ETA: 2:16 - loss: 2.1277 - regression_loss: 1.7714 - classification_loss: 0.3563
 524/1000 [==============>...............] - ETA: 2:16 - loss: 2.1282 - regression_loss: 1.7715 - classification_loss: 0.3566
 525/1000 [==============>...............] - ETA: 2:16 - loss: 2.1290 - regression_loss: 1.7721 - classification_loss: 0.3568
 526/1000 [==============>...............] - ETA: 2:15 - loss: 2.1297 - regression_loss: 1.7725 - classification_loss: 0.3572
 527/1000 [==============>...............] - ETA: 2:15 - loss: 2.1294 - regression_loss: 1.7724 - classification_loss: 0.3570
 528/1000 [==============>...............] - ETA: 2:15 - loss: 2.1278 - regression_loss: 1.7711 - classification_loss: 0.3568
 529/1000 [==============>...............] - ETA: 2:14 - loss: 2.1283 - regression_loss: 1.7715 - classification_loss: 0.3568
 530/1000 [==============>...............] - ETA: 2:14 - loss: 2.1291 - regression_loss: 1.7725 - classification_loss: 0.3567
 531/1000 [==============>...............] - ETA: 2:14 - loss: 2.1282 - regression_loss: 1.7716 - classification_loss: 0.3566
 532/1000 [==============>...............] - ETA: 2:14 - loss: 2.1279 - regression_loss: 1.7716 - classification_loss: 0.3563
 533/1000 [==============>...............] - ETA: 2:13 - loss: 2.1266 - regression_loss: 1.7705 - classification_loss: 0.3561
 534/1000 [===============>..............] - ETA: 2:13 - loss: 2.1259 - regression_loss: 1.7700 - classification_loss: 0.3560
 535/1000 [===============>..............] - ETA: 2:13 - loss: 2.1274 - regression_loss: 1.7711 - classification_loss: 0.3563
 536/1000 [===============>..............] - ETA: 2:12 - loss: 2.1266 - regression_loss: 1.7705 - classification_loss: 0.3561
 537/1000 [===============>..............] - ETA: 2:12 - loss: 2.1269 - regression_loss: 1.7710 - classification_loss: 0.3559
 538/1000 [===============>..............] - ETA: 2:12 - loss: 2.1261 - regression_loss: 1.7705 - classification_loss: 0.3557
 539/1000 [===============>..............] - ETA: 2:12 - loss: 2.1273 - regression_loss: 1.7707 - classification_loss: 0.3566
 540/1000 [===============>..............] - ETA: 2:11 - loss: 2.1271 - regression_loss: 1.7705 - classification_loss: 0.3566
 541/1000 [===============>..............] - ETA: 2:11 - loss: 2.1273 - regression_loss: 1.7708 - classification_loss: 0.3565
 542/1000 [===============>..............] - ETA: 2:11 - loss: 2.1274 - regression_loss: 1.7709 - classification_loss: 0.3565
 543/1000 [===============>..............] - ETA: 2:10 - loss: 2.1269 - regression_loss: 1.7707 - classification_loss: 0.3562
 544/1000 [===============>..............] - ETA: 2:10 - loss: 2.1264 - regression_loss: 1.7704 - classification_loss: 0.3560
 545/1000 [===============>..............] - ETA: 2:10 - loss: 2.1285 - regression_loss: 1.7718 - classification_loss: 0.3567
 546/1000 [===============>..............] - ETA: 2:10 - loss: 2.1295 - regression_loss: 1.7725 - classification_loss: 0.3570
 547/1000 [===============>..............] - ETA: 2:09 - loss: 2.1297 - regression_loss: 1.7727 - classification_loss: 0.3570
 548/1000 [===============>..............] - ETA: 2:09 - loss: 2.1277 - regression_loss: 1.7711 - classification_loss: 0.3566
 549/1000 [===============>..............] - ETA: 2:09 - loss: 2.1294 - regression_loss: 1.7723 - classification_loss: 0.3571
 550/1000 [===============>..............] - ETA: 2:08 - loss: 2.1287 - regression_loss: 1.7716 - classification_loss: 0.3571
 551/1000 [===============>..............] - ETA: 2:08 - loss: 2.1285 - regression_loss: 1.7715 - classification_loss: 0.3570
 552/1000 [===============>..............] - ETA: 2:08 - loss: 2.1262 - regression_loss: 1.7696 - classification_loss: 0.3566
 553/1000 [===============>..............] - ETA: 2:08 - loss: 2.1253 - regression_loss: 1.7689 - classification_loss: 0.3564
 554/1000 [===============>..............] - ETA: 2:07 - loss: 2.1243 - regression_loss: 1.7682 - classification_loss: 0.3561
 555/1000 [===============>..............] - ETA: 2:07 - loss: 2.1234 - regression_loss: 1.7675 - classification_loss: 0.3560
 556/1000 [===============>..............] - ETA: 2:07 - loss: 2.1222 - regression_loss: 1.7664 - classification_loss: 0.3558
 557/1000 [===============>..............] - ETA: 2:06 - loss: 2.1226 - regression_loss: 1.7665 - classification_loss: 0.3561
 558/1000 [===============>..............] - ETA: 2:06 - loss: 2.1215 - regression_loss: 1.7657 - classification_loss: 0.3558
 559/1000 [===============>..............] - ETA: 2:06 - loss: 2.1221 - regression_loss: 1.7661 - classification_loss: 0.3560
 560/1000 [===============>..............] - ETA: 2:06 - loss: 2.1202 - regression_loss: 1.7644 - classification_loss: 0.3557
 561/1000 [===============>..............] - ETA: 2:05 - loss: 2.1198 - regression_loss: 1.7641 - classification_loss: 0.3557
 562/1000 [===============>..............] - ETA: 2:05 - loss: 2.1195 - regression_loss: 1.7640 - classification_loss: 0.3555
 563/1000 [===============>..............] - ETA: 2:05 - loss: 2.1197 - regression_loss: 1.7640 - classification_loss: 0.3557
 564/1000 [===============>..............] - ETA: 2:04 - loss: 2.1200 - regression_loss: 1.7643 - classification_loss: 0.3558
 565/1000 [===============>..............] - ETA: 2:04 - loss: 2.1213 - regression_loss: 1.7654 - classification_loss: 0.3559
 566/1000 [===============>..............] - ETA: 2:04 - loss: 2.1221 - regression_loss: 1.7662 - classification_loss: 0.3559
 567/1000 [================>.............] - ETA: 2:04 - loss: 2.1211 - regression_loss: 1.7655 - classification_loss: 0.3556
 568/1000 [================>.............] - ETA: 2:03 - loss: 2.1196 - regression_loss: 1.7642 - classification_loss: 0.3554
 569/1000 [================>.............] - ETA: 2:03 - loss: 2.1208 - regression_loss: 1.7653 - classification_loss: 0.3554
 570/1000 [================>.............] - ETA: 2:03 - loss: 2.1225 - regression_loss: 1.7663 - classification_loss: 0.3562
 571/1000 [================>.............] - ETA: 2:02 - loss: 2.1229 - regression_loss: 1.7669 - classification_loss: 0.3560
 572/1000 [================>.............] - ETA: 2:02 - loss: 2.1237 - regression_loss: 1.7675 - classification_loss: 0.3562
 573/1000 [================>.............] - ETA: 2:02 - loss: 2.1268 - regression_loss: 1.7700 - classification_loss: 0.3569
 574/1000 [================>.............] - ETA: 2:02 - loss: 2.1274 - regression_loss: 1.7704 - classification_loss: 0.3570
 575/1000 [================>.............] - ETA: 2:01 - loss: 2.1271 - regression_loss: 1.7703 - classification_loss: 0.3568
 576/1000 [================>.............] - ETA: 2:01 - loss: 2.1275 - regression_loss: 1.7705 - classification_loss: 0.3570
 577/1000 [================>.............] - ETA: 2:01 - loss: 2.1265 - regression_loss: 1.7698 - classification_loss: 0.3567
 578/1000 [================>.............] - ETA: 2:00 - loss: 2.1276 - regression_loss: 1.7705 - classification_loss: 0.3571
 579/1000 [================>.............] - ETA: 2:00 - loss: 2.1272 - regression_loss: 1.7703 - classification_loss: 0.3570
 580/1000 [================>.............] - ETA: 2:00 - loss: 2.1280 - regression_loss: 1.7709 - classification_loss: 0.3571
 581/1000 [================>.............] - ETA: 2:00 - loss: 2.1298 - regression_loss: 1.7721 - classification_loss: 0.3576
 582/1000 [================>.............] - ETA: 1:59 - loss: 2.1297 - regression_loss: 1.7720 - classification_loss: 0.3578
 583/1000 [================>.............] - ETA: 1:59 - loss: 2.1291 - regression_loss: 1.7713 - classification_loss: 0.3578
 584/1000 [================>.............] - ETA: 1:59 - loss: 2.1276 - regression_loss: 1.7700 - classification_loss: 0.3576
 585/1000 [================>.............] - ETA: 1:58 - loss: 2.1274 - regression_loss: 1.7699 - classification_loss: 0.3575
 586/1000 [================>.............] - ETA: 1:58 - loss: 2.1261 - regression_loss: 1.7688 - classification_loss: 0.3573
 587/1000 [================>.............] - ETA: 1:58 - loss: 2.1259 - regression_loss: 1.7688 - classification_loss: 0.3571
 588/1000 [================>.............] - ETA: 1:58 - loss: 2.1251 - regression_loss: 1.7682 - classification_loss: 0.3569
 589/1000 [================>.............] - ETA: 1:57 - loss: 2.1245 - regression_loss: 1.7678 - classification_loss: 0.3567
 590/1000 [================>.............] - ETA: 1:57 - loss: 2.1240 - regression_loss: 1.7674 - classification_loss: 0.3566
 591/1000 [================>.............] - ETA: 1:57 - loss: 2.1254 - regression_loss: 1.7683 - classification_loss: 0.3571
 592/1000 [================>.............] - ETA: 1:56 - loss: 2.1254 - regression_loss: 1.7684 - classification_loss: 0.3570
 593/1000 [================>.............] - ETA: 1:56 - loss: 2.1254 - regression_loss: 1.7684 - classification_loss: 0.3569
 594/1000 [================>.............] - ETA: 1:56 - loss: 2.1250 - regression_loss: 1.7681 - classification_loss: 0.3569
 595/1000 [================>.............] - ETA: 1:56 - loss: 2.1245 - regression_loss: 1.7678 - classification_loss: 0.3567
 596/1000 [================>.............] - ETA: 1:55 - loss: 2.1244 - regression_loss: 1.7677 - classification_loss: 0.3567
 597/1000 [================>.............] - ETA: 1:55 - loss: 2.1243 - regression_loss: 1.7675 - classification_loss: 0.3568
 598/1000 [================>.............] - ETA: 1:55 - loss: 2.1246 - regression_loss: 1.7677 - classification_loss: 0.3568
 599/1000 [================>.............] - ETA: 1:54 - loss: 2.1243 - regression_loss: 1.7675 - classification_loss: 0.3568
 600/1000 [=================>............] - ETA: 1:54 - loss: 2.1241 - regression_loss: 1.7673 - classification_loss: 0.3568
 601/1000 [=================>............] - ETA: 1:54 - loss: 2.1239 - regression_loss: 1.7673 - classification_loss: 0.3566
 602/1000 [=================>............] - ETA: 1:54 - loss: 2.1242 - regression_loss: 1.7675 - classification_loss: 0.3567
 603/1000 [=================>............] - ETA: 1:53 - loss: 2.1241 - regression_loss: 1.7674 - classification_loss: 0.3567
 604/1000 [=================>............] - ETA: 1:53 - loss: 2.1228 - regression_loss: 1.7664 - classification_loss: 0.3564
 605/1000 [=================>............] - ETA: 1:53 - loss: 2.1243 - regression_loss: 1.7673 - classification_loss: 0.3569
 606/1000 [=================>............] - ETA: 1:52 - loss: 2.1239 - regression_loss: 1.7670 - classification_loss: 0.3569
 607/1000 [=================>............] - ETA: 1:52 - loss: 2.1240 - regression_loss: 1.7673 - classification_loss: 0.3567
 608/1000 [=================>............] - ETA: 1:52 - loss: 2.1231 - regression_loss: 1.7666 - classification_loss: 0.3565
 609/1000 [=================>............] - ETA: 1:52 - loss: 2.1228 - regression_loss: 1.7664 - classification_loss: 0.3564
 610/1000 [=================>............] - ETA: 1:51 - loss: 2.1216 - regression_loss: 1.7655 - classification_loss: 0.3561
 611/1000 [=================>............] - ETA: 1:51 - loss: 2.1212 - regression_loss: 1.7651 - classification_loss: 0.3561
 612/1000 [=================>............] - ETA: 1:51 - loss: 2.1212 - regression_loss: 1.7652 - classification_loss: 0.3560
 613/1000 [=================>............] - ETA: 1:50 - loss: 2.1218 - regression_loss: 1.7657 - classification_loss: 0.3561
 614/1000 [=================>............] - ETA: 1:50 - loss: 2.1207 - regression_loss: 1.7648 - classification_loss: 0.3558
 615/1000 [=================>............] - ETA: 1:50 - loss: 2.1198 - regression_loss: 1.7641 - classification_loss: 0.3556
 616/1000 [=================>............] - ETA: 1:50 - loss: 2.1201 - regression_loss: 1.7642 - classification_loss: 0.3559
 617/1000 [=================>............] - ETA: 1:49 - loss: 2.1200 - regression_loss: 1.7641 - classification_loss: 0.3559
 618/1000 [=================>............] - ETA: 1:49 - loss: 2.1181 - regression_loss: 1.7626 - classification_loss: 0.3555
 619/1000 [=================>............] - ETA: 1:49 - loss: 2.1184 - regression_loss: 1.7630 - classification_loss: 0.3554
 620/1000 [=================>............] - ETA: 1:48 - loss: 2.1179 - regression_loss: 1.7627 - classification_loss: 0.3551
 621/1000 [=================>............] - ETA: 1:48 - loss: 2.1175 - regression_loss: 1.7626 - classification_loss: 0.3549
 622/1000 [=================>............] - ETA: 1:48 - loss: 2.1162 - regression_loss: 1.7614 - classification_loss: 0.3548
 623/1000 [=================>............] - ETA: 1:47 - loss: 2.1146 - regression_loss: 1.7601 - classification_loss: 0.3545
 624/1000 [=================>............] - ETA: 1:47 - loss: 2.1147 - regression_loss: 1.7603 - classification_loss: 0.3544
 625/1000 [=================>............] - ETA: 1:47 - loss: 2.1136 - regression_loss: 1.7594 - classification_loss: 0.3542
 626/1000 [=================>............] - ETA: 1:47 - loss: 2.1129 - regression_loss: 1.7588 - classification_loss: 0.3541
 627/1000 [=================>............] - ETA: 1:46 - loss: 2.1131 - regression_loss: 1.7590 - classification_loss: 0.3540
 628/1000 [=================>............] - ETA: 1:46 - loss: 2.1121 - regression_loss: 1.7582 - classification_loss: 0.3539
 629/1000 [=================>............] - ETA: 1:46 - loss: 2.1109 - regression_loss: 1.7572 - classification_loss: 0.3537
 630/1000 [=================>............] - ETA: 1:46 - loss: 2.1099 - regression_loss: 1.7565 - classification_loss: 0.3534
 631/1000 [=================>............] - ETA: 1:45 - loss: 2.1106 - regression_loss: 1.7571 - classification_loss: 0.3536
 632/1000 [=================>............] - ETA: 1:45 - loss: 2.1096 - regression_loss: 1.7564 - classification_loss: 0.3532
 633/1000 [=================>............] - ETA: 1:45 - loss: 2.1091 - regression_loss: 1.7556 - classification_loss: 0.3536
 634/1000 [==================>...........] - ETA: 1:44 - loss: 2.1092 - regression_loss: 1.7555 - classification_loss: 0.3536
 635/1000 [==================>...........] - ETA: 1:44 - loss: 2.1085 - regression_loss: 1.7551 - classification_loss: 0.3534
 636/1000 [==================>...........] - ETA: 1:44 - loss: 2.1074 - regression_loss: 1.7543 - classification_loss: 0.3531
 637/1000 [==================>...........] - ETA: 1:43 - loss: 2.1076 - regression_loss: 1.7543 - classification_loss: 0.3532
 638/1000 [==================>...........] - ETA: 1:43 - loss: 2.1066 - regression_loss: 1.7536 - classification_loss: 0.3531
 639/1000 [==================>...........] - ETA: 1:43 - loss: 2.1060 - regression_loss: 1.7531 - classification_loss: 0.3529
 640/1000 [==================>...........] - ETA: 1:43 - loss: 2.1046 - regression_loss: 1.7520 - classification_loss: 0.3525
 641/1000 [==================>...........] - ETA: 1:42 - loss: 2.1048 - regression_loss: 1.7525 - classification_loss: 0.3524
 642/1000 [==================>...........] - ETA: 1:42 - loss: 2.1044 - regression_loss: 1.7523 - classification_loss: 0.3521
 643/1000 [==================>...........] - ETA: 1:42 - loss: 2.1042 - regression_loss: 1.7522 - classification_loss: 0.3520
 644/1000 [==================>...........] - ETA: 1:41 - loss: 2.1052 - regression_loss: 1.7534 - classification_loss: 0.3518
 645/1000 [==================>...........] - ETA: 1:41 - loss: 2.1051 - regression_loss: 1.7532 - classification_loss: 0.3519
 646/1000 [==================>...........] - ETA: 1:41 - loss: 2.1056 - regression_loss: 1.7540 - classification_loss: 0.3516
 647/1000 [==================>...........] - ETA: 1:41 - loss: 2.1050 - regression_loss: 1.7536 - classification_loss: 0.3514
 648/1000 [==================>...........] - ETA: 1:40 - loss: 2.1056 - regression_loss: 1.7542 - classification_loss: 0.3514
 649/1000 [==================>...........] - ETA: 1:40 - loss: 2.1048 - regression_loss: 1.7536 - classification_loss: 0.3512
 650/1000 [==================>...........] - ETA: 1:40 - loss: 2.1047 - regression_loss: 1.7535 - classification_loss: 0.3512
 651/1000 [==================>...........] - ETA: 1:39 - loss: 2.1035 - regression_loss: 1.7525 - classification_loss: 0.3510
 652/1000 [==================>...........] - ETA: 1:39 - loss: 2.1035 - regression_loss: 1.7526 - classification_loss: 0.3509
 653/1000 [==================>...........] - ETA: 1:39 - loss: 2.1036 - regression_loss: 1.7523 - classification_loss: 0.3512
 654/1000 [==================>...........] - ETA: 1:39 - loss: 2.1101 - regression_loss: 1.7497 - classification_loss: 0.3604
 655/1000 [==================>...........] - ETA: 1:38 - loss: 2.1104 - regression_loss: 1.7501 - classification_loss: 0.3603
 656/1000 [==================>...........] - ETA: 1:38 - loss: 2.1100 - regression_loss: 1.7497 - classification_loss: 0.3603
 657/1000 [==================>...........] - ETA: 1:38 - loss: 2.1097 - regression_loss: 1.7496 - classification_loss: 0.3601
 658/1000 [==================>...........] - ETA: 1:37 - loss: 2.1100 - regression_loss: 1.7500 - classification_loss: 0.3600
 659/1000 [==================>...........] - ETA: 1:37 - loss: 2.1095 - regression_loss: 1.7495 - classification_loss: 0.3600
 660/1000 [==================>...........] - ETA: 1:37 - loss: 2.1090 - regression_loss: 1.7491 - classification_loss: 0.3599
 661/1000 [==================>...........] - ETA: 1:37 - loss: 2.1082 - regression_loss: 1.7487 - classification_loss: 0.3596
 662/1000 [==================>...........] - ETA: 1:36 - loss: 2.1092 - regression_loss: 1.7492 - classification_loss: 0.3600
 663/1000 [==================>...........] - ETA: 1:36 - loss: 2.1080 - regression_loss: 1.7483 - classification_loss: 0.3597
 664/1000 [==================>...........] - ETA: 1:36 - loss: 2.1066 - regression_loss: 1.7472 - classification_loss: 0.3594
 665/1000 [==================>...........] - ETA: 1:35 - loss: 2.1064 - regression_loss: 1.7470 - classification_loss: 0.3594
 666/1000 [==================>...........] - ETA: 1:35 - loss: 2.1079 - regression_loss: 1.7479 - classification_loss: 0.3601
 667/1000 [===================>..........] - ETA: 1:35 - loss: 2.1082 - regression_loss: 1.7482 - classification_loss: 0.3600
 668/1000 [===================>..........] - ETA: 1:35 - loss: 2.1066 - regression_loss: 1.7469 - classification_loss: 0.3597
 669/1000 [===================>..........] - ETA: 1:34 - loss: 2.1053 - regression_loss: 1.7458 - classification_loss: 0.3595
 670/1000 [===================>..........] - ETA: 1:34 - loss: 2.1046 - regression_loss: 1.7453 - classification_loss: 0.3593
 671/1000 [===================>..........] - ETA: 1:34 - loss: 2.1035 - regression_loss: 1.7442 - classification_loss: 0.3592
 672/1000 [===================>..........] - ETA: 1:33 - loss: 2.1037 - regression_loss: 1.7447 - classification_loss: 0.3590
 673/1000 [===================>..........] - ETA: 1:33 - loss: 2.1031 - regression_loss: 1.7442 - classification_loss: 0.3589
 674/1000 [===================>..........] - ETA: 1:33 - loss: 2.1020 - regression_loss: 1.7433 - classification_loss: 0.3587
 675/1000 [===================>..........] - ETA: 1:33 - loss: 2.1020 - regression_loss: 1.7431 - classification_loss: 0.3589
 676/1000 [===================>..........] - ETA: 1:32 - loss: 2.1011 - regression_loss: 1.7423 - classification_loss: 0.3588
 677/1000 [===================>..........] - ETA: 1:32 - loss: 2.1021 - regression_loss: 1.7433 - classification_loss: 0.3588
 678/1000 [===================>..........] - ETA: 1:32 - loss: 2.1023 - regression_loss: 1.7433 - classification_loss: 0.3590
 679/1000 [===================>..........] - ETA: 1:31 - loss: 2.1011 - regression_loss: 1.7423 - classification_loss: 0.3589
 680/1000 [===================>..........] - ETA: 1:31 - loss: 2.1004 - regression_loss: 1.7417 - classification_loss: 0.3587
 681/1000 [===================>..........] - ETA: 1:31 - loss: 2.1003 - regression_loss: 1.7417 - classification_loss: 0.3586
 682/1000 [===================>..........] - ETA: 1:31 - loss: 2.1004 - regression_loss: 1.7419 - classification_loss: 0.3585
 683/1000 [===================>..........] - ETA: 1:30 - loss: 2.0998 - regression_loss: 1.7413 - classification_loss: 0.3585
 684/1000 [===================>..........] - ETA: 1:30 - loss: 2.0992 - regression_loss: 1.7410 - classification_loss: 0.3582
 685/1000 [===================>..........] - ETA: 1:30 - loss: 2.0978 - regression_loss: 1.7398 - classification_loss: 0.3580
 686/1000 [===================>..........] - ETA: 1:29 - loss: 2.0979 - regression_loss: 1.7400 - classification_loss: 0.3579
 687/1000 [===================>..........] - ETA: 1:29 - loss: 2.0965 - regression_loss: 1.7389 - classification_loss: 0.3576
 688/1000 [===================>..........] - ETA: 1:29 - loss: 2.0953 - regression_loss: 1.7377 - classification_loss: 0.3576
 689/1000 [===================>..........] - ETA: 1:29 - loss: 2.0937 - regression_loss: 1.7363 - classification_loss: 0.3574
 690/1000 [===================>..........] - ETA: 1:28 - loss: 2.0941 - regression_loss: 1.7365 - classification_loss: 0.3575
 691/1000 [===================>..........] - ETA: 1:28 - loss: 2.0932 - regression_loss: 1.7359 - classification_loss: 0.3573
 692/1000 [===================>..........] - ETA: 1:28 - loss: 2.0932 - regression_loss: 1.7357 - classification_loss: 0.3574
 693/1000 [===================>..........] - ETA: 1:27 - loss: 2.0916 - regression_loss: 1.7344 - classification_loss: 0.3572
 694/1000 [===================>..........] - ETA: 1:27 - loss: 2.0908 - regression_loss: 1.7337 - classification_loss: 0.3571
 695/1000 [===================>..........] - ETA: 1:27 - loss: 2.0894 - regression_loss: 1.7326 - classification_loss: 0.3569
 696/1000 [===================>..........] - ETA: 1:27 - loss: 2.0893 - regression_loss: 1.7325 - classification_loss: 0.3568
 697/1000 [===================>..........] - ETA: 1:26 - loss: 2.0888 - regression_loss: 1.7321 - classification_loss: 0.3567
 698/1000 [===================>..........] - ETA: 1:26 - loss: 2.0873 - regression_loss: 1.7309 - classification_loss: 0.3564
 699/1000 [===================>..........] - ETA: 1:26 - loss: 2.0879 - regression_loss: 1.7311 - classification_loss: 0.3568
 700/1000 [====================>.........] - ETA: 1:25 - loss: 2.0865 - regression_loss: 1.7300 - classification_loss: 0.3565
 701/1000 [====================>.........] - ETA: 1:25 - loss: 2.0872 - regression_loss: 1.7305 - classification_loss: 0.3566
 702/1000 [====================>.........] - ETA: 1:25 - loss: 2.0858 - regression_loss: 1.7294 - classification_loss: 0.3564
 703/1000 [====================>.........] - ETA: 1:25 - loss: 2.0869 - regression_loss: 1.7304 - classification_loss: 0.3566
 704/1000 [====================>.........] - ETA: 1:24 - loss: 2.0865 - regression_loss: 1.7299 - classification_loss: 0.3566
 705/1000 [====================>.........] - ETA: 1:24 - loss: 2.0861 - regression_loss: 1.7297 - classification_loss: 0.3565
 706/1000 [====================>.........] - ETA: 1:24 - loss: 2.0862 - regression_loss: 1.7298 - classification_loss: 0.3564
 707/1000 [====================>.........] - ETA: 1:23 - loss: 2.0867 - regression_loss: 1.7301 - classification_loss: 0.3566
 708/1000 [====================>.........] - ETA: 1:23 - loss: 2.0846 - regression_loss: 1.7282 - classification_loss: 0.3563
 709/1000 [====================>.........] - ETA: 1:23 - loss: 2.0844 - regression_loss: 1.7283 - classification_loss: 0.3560
 710/1000 [====================>.........] - ETA: 1:23 - loss: 2.0836 - regression_loss: 1.7278 - classification_loss: 0.3558
 711/1000 [====================>.........] - ETA: 1:22 - loss: 2.0840 - regression_loss: 1.7283 - classification_loss: 0.3557
 712/1000 [====================>.........] - ETA: 1:22 - loss: 2.0838 - regression_loss: 1.7283 - classification_loss: 0.3555
 713/1000 [====================>.........] - ETA: 1:22 - loss: 2.0825 - regression_loss: 1.7272 - classification_loss: 0.3553
 714/1000 [====================>.........] - ETA: 1:21 - loss: 2.0829 - regression_loss: 1.7276 - classification_loss: 0.3553
 715/1000 [====================>.........] - ETA: 1:21 - loss: 2.0828 - regression_loss: 1.7276 - classification_loss: 0.3552
 716/1000 [====================>.........] - ETA: 1:21 - loss: 2.0834 - regression_loss: 1.7280 - classification_loss: 0.3554
 717/1000 [====================>.........] - ETA: 1:21 - loss: 2.0819 - regression_loss: 1.7268 - classification_loss: 0.3551
 718/1000 [====================>.........] - ETA: 1:20 - loss: 2.0817 - regression_loss: 1.7264 - classification_loss: 0.3554
 719/1000 [====================>.........] - ETA: 1:20 - loss: 2.0805 - regression_loss: 1.7253 - classification_loss: 0.3551
 720/1000 [====================>.........] - ETA: 1:20 - loss: 2.0802 - regression_loss: 1.7251 - classification_loss: 0.3550
 721/1000 [====================>.........] - ETA: 1:19 - loss: 2.0805 - regression_loss: 1.7256 - classification_loss: 0.3549
 722/1000 [====================>.........] - ETA: 1:19 - loss: 2.0809 - regression_loss: 1.7259 - classification_loss: 0.3549
 723/1000 [====================>.........] - ETA: 1:19 - loss: 2.0798 - regression_loss: 1.7251 - classification_loss: 0.3547
 724/1000 [====================>.........] - ETA: 1:19 - loss: 2.0788 - regression_loss: 1.7243 - classification_loss: 0.3545
 725/1000 [====================>.........] - ETA: 1:18 - loss: 2.0799 - regression_loss: 1.7249 - classification_loss: 0.3549
 726/1000 [====================>.........] - ETA: 1:18 - loss: 2.0809 - regression_loss: 1.7256 - classification_loss: 0.3554
 727/1000 [====================>.........] - ETA: 1:18 - loss: 2.0806 - regression_loss: 1.7255 - classification_loss: 0.3552
 728/1000 [====================>.........] - ETA: 1:17 - loss: 2.0804 - regression_loss: 1.7250 - classification_loss: 0.3553
 729/1000 [====================>.........] - ETA: 1:17 - loss: 2.0796 - regression_loss: 1.7244 - classification_loss: 0.3552
 730/1000 [====================>.........] - ETA: 1:17 - loss: 2.0809 - regression_loss: 1.7255 - classification_loss: 0.3554
 731/1000 [====================>.........] - ETA: 1:17 - loss: 2.0818 - regression_loss: 1.7262 - classification_loss: 0.3556
 732/1000 [====================>.........] - ETA: 1:16 - loss: 2.0813 - regression_loss: 1.7260 - classification_loss: 0.3554
 733/1000 [====================>.........] - ETA: 1:16 - loss: 2.0804 - regression_loss: 1.7253 - classification_loss: 0.3552
 734/1000 [=====================>........] - ETA: 1:16 - loss: 2.0797 - regression_loss: 1.7246 - classification_loss: 0.3551
 735/1000 [=====================>........] - ETA: 1:15 - loss: 2.0808 - regression_loss: 1.7257 - classification_loss: 0.3550
 736/1000 [=====================>........] - ETA: 1:15 - loss: 2.0792 - regression_loss: 1.7245 - classification_loss: 0.3548
 737/1000 [=====================>........] - ETA: 1:15 - loss: 2.0786 - regression_loss: 1.7240 - classification_loss: 0.3546
 738/1000 [=====================>........] - ETA: 1:15 - loss: 2.0788 - regression_loss: 1.7243 - classification_loss: 0.3545
 739/1000 [=====================>........] - ETA: 1:14 - loss: 2.0779 - regression_loss: 1.7235 - classification_loss: 0.3544
 740/1000 [=====================>........] - ETA: 1:14 - loss: 2.0776 - regression_loss: 1.7233 - classification_loss: 0.3543
 741/1000 [=====================>........] - ETA: 1:14 - loss: 2.0785 - regression_loss: 1.7239 - classification_loss: 0.3546
 742/1000 [=====================>........] - ETA: 1:13 - loss: 2.0783 - regression_loss: 1.7239 - classification_loss: 0.3544
 743/1000 [=====================>........] - ETA: 1:13 - loss: 2.0778 - regression_loss: 1.7236 - classification_loss: 0.3542
 744/1000 [=====================>........] - ETA: 1:13 - loss: 2.0780 - regression_loss: 1.7237 - classification_loss: 0.3542
 745/1000 [=====================>........] - ETA: 1:13 - loss: 2.0785 - regression_loss: 1.7241 - classification_loss: 0.3544
 746/1000 [=====================>........] - ETA: 1:12 - loss: 2.0772 - regression_loss: 1.7231 - classification_loss: 0.3541
 747/1000 [=====================>........] - ETA: 1:12 - loss: 2.0767 - regression_loss: 1.7228 - classification_loss: 0.3540
 748/1000 [=====================>........] - ETA: 1:12 - loss: 2.0767 - regression_loss: 1.7229 - classification_loss: 0.3537
 749/1000 [=====================>........] - ETA: 1:11 - loss: 2.0753 - regression_loss: 1.7218 - classification_loss: 0.3535
 750/1000 [=====================>........] - ETA: 1:11 - loss: 2.0757 - regression_loss: 1.7222 - classification_loss: 0.3535
 751/1000 [=====================>........] - ETA: 1:11 - loss: 2.0773 - regression_loss: 1.7234 - classification_loss: 0.3539
 752/1000 [=====================>........] - ETA: 1:11 - loss: 2.0776 - regression_loss: 1.7237 - classification_loss: 0.3539
 753/1000 [=====================>........] - ETA: 1:10 - loss: 2.0769 - regression_loss: 1.7230 - classification_loss: 0.3539
 754/1000 [=====================>........] - ETA: 1:10 - loss: 2.0777 - regression_loss: 1.7236 - classification_loss: 0.3540
 755/1000 [=====================>........] - ETA: 1:10 - loss: 2.0773 - regression_loss: 1.7235 - classification_loss: 0.3538
 756/1000 [=====================>........] - ETA: 1:09 - loss: 2.0763 - regression_loss: 1.7228 - classification_loss: 0.3535
 757/1000 [=====================>........] - ETA: 1:09 - loss: 2.0764 - regression_loss: 1.7229 - classification_loss: 0.3535
 758/1000 [=====================>........] - ETA: 1:09 - loss: 2.0771 - regression_loss: 1.7235 - classification_loss: 0.3537
 759/1000 [=====================>........] - ETA: 1:09 - loss: 2.0762 - regression_loss: 1.7226 - classification_loss: 0.3535
 760/1000 [=====================>........] - ETA: 1:08 - loss: 2.0753 - regression_loss: 1.7220 - classification_loss: 0.3534
 761/1000 [=====================>........] - ETA: 1:08 - loss: 2.0758 - regression_loss: 1.7226 - classification_loss: 0.3533
 762/1000 [=====================>........] - ETA: 1:08 - loss: 2.0753 - regression_loss: 1.7221 - classification_loss: 0.3532
 763/1000 [=====================>........] - ETA: 1:07 - loss: 2.0747 - regression_loss: 1.7216 - classification_loss: 0.3531
 764/1000 [=====================>........] - ETA: 1:07 - loss: 2.0765 - regression_loss: 1.7229 - classification_loss: 0.3536
 765/1000 [=====================>........] - ETA: 1:07 - loss: 2.0761 - regression_loss: 1.7227 - classification_loss: 0.3534
 766/1000 [=====================>........] - ETA: 1:07 - loss: 2.0764 - regression_loss: 1.7230 - classification_loss: 0.3534
 767/1000 [======================>.......] - ETA: 1:06 - loss: 2.0753 - regression_loss: 1.7221 - classification_loss: 0.3532
 768/1000 [======================>.......] - ETA: 1:06 - loss: 2.0756 - regression_loss: 1.7225 - classification_loss: 0.3531
 769/1000 [======================>.......] - ETA: 1:06 - loss: 2.0753 - regression_loss: 1.7224 - classification_loss: 0.3529
 770/1000 [======================>.......] - ETA: 1:05 - loss: 2.0754 - regression_loss: 1.7223 - classification_loss: 0.3531
 771/1000 [======================>.......] - ETA: 1:05 - loss: 2.0745 - regression_loss: 1.7217 - classification_loss: 0.3528
 772/1000 [======================>.......] - ETA: 1:05 - loss: 2.0741 - regression_loss: 1.7215 - classification_loss: 0.3526
 773/1000 [======================>.......] - ETA: 1:05 - loss: 2.0749 - regression_loss: 1.7223 - classification_loss: 0.3526
 774/1000 [======================>.......] - ETA: 1:04 - loss: 2.0754 - regression_loss: 1.7227 - classification_loss: 0.3527
 775/1000 [======================>.......] - ETA: 1:04 - loss: 2.0761 - regression_loss: 1.7235 - classification_loss: 0.3527
 776/1000 [======================>.......] - ETA: 1:04 - loss: 2.0764 - regression_loss: 1.7237 - classification_loss: 0.3528
 777/1000 [======================>.......] - ETA: 1:03 - loss: 2.0769 - regression_loss: 1.7240 - classification_loss: 0.3529
 778/1000 [======================>.......] - ETA: 1:03 - loss: 2.0768 - regression_loss: 1.7239 - classification_loss: 0.3530
 779/1000 [======================>.......] - ETA: 1:03 - loss: 2.0762 - regression_loss: 1.7233 - classification_loss: 0.3529
 780/1000 [======================>.......] - ETA: 1:03 - loss: 2.0752 - regression_loss: 1.7224 - classification_loss: 0.3528
 781/1000 [======================>.......] - ETA: 1:02 - loss: 2.0743 - regression_loss: 1.7215 - classification_loss: 0.3527
 782/1000 [======================>.......] - ETA: 1:02 - loss: 2.0735 - regression_loss: 1.7207 - classification_loss: 0.3528
 783/1000 [======================>.......] - ETA: 1:02 - loss: 2.0731 - regression_loss: 1.7204 - classification_loss: 0.3527
 784/1000 [======================>.......] - ETA: 1:01 - loss: 2.0721 - regression_loss: 1.7195 - classification_loss: 0.3526
 785/1000 [======================>.......] - ETA: 1:01 - loss: 2.0716 - regression_loss: 1.7192 - classification_loss: 0.3524
 786/1000 [======================>.......] - ETA: 1:01 - loss: 2.0708 - regression_loss: 1.7187 - classification_loss: 0.3521
 787/1000 [======================>.......] - ETA: 1:01 - loss: 2.0716 - regression_loss: 1.7192 - classification_loss: 0.3524
 788/1000 [======================>.......] - ETA: 1:00 - loss: 2.0703 - regression_loss: 1.7182 - classification_loss: 0.3522
 789/1000 [======================>.......] - ETA: 1:00 - loss: 2.0702 - regression_loss: 1.7181 - classification_loss: 0.3521
 790/1000 [======================>.......] - ETA: 1:00 - loss: 2.0697 - regression_loss: 1.7178 - classification_loss: 0.3520
 791/1000 [======================>.......] - ETA: 59s - loss: 2.0689 - regression_loss: 1.7171 - classification_loss: 0.3518 
 792/1000 [======================>.......] - ETA: 59s - loss: 2.0687 - regression_loss: 1.7170 - classification_loss: 0.3516
 793/1000 [======================>.......] - ETA: 59s - loss: 2.0699 - regression_loss: 1.7180 - classification_loss: 0.3519
 794/1000 [======================>.......] - ETA: 59s - loss: 2.0687 - regression_loss: 1.7170 - classification_loss: 0.3517
 795/1000 [======================>.......] - ETA: 58s - loss: 2.0690 - regression_loss: 1.7172 - classification_loss: 0.3518
 796/1000 [======================>.......] - ETA: 58s - loss: 2.0691 - regression_loss: 1.7174 - classification_loss: 0.3517
 797/1000 [======================>.......] - ETA: 58s - loss: 2.0682 - regression_loss: 1.7166 - classification_loss: 0.3516
 798/1000 [======================>.......] - ETA: 57s - loss: 2.0680 - regression_loss: 1.7165 - classification_loss: 0.3515
 799/1000 [======================>.......] - ETA: 57s - loss: 2.0680 - regression_loss: 1.7164 - classification_loss: 0.3516
 800/1000 [=======================>......] - ETA: 57s - loss: 2.0675 - regression_loss: 1.7161 - classification_loss: 0.3514
 801/1000 [=======================>......] - ETA: 57s - loss: 2.0666 - regression_loss: 1.7153 - classification_loss: 0.3512
 802/1000 [=======================>......] - ETA: 56s - loss: 2.0665 - regression_loss: 1.7153 - classification_loss: 0.3511
 803/1000 [=======================>......] - ETA: 56s - loss: 2.0651 - regression_loss: 1.7142 - classification_loss: 0.3510
 804/1000 [=======================>......] - ETA: 56s - loss: 2.0649 - regression_loss: 1.7140 - classification_loss: 0.3509
 805/1000 [=======================>......] - ETA: 55s - loss: 2.0649 - regression_loss: 1.7141 - classification_loss: 0.3508
 806/1000 [=======================>......] - ETA: 55s - loss: 2.0650 - regression_loss: 1.7144 - classification_loss: 0.3507
 807/1000 [=======================>......] - ETA: 55s - loss: 2.0645 - regression_loss: 1.7138 - classification_loss: 0.3506
 808/1000 [=======================>......] - ETA: 55s - loss: 2.0642 - regression_loss: 1.7137 - classification_loss: 0.3505
 809/1000 [=======================>......] - ETA: 54s - loss: 2.0631 - regression_loss: 1.7128 - classification_loss: 0.3503
 810/1000 [=======================>......] - ETA: 54s - loss: 2.0629 - regression_loss: 1.7126 - classification_loss: 0.3503
 811/1000 [=======================>......] - ETA: 54s - loss: 2.0642 - regression_loss: 1.7137 - classification_loss: 0.3505
 812/1000 [=======================>......] - ETA: 53s - loss: 2.0646 - regression_loss: 1.7138 - classification_loss: 0.3509
 813/1000 [=======================>......] - ETA: 53s - loss: 2.0646 - regression_loss: 1.7138 - classification_loss: 0.3508
 814/1000 [=======================>......] - ETA: 53s - loss: 2.0657 - regression_loss: 1.7146 - classification_loss: 0.3510
 815/1000 [=======================>......] - ETA: 53s - loss: 2.0669 - regression_loss: 1.7155 - classification_loss: 0.3515
 816/1000 [=======================>......] - ETA: 52s - loss: 2.0656 - regression_loss: 1.7144 - classification_loss: 0.3512
 817/1000 [=======================>......] - ETA: 52s - loss: 2.0647 - regression_loss: 1.7137 - classification_loss: 0.3510
 818/1000 [=======================>......] - ETA: 52s - loss: 2.0649 - regression_loss: 1.7140 - classification_loss: 0.3509
 819/1000 [=======================>......] - ETA: 51s - loss: 2.0651 - regression_loss: 1.7141 - classification_loss: 0.3511
 820/1000 [=======================>......] - ETA: 51s - loss: 2.0653 - regression_loss: 1.7144 - classification_loss: 0.3509
 821/1000 [=======================>......] - ETA: 51s - loss: 2.0654 - regression_loss: 1.7145 - classification_loss: 0.3509
 822/1000 [=======================>......] - ETA: 51s - loss: 2.0653 - regression_loss: 1.7145 - classification_loss: 0.3507
 823/1000 [=======================>......] - ETA: 50s - loss: 2.0656 - regression_loss: 1.7148 - classification_loss: 0.3508
 824/1000 [=======================>......] - ETA: 50s - loss: 2.0650 - regression_loss: 1.7144 - classification_loss: 0.3506
 825/1000 [=======================>......] - ETA: 50s - loss: 2.0637 - regression_loss: 1.7133 - classification_loss: 0.3504
 826/1000 [=======================>......] - ETA: 49s - loss: 2.0626 - regression_loss: 1.7124 - classification_loss: 0.3502
 827/1000 [=======================>......] - ETA: 49s - loss: 2.0625 - regression_loss: 1.7124 - classification_loss: 0.3501
 828/1000 [=======================>......] - ETA: 49s - loss: 2.0625 - regression_loss: 1.7123 - classification_loss: 0.3502
 829/1000 [=======================>......] - ETA: 49s - loss: 2.0629 - regression_loss: 1.7127 - classification_loss: 0.3502
 830/1000 [=======================>......] - ETA: 48s - loss: 2.0623 - regression_loss: 1.7123 - classification_loss: 0.3500
 831/1000 [=======================>......] - ETA: 48s - loss: 2.0623 - regression_loss: 1.7122 - classification_loss: 0.3501
 832/1000 [=======================>......] - ETA: 48s - loss: 2.0614 - regression_loss: 1.7114 - classification_loss: 0.3499
 833/1000 [=======================>......] - ETA: 47s - loss: 2.0607 - regression_loss: 1.7110 - classification_loss: 0.3497
 834/1000 [========================>.....] - ETA: 47s - loss: 2.0607 - regression_loss: 1.7109 - classification_loss: 0.3497
 835/1000 [========================>.....] - ETA: 47s - loss: 2.0600 - regression_loss: 1.7104 - classification_loss: 0.3496
 836/1000 [========================>.....] - ETA: 47s - loss: 2.0599 - regression_loss: 1.7102 - classification_loss: 0.3497
 837/1000 [========================>.....] - ETA: 46s - loss: 2.0605 - regression_loss: 1.7107 - classification_loss: 0.3498
 838/1000 [========================>.....] - ETA: 46s - loss: 2.0606 - regression_loss: 1.7107 - classification_loss: 0.3499
 839/1000 [========================>.....] - ETA: 46s - loss: 2.0608 - regression_loss: 1.7110 - classification_loss: 0.3497
 840/1000 [========================>.....] - ETA: 45s - loss: 2.0600 - regression_loss: 1.7104 - classification_loss: 0.3496
 841/1000 [========================>.....] - ETA: 45s - loss: 2.0588 - regression_loss: 1.7095 - classification_loss: 0.3494
 842/1000 [========================>.....] - ETA: 45s - loss: 2.0591 - regression_loss: 1.7095 - classification_loss: 0.3496
 843/1000 [========================>.....] - ETA: 44s - loss: 2.0587 - regression_loss: 1.7093 - classification_loss: 0.3494
 844/1000 [========================>.....] - ETA: 44s - loss: 2.0583 - regression_loss: 1.7089 - classification_loss: 0.3493
 845/1000 [========================>.....] - ETA: 44s - loss: 2.0581 - regression_loss: 1.7089 - classification_loss: 0.3492
 846/1000 [========================>.....] - ETA: 44s - loss: 2.0578 - regression_loss: 1.7085 - classification_loss: 0.3493
 847/1000 [========================>.....] - ETA: 43s - loss: 2.0592 - regression_loss: 1.7094 - classification_loss: 0.3499
 848/1000 [========================>.....] - ETA: 43s - loss: 2.0581 - regression_loss: 1.7085 - classification_loss: 0.3496
 849/1000 [========================>.....] - ETA: 43s - loss: 2.0583 - regression_loss: 1.7087 - classification_loss: 0.3496
 850/1000 [========================>.....] - ETA: 42s - loss: 2.0585 - regression_loss: 1.7090 - classification_loss: 0.3495
 851/1000 [========================>.....] - ETA: 42s - loss: 2.0593 - regression_loss: 1.7097 - classification_loss: 0.3496
 852/1000 [========================>.....] - ETA: 42s - loss: 2.0581 - regression_loss: 1.7088 - classification_loss: 0.3494
 853/1000 [========================>.....] - ETA: 42s - loss: 2.0580 - regression_loss: 1.7087 - classification_loss: 0.3493
 854/1000 [========================>.....] - ETA: 41s - loss: 2.0578 - regression_loss: 1.7084 - classification_loss: 0.3494
 855/1000 [========================>.....] - ETA: 41s - loss: 2.0577 - regression_loss: 1.7084 - classification_loss: 0.3493
 856/1000 [========================>.....] - ETA: 41s - loss: 2.0573 - regression_loss: 1.7080 - classification_loss: 0.3493
 857/1000 [========================>.....] - ETA: 40s - loss: 2.0577 - regression_loss: 1.7083 - classification_loss: 0.3494
 858/1000 [========================>.....] - ETA: 40s - loss: 2.0574 - regression_loss: 1.7081 - classification_loss: 0.3493
 859/1000 [========================>.....] - ETA: 40s - loss: 2.0565 - regression_loss: 1.7074 - classification_loss: 0.3491
 860/1000 [========================>.....] - ETA: 40s - loss: 2.0578 - regression_loss: 1.7083 - classification_loss: 0.3495
 861/1000 [========================>.....] - ETA: 39s - loss: 2.0575 - regression_loss: 1.7081 - classification_loss: 0.3494
 862/1000 [========================>.....] - ETA: 39s - loss: 2.0576 - regression_loss: 1.7082 - classification_loss: 0.3494
 863/1000 [========================>.....] - ETA: 39s - loss: 2.0571 - regression_loss: 1.7078 - classification_loss: 0.3493
 864/1000 [========================>.....] - ETA: 38s - loss: 2.0582 - regression_loss: 1.7085 - classification_loss: 0.3496
 865/1000 [========================>.....] - ETA: 38s - loss: 2.0581 - regression_loss: 1.7082 - classification_loss: 0.3500
 866/1000 [========================>.....] - ETA: 38s - loss: 2.0574 - regression_loss: 1.7076 - classification_loss: 0.3497
 867/1000 [=========================>....] - ETA: 38s - loss: 2.0565 - regression_loss: 1.7070 - classification_loss: 0.3495
 868/1000 [=========================>....] - ETA: 37s - loss: 2.0553 - regression_loss: 1.7059 - classification_loss: 0.3494
 869/1000 [=========================>....] - ETA: 37s - loss: 2.0545 - regression_loss: 1.7051 - classification_loss: 0.3494
 870/1000 [=========================>....] - ETA: 37s - loss: 2.0537 - regression_loss: 1.7044 - classification_loss: 0.3493
 871/1000 [=========================>....] - ETA: 36s - loss: 2.0547 - regression_loss: 1.7051 - classification_loss: 0.3495
 872/1000 [=========================>....] - ETA: 36s - loss: 2.0543 - regression_loss: 1.7049 - classification_loss: 0.3494
 873/1000 [=========================>....] - ETA: 36s - loss: 2.0538 - regression_loss: 1.7045 - classification_loss: 0.3493
 874/1000 [=========================>....] - ETA: 36s - loss: 2.0534 - regression_loss: 1.7042 - classification_loss: 0.3493
 875/1000 [=========================>....] - ETA: 35s - loss: 2.0539 - regression_loss: 1.7046 - classification_loss: 0.3493
 876/1000 [=========================>....] - ETA: 35s - loss: 2.0533 - regression_loss: 1.7039 - classification_loss: 0.3494
 877/1000 [=========================>....] - ETA: 35s - loss: 2.0536 - regression_loss: 1.7041 - classification_loss: 0.3494
 878/1000 [=========================>....] - ETA: 34s - loss: 2.0539 - regression_loss: 1.7043 - classification_loss: 0.3495
 879/1000 [=========================>....] - ETA: 34s - loss: 2.0534 - regression_loss: 1.7040 - classification_loss: 0.3494
 880/1000 [=========================>....] - ETA: 34s - loss: 2.0532 - regression_loss: 1.7039 - classification_loss: 0.3493
 881/1000 [=========================>....] - ETA: 34s - loss: 2.0532 - regression_loss: 1.7039 - classification_loss: 0.3494
 882/1000 [=========================>....] - ETA: 33s - loss: 2.0534 - regression_loss: 1.7041 - classification_loss: 0.3493
 883/1000 [=========================>....] - ETA: 33s - loss: 2.0533 - regression_loss: 1.7040 - classification_loss: 0.3493
 884/1000 [=========================>....] - ETA: 33s - loss: 2.0534 - regression_loss: 1.7039 - classification_loss: 0.3495
 885/1000 [=========================>....] - ETA: 32s - loss: 2.0533 - regression_loss: 1.7039 - classification_loss: 0.3494
 886/1000 [=========================>....] - ETA: 32s - loss: 2.0536 - regression_loss: 1.7041 - classification_loss: 0.3494
 887/1000 [=========================>....] - ETA: 32s - loss: 2.0528 - regression_loss: 1.7034 - classification_loss: 0.3493
 888/1000 [=========================>....] - ETA: 32s - loss: 2.0524 - regression_loss: 1.7033 - classification_loss: 0.3491
 889/1000 [=========================>....] - ETA: 31s - loss: 2.0525 - regression_loss: 1.7034 - classification_loss: 0.3491
 890/1000 [=========================>....] - ETA: 31s - loss: 2.0529 - regression_loss: 1.7034 - classification_loss: 0.3496
 891/1000 [=========================>....] - ETA: 31s - loss: 2.0520 - regression_loss: 1.7027 - classification_loss: 0.3493
 892/1000 [=========================>....] - ETA: 30s - loss: 2.0525 - regression_loss: 1.7031 - classification_loss: 0.3494
 893/1000 [=========================>....] - ETA: 30s - loss: 2.0525 - regression_loss: 1.7031 - classification_loss: 0.3494
 894/1000 [=========================>....] - ETA: 30s - loss: 2.0514 - regression_loss: 1.7021 - classification_loss: 0.3493
 895/1000 [=========================>....] - ETA: 30s - loss: 2.0509 - regression_loss: 1.7017 - classification_loss: 0.3492
 896/1000 [=========================>....] - ETA: 29s - loss: 2.0501 - regression_loss: 1.7010 - classification_loss: 0.3491
 897/1000 [=========================>....] - ETA: 29s - loss: 2.0508 - regression_loss: 1.7017 - classification_loss: 0.3492
 898/1000 [=========================>....] - ETA: 29s - loss: 2.0516 - regression_loss: 1.7022 - classification_loss: 0.3495
 899/1000 [=========================>....] - ETA: 28s - loss: 2.0511 - regression_loss: 1.7018 - classification_loss: 0.3493
 900/1000 [==========================>...] - ETA: 28s - loss: 2.0505 - regression_loss: 1.7013 - classification_loss: 0.3492
 901/1000 [==========================>...] - ETA: 28s - loss: 2.0510 - regression_loss: 1.7018 - classification_loss: 0.3492
 902/1000 [==========================>...] - ETA: 28s - loss: 2.0507 - regression_loss: 1.7015 - classification_loss: 0.3492
 903/1000 [==========================>...] - ETA: 27s - loss: 2.0503 - regression_loss: 1.7012 - classification_loss: 0.3491
 904/1000 [==========================>...] - ETA: 27s - loss: 2.0497 - regression_loss: 1.7007 - classification_loss: 0.3489
 905/1000 [==========================>...] - ETA: 27s - loss: 2.0495 - regression_loss: 1.7006 - classification_loss: 0.3488
 906/1000 [==========================>...] - ETA: 26s - loss: 2.0491 - regression_loss: 1.7004 - classification_loss: 0.3487
 907/1000 [==========================>...] - ETA: 26s - loss: 2.0490 - regression_loss: 1.7004 - classification_loss: 0.3486
 908/1000 [==========================>...] - ETA: 26s - loss: 2.0486 - regression_loss: 1.7001 - classification_loss: 0.3485
 909/1000 [==========================>...] - ETA: 26s - loss: 2.0484 - regression_loss: 1.6999 - classification_loss: 0.3484
 910/1000 [==========================>...] - ETA: 25s - loss: 2.0483 - regression_loss: 1.7000 - classification_loss: 0.3483
 911/1000 [==========================>...] - ETA: 25s - loss: 2.0488 - regression_loss: 1.7005 - classification_loss: 0.3483
 912/1000 [==========================>...] - ETA: 25s - loss: 2.0509 - regression_loss: 1.7022 - classification_loss: 0.3487
 913/1000 [==========================>...] - ETA: 24s - loss: 2.0507 - regression_loss: 1.7019 - classification_loss: 0.3488
 914/1000 [==========================>...] - ETA: 24s - loss: 2.0513 - regression_loss: 1.7026 - classification_loss: 0.3488
 915/1000 [==========================>...] - ETA: 24s - loss: 2.0519 - regression_loss: 1.7032 - classification_loss: 0.3487
 916/1000 [==========================>...] - ETA: 24s - loss: 2.0538 - regression_loss: 1.7051 - classification_loss: 0.3487
 917/1000 [==========================>...] - ETA: 23s - loss: 2.0532 - regression_loss: 1.7047 - classification_loss: 0.3486
 918/1000 [==========================>...] - ETA: 23s - loss: 2.0535 - regression_loss: 1.7049 - classification_loss: 0.3486
 919/1000 [==========================>...] - ETA: 23s - loss: 2.0531 - regression_loss: 1.7047 - classification_loss: 0.3485
 920/1000 [==========================>...] - ETA: 22s - loss: 2.0534 - regression_loss: 1.7050 - classification_loss: 0.3485
 921/1000 [==========================>...] - ETA: 22s - loss: 2.0539 - regression_loss: 1.7054 - classification_loss: 0.3485
 922/1000 [==========================>...] - ETA: 22s - loss: 2.0546 - regression_loss: 1.7056 - classification_loss: 0.3490
 923/1000 [==========================>...] - ETA: 22s - loss: 2.0542 - regression_loss: 1.7054 - classification_loss: 0.3488
 924/1000 [==========================>...] - ETA: 21s - loss: 2.0538 - regression_loss: 1.7050 - classification_loss: 0.3488
 925/1000 [==========================>...] - ETA: 21s - loss: 2.0534 - regression_loss: 1.7047 - classification_loss: 0.3486
 926/1000 [==========================>...] - ETA: 21s - loss: 2.0533 - regression_loss: 1.7048 - classification_loss: 0.3486
 927/1000 [==========================>...] - ETA: 20s - loss: 2.0535 - regression_loss: 1.7049 - classification_loss: 0.3486
 928/1000 [==========================>...] - ETA: 20s - loss: 2.0529 - regression_loss: 1.7045 - classification_loss: 0.3485
 929/1000 [==========================>...] - ETA: 20s - loss: 2.0531 - regression_loss: 1.7046 - classification_loss: 0.3486
 930/1000 [==========================>...] - ETA: 20s - loss: 2.0526 - regression_loss: 1.7041 - classification_loss: 0.3485
 931/1000 [==========================>...] - ETA: 19s - loss: 2.0525 - regression_loss: 1.7040 - classification_loss: 0.3485
 932/1000 [==========================>...] - ETA: 19s - loss: 2.0513 - regression_loss: 1.7030 - classification_loss: 0.3483
 933/1000 [==========================>...] - ETA: 19s - loss: 2.0511 - regression_loss: 1.7029 - classification_loss: 0.3482
 934/1000 [===========================>..] - ETA: 18s - loss: 2.0507 - regression_loss: 1.7025 - classification_loss: 0.3482
 935/1000 [===========================>..] - ETA: 18s - loss: 2.0515 - regression_loss: 1.7031 - classification_loss: 0.3484
 936/1000 [===========================>..] - ETA: 18s - loss: 2.0522 - regression_loss: 1.7036 - classification_loss: 0.3486
 937/1000 [===========================>..] - ETA: 18s - loss: 2.0520 - regression_loss: 1.7034 - classification_loss: 0.3486
 938/1000 [===========================>..] - ETA: 17s - loss: 2.0523 - regression_loss: 1.7037 - classification_loss: 0.3486
 939/1000 [===========================>..] - ETA: 17s - loss: 2.0524 - regression_loss: 1.7039 - classification_loss: 0.3484
 940/1000 [===========================>..] - ETA: 17s - loss: 2.0527 - regression_loss: 1.7043 - classification_loss: 0.3484
 941/1000 [===========================>..] - ETA: 16s - loss: 2.0510 - regression_loss: 1.7024 - classification_loss: 0.3485
 942/1000 [===========================>..] - ETA: 16s - loss: 2.0508 - regression_loss: 1.7023 - classification_loss: 0.3485
 943/1000 [===========================>..] - ETA: 16s - loss: 2.0499 - regression_loss: 1.7016 - classification_loss: 0.3484
 944/1000 [===========================>..] - ETA: 16s - loss: 2.0494 - regression_loss: 1.7013 - classification_loss: 0.3481
 945/1000 [===========================>..] - ETA: 15s - loss: 2.0485 - regression_loss: 1.7004 - classification_loss: 0.3480
 946/1000 [===========================>..] - ETA: 15s - loss: 2.0497 - regression_loss: 1.7017 - classification_loss: 0.3480
 947/1000 [===========================>..] - ETA: 15s - loss: 2.0507 - regression_loss: 1.7024 - classification_loss: 0.3482
 948/1000 [===========================>..] - ETA: 14s - loss: 2.0511 - regression_loss: 1.7028 - classification_loss: 0.3483
 949/1000 [===========================>..] - ETA: 14s - loss: 2.0511 - regression_loss: 1.7029 - classification_loss: 0.3482
 950/1000 [===========================>..] - ETA: 14s - loss: 2.0514 - regression_loss: 1.7031 - classification_loss: 0.3483
 951/1000 [===========================>..] - ETA: 14s - loss: 2.0506 - regression_loss: 1.7025 - classification_loss: 0.3482
 952/1000 [===========================>..] - ETA: 13s - loss: 2.0504 - regression_loss: 1.7022 - classification_loss: 0.3482
 953/1000 [===========================>..] - ETA: 13s - loss: 2.0507 - regression_loss: 1.7027 - classification_loss: 0.3480
 954/1000 [===========================>..] - ETA: 13s - loss: 2.0499 - regression_loss: 1.7021 - classification_loss: 0.3479
 955/1000 [===========================>..] - ETA: 12s - loss: 2.0497 - regression_loss: 1.7019 - classification_loss: 0.3478
 956/1000 [===========================>..] - ETA: 12s - loss: 2.0494 - regression_loss: 1.7017 - classification_loss: 0.3477
 957/1000 [===========================>..] - ETA: 12s - loss: 2.0495 - regression_loss: 1.7018 - classification_loss: 0.3477
 958/1000 [===========================>..] - ETA: 12s - loss: 2.0509 - regression_loss: 1.7030 - classification_loss: 0.3478
 959/1000 [===========================>..] - ETA: 11s - loss: 2.0507 - regression_loss: 1.7029 - classification_loss: 0.3477
 960/1000 [===========================>..] - ETA: 11s - loss: 2.0509 - regression_loss: 1.7030 - classification_loss: 0.3479
 961/1000 [===========================>..] - ETA: 11s - loss: 2.0521 - regression_loss: 1.7041 - classification_loss: 0.3481
 962/1000 [===========================>..] - ETA: 10s - loss: 2.0513 - regression_loss: 1.7034 - classification_loss: 0.3479
 963/1000 [===========================>..] - ETA: 10s - loss: 2.0511 - regression_loss: 1.7033 - classification_loss: 0.3478
 964/1000 [===========================>..] - ETA: 10s - loss: 2.0512 - regression_loss: 1.7033 - classification_loss: 0.3479
 965/1000 [===========================>..] - ETA: 10s - loss: 2.0503 - regression_loss: 1.7026 - classification_loss: 0.3477
 966/1000 [===========================>..] - ETA: 9s - loss: 2.0506 - regression_loss: 1.7029 - classification_loss: 0.3477 
 967/1000 [============================>.] - ETA: 9s - loss: 2.0501 - regression_loss: 1.7025 - classification_loss: 0.3476
 968/1000 [============================>.] - ETA: 9s - loss: 2.0500 - regression_loss: 1.7024 - classification_loss: 0.3476
 969/1000 [============================>.] - ETA: 8s - loss: 2.0496 - regression_loss: 1.7022 - classification_loss: 0.3474
 970/1000 [============================>.] - ETA: 8s - loss: 2.0502 - regression_loss: 1.7026 - classification_loss: 0.3476
 971/1000 [============================>.] - ETA: 8s - loss: 2.0500 - regression_loss: 1.7024 - classification_loss: 0.3476
 972/1000 [============================>.] - ETA: 8s - loss: 2.0508 - regression_loss: 1.7032 - classification_loss: 0.3476
 973/1000 [============================>.] - ETA: 7s - loss: 2.0500 - regression_loss: 1.7026 - classification_loss: 0.3474
 974/1000 [============================>.] - ETA: 7s - loss: 2.0494 - regression_loss: 1.7022 - classification_loss: 0.3472
 975/1000 [============================>.] - ETA: 7s - loss: 2.0490 - regression_loss: 1.7018 - classification_loss: 0.3471
 976/1000 [============================>.] - ETA: 6s - loss: 2.0488 - regression_loss: 1.7017 - classification_loss: 0.3471
 977/1000 [============================>.] - ETA: 6s - loss: 2.0477 - regression_loss: 1.7008 - classification_loss: 0.3469
 978/1000 [============================>.] - ETA: 6s - loss: 2.0467 - regression_loss: 1.7001 - classification_loss: 0.3467
 979/1000 [============================>.] - ETA: 6s - loss: 2.0472 - regression_loss: 1.7005 - classification_loss: 0.3467
 980/1000 [============================>.] - ETA: 5s - loss: 2.0466 - regression_loss: 1.7001 - classification_loss: 0.3465
 981/1000 [============================>.] - ETA: 5s - loss: 2.0469 - regression_loss: 1.7004 - classification_loss: 0.3465
 982/1000 [============================>.] - ETA: 5s - loss: 2.0458 - regression_loss: 1.6995 - classification_loss: 0.3463
 983/1000 [============================>.] - ETA: 4s - loss: 2.0451 - regression_loss: 1.6990 - classification_loss: 0.3461
 984/1000 [============================>.] - ETA: 4s - loss: 2.0453 - regression_loss: 1.6993 - classification_loss: 0.3460
 985/1000 [============================>.] - ETA: 4s - loss: 2.0460 - regression_loss: 1.6999 - classification_loss: 0.3460
 986/1000 [============================>.] - ETA: 4s - loss: 2.0459 - regression_loss: 1.6998 - classification_loss: 0.3460
 987/1000 [============================>.] - ETA: 3s - loss: 2.0458 - regression_loss: 1.6998 - classification_loss: 0.3460
 988/1000 [============================>.] - ETA: 3s - loss: 2.0455 - regression_loss: 1.6996 - classification_loss: 0.3459
 989/1000 [============================>.] - ETA: 3s - loss: 2.0463 - regression_loss: 1.7003 - classification_loss: 0.3460
 990/1000 [============================>.] - ETA: 2s - loss: 2.0464 - regression_loss: 1.7005 - classification_loss: 0.3459
 991/1000 [============================>.] - ETA: 2s - loss: 2.0458 - regression_loss: 1.6999 - classification_loss: 0.3459
 992/1000 [============================>.] - ETA: 2s - loss: 2.0458 - regression_loss: 1.6999 - classification_loss: 0.3459
 993/1000 [============================>.] - ETA: 2s - loss: 2.0469 - regression_loss: 1.7008 - classification_loss: 0.3461
 994/1000 [============================>.] - ETA: 1s - loss: 2.0468 - regression_loss: 1.7007 - classification_loss: 0.3461
 995/1000 [============================>.] - ETA: 1s - loss: 2.0466 - regression_loss: 1.7005 - classification_loss: 0.3461
 996/1000 [============================>.] - ETA: 1s - loss: 2.0476 - regression_loss: 1.7016 - classification_loss: 0.3460
 997/1000 [============================>.] - ETA: 0s - loss: 2.0484 - regression_loss: 1.7024 - classification_loss: 0.3461
 998/1000 [============================>.] - ETA: 0s - loss: 2.0478 - regression_loss: 1.7019 - classification_loss: 0.3459
 999/1000 [============================>.] - ETA: 0s - loss: 2.0497 - regression_loss: 1.7036 - classification_loss: 0.3462
1000/1000 [==============================] - 286s 286ms/step - loss: 2.0503 - regression_loss: 1.7039 - classification_loss: 0.3463

Epoch 00002: saving model to ./snapshots/resnet50_csv_02.h5
Epoch 3/10

   1/1000 [..............................] - ETA: 4:43 - loss: 2.0121 - regression_loss: 1.7621 - classification_loss: 0.2500
   2/1000 [..............................] - ETA: 4:50 - loss: 2.4535 - regression_loss: 2.1036 - classification_loss: 0.3499
   3/1000 [..............................] - ETA: 4:49 - loss: 1.9862 - regression_loss: 1.7020 - classification_loss: 0.2842
   4/1000 [..............................] - ETA: 4:47 - loss: 1.7737 - regression_loss: 1.5243 - classification_loss: 0.2494
   5/1000 [..............................] - ETA: 4:44 - loss: 1.7072 - regression_loss: 1.4685 - classification_loss: 0.2388
   6/1000 [..............................] - ETA: 4:43 - loss: 1.6653 - regression_loss: 1.4342 - classification_loss: 0.2311
   7/1000 [..............................] - ETA: 4:42 - loss: 1.8934 - regression_loss: 1.6048 - classification_loss: 0.2886
   8/1000 [..............................] - ETA: 4:42 - loss: 1.9202 - regression_loss: 1.6314 - classification_loss: 0.2888
   9/1000 [..............................] - ETA: 4:42 - loss: 1.8995 - regression_loss: 1.6186 - classification_loss: 0.2809
  10/1000 [..............................] - ETA: 4:43 - loss: 1.8787 - regression_loss: 1.6039 - classification_loss: 0.2749
  11/1000 [..............................] - ETA: 4:43 - loss: 1.9641 - regression_loss: 1.6809 - classification_loss: 0.2832
  12/1000 [..............................] - ETA: 4:42 - loss: 1.9135 - regression_loss: 1.6396 - classification_loss: 0.2739
  13/1000 [..............................] - ETA: 4:43 - loss: 1.9158 - regression_loss: 1.6488 - classification_loss: 0.2670
  14/1000 [..............................] - ETA: 4:42 - loss: 2.0067 - regression_loss: 1.7155 - classification_loss: 0.2913
  15/1000 [..............................] - ETA: 4:42 - loss: 1.9753 - regression_loss: 1.6888 - classification_loss: 0.2865
  16/1000 [..............................] - ETA: 4:41 - loss: 1.9496 - regression_loss: 1.6679 - classification_loss: 0.2817
  17/1000 [..............................] - ETA: 4:41 - loss: 1.8980 - regression_loss: 1.6253 - classification_loss: 0.2727
  18/1000 [..............................] - ETA: 4:41 - loss: 1.9045 - regression_loss: 1.6284 - classification_loss: 0.2760
  19/1000 [..............................] - ETA: 4:40 - loss: 1.8749 - regression_loss: 1.5849 - classification_loss: 0.2901
  20/1000 [..............................] - ETA: 4:40 - loss: 1.8880 - regression_loss: 1.5948 - classification_loss: 0.2932
  21/1000 [..............................] - ETA: 4:40 - loss: 1.8561 - regression_loss: 1.5699 - classification_loss: 0.2862
  22/1000 [..............................] - ETA: 4:40 - loss: 1.8237 - regression_loss: 1.5441 - classification_loss: 0.2796
  23/1000 [..............................] - ETA: 4:39 - loss: 1.8191 - regression_loss: 1.5411 - classification_loss: 0.2781
  24/1000 [..............................] - ETA: 4:39 - loss: 1.7961 - regression_loss: 1.5216 - classification_loss: 0.2745
  25/1000 [..............................] - ETA: 4:39 - loss: 1.8165 - regression_loss: 1.5409 - classification_loss: 0.2756
  26/1000 [..............................] - ETA: 4:38 - loss: 1.8313 - regression_loss: 1.5565 - classification_loss: 0.2748
  27/1000 [..............................] - ETA: 4:38 - loss: 1.8373 - regression_loss: 1.5579 - classification_loss: 0.2794
  28/1000 [..............................] - ETA: 4:38 - loss: 1.8450 - regression_loss: 1.5656 - classification_loss: 0.2794
  29/1000 [..............................] - ETA: 4:38 - loss: 1.8519 - regression_loss: 1.5691 - classification_loss: 0.2828
  30/1000 [..............................] - ETA: 4:38 - loss: 1.8465 - regression_loss: 1.5661 - classification_loss: 0.2803
  31/1000 [..............................] - ETA: 4:37 - loss: 1.8563 - regression_loss: 1.5718 - classification_loss: 0.2845
  32/1000 [..............................] - ETA: 4:37 - loss: 1.8464 - regression_loss: 1.5626 - classification_loss: 0.2838
  33/1000 [..............................] - ETA: 4:36 - loss: 1.8371 - regression_loss: 1.5536 - classification_loss: 0.2835
  34/1000 [>.............................] - ETA: 4:37 - loss: 1.8399 - regression_loss: 1.5550 - classification_loss: 0.2849
  35/1000 [>.............................] - ETA: 4:36 - loss: 1.8445 - regression_loss: 1.5601 - classification_loss: 0.2844
  36/1000 [>.............................] - ETA: 4:36 - loss: 1.8538 - regression_loss: 1.5672 - classification_loss: 0.2866
  37/1000 [>.............................] - ETA: 4:35 - loss: 1.8461 - regression_loss: 1.5625 - classification_loss: 0.2836
  38/1000 [>.............................] - ETA: 4:35 - loss: 1.8405 - regression_loss: 1.5593 - classification_loss: 0.2812
  39/1000 [>.............................] - ETA: 4:35 - loss: 1.8490 - regression_loss: 1.5685 - classification_loss: 0.2805
  40/1000 [>.............................] - ETA: 4:34 - loss: 1.8574 - regression_loss: 1.5794 - classification_loss: 0.2780
  41/1000 [>.............................] - ETA: 4:34 - loss: 1.8611 - regression_loss: 1.5818 - classification_loss: 0.2793
  42/1000 [>.............................] - ETA: 4:34 - loss: 1.8450 - regression_loss: 1.5687 - classification_loss: 0.2762
  43/1000 [>.............................] - ETA: 4:34 - loss: 1.8265 - regression_loss: 1.5539 - classification_loss: 0.2726
  44/1000 [>.............................] - ETA: 4:34 - loss: 1.8259 - regression_loss: 1.5519 - classification_loss: 0.2740
  45/1000 [>.............................] - ETA: 4:33 - loss: 1.8143 - regression_loss: 1.5429 - classification_loss: 0.2714
  46/1000 [>.............................] - ETA: 4:33 - loss: 1.8004 - regression_loss: 1.5323 - classification_loss: 0.2681
  47/1000 [>.............................] - ETA: 4:33 - loss: 1.8128 - regression_loss: 1.5408 - classification_loss: 0.2719
  48/1000 [>.............................] - ETA: 4:32 - loss: 1.8085 - regression_loss: 1.5383 - classification_loss: 0.2702
  49/1000 [>.............................] - ETA: 4:32 - loss: 1.7957 - regression_loss: 1.5262 - classification_loss: 0.2695
  50/1000 [>.............................] - ETA: 4:32 - loss: 1.8126 - regression_loss: 1.5365 - classification_loss: 0.2761
  51/1000 [>.............................] - ETA: 4:31 - loss: 1.7997 - regression_loss: 1.5267 - classification_loss: 0.2730
  52/1000 [>.............................] - ETA: 4:31 - loss: 1.7990 - regression_loss: 1.5264 - classification_loss: 0.2726
  53/1000 [>.............................] - ETA: 4:31 - loss: 1.8002 - regression_loss: 1.5287 - classification_loss: 0.2715
  54/1000 [>.............................] - ETA: 4:30 - loss: 1.7914 - regression_loss: 1.5221 - classification_loss: 0.2693
  55/1000 [>.............................] - ETA: 4:30 - loss: 1.7876 - regression_loss: 1.5192 - classification_loss: 0.2684
  56/1000 [>.............................] - ETA: 4:30 - loss: 1.7831 - regression_loss: 1.5162 - classification_loss: 0.2669
  57/1000 [>.............................] - ETA: 4:30 - loss: 1.7920 - regression_loss: 1.5223 - classification_loss: 0.2697
  58/1000 [>.............................] - ETA: 4:29 - loss: 1.7820 - regression_loss: 1.5140 - classification_loss: 0.2680
  59/1000 [>.............................] - ETA: 4:29 - loss: 1.7830 - regression_loss: 1.5137 - classification_loss: 0.2692
  60/1000 [>.............................] - ETA: 4:29 - loss: 1.7840 - regression_loss: 1.5141 - classification_loss: 0.2699
  61/1000 [>.............................] - ETA: 4:29 - loss: 1.7797 - regression_loss: 1.5101 - classification_loss: 0.2697
  62/1000 [>.............................] - ETA: 4:29 - loss: 1.7707 - regression_loss: 1.5020 - classification_loss: 0.2687
  63/1000 [>.............................] - ETA: 4:28 - loss: 1.7676 - regression_loss: 1.4976 - classification_loss: 0.2700
  64/1000 [>.............................] - ETA: 4:28 - loss: 1.7667 - regression_loss: 1.4974 - classification_loss: 0.2692
  65/1000 [>.............................] - ETA: 4:28 - loss: 1.7548 - regression_loss: 1.4880 - classification_loss: 0.2667
  66/1000 [>.............................] - ETA: 4:27 - loss: 1.7405 - regression_loss: 1.4754 - classification_loss: 0.2652
  67/1000 [=>............................] - ETA: 4:27 - loss: 1.7616 - regression_loss: 1.4911 - classification_loss: 0.2705
  68/1000 [=>............................] - ETA: 4:27 - loss: 1.7564 - regression_loss: 1.4874 - classification_loss: 0.2691
  69/1000 [=>............................] - ETA: 4:27 - loss: 1.7539 - regression_loss: 1.4866 - classification_loss: 0.2673
  70/1000 [=>............................] - ETA: 4:26 - loss: 1.7581 - regression_loss: 1.4888 - classification_loss: 0.2693
  71/1000 [=>............................] - ETA: 4:26 - loss: 1.7485 - regression_loss: 1.4809 - classification_loss: 0.2675
  72/1000 [=>............................] - ETA: 4:26 - loss: 1.7475 - regression_loss: 1.4803 - classification_loss: 0.2672
  73/1000 [=>............................] - ETA: 4:25 - loss: 1.7381 - regression_loss: 1.4711 - classification_loss: 0.2670
  74/1000 [=>............................] - ETA: 4:25 - loss: 1.7380 - regression_loss: 1.4719 - classification_loss: 0.2661
  75/1000 [=>............................] - ETA: 4:25 - loss: 1.7369 - regression_loss: 1.4697 - classification_loss: 0.2673
  76/1000 [=>............................] - ETA: 4:24 - loss: 1.7439 - regression_loss: 1.4756 - classification_loss: 0.2684
  77/1000 [=>............................] - ETA: 4:24 - loss: 1.7622 - regression_loss: 1.4890 - classification_loss: 0.2732
  78/1000 [=>............................] - ETA: 4:24 - loss: 1.7595 - regression_loss: 1.4870 - classification_loss: 0.2725
  79/1000 [=>............................] - ETA: 4:24 - loss: 1.7548 - regression_loss: 1.4820 - classification_loss: 0.2728
  80/1000 [=>............................] - ETA: 4:23 - loss: 1.7622 - regression_loss: 1.4880 - classification_loss: 0.2742
  81/1000 [=>............................] - ETA: 4:23 - loss: 1.7522 - regression_loss: 1.4799 - classification_loss: 0.2722
  82/1000 [=>............................] - ETA: 4:23 - loss: 1.7543 - regression_loss: 1.4820 - classification_loss: 0.2722
  83/1000 [=>............................] - ETA: 4:23 - loss: 1.7466 - regression_loss: 1.4758 - classification_loss: 0.2708
  84/1000 [=>............................] - ETA: 4:22 - loss: 1.7398 - regression_loss: 1.4699 - classification_loss: 0.2699
  85/1000 [=>............................] - ETA: 4:22 - loss: 1.7427 - regression_loss: 1.4719 - classification_loss: 0.2708
  86/1000 [=>............................] - ETA: 4:22 - loss: 1.7426 - regression_loss: 1.4717 - classification_loss: 0.2709
  87/1000 [=>............................] - ETA: 4:22 - loss: 1.7426 - regression_loss: 1.4718 - classification_loss: 0.2708
  88/1000 [=>............................] - ETA: 4:21 - loss: 1.7495 - regression_loss: 1.4775 - classification_loss: 0.2720
  89/1000 [=>............................] - ETA: 4:21 - loss: 1.7609 - regression_loss: 1.4851 - classification_loss: 0.2757
  90/1000 [=>............................] - ETA: 4:21 - loss: 1.7534 - regression_loss: 1.4779 - classification_loss: 0.2754
  91/1000 [=>............................] - ETA: 4:21 - loss: 1.7505 - regression_loss: 1.4758 - classification_loss: 0.2747
  92/1000 [=>............................] - ETA: 4:20 - loss: 1.7604 - regression_loss: 1.4839 - classification_loss: 0.2765
  93/1000 [=>............................] - ETA: 4:20 - loss: 1.7573 - regression_loss: 1.4815 - classification_loss: 0.2758
  94/1000 [=>............................] - ETA: 4:20 - loss: 1.7608 - regression_loss: 1.4855 - classification_loss: 0.2753
  95/1000 [=>............................] - ETA: 4:19 - loss: 1.7649 - regression_loss: 1.4870 - classification_loss: 0.2780
  96/1000 [=>............................] - ETA: 4:19 - loss: 1.7693 - regression_loss: 1.4906 - classification_loss: 0.2787
  97/1000 [=>............................] - ETA: 4:19 - loss: 1.7634 - regression_loss: 1.4752 - classification_loss: 0.2882
  98/1000 [=>............................] - ETA: 4:19 - loss: 1.7612 - regression_loss: 1.4735 - classification_loss: 0.2877
  99/1000 [=>............................] - ETA: 4:18 - loss: 1.7600 - regression_loss: 1.4727 - classification_loss: 0.2873
 100/1000 [==>...........................] - ETA: 4:18 - loss: 1.7579 - regression_loss: 1.4707 - classification_loss: 0.2872
 101/1000 [==>...........................] - ETA: 4:18 - loss: 1.7579 - regression_loss: 1.4708 - classification_loss: 0.2871
 102/1000 [==>...........................] - ETA: 4:18 - loss: 1.7599 - regression_loss: 1.4723 - classification_loss: 0.2876
 103/1000 [==>...........................] - ETA: 4:17 - loss: 1.7654 - regression_loss: 1.4769 - classification_loss: 0.2885
 104/1000 [==>...........................] - ETA: 4:17 - loss: 1.7716 - regression_loss: 1.4826 - classification_loss: 0.2890
 105/1000 [==>...........................] - ETA: 4:17 - loss: 1.7819 - regression_loss: 1.4895 - classification_loss: 0.2924
 106/1000 [==>...........................] - ETA: 4:16 - loss: 1.7928 - regression_loss: 1.4990 - classification_loss: 0.2938
 107/1000 [==>...........................] - ETA: 4:16 - loss: 1.7905 - regression_loss: 1.4970 - classification_loss: 0.2935
 108/1000 [==>...........................] - ETA: 4:16 - loss: 1.7872 - regression_loss: 1.4940 - classification_loss: 0.2932
 109/1000 [==>...........................] - ETA: 4:16 - loss: 1.7896 - regression_loss: 1.4958 - classification_loss: 0.2938
 110/1000 [==>...........................] - ETA: 4:15 - loss: 1.7871 - regression_loss: 1.4938 - classification_loss: 0.2933
 111/1000 [==>...........................] - ETA: 4:15 - loss: 1.7959 - regression_loss: 1.4999 - classification_loss: 0.2960
 112/1000 [==>...........................] - ETA: 4:15 - loss: 1.7940 - regression_loss: 1.4989 - classification_loss: 0.2952
 113/1000 [==>...........................] - ETA: 4:14 - loss: 1.7953 - regression_loss: 1.5005 - classification_loss: 0.2948
 114/1000 [==>...........................] - ETA: 4:14 - loss: 1.7931 - regression_loss: 1.4988 - classification_loss: 0.2942
 115/1000 [==>...........................] - ETA: 4:14 - loss: 1.7960 - regression_loss: 1.5002 - classification_loss: 0.2958
 116/1000 [==>...........................] - ETA: 4:13 - loss: 1.7932 - regression_loss: 1.4978 - classification_loss: 0.2954
 117/1000 [==>...........................] - ETA: 4:13 - loss: 1.7915 - regression_loss: 1.4954 - classification_loss: 0.2961
 118/1000 [==>...........................] - ETA: 4:13 - loss: 1.7954 - regression_loss: 1.4976 - classification_loss: 0.2979
 119/1000 [==>...........................] - ETA: 4:13 - loss: 1.7968 - regression_loss: 1.4970 - classification_loss: 0.2998
 120/1000 [==>...........................] - ETA: 4:12 - loss: 1.7998 - regression_loss: 1.4979 - classification_loss: 0.3019
 121/1000 [==>...........................] - ETA: 4:12 - loss: 1.7969 - regression_loss: 1.4954 - classification_loss: 0.3015
 122/1000 [==>...........................] - ETA: 4:12 - loss: 1.7900 - regression_loss: 1.4898 - classification_loss: 0.3002
 123/1000 [==>...........................] - ETA: 4:11 - loss: 1.7912 - regression_loss: 1.4916 - classification_loss: 0.2996
 124/1000 [==>...........................] - ETA: 4:11 - loss: 1.8043 - regression_loss: 1.5034 - classification_loss: 0.3010
 125/1000 [==>...........................] - ETA: 4:11 - loss: 1.8024 - regression_loss: 1.5026 - classification_loss: 0.2997
 126/1000 [==>...........................] - ETA: 4:11 - loss: 1.8043 - regression_loss: 1.5036 - classification_loss: 0.3008
 127/1000 [==>...........................] - ETA: 4:10 - loss: 1.8085 - regression_loss: 1.5081 - classification_loss: 0.3004
 128/1000 [==>...........................] - ETA: 4:10 - loss: 1.8046 - regression_loss: 1.5045 - classification_loss: 0.3001
 129/1000 [==>...........................] - ETA: 4:10 - loss: 1.8052 - regression_loss: 1.5048 - classification_loss: 0.3004
 130/1000 [==>...........................] - ETA: 4:09 - loss: 1.8050 - regression_loss: 1.5049 - classification_loss: 0.3001
 131/1000 [==>...........................] - ETA: 4:09 - loss: 1.8074 - regression_loss: 1.5068 - classification_loss: 0.3005
 132/1000 [==>...........................] - ETA: 4:09 - loss: 1.8043 - regression_loss: 1.5045 - classification_loss: 0.2998
 133/1000 [==>...........................] - ETA: 4:08 - loss: 1.8033 - regression_loss: 1.5033 - classification_loss: 0.3000
 134/1000 [===>..........................] - ETA: 4:08 - loss: 1.8153 - regression_loss: 1.5115 - classification_loss: 0.3038
 135/1000 [===>..........................] - ETA: 4:08 - loss: 1.8075 - regression_loss: 1.5045 - classification_loss: 0.3030
 136/1000 [===>..........................] - ETA: 4:08 - loss: 1.7987 - regression_loss: 1.4969 - classification_loss: 0.3019
 137/1000 [===>..........................] - ETA: 4:07 - loss: 1.7997 - regression_loss: 1.4973 - classification_loss: 0.3024
 138/1000 [===>..........................] - ETA: 4:07 - loss: 1.8069 - regression_loss: 1.5035 - classification_loss: 0.3034
 139/1000 [===>..........................] - ETA: 4:07 - loss: 1.8018 - regression_loss: 1.4996 - classification_loss: 0.3022
 140/1000 [===>..........................] - ETA: 4:06 - loss: 1.7984 - regression_loss: 1.4959 - classification_loss: 0.3025
 141/1000 [===>..........................] - ETA: 4:06 - loss: 1.8020 - regression_loss: 1.4999 - classification_loss: 0.3022
 142/1000 [===>..........................] - ETA: 4:06 - loss: 1.7973 - regression_loss: 1.4962 - classification_loss: 0.3011
 143/1000 [===>..........................] - ETA: 4:05 - loss: 1.7951 - regression_loss: 1.4939 - classification_loss: 0.3012
 144/1000 [===>..........................] - ETA: 4:05 - loss: 1.7910 - regression_loss: 1.4903 - classification_loss: 0.3007
 145/1000 [===>..........................] - ETA: 4:05 - loss: 1.7933 - regression_loss: 1.4922 - classification_loss: 0.3011
 146/1000 [===>..........................] - ETA: 4:05 - loss: 1.7981 - regression_loss: 1.4968 - classification_loss: 0.3013
 147/1000 [===>..........................] - ETA: 4:04 - loss: 1.7978 - regression_loss: 1.4969 - classification_loss: 0.3009
 148/1000 [===>..........................] - ETA: 4:04 - loss: 1.8039 - regression_loss: 1.5012 - classification_loss: 0.3027
 149/1000 [===>..........................] - ETA: 4:04 - loss: 1.7983 - regression_loss: 1.4966 - classification_loss: 0.3017
 150/1000 [===>..........................] - ETA: 4:03 - loss: 1.7936 - regression_loss: 1.4929 - classification_loss: 0.3008
 151/1000 [===>..........................] - ETA: 4:03 - loss: 1.7964 - regression_loss: 1.4953 - classification_loss: 0.3011
 152/1000 [===>..........................] - ETA: 4:03 - loss: 1.7972 - regression_loss: 1.4968 - classification_loss: 0.3004
 153/1000 [===>..........................] - ETA: 4:03 - loss: 1.8046 - regression_loss: 1.5029 - classification_loss: 0.3017
 154/1000 [===>..........................] - ETA: 4:02 - loss: 1.8005 - regression_loss: 1.4991 - classification_loss: 0.3014
 155/1000 [===>..........................] - ETA: 4:02 - loss: 1.7978 - regression_loss: 1.4974 - classification_loss: 0.3004
 156/1000 [===>..........................] - ETA: 4:02 - loss: 1.7960 - regression_loss: 1.4963 - classification_loss: 0.2997
 157/1000 [===>..........................] - ETA: 4:01 - loss: 1.7977 - regression_loss: 1.4983 - classification_loss: 0.2994
 158/1000 [===>..........................] - ETA: 4:01 - loss: 1.7958 - regression_loss: 1.4963 - classification_loss: 0.2995
 159/1000 [===>..........................] - ETA: 4:01 - loss: 1.7953 - regression_loss: 1.4963 - classification_loss: 0.2990
 160/1000 [===>..........................] - ETA: 4:01 - loss: 1.7925 - regression_loss: 1.4937 - classification_loss: 0.2988
 161/1000 [===>..........................] - ETA: 4:00 - loss: 1.7917 - regression_loss: 1.4911 - classification_loss: 0.3006
 162/1000 [===>..........................] - ETA: 4:00 - loss: 1.7945 - regression_loss: 1.4946 - classification_loss: 0.2999
 163/1000 [===>..........................] - ETA: 4:00 - loss: 1.7935 - regression_loss: 1.4942 - classification_loss: 0.2994
 164/1000 [===>..........................] - ETA: 3:59 - loss: 1.7935 - regression_loss: 1.4944 - classification_loss: 0.2991
 165/1000 [===>..........................] - ETA: 3:59 - loss: 1.7949 - regression_loss: 1.4952 - classification_loss: 0.2997
 166/1000 [===>..........................] - ETA: 3:59 - loss: 1.7940 - regression_loss: 1.4948 - classification_loss: 0.2992
 167/1000 [====>.........................] - ETA: 3:59 - loss: 1.7942 - regression_loss: 1.4948 - classification_loss: 0.2993
 168/1000 [====>.........................] - ETA: 3:58 - loss: 1.7940 - regression_loss: 1.4948 - classification_loss: 0.2992
 169/1000 [====>.........................] - ETA: 3:58 - loss: 1.7916 - regression_loss: 1.4932 - classification_loss: 0.2984
 170/1000 [====>.........................] - ETA: 3:58 - loss: 1.7939 - regression_loss: 1.4955 - classification_loss: 0.2984
 171/1000 [====>.........................] - ETA: 3:57 - loss: 1.7920 - regression_loss: 1.4943 - classification_loss: 0.2977
 172/1000 [====>.........................] - ETA: 3:57 - loss: 1.7869 - regression_loss: 1.4900 - classification_loss: 0.2970
 173/1000 [====>.........................] - ETA: 3:57 - loss: 1.7862 - regression_loss: 1.4893 - classification_loss: 0.2969
 174/1000 [====>.........................] - ETA: 3:57 - loss: 1.7847 - regression_loss: 1.4883 - classification_loss: 0.2965
 175/1000 [====>.........................] - ETA: 3:56 - loss: 1.7796 - regression_loss: 1.4840 - classification_loss: 0.2956
 176/1000 [====>.........................] - ETA: 3:56 - loss: 1.7800 - regression_loss: 1.4845 - classification_loss: 0.2955
 177/1000 [====>.........................] - ETA: 3:56 - loss: 1.7806 - regression_loss: 1.4855 - classification_loss: 0.2951
 178/1000 [====>.........................] - ETA: 3:55 - loss: 1.7820 - regression_loss: 1.4876 - classification_loss: 0.2944
 179/1000 [====>.........................] - ETA: 3:55 - loss: 1.7891 - regression_loss: 1.4928 - classification_loss: 0.2963
 180/1000 [====>.........................] - ETA: 3:55 - loss: 1.7856 - regression_loss: 1.4897 - classification_loss: 0.2959
 181/1000 [====>.........................] - ETA: 3:54 - loss: 1.7844 - regression_loss: 1.4882 - classification_loss: 0.2962
 182/1000 [====>.........................] - ETA: 3:54 - loss: 1.7795 - regression_loss: 1.4838 - classification_loss: 0.2957
 183/1000 [====>.........................] - ETA: 3:54 - loss: 1.7791 - regression_loss: 1.4836 - classification_loss: 0.2955
 184/1000 [====>.........................] - ETA: 3:54 - loss: 1.7754 - regression_loss: 1.4809 - classification_loss: 0.2945
 185/1000 [====>.........................] - ETA: 3:53 - loss: 1.7760 - regression_loss: 1.4816 - classification_loss: 0.2944
 186/1000 [====>.........................] - ETA: 3:53 - loss: 1.7763 - regression_loss: 1.4822 - classification_loss: 0.2941
 187/1000 [====>.........................] - ETA: 3:53 - loss: 1.7766 - regression_loss: 1.4830 - classification_loss: 0.2936
 188/1000 [====>.........................] - ETA: 3:53 - loss: 1.7786 - regression_loss: 1.4843 - classification_loss: 0.2943
 189/1000 [====>.........................] - ETA: 3:52 - loss: 1.7764 - regression_loss: 1.4828 - classification_loss: 0.2936
 190/1000 [====>.........................] - ETA: 3:52 - loss: 1.7789 - regression_loss: 1.4839 - classification_loss: 0.2950
 191/1000 [====>.........................] - ETA: 3:52 - loss: 1.7791 - regression_loss: 1.4840 - classification_loss: 0.2951
 192/1000 [====>.........................] - ETA: 3:52 - loss: 1.7843 - regression_loss: 1.4875 - classification_loss: 0.2968
 193/1000 [====>.........................] - ETA: 3:51 - loss: 1.7807 - regression_loss: 1.4844 - classification_loss: 0.2963
 194/1000 [====>.........................] - ETA: 3:51 - loss: 1.7782 - regression_loss: 1.4823 - classification_loss: 0.2959
 195/1000 [====>.........................] - ETA: 3:51 - loss: 1.7794 - regression_loss: 1.4825 - classification_loss: 0.2969
 196/1000 [====>.........................] - ETA: 3:50 - loss: 1.7767 - regression_loss: 1.4806 - classification_loss: 0.2961
 197/1000 [====>.........................] - ETA: 3:50 - loss: 1.7768 - regression_loss: 1.4806 - classification_loss: 0.2962
 198/1000 [====>.........................] - ETA: 3:50 - loss: 1.7792 - regression_loss: 1.4832 - classification_loss: 0.2960
 199/1000 [====>.........................] - ETA: 3:49 - loss: 1.7802 - regression_loss: 1.4847 - classification_loss: 0.2955
 200/1000 [=====>........................] - ETA: 3:49 - loss: 1.7792 - regression_loss: 1.4840 - classification_loss: 0.2952
 201/1000 [=====>........................] - ETA: 3:49 - loss: 1.7769 - regression_loss: 1.4823 - classification_loss: 0.2946
 202/1000 [=====>........................] - ETA: 3:49 - loss: 1.7767 - regression_loss: 1.4822 - classification_loss: 0.2946
 203/1000 [=====>........................] - ETA: 3:48 - loss: 1.7803 - regression_loss: 1.4850 - classification_loss: 0.2953
 204/1000 [=====>........................] - ETA: 3:48 - loss: 1.7830 - regression_loss: 1.4873 - classification_loss: 0.2957
 205/1000 [=====>........................] - ETA: 3:48 - loss: 1.7803 - regression_loss: 1.4850 - classification_loss: 0.2953
 206/1000 [=====>........................] - ETA: 3:47 - loss: 1.7824 - regression_loss: 1.4870 - classification_loss: 0.2954
 207/1000 [=====>........................] - ETA: 3:47 - loss: 1.7833 - regression_loss: 1.4884 - classification_loss: 0.2949
 208/1000 [=====>........................] - ETA: 3:47 - loss: 1.7814 - regression_loss: 1.4864 - classification_loss: 0.2950
 209/1000 [=====>........................] - ETA: 3:47 - loss: 1.7786 - regression_loss: 1.4846 - classification_loss: 0.2941
 210/1000 [=====>........................] - ETA: 3:46 - loss: 1.7775 - regression_loss: 1.4839 - classification_loss: 0.2936
 211/1000 [=====>........................] - ETA: 3:46 - loss: 1.7730 - regression_loss: 1.4800 - classification_loss: 0.2929
 212/1000 [=====>........................] - ETA: 3:46 - loss: 1.7675 - regression_loss: 1.4752 - classification_loss: 0.2922
 213/1000 [=====>........................] - ETA: 3:45 - loss: 1.7650 - regression_loss: 1.4729 - classification_loss: 0.2921
 214/1000 [=====>........................] - ETA: 3:45 - loss: 1.7648 - regression_loss: 1.4732 - classification_loss: 0.2916
 215/1000 [=====>........................] - ETA: 3:45 - loss: 1.7627 - regression_loss: 1.4715 - classification_loss: 0.2912
 216/1000 [=====>........................] - ETA: 3:45 - loss: 1.7615 - regression_loss: 1.4708 - classification_loss: 0.2907
 217/1000 [=====>........................] - ETA: 3:44 - loss: 1.7642 - regression_loss: 1.4735 - classification_loss: 0.2907
 218/1000 [=====>........................] - ETA: 3:44 - loss: 1.7630 - regression_loss: 1.4725 - classification_loss: 0.2905
 219/1000 [=====>........................] - ETA: 3:44 - loss: 1.7587 - regression_loss: 1.4687 - classification_loss: 0.2899
 220/1000 [=====>........................] - ETA: 3:43 - loss: 1.7555 - regression_loss: 1.4660 - classification_loss: 0.2895
 221/1000 [=====>........................] - ETA: 3:43 - loss: 1.7510 - regression_loss: 1.4624 - classification_loss: 0.2886
 222/1000 [=====>........................] - ETA: 3:43 - loss: 1.7516 - regression_loss: 1.4630 - classification_loss: 0.2887
 223/1000 [=====>........................] - ETA: 3:42 - loss: 1.7513 - regression_loss: 1.4630 - classification_loss: 0.2883
 224/1000 [=====>........................] - ETA: 3:42 - loss: 1.7516 - regression_loss: 1.4634 - classification_loss: 0.2882
 225/1000 [=====>........................] - ETA: 3:42 - loss: 1.7554 - regression_loss: 1.4664 - classification_loss: 0.2890
 226/1000 [=====>........................] - ETA: 3:42 - loss: 1.7555 - regression_loss: 1.4662 - classification_loss: 0.2893
 227/1000 [=====>........................] - ETA: 3:41 - loss: 1.7566 - regression_loss: 1.4675 - classification_loss: 0.2891
 228/1000 [=====>........................] - ETA: 3:41 - loss: 1.7571 - regression_loss: 1.4680 - classification_loss: 0.2890
 229/1000 [=====>........................] - ETA: 3:41 - loss: 1.7558 - regression_loss: 1.4671 - classification_loss: 0.2887
 230/1000 [=====>........................] - ETA: 3:40 - loss: 1.7581 - regression_loss: 1.4688 - classification_loss: 0.2893
 231/1000 [=====>........................] - ETA: 3:40 - loss: 1.7575 - regression_loss: 1.4681 - classification_loss: 0.2894
 232/1000 [=====>........................] - ETA: 3:40 - loss: 1.7554 - regression_loss: 1.4661 - classification_loss: 0.2893
 233/1000 [=====>........................] - ETA: 3:40 - loss: 1.7569 - regression_loss: 1.4679 - classification_loss: 0.2890
 234/1000 [======>.......................] - ETA: 3:39 - loss: 1.7552 - regression_loss: 1.4665 - classification_loss: 0.2888
 235/1000 [======>.......................] - ETA: 3:39 - loss: 1.7574 - regression_loss: 1.4679 - classification_loss: 0.2896
 236/1000 [======>.......................] - ETA: 3:39 - loss: 1.7593 - regression_loss: 1.4691 - classification_loss: 0.2901
 237/1000 [======>.......................] - ETA: 3:38 - loss: 1.7601 - regression_loss: 1.4699 - classification_loss: 0.2902
 238/1000 [======>.......................] - ETA: 3:38 - loss: 1.7588 - regression_loss: 1.4688 - classification_loss: 0.2900
 239/1000 [======>.......................] - ETA: 3:38 - loss: 1.7569 - regression_loss: 1.4674 - classification_loss: 0.2895
 240/1000 [======>.......................] - ETA: 3:38 - loss: 1.7553 - regression_loss: 1.4662 - classification_loss: 0.2891
 241/1000 [======>.......................] - ETA: 3:37 - loss: 1.7539 - regression_loss: 1.4653 - classification_loss: 0.2886
 242/1000 [======>.......................] - ETA: 3:37 - loss: 1.7545 - regression_loss: 1.4661 - classification_loss: 0.2883
 243/1000 [======>.......................] - ETA: 3:37 - loss: 1.7536 - regression_loss: 1.4657 - classification_loss: 0.2879
 244/1000 [======>.......................] - ETA: 3:36 - loss: 1.7507 - regression_loss: 1.4636 - classification_loss: 0.2871
 245/1000 [======>.......................] - ETA: 3:36 - loss: 1.7560 - regression_loss: 1.4683 - classification_loss: 0.2877
 246/1000 [======>.......................] - ETA: 3:36 - loss: 1.7578 - regression_loss: 1.4691 - classification_loss: 0.2887
 247/1000 [======>.......................] - ETA: 3:36 - loss: 1.7574 - regression_loss: 1.4676 - classification_loss: 0.2898
 248/1000 [======>.......................] - ETA: 3:35 - loss: 1.7578 - regression_loss: 1.4660 - classification_loss: 0.2918
 249/1000 [======>.......................] - ETA: 3:35 - loss: 1.7589 - regression_loss: 1.4665 - classification_loss: 0.2925
 250/1000 [======>.......................] - ETA: 3:35 - loss: 1.7615 - regression_loss: 1.4679 - classification_loss: 0.2936
 251/1000 [======>.......................] - ETA: 3:34 - loss: 1.7616 - regression_loss: 1.4681 - classification_loss: 0.2935
 252/1000 [======>.......................] - ETA: 3:34 - loss: 1.7631 - regression_loss: 1.4693 - classification_loss: 0.2938
 253/1000 [======>.......................] - ETA: 3:34 - loss: 1.7615 - regression_loss: 1.4678 - classification_loss: 0.2937
 254/1000 [======>.......................] - ETA: 3:33 - loss: 1.7583 - regression_loss: 1.4653 - classification_loss: 0.2930
 255/1000 [======>.......................] - ETA: 3:33 - loss: 1.7557 - regression_loss: 1.4627 - classification_loss: 0.2930
 256/1000 [======>.......................] - ETA: 3:33 - loss: 1.7565 - regression_loss: 1.4631 - classification_loss: 0.2934
 257/1000 [======>.......................] - ETA: 3:33 - loss: 1.7586 - regression_loss: 1.4640 - classification_loss: 0.2946
 258/1000 [======>.......................] - ETA: 3:32 - loss: 1.7577 - regression_loss: 1.4627 - classification_loss: 0.2950
 259/1000 [======>.......................] - ETA: 3:32 - loss: 1.7605 - regression_loss: 1.4640 - classification_loss: 0.2965
 260/1000 [======>.......................] - ETA: 3:32 - loss: 1.7600 - regression_loss: 1.4636 - classification_loss: 0.2964
 261/1000 [======>.......................] - ETA: 3:31 - loss: 1.7611 - regression_loss: 1.4641 - classification_loss: 0.2971
 262/1000 [======>.......................] - ETA: 3:31 - loss: 1.7638 - regression_loss: 1.4657 - classification_loss: 0.2981
 263/1000 [======>.......................] - ETA: 3:31 - loss: 1.7648 - regression_loss: 1.4657 - classification_loss: 0.2991
 264/1000 [======>.......................] - ETA: 3:31 - loss: 1.7653 - regression_loss: 1.4662 - classification_loss: 0.2991
 265/1000 [======>.......................] - ETA: 3:30 - loss: 1.7710 - regression_loss: 1.4715 - classification_loss: 0.2995
 266/1000 [======>.......................] - ETA: 3:30 - loss: 1.7753 - regression_loss: 1.4742 - classification_loss: 0.3011
 267/1000 [=======>......................] - ETA: 3:30 - loss: 1.7728 - regression_loss: 1.4724 - classification_loss: 0.3004
 268/1000 [=======>......................] - ETA: 3:29 - loss: 1.7718 - regression_loss: 1.4718 - classification_loss: 0.3000
 269/1000 [=======>......................] - ETA: 3:29 - loss: 1.7698 - regression_loss: 1.4704 - classification_loss: 0.2994
 270/1000 [=======>......................] - ETA: 3:29 - loss: 1.7699 - regression_loss: 1.4706 - classification_loss: 0.2993
 271/1000 [=======>......................] - ETA: 3:29 - loss: 1.7662 - regression_loss: 1.4676 - classification_loss: 0.2986
 272/1000 [=======>......................] - ETA: 3:28 - loss: 1.7659 - regression_loss: 1.4674 - classification_loss: 0.2984
 273/1000 [=======>......................] - ETA: 3:28 - loss: 1.7654 - regression_loss: 1.4674 - classification_loss: 0.2981
 274/1000 [=======>......................] - ETA: 3:28 - loss: 1.7634 - regression_loss: 1.4650 - classification_loss: 0.2984
 275/1000 [=======>......................] - ETA: 3:27 - loss: 1.7643 - regression_loss: 1.4659 - classification_loss: 0.2984
 276/1000 [=======>......................] - ETA: 3:27 - loss: 1.7647 - regression_loss: 1.4663 - classification_loss: 0.2984
 277/1000 [=======>......................] - ETA: 3:27 - loss: 1.7630 - regression_loss: 1.4649 - classification_loss: 0.2981
 278/1000 [=======>......................] - ETA: 3:27 - loss: 1.7641 - regression_loss: 1.4661 - classification_loss: 0.2980
 279/1000 [=======>......................] - ETA: 3:26 - loss: 1.7687 - regression_loss: 1.4694 - classification_loss: 0.2993
 280/1000 [=======>......................] - ETA: 3:26 - loss: 1.7668 - regression_loss: 1.4680 - classification_loss: 0.2987
 281/1000 [=======>......................] - ETA: 3:26 - loss: 1.7645 - regression_loss: 1.4662 - classification_loss: 0.2983
 282/1000 [=======>......................] - ETA: 3:25 - loss: 1.7623 - regression_loss: 1.4644 - classification_loss: 0.2979
 283/1000 [=======>......................] - ETA: 3:25 - loss: 1.7598 - regression_loss: 1.4622 - classification_loss: 0.2976
 284/1000 [=======>......................] - ETA: 3:25 - loss: 1.7604 - regression_loss: 1.4619 - classification_loss: 0.2985
 285/1000 [=======>......................] - ETA: 3:25 - loss: 1.7614 - regression_loss: 1.4629 - classification_loss: 0.2985
 286/1000 [=======>......................] - ETA: 3:24 - loss: 1.7602 - regression_loss: 1.4621 - classification_loss: 0.2980
 287/1000 [=======>......................] - ETA: 3:24 - loss: 1.7595 - regression_loss: 1.4618 - classification_loss: 0.2977
 288/1000 [=======>......................] - ETA: 3:24 - loss: 1.7586 - regression_loss: 1.4614 - classification_loss: 0.2973
 289/1000 [=======>......................] - ETA: 3:23 - loss: 1.7573 - regression_loss: 1.4603 - classification_loss: 0.2970
 290/1000 [=======>......................] - ETA: 3:23 - loss: 1.7550 - regression_loss: 1.4579 - classification_loss: 0.2971
 291/1000 [=======>......................] - ETA: 3:23 - loss: 1.7532 - regression_loss: 1.4567 - classification_loss: 0.2965
 292/1000 [=======>......................] - ETA: 3:23 - loss: 1.7541 - regression_loss: 1.4576 - classification_loss: 0.2966
 293/1000 [=======>......................] - ETA: 3:22 - loss: 1.7545 - regression_loss: 1.4578 - classification_loss: 0.2966
 294/1000 [=======>......................] - ETA: 3:22 - loss: 1.7532 - regression_loss: 1.4566 - classification_loss: 0.2966
 295/1000 [=======>......................] - ETA: 3:22 - loss: 1.7525 - regression_loss: 1.4563 - classification_loss: 0.2962
 296/1000 [=======>......................] - ETA: 3:21 - loss: 1.7581 - regression_loss: 1.4599 - classification_loss: 0.2982
 297/1000 [=======>......................] - ETA: 3:21 - loss: 1.7589 - regression_loss: 1.4605 - classification_loss: 0.2984
 298/1000 [=======>......................] - ETA: 3:21 - loss: 1.7605 - regression_loss: 1.4619 - classification_loss: 0.2986
 299/1000 [=======>......................] - ETA: 3:21 - loss: 1.7577 - regression_loss: 1.4597 - classification_loss: 0.2981
 300/1000 [========>.....................] - ETA: 3:20 - loss: 1.7567 - regression_loss: 1.4590 - classification_loss: 0.2978
 301/1000 [========>.....................] - ETA: 3:20 - loss: 1.7556 - regression_loss: 1.4582 - classification_loss: 0.2974
 302/1000 [========>.....................] - ETA: 3:20 - loss: 1.7575 - regression_loss: 1.4599 - classification_loss: 0.2977
 303/1000 [========>.....................] - ETA: 3:19 - loss: 1.7591 - regression_loss: 1.4613 - classification_loss: 0.2978
 304/1000 [========>.....................] - ETA: 3:19 - loss: 1.7599 - regression_loss: 1.4622 - classification_loss: 0.2977
 305/1000 [========>.....................] - ETA: 3:19 - loss: 1.7588 - regression_loss: 1.4610 - classification_loss: 0.2978
 306/1000 [========>.....................] - ETA: 3:19 - loss: 1.7586 - regression_loss: 1.4609 - classification_loss: 0.2977
 307/1000 [========>.....................] - ETA: 3:18 - loss: 1.7613 - regression_loss: 1.4630 - classification_loss: 0.2983
 308/1000 [========>.....................] - ETA: 3:18 - loss: 1.7600 - regression_loss: 1.4620 - classification_loss: 0.2980
 309/1000 [========>.....................] - ETA: 3:18 - loss: 1.7605 - regression_loss: 1.4625 - classification_loss: 0.2979
 310/1000 [========>.....................] - ETA: 3:17 - loss: 1.7624 - regression_loss: 1.4636 - classification_loss: 0.2988
 311/1000 [========>.....................] - ETA: 3:17 - loss: 1.7644 - regression_loss: 1.4651 - classification_loss: 0.2992
 312/1000 [========>.....................] - ETA: 3:17 - loss: 1.7731 - regression_loss: 1.4676 - classification_loss: 0.3055
 313/1000 [========>.....................] - ETA: 3:16 - loss: 1.7711 - regression_loss: 1.4659 - classification_loss: 0.3052
 314/1000 [========>.....................] - ETA: 3:16 - loss: 1.7695 - regression_loss: 1.4646 - classification_loss: 0.3049
 315/1000 [========>.....................] - ETA: 3:16 - loss: 1.7680 - regression_loss: 1.4633 - classification_loss: 0.3047
 316/1000 [========>.....................] - ETA: 3:16 - loss: 1.7654 - regression_loss: 1.4612 - classification_loss: 0.3043
 317/1000 [========>.....................] - ETA: 3:15 - loss: 1.7651 - regression_loss: 1.4610 - classification_loss: 0.3041
 318/1000 [========>.....................] - ETA: 3:15 - loss: 1.7648 - regression_loss: 1.4606 - classification_loss: 0.3042
 319/1000 [========>.....................] - ETA: 3:15 - loss: 1.7638 - regression_loss: 1.4600 - classification_loss: 0.3038
 320/1000 [========>.....................] - ETA: 3:14 - loss: 1.7629 - regression_loss: 1.4591 - classification_loss: 0.3038
 321/1000 [========>.....................] - ETA: 3:14 - loss: 1.7640 - regression_loss: 1.4604 - classification_loss: 0.3035
 322/1000 [========>.....................] - ETA: 3:14 - loss: 1.7604 - regression_loss: 1.4575 - classification_loss: 0.3029
 323/1000 [========>.....................] - ETA: 3:14 - loss: 1.7593 - regression_loss: 1.4566 - classification_loss: 0.3027
 324/1000 [========>.....................] - ETA: 3:13 - loss: 1.7613 - regression_loss: 1.4583 - classification_loss: 0.3030
 325/1000 [========>.....................] - ETA: 3:13 - loss: 1.7620 - regression_loss: 1.4590 - classification_loss: 0.3031
 326/1000 [========>.....................] - ETA: 3:13 - loss: 1.7601 - regression_loss: 1.4575 - classification_loss: 0.3027
 327/1000 [========>.....................] - ETA: 3:12 - loss: 1.7609 - regression_loss: 1.4583 - classification_loss: 0.3026
 328/1000 [========>.....................] - ETA: 3:12 - loss: 1.7593 - regression_loss: 1.4569 - classification_loss: 0.3024
 329/1000 [========>.....................] - ETA: 3:12 - loss: 1.7601 - regression_loss: 1.4575 - classification_loss: 0.3026
 330/1000 [========>.....................] - ETA: 3:12 - loss: 1.7595 - regression_loss: 1.4570 - classification_loss: 0.3025
 331/1000 [========>.....................] - ETA: 3:11 - loss: 1.7587 - regression_loss: 1.4563 - classification_loss: 0.3023
 332/1000 [========>.....................] - ETA: 3:11 - loss: 1.7578 - regression_loss: 1.4555 - classification_loss: 0.3023
 333/1000 [========>.....................] - ETA: 3:11 - loss: 1.7591 - regression_loss: 1.4566 - classification_loss: 0.3025
 334/1000 [=========>....................] - ETA: 3:10 - loss: 1.7625 - regression_loss: 1.4595 - classification_loss: 0.3031
 335/1000 [=========>....................] - ETA: 3:10 - loss: 1.7625 - regression_loss: 1.4598 - classification_loss: 0.3027
 336/1000 [=========>....................] - ETA: 3:10 - loss: 1.7618 - regression_loss: 1.4589 - classification_loss: 0.3029
 337/1000 [=========>....................] - ETA: 3:10 - loss: 1.7600 - regression_loss: 1.4574 - classification_loss: 0.3026
 338/1000 [=========>....................] - ETA: 3:09 - loss: 1.7585 - regression_loss: 1.4564 - classification_loss: 0.3022
 339/1000 [=========>....................] - ETA: 3:09 - loss: 1.7589 - regression_loss: 1.4567 - classification_loss: 0.3022
 340/1000 [=========>....................] - ETA: 3:09 - loss: 1.7589 - regression_loss: 1.4569 - classification_loss: 0.3021
 341/1000 [=========>....................] - ETA: 3:08 - loss: 1.7608 - regression_loss: 1.4583 - classification_loss: 0.3025
 342/1000 [=========>....................] - ETA: 3:08 - loss: 1.7611 - regression_loss: 1.4587 - classification_loss: 0.3024
 343/1000 [=========>....................] - ETA: 3:08 - loss: 1.7612 - regression_loss: 1.4589 - classification_loss: 0.3023
 344/1000 [=========>....................] - ETA: 3:08 - loss: 1.7587 - regression_loss: 1.4569 - classification_loss: 0.3017
 345/1000 [=========>....................] - ETA: 3:07 - loss: 1.7610 - regression_loss: 1.4589 - classification_loss: 0.3020
 346/1000 [=========>....................] - ETA: 3:07 - loss: 1.7599 - regression_loss: 1.4581 - classification_loss: 0.3018
 347/1000 [=========>....................] - ETA: 3:07 - loss: 1.7609 - regression_loss: 1.4587 - classification_loss: 0.3021
 348/1000 [=========>....................] - ETA: 3:06 - loss: 1.7591 - regression_loss: 1.4574 - classification_loss: 0.3017
 349/1000 [=========>....................] - ETA: 3:06 - loss: 1.7622 - regression_loss: 1.4600 - classification_loss: 0.3022
 350/1000 [=========>....................] - ETA: 3:06 - loss: 1.7590 - regression_loss: 1.4574 - classification_loss: 0.3016
 351/1000 [=========>....................] - ETA: 3:06 - loss: 1.7606 - regression_loss: 1.4588 - classification_loss: 0.3018
 352/1000 [=========>....................] - ETA: 3:05 - loss: 1.7592 - regression_loss: 1.4578 - classification_loss: 0.3014
 353/1000 [=========>....................] - ETA: 3:05 - loss: 1.7592 - regression_loss: 1.4577 - classification_loss: 0.3015
 354/1000 [=========>....................] - ETA: 3:05 - loss: 1.7600 - regression_loss: 1.4585 - classification_loss: 0.3015
 355/1000 [=========>....................] - ETA: 3:04 - loss: 1.7582 - regression_loss: 1.4571 - classification_loss: 0.3011
 356/1000 [=========>....................] - ETA: 3:04 - loss: 1.7613 - regression_loss: 1.4592 - classification_loss: 0.3021
 357/1000 [=========>....................] - ETA: 3:04 - loss: 1.7628 - regression_loss: 1.4605 - classification_loss: 0.3023
 358/1000 [=========>....................] - ETA: 3:04 - loss: 1.7633 - regression_loss: 1.4610 - classification_loss: 0.3023
 359/1000 [=========>....................] - ETA: 3:03 - loss: 1.7623 - regression_loss: 1.4604 - classification_loss: 0.3019
 360/1000 [=========>....................] - ETA: 3:03 - loss: 1.7617 - regression_loss: 1.4600 - classification_loss: 0.3017
 361/1000 [=========>....................] - ETA: 3:03 - loss: 1.7590 - regression_loss: 1.4578 - classification_loss: 0.3012
 362/1000 [=========>....................] - ETA: 3:02 - loss: 1.7585 - regression_loss: 1.4575 - classification_loss: 0.3010
 363/1000 [=========>....................] - ETA: 3:02 - loss: 1.7575 - regression_loss: 1.4569 - classification_loss: 0.3006
 364/1000 [=========>....................] - ETA: 3:02 - loss: 1.7598 - regression_loss: 1.4591 - classification_loss: 0.3007
 365/1000 [=========>....................] - ETA: 3:02 - loss: 1.7584 - regression_loss: 1.4580 - classification_loss: 0.3004
 366/1000 [=========>....................] - ETA: 3:01 - loss: 1.7580 - regression_loss: 1.4576 - classification_loss: 0.3004
 367/1000 [==========>...................] - ETA: 3:01 - loss: 1.7576 - regression_loss: 1.4575 - classification_loss: 0.3000
 368/1000 [==========>...................] - ETA: 3:01 - loss: 1.7576 - regression_loss: 1.4575 - classification_loss: 0.3001
 369/1000 [==========>...................] - ETA: 3:00 - loss: 1.7582 - regression_loss: 1.4583 - classification_loss: 0.2999
 370/1000 [==========>...................] - ETA: 3:00 - loss: 1.7617 - regression_loss: 1.4608 - classification_loss: 0.3009
 371/1000 [==========>...................] - ETA: 3:00 - loss: 1.7617 - regression_loss: 1.4610 - classification_loss: 0.3007
 372/1000 [==========>...................] - ETA: 3:00 - loss: 1.7594 - regression_loss: 1.4592 - classification_loss: 0.3002
 373/1000 [==========>...................] - ETA: 2:59 - loss: 1.7588 - regression_loss: 1.4589 - classification_loss: 0.2999
 374/1000 [==========>...................] - ETA: 2:59 - loss: 1.7620 - regression_loss: 1.4619 - classification_loss: 0.3002
 375/1000 [==========>...................] - ETA: 2:59 - loss: 1.7634 - regression_loss: 1.4629 - classification_loss: 0.3005
 376/1000 [==========>...................] - ETA: 2:58 - loss: 1.7622 - regression_loss: 1.4618 - classification_loss: 0.3004
 377/1000 [==========>...................] - ETA: 2:58 - loss: 1.7623 - regression_loss: 1.4619 - classification_loss: 0.3005
 378/1000 [==========>...................] - ETA: 2:58 - loss: 1.7616 - regression_loss: 1.4611 - classification_loss: 0.3005
 379/1000 [==========>...................] - ETA: 2:58 - loss: 1.7614 - regression_loss: 1.4610 - classification_loss: 0.3004
 380/1000 [==========>...................] - ETA: 2:57 - loss: 1.7619 - regression_loss: 1.4613 - classification_loss: 0.3006
 381/1000 [==========>...................] - ETA: 2:57 - loss: 1.7607 - regression_loss: 1.4603 - classification_loss: 0.3003
 382/1000 [==========>...................] - ETA: 2:57 - loss: 1.7630 - regression_loss: 1.4622 - classification_loss: 0.3008
 383/1000 [==========>...................] - ETA: 2:56 - loss: 1.7623 - regression_loss: 1.4617 - classification_loss: 0.3007
 384/1000 [==========>...................] - ETA: 2:56 - loss: 1.7618 - regression_loss: 1.4613 - classification_loss: 0.3004
 385/1000 [==========>...................] - ETA: 2:56 - loss: 1.7631 - regression_loss: 1.4625 - classification_loss: 0.3006
 386/1000 [==========>...................] - ETA: 2:56 - loss: 1.7620 - regression_loss: 1.4617 - classification_loss: 0.3003
 387/1000 [==========>...................] - ETA: 2:55 - loss: 1.7615 - regression_loss: 1.4615 - classification_loss: 0.3000
 388/1000 [==========>...................] - ETA: 2:55 - loss: 1.7619 - regression_loss: 1.4618 - classification_loss: 0.3001
 389/1000 [==========>...................] - ETA: 2:55 - loss: 1.7739 - regression_loss: 1.4680 - classification_loss: 0.3059
 390/1000 [==========>...................] - ETA: 2:54 - loss: 1.7749 - regression_loss: 1.4692 - classification_loss: 0.3057
 391/1000 [==========>...................] - ETA: 2:54 - loss: 1.7735 - regression_loss: 1.4681 - classification_loss: 0.3055
 392/1000 [==========>...................] - ETA: 2:54 - loss: 1.7743 - regression_loss: 1.4683 - classification_loss: 0.3060
 393/1000 [==========>...................] - ETA: 2:54 - loss: 1.7737 - regression_loss: 1.4678 - classification_loss: 0.3060
 394/1000 [==========>...................] - ETA: 2:53 - loss: 1.7722 - regression_loss: 1.4666 - classification_loss: 0.3056
 395/1000 [==========>...................] - ETA: 2:53 - loss: 1.7701 - regression_loss: 1.4647 - classification_loss: 0.3054
 396/1000 [==========>...................] - ETA: 2:53 - loss: 1.7695 - regression_loss: 1.4641 - classification_loss: 0.3054
 397/1000 [==========>...................] - ETA: 2:52 - loss: 1.7693 - regression_loss: 1.4640 - classification_loss: 0.3053
 398/1000 [==========>...................] - ETA: 2:52 - loss: 1.7679 - regression_loss: 1.4628 - classification_loss: 0.3051
 399/1000 [==========>...................] - ETA: 2:52 - loss: 1.7693 - regression_loss: 1.4641 - classification_loss: 0.3052
 400/1000 [===========>..................] - ETA: 2:52 - loss: 1.7690 - regression_loss: 1.4638 - classification_loss: 0.3052
 401/1000 [===========>..................] - ETA: 2:51 - loss: 1.7668 - regression_loss: 1.4619 - classification_loss: 0.3049
 402/1000 [===========>..................] - ETA: 2:51 - loss: 1.7672 - regression_loss: 1.4621 - classification_loss: 0.3051
 403/1000 [===========>..................] - ETA: 2:51 - loss: 1.7698 - regression_loss: 1.4646 - classification_loss: 0.3052
 404/1000 [===========>..................] - ETA: 2:50 - loss: 1.7698 - regression_loss: 1.4649 - classification_loss: 0.3049
 405/1000 [===========>..................] - ETA: 2:50 - loss: 1.7691 - regression_loss: 1.4643 - classification_loss: 0.3049
 406/1000 [===========>..................] - ETA: 2:50 - loss: 1.7673 - regression_loss: 1.4628 - classification_loss: 0.3045
 407/1000 [===========>..................] - ETA: 2:50 - loss: 1.7698 - regression_loss: 1.4648 - classification_loss: 0.3050
 408/1000 [===========>..................] - ETA: 2:49 - loss: 1.7696 - regression_loss: 1.4648 - classification_loss: 0.3048
 409/1000 [===========>..................] - ETA: 2:49 - loss: 1.7711 - regression_loss: 1.4661 - classification_loss: 0.3050
 410/1000 [===========>..................] - ETA: 2:49 - loss: 1.7691 - regression_loss: 1.4645 - classification_loss: 0.3046
 411/1000 [===========>..................] - ETA: 2:48 - loss: 1.7683 - regression_loss: 1.4639 - classification_loss: 0.3044
 412/1000 [===========>..................] - ETA: 2:48 - loss: 1.7706 - regression_loss: 1.4658 - classification_loss: 0.3048
 413/1000 [===========>..................] - ETA: 2:48 - loss: 1.7705 - regression_loss: 1.4658 - classification_loss: 0.3047
 414/1000 [===========>..................] - ETA: 2:48 - loss: 1.7732 - regression_loss: 1.4675 - classification_loss: 0.3056
 415/1000 [===========>..................] - ETA: 2:47 - loss: 1.7734 - regression_loss: 1.4679 - classification_loss: 0.3055
 416/1000 [===========>..................] - ETA: 2:47 - loss: 1.7709 - regression_loss: 1.4660 - classification_loss: 0.3049
 417/1000 [===========>..................] - ETA: 2:47 - loss: 1.7705 - regression_loss: 1.4657 - classification_loss: 0.3048
 418/1000 [===========>..................] - ETA: 2:46 - loss: 1.7684 - regression_loss: 1.4640 - classification_loss: 0.3044
 419/1000 [===========>..................] - ETA: 2:46 - loss: 1.7683 - regression_loss: 1.4639 - classification_loss: 0.3044
 420/1000 [===========>..................] - ETA: 2:46 - loss: 1.7677 - regression_loss: 1.4627 - classification_loss: 0.3050
 421/1000 [===========>..................] - ETA: 2:46 - loss: 1.7667 - regression_loss: 1.4619 - classification_loss: 0.3048
 422/1000 [===========>..................] - ETA: 2:45 - loss: 1.7682 - regression_loss: 1.4625 - classification_loss: 0.3057
 423/1000 [===========>..................] - ETA: 2:45 - loss: 1.7673 - regression_loss: 1.4618 - classification_loss: 0.3055
 424/1000 [===========>..................] - ETA: 2:45 - loss: 1.7671 - regression_loss: 1.4620 - classification_loss: 0.3052
 425/1000 [===========>..................] - ETA: 2:44 - loss: 1.7667 - regression_loss: 1.4615 - classification_loss: 0.3052
 426/1000 [===========>..................] - ETA: 2:44 - loss: 1.7680 - regression_loss: 1.4624 - classification_loss: 0.3056
 427/1000 [===========>..................] - ETA: 2:44 - loss: 1.7674 - regression_loss: 1.4620 - classification_loss: 0.3055
 428/1000 [===========>..................] - ETA: 2:44 - loss: 1.7664 - regression_loss: 1.4613 - classification_loss: 0.3051
 429/1000 [===========>..................] - ETA: 2:43 - loss: 1.7675 - regression_loss: 1.4622 - classification_loss: 0.3053
 430/1000 [===========>..................] - ETA: 2:43 - loss: 1.7682 - regression_loss: 1.4629 - classification_loss: 0.3053
 431/1000 [===========>..................] - ETA: 2:43 - loss: 1.7662 - regression_loss: 1.4612 - classification_loss: 0.3050
 432/1000 [===========>..................] - ETA: 2:42 - loss: 1.7644 - regression_loss: 1.4597 - classification_loss: 0.3047
 433/1000 [===========>..................] - ETA: 2:42 - loss: 1.7625 - regression_loss: 1.4581 - classification_loss: 0.3044
 434/1000 [============>.................] - ETA: 2:42 - loss: 1.7629 - regression_loss: 1.4587 - classification_loss: 0.3043
 435/1000 [============>.................] - ETA: 2:42 - loss: 1.7627 - regression_loss: 1.4586 - classification_loss: 0.3041
 436/1000 [============>.................] - ETA: 2:41 - loss: 1.7644 - regression_loss: 1.4601 - classification_loss: 0.3043
 437/1000 [============>.................] - ETA: 2:41 - loss: 1.7651 - regression_loss: 1.4609 - classification_loss: 0.3042
 438/1000 [============>.................] - ETA: 2:41 - loss: 1.7639 - regression_loss: 1.4600 - classification_loss: 0.3039
 439/1000 [============>.................] - ETA: 2:40 - loss: 1.7628 - regression_loss: 1.4591 - classification_loss: 0.3037
 440/1000 [============>.................] - ETA: 2:40 - loss: 1.7633 - regression_loss: 1.4595 - classification_loss: 0.3039
 441/1000 [============>.................] - ETA: 2:40 - loss: 1.7631 - regression_loss: 1.4592 - classification_loss: 0.3038
 442/1000 [============>.................] - ETA: 2:40 - loss: 1.7625 - regression_loss: 1.4588 - classification_loss: 0.3037
 443/1000 [============>.................] - ETA: 2:39 - loss: 1.7633 - regression_loss: 1.4593 - classification_loss: 0.3040
 444/1000 [============>.................] - ETA: 2:39 - loss: 1.7621 - regression_loss: 1.4585 - classification_loss: 0.3036
 445/1000 [============>.................] - ETA: 2:39 - loss: 1.7658 - regression_loss: 1.4611 - classification_loss: 0.3047
 446/1000 [============>.................] - ETA: 2:38 - loss: 1.7639 - regression_loss: 1.4591 - classification_loss: 0.3048
 447/1000 [============>.................] - ETA: 2:38 - loss: 1.7655 - regression_loss: 1.4593 - classification_loss: 0.3061
 448/1000 [============>.................] - ETA: 2:38 - loss: 1.7667 - regression_loss: 1.4603 - classification_loss: 0.3064
 449/1000 [============>.................] - ETA: 2:38 - loss: 1.7658 - regression_loss: 1.4598 - classification_loss: 0.3061
 450/1000 [============>.................] - ETA: 2:37 - loss: 1.7654 - regression_loss: 1.4596 - classification_loss: 0.3058
 451/1000 [============>.................] - ETA: 2:37 - loss: 1.7666 - regression_loss: 1.4605 - classification_loss: 0.3061
 452/1000 [============>.................] - ETA: 2:37 - loss: 1.7661 - regression_loss: 1.4601 - classification_loss: 0.3060
 453/1000 [============>.................] - ETA: 2:36 - loss: 1.7656 - regression_loss: 1.4597 - classification_loss: 0.3059
 454/1000 [============>.................] - ETA: 2:36 - loss: 1.7663 - regression_loss: 1.4603 - classification_loss: 0.3060
 455/1000 [============>.................] - ETA: 2:36 - loss: 1.7663 - regression_loss: 1.4603 - classification_loss: 0.3060
 456/1000 [============>.................] - ETA: 2:36 - loss: 1.7668 - regression_loss: 1.4607 - classification_loss: 0.3061
 457/1000 [============>.................] - ETA: 2:35 - loss: 1.7669 - regression_loss: 1.4609 - classification_loss: 0.3059
 458/1000 [============>.................] - ETA: 2:35 - loss: 1.7669 - regression_loss: 1.4610 - classification_loss: 0.3058
 459/1000 [============>.................] - ETA: 2:35 - loss: 1.7694 - regression_loss: 1.4632 - classification_loss: 0.3062
 460/1000 [============>.................] - ETA: 2:34 - loss: 1.7691 - regression_loss: 1.4630 - classification_loss: 0.3062
 461/1000 [============>.................] - ETA: 2:34 - loss: 1.7692 - regression_loss: 1.4630 - classification_loss: 0.3062
 462/1000 [============>.................] - ETA: 2:34 - loss: 1.7678 - regression_loss: 1.4619 - classification_loss: 0.3059
 463/1000 [============>.................] - ETA: 2:34 - loss: 1.7682 - regression_loss: 1.4623 - classification_loss: 0.3059
 464/1000 [============>.................] - ETA: 2:33 - loss: 1.7690 - regression_loss: 1.4631 - classification_loss: 0.3059
 465/1000 [============>.................] - ETA: 2:33 - loss: 1.7702 - regression_loss: 1.4643 - classification_loss: 0.3059
 466/1000 [============>.................] - ETA: 2:33 - loss: 1.7703 - regression_loss: 1.4643 - classification_loss: 0.3061
 467/1000 [=============>................] - ETA: 2:32 - loss: 1.7705 - regression_loss: 1.4643 - classification_loss: 0.3063
 468/1000 [=============>................] - ETA: 2:32 - loss: 1.7689 - regression_loss: 1.4630 - classification_loss: 0.3059
 469/1000 [=============>................] - ETA: 2:32 - loss: 1.7689 - regression_loss: 1.4632 - classification_loss: 0.3057
 470/1000 [=============>................] - ETA: 2:32 - loss: 1.7670 - regression_loss: 1.4615 - classification_loss: 0.3055
 471/1000 [=============>................] - ETA: 2:31 - loss: 1.7683 - regression_loss: 1.4628 - classification_loss: 0.3054
 472/1000 [=============>................] - ETA: 2:31 - loss: 1.7677 - regression_loss: 1.4624 - classification_loss: 0.3053
 473/1000 [=============>................] - ETA: 2:31 - loss: 1.7665 - regression_loss: 1.4614 - classification_loss: 0.3051
 474/1000 [=============>................] - ETA: 2:30 - loss: 1.7664 - regression_loss: 1.4612 - classification_loss: 0.3052
 475/1000 [=============>................] - ETA: 2:30 - loss: 1.7660 - regression_loss: 1.4610 - classification_loss: 0.3050
 476/1000 [=============>................] - ETA: 2:30 - loss: 1.7643 - regression_loss: 1.4596 - classification_loss: 0.3046
 477/1000 [=============>................] - ETA: 2:30 - loss: 1.7642 - regression_loss: 1.4596 - classification_loss: 0.3046
 478/1000 [=============>................] - ETA: 2:29 - loss: 1.7617 - regression_loss: 1.4574 - classification_loss: 0.3043
 479/1000 [=============>................] - ETA: 2:29 - loss: 1.7600 - regression_loss: 1.4559 - classification_loss: 0.3041
 480/1000 [=============>................] - ETA: 2:29 - loss: 1.7609 - regression_loss: 1.4569 - classification_loss: 0.3040
 481/1000 [=============>................] - ETA: 2:28 - loss: 1.7622 - regression_loss: 1.4581 - classification_loss: 0.3041
 482/1000 [=============>................] - ETA: 2:28 - loss: 1.7617 - regression_loss: 1.4580 - classification_loss: 0.3037
 483/1000 [=============>................] - ETA: 2:28 - loss: 1.7631 - regression_loss: 1.4591 - classification_loss: 0.3040
 484/1000 [=============>................] - ETA: 2:28 - loss: 1.7613 - regression_loss: 1.4576 - classification_loss: 0.3036
 485/1000 [=============>................] - ETA: 2:27 - loss: 1.7631 - regression_loss: 1.4593 - classification_loss: 0.3038
 486/1000 [=============>................] - ETA: 2:27 - loss: 1.7610 - regression_loss: 1.4577 - classification_loss: 0.3033
 487/1000 [=============>................] - ETA: 2:27 - loss: 1.7594 - regression_loss: 1.4565 - classification_loss: 0.3029
 488/1000 [=============>................] - ETA: 2:26 - loss: 1.7580 - regression_loss: 1.4553 - classification_loss: 0.3026
 489/1000 [=============>................] - ETA: 2:26 - loss: 1.7570 - regression_loss: 1.4546 - classification_loss: 0.3024
 490/1000 [=============>................] - ETA: 2:26 - loss: 1.7559 - regression_loss: 1.4539 - classification_loss: 0.3021
 491/1000 [=============>................] - ETA: 2:25 - loss: 1.7573 - regression_loss: 1.4550 - classification_loss: 0.3023
 492/1000 [=============>................] - ETA: 2:25 - loss: 1.7572 - regression_loss: 1.4551 - classification_loss: 0.3021
 493/1000 [=============>................] - ETA: 2:25 - loss: 1.7570 - regression_loss: 1.4543 - classification_loss: 0.3026
 494/1000 [=============>................] - ETA: 2:25 - loss: 1.7571 - regression_loss: 1.4546 - classification_loss: 0.3025
 495/1000 [=============>................] - ETA: 2:24 - loss: 1.7562 - regression_loss: 1.4540 - classification_loss: 0.3022
 496/1000 [=============>................] - ETA: 2:24 - loss: 1.7550 - regression_loss: 1.4531 - classification_loss: 0.3019
 497/1000 [=============>................] - ETA: 2:24 - loss: 1.7556 - regression_loss: 1.4537 - classification_loss: 0.3020
 498/1000 [=============>................] - ETA: 2:23 - loss: 1.7564 - regression_loss: 1.4542 - classification_loss: 0.3022
 499/1000 [=============>................] - ETA: 2:23 - loss: 1.7550 - regression_loss: 1.4530 - classification_loss: 0.3020
 500/1000 [==============>...............] - ETA: 2:23 - loss: 1.7548 - regression_loss: 1.4529 - classification_loss: 0.3019
 501/1000 [==============>...............] - ETA: 2:23 - loss: 1.7556 - regression_loss: 1.4536 - classification_loss: 0.3020
 502/1000 [==============>...............] - ETA: 2:22 - loss: 1.7557 - regression_loss: 1.4539 - classification_loss: 0.3018
 503/1000 [==============>...............] - ETA: 2:22 - loss: 1.7564 - regression_loss: 1.4546 - classification_loss: 0.3018
 504/1000 [==============>...............] - ETA: 2:22 - loss: 1.7564 - regression_loss: 1.4545 - classification_loss: 0.3018
 505/1000 [==============>...............] - ETA: 2:22 - loss: 1.7558 - regression_loss: 1.4542 - classification_loss: 0.3016
 506/1000 [==============>...............] - ETA: 2:21 - loss: 1.7573 - regression_loss: 1.4557 - classification_loss: 0.3016
 507/1000 [==============>...............] - ETA: 2:21 - loss: 1.7577 - regression_loss: 1.4559 - classification_loss: 0.3017
 508/1000 [==============>...............] - ETA: 2:21 - loss: 1.7590 - regression_loss: 1.4568 - classification_loss: 0.3022
 509/1000 [==============>...............] - ETA: 2:20 - loss: 1.7595 - regression_loss: 1.4572 - classification_loss: 0.3023
 510/1000 [==============>...............] - ETA: 2:20 - loss: 1.7588 - regression_loss: 1.4566 - classification_loss: 0.3021
 511/1000 [==============>...............] - ETA: 2:20 - loss: 1.7595 - regression_loss: 1.4571 - classification_loss: 0.3025
 512/1000 [==============>...............] - ETA: 2:20 - loss: 1.7590 - regression_loss: 1.4567 - classification_loss: 0.3023
 513/1000 [==============>...............] - ETA: 2:19 - loss: 1.7579 - regression_loss: 1.4558 - classification_loss: 0.3021
 514/1000 [==============>...............] - ETA: 2:19 - loss: 1.7570 - regression_loss: 1.4551 - classification_loss: 0.3019
 515/1000 [==============>...............] - ETA: 2:19 - loss: 1.7583 - regression_loss: 1.4561 - classification_loss: 0.3022
 516/1000 [==============>...............] - ETA: 2:18 - loss: 1.7571 - regression_loss: 1.4553 - classification_loss: 0.3018
 517/1000 [==============>...............] - ETA: 2:18 - loss: 1.7573 - regression_loss: 1.4553 - classification_loss: 0.3020
 518/1000 [==============>...............] - ETA: 2:18 - loss: 1.7572 - regression_loss: 1.4554 - classification_loss: 0.3019
 519/1000 [==============>...............] - ETA: 2:18 - loss: 1.7573 - regression_loss: 1.4552 - classification_loss: 0.3022
 520/1000 [==============>...............] - ETA: 2:17 - loss: 1.7566 - regression_loss: 1.4546 - classification_loss: 0.3020
 521/1000 [==============>...............] - ETA: 2:17 - loss: 1.7570 - regression_loss: 1.4552 - classification_loss: 0.3018
 522/1000 [==============>...............] - ETA: 2:17 - loss: 1.7560 - regression_loss: 1.4544 - classification_loss: 0.3016
 523/1000 [==============>...............] - ETA: 2:16 - loss: 1.7560 - regression_loss: 1.4544 - classification_loss: 0.3016
 524/1000 [==============>...............] - ETA: 2:16 - loss: 1.7572 - regression_loss: 1.4553 - classification_loss: 0.3019
 525/1000 [==============>...............] - ETA: 2:16 - loss: 1.7559 - regression_loss: 1.4542 - classification_loss: 0.3016
 526/1000 [==============>...............] - ETA: 2:15 - loss: 1.7553 - regression_loss: 1.4538 - classification_loss: 0.3015
 527/1000 [==============>...............] - ETA: 2:15 - loss: 1.7572 - regression_loss: 1.4550 - classification_loss: 0.3022
 528/1000 [==============>...............] - ETA: 2:15 - loss: 1.7586 - regression_loss: 1.4563 - classification_loss: 0.3023
 529/1000 [==============>...............] - ETA: 2:15 - loss: 1.7570 - regression_loss: 1.4550 - classification_loss: 0.3021
 530/1000 [==============>...............] - ETA: 2:14 - loss: 1.7567 - regression_loss: 1.4547 - classification_loss: 0.3019
 531/1000 [==============>...............] - ETA: 2:14 - loss: 1.7565 - regression_loss: 1.4546 - classification_loss: 0.3018
 532/1000 [==============>...............] - ETA: 2:14 - loss: 1.7568 - regression_loss: 1.4548 - classification_loss: 0.3020
 533/1000 [==============>...............] - ETA: 2:13 - loss: 1.7549 - regression_loss: 1.4531 - classification_loss: 0.3018
 534/1000 [===============>..............] - ETA: 2:13 - loss: 1.7541 - regression_loss: 1.4527 - classification_loss: 0.3015
 535/1000 [===============>..............] - ETA: 2:13 - loss: 1.7531 - regression_loss: 1.4519 - classification_loss: 0.3012
 536/1000 [===============>..............] - ETA: 2:13 - loss: 1.7519 - regression_loss: 1.4509 - classification_loss: 0.3010
 537/1000 [===============>..............] - ETA: 2:12 - loss: 1.7537 - regression_loss: 1.4526 - classification_loss: 0.3011
 538/1000 [===============>..............] - ETA: 2:12 - loss: 1.7556 - regression_loss: 1.4546 - classification_loss: 0.3010
 539/1000 [===============>..............] - ETA: 2:12 - loss: 1.7544 - regression_loss: 1.4535 - classification_loss: 0.3009
 540/1000 [===============>..............] - ETA: 2:11 - loss: 1.7546 - regression_loss: 1.4540 - classification_loss: 0.3006
 541/1000 [===============>..............] - ETA: 2:11 - loss: 1.7567 - regression_loss: 1.4558 - classification_loss: 0.3009
 542/1000 [===============>..............] - ETA: 2:11 - loss: 1.7572 - regression_loss: 1.4562 - classification_loss: 0.3010
 543/1000 [===============>..............] - ETA: 2:11 - loss: 1.7570 - regression_loss: 1.4560 - classification_loss: 0.3010
 544/1000 [===============>..............] - ETA: 2:10 - loss: 1.7566 - regression_loss: 1.4557 - classification_loss: 0.3009
 545/1000 [===============>..............] - ETA: 2:10 - loss: 1.7569 - regression_loss: 1.4558 - classification_loss: 0.3011
 546/1000 [===============>..............] - ETA: 2:10 - loss: 1.7574 - regression_loss: 1.4563 - classification_loss: 0.3011
 547/1000 [===============>..............] - ETA: 2:09 - loss: 1.7565 - regression_loss: 1.4556 - classification_loss: 0.3009
 548/1000 [===============>..............] - ETA: 2:09 - loss: 1.7578 - regression_loss: 1.4562 - classification_loss: 0.3015
 549/1000 [===============>..............] - ETA: 2:09 - loss: 1.7585 - regression_loss: 1.4568 - classification_loss: 0.3017
 550/1000 [===============>..............] - ETA: 2:09 - loss: 1.7594 - regression_loss: 1.4577 - classification_loss: 0.3018
 551/1000 [===============>..............] - ETA: 2:08 - loss: 1.7584 - regression_loss: 1.4569 - classification_loss: 0.3016
 552/1000 [===============>..............] - ETA: 2:08 - loss: 1.7573 - regression_loss: 1.4560 - classification_loss: 0.3013
 553/1000 [===============>..............] - ETA: 2:08 - loss: 1.7558 - regression_loss: 1.4547 - classification_loss: 0.3012
 554/1000 [===============>..............] - ETA: 2:07 - loss: 1.7559 - regression_loss: 1.4547 - classification_loss: 0.3012
 555/1000 [===============>..............] - ETA: 2:07 - loss: 1.7563 - regression_loss: 1.4552 - classification_loss: 0.3012
 556/1000 [===============>..............] - ETA: 2:07 - loss: 1.7563 - regression_loss: 1.4548 - classification_loss: 0.3015
 557/1000 [===============>..............] - ETA: 2:07 - loss: 1.7558 - regression_loss: 1.4544 - classification_loss: 0.3014
 558/1000 [===============>..............] - ETA: 2:06 - loss: 1.7556 - regression_loss: 1.4543 - classification_loss: 0.3013
 559/1000 [===============>..............] - ETA: 2:06 - loss: 1.7565 - regression_loss: 1.4553 - classification_loss: 0.3012
 560/1000 [===============>..............] - ETA: 2:06 - loss: 1.7567 - regression_loss: 1.4556 - classification_loss: 0.3011
 561/1000 [===============>..............] - ETA: 2:05 - loss: 1.7562 - regression_loss: 1.4554 - classification_loss: 0.3009
 562/1000 [===============>..............] - ETA: 2:05 - loss: 1.7578 - regression_loss: 1.4564 - classification_loss: 0.3014
 563/1000 [===============>..............] - ETA: 2:05 - loss: 1.7572 - regression_loss: 1.4558 - classification_loss: 0.3014
 564/1000 [===============>..............] - ETA: 2:05 - loss: 1.7565 - regression_loss: 1.4551 - classification_loss: 0.3013
 565/1000 [===============>..............] - ETA: 2:04 - loss: 1.7574 - regression_loss: 1.4559 - classification_loss: 0.3015
 566/1000 [===============>..............] - ETA: 2:04 - loss: 1.7566 - regression_loss: 1.4552 - classification_loss: 0.3014
 567/1000 [================>.............] - ETA: 2:04 - loss: 1.7573 - regression_loss: 1.4561 - classification_loss: 0.3012
 568/1000 [================>.............] - ETA: 2:03 - loss: 1.7585 - regression_loss: 1.4570 - classification_loss: 0.3015
 569/1000 [================>.............] - ETA: 2:03 - loss: 1.7578 - regression_loss: 1.4565 - classification_loss: 0.3013
 570/1000 [================>.............] - ETA: 2:03 - loss: 1.7580 - regression_loss: 1.4568 - classification_loss: 0.3012
 571/1000 [================>.............] - ETA: 2:03 - loss: 1.7581 - regression_loss: 1.4571 - classification_loss: 0.3011
 572/1000 [================>.............] - ETA: 2:02 - loss: 1.7570 - regression_loss: 1.4561 - classification_loss: 0.3009
 573/1000 [================>.............] - ETA: 2:02 - loss: 1.7566 - regression_loss: 1.4557 - classification_loss: 0.3009
 574/1000 [================>.............] - ETA: 2:02 - loss: 1.7571 - regression_loss: 1.4564 - classification_loss: 0.3008
 575/1000 [================>.............] - ETA: 2:01 - loss: 1.7567 - regression_loss: 1.4560 - classification_loss: 0.3007
 576/1000 [================>.............] - ETA: 2:01 - loss: 1.7569 - regression_loss: 1.4562 - classification_loss: 0.3006
 577/1000 [================>.............] - ETA: 2:01 - loss: 1.7575 - regression_loss: 1.4570 - classification_loss: 0.3005
 578/1000 [================>.............] - ETA: 2:01 - loss: 1.7568 - regression_loss: 1.4564 - classification_loss: 0.3004
 579/1000 [================>.............] - ETA: 2:00 - loss: 1.7559 - regression_loss: 1.4555 - classification_loss: 0.3004
 580/1000 [================>.............] - ETA: 2:00 - loss: 1.7559 - regression_loss: 1.4556 - classification_loss: 0.3003
 581/1000 [================>.............] - ETA: 2:00 - loss: 1.7574 - regression_loss: 1.4570 - classification_loss: 0.3004
 582/1000 [================>.............] - ETA: 1:59 - loss: 1.7576 - regression_loss: 1.4573 - classification_loss: 0.3003
 583/1000 [================>.............] - ETA: 1:59 - loss: 1.7565 - regression_loss: 1.4563 - classification_loss: 0.3002
 584/1000 [================>.............] - ETA: 1:59 - loss: 1.7557 - regression_loss: 1.4557 - classification_loss: 0.3000
 585/1000 [================>.............] - ETA: 1:59 - loss: 1.7544 - regression_loss: 1.4546 - classification_loss: 0.2997
 586/1000 [================>.............] - ETA: 1:58 - loss: 1.7564 - regression_loss: 1.4562 - classification_loss: 0.3002
 587/1000 [================>.............] - ETA: 1:58 - loss: 1.7563 - regression_loss: 1.4560 - classification_loss: 0.3003
 588/1000 [================>.............] - ETA: 1:58 - loss: 1.7579 - regression_loss: 1.4572 - classification_loss: 0.3007
 589/1000 [================>.............] - ETA: 1:57 - loss: 1.7582 - regression_loss: 1.4576 - classification_loss: 0.3006
 590/1000 [================>.............] - ETA: 1:57 - loss: 1.7566 - regression_loss: 1.4564 - classification_loss: 0.3002
 591/1000 [================>.............] - ETA: 1:57 - loss: 1.7559 - regression_loss: 1.4558 - classification_loss: 0.3001
 592/1000 [================>.............] - ETA: 1:56 - loss: 1.7566 - regression_loss: 1.4565 - classification_loss: 0.3001
 593/1000 [================>.............] - ETA: 1:56 - loss: 1.7566 - regression_loss: 1.4566 - classification_loss: 0.3000
 594/1000 [================>.............] - ETA: 1:56 - loss: 1.7563 - regression_loss: 1.4564 - classification_loss: 0.2999
 595/1000 [================>.............] - ETA: 1:56 - loss: 1.7547 - regression_loss: 1.4551 - classification_loss: 0.2997
 596/1000 [================>.............] - ETA: 1:55 - loss: 1.7543 - regression_loss: 1.4547 - classification_loss: 0.2996
 597/1000 [================>.............] - ETA: 1:55 - loss: 1.7543 - regression_loss: 1.4547 - classification_loss: 0.2996
 598/1000 [================>.............] - ETA: 1:55 - loss: 1.7538 - regression_loss: 1.4544 - classification_loss: 0.2994
 599/1000 [================>.............] - ETA: 1:54 - loss: 1.7570 - regression_loss: 1.4571 - classification_loss: 0.2999
 600/1000 [=================>............] - ETA: 1:54 - loss: 1.7599 - regression_loss: 1.4589 - classification_loss: 0.3009
 601/1000 [=================>............] - ETA: 1:54 - loss: 1.7593 - regression_loss: 1.4586 - classification_loss: 0.3007
 602/1000 [=================>............] - ETA: 1:54 - loss: 1.7584 - regression_loss: 1.4579 - classification_loss: 0.3005
 603/1000 [=================>............] - ETA: 1:53 - loss: 1.7582 - regression_loss: 1.4576 - classification_loss: 0.3006
 604/1000 [=================>............] - ETA: 1:53 - loss: 1.7571 - regression_loss: 1.4568 - classification_loss: 0.3004
 605/1000 [=================>............] - ETA: 1:53 - loss: 1.7588 - regression_loss: 1.4580 - classification_loss: 0.3008
 606/1000 [=================>............] - ETA: 1:52 - loss: 1.7605 - regression_loss: 1.4590 - classification_loss: 0.3015
 607/1000 [=================>............] - ETA: 1:52 - loss: 1.7614 - regression_loss: 1.4595 - classification_loss: 0.3019
 608/1000 [=================>............] - ETA: 1:52 - loss: 1.7619 - regression_loss: 1.4599 - classification_loss: 0.3020
 609/1000 [=================>............] - ETA: 1:52 - loss: 1.7615 - regression_loss: 1.4596 - classification_loss: 0.3019
 610/1000 [=================>............] - ETA: 1:51 - loss: 1.7634 - regression_loss: 1.4609 - classification_loss: 0.3025
 611/1000 [=================>............] - ETA: 1:51 - loss: 1.7635 - regression_loss: 1.4612 - classification_loss: 0.3023
 612/1000 [=================>............] - ETA: 1:51 - loss: 1.7622 - regression_loss: 1.4601 - classification_loss: 0.3021
 613/1000 [=================>............] - ETA: 1:50 - loss: 1.7617 - regression_loss: 1.4597 - classification_loss: 0.3020
 614/1000 [=================>............] - ETA: 1:50 - loss: 1.7631 - regression_loss: 1.4604 - classification_loss: 0.3027
 615/1000 [=================>............] - ETA: 1:50 - loss: 1.7641 - regression_loss: 1.4614 - classification_loss: 0.3027
 616/1000 [=================>............] - ETA: 1:50 - loss: 1.7646 - regression_loss: 1.4620 - classification_loss: 0.3026
 617/1000 [=================>............] - ETA: 1:49 - loss: 1.7668 - regression_loss: 1.4636 - classification_loss: 0.3032
 618/1000 [=================>............] - ETA: 1:49 - loss: 1.7656 - regression_loss: 1.4626 - classification_loss: 0.3029
 619/1000 [=================>............] - ETA: 1:49 - loss: 1.7670 - regression_loss: 1.4639 - classification_loss: 0.3031
 620/1000 [=================>............] - ETA: 1:48 - loss: 1.7674 - regression_loss: 1.4645 - classification_loss: 0.3029
 621/1000 [=================>............] - ETA: 1:48 - loss: 1.7676 - regression_loss: 1.4648 - classification_loss: 0.3028
 622/1000 [=================>............] - ETA: 1:48 - loss: 1.7675 - regression_loss: 1.4650 - classification_loss: 0.3026
 623/1000 [=================>............] - ETA: 1:48 - loss: 1.7678 - regression_loss: 1.4651 - classification_loss: 0.3027
 624/1000 [=================>............] - ETA: 1:47 - loss: 1.7672 - regression_loss: 1.4646 - classification_loss: 0.3026
 625/1000 [=================>............] - ETA: 1:47 - loss: 1.7662 - regression_loss: 1.4638 - classification_loss: 0.3024
 626/1000 [=================>............] - ETA: 1:47 - loss: 1.7649 - regression_loss: 1.4627 - classification_loss: 0.3022
 627/1000 [=================>............] - ETA: 1:46 - loss: 1.7666 - regression_loss: 1.4640 - classification_loss: 0.3026
 628/1000 [=================>............] - ETA: 1:46 - loss: 1.7663 - regression_loss: 1.4639 - classification_loss: 0.3024
 629/1000 [=================>............] - ETA: 1:46 - loss: 1.7658 - regression_loss: 1.4637 - classification_loss: 0.3021
 630/1000 [=================>............] - ETA: 1:46 - loss: 1.7658 - regression_loss: 1.4637 - classification_loss: 0.3021
 631/1000 [=================>............] - ETA: 1:45 - loss: 1.7652 - regression_loss: 1.4633 - classification_loss: 0.3019
 632/1000 [=================>............] - ETA: 1:45 - loss: 1.7642 - regression_loss: 1.4626 - classification_loss: 0.3017
 633/1000 [=================>............] - ETA: 1:45 - loss: 1.7638 - regression_loss: 1.4624 - classification_loss: 0.3014
 634/1000 [==================>...........] - ETA: 1:44 - loss: 1.7647 - regression_loss: 1.4631 - classification_loss: 0.3017
 635/1000 [==================>...........] - ETA: 1:44 - loss: 1.7643 - regression_loss: 1.4628 - classification_loss: 0.3015
 636/1000 [==================>...........] - ETA: 1:44 - loss: 1.7635 - regression_loss: 1.4622 - classification_loss: 0.3013
 637/1000 [==================>...........] - ETA: 1:44 - loss: 1.7631 - regression_loss: 1.4620 - classification_loss: 0.3011
 638/1000 [==================>...........] - ETA: 1:43 - loss: 1.7628 - regression_loss: 1.4617 - classification_loss: 0.3011
 639/1000 [==================>...........] - ETA: 1:43 - loss: 1.7616 - regression_loss: 1.4609 - classification_loss: 0.3007
 640/1000 [==================>...........] - ETA: 1:43 - loss: 1.7624 - regression_loss: 1.4611 - classification_loss: 0.3013
 641/1000 [==================>...........] - ETA: 1:42 - loss: 1.7623 - regression_loss: 1.4611 - classification_loss: 0.3012
 642/1000 [==================>...........] - ETA: 1:42 - loss: 1.7617 - regression_loss: 1.4604 - classification_loss: 0.3013
 643/1000 [==================>...........] - ETA: 1:42 - loss: 1.7602 - regression_loss: 1.4591 - classification_loss: 0.3010
 644/1000 [==================>...........] - ETA: 1:42 - loss: 1.7610 - regression_loss: 1.4600 - classification_loss: 0.3011
 645/1000 [==================>...........] - ETA: 1:41 - loss: 1.7601 - regression_loss: 1.4591 - classification_loss: 0.3010
 646/1000 [==================>...........] - ETA: 1:41 - loss: 1.7592 - regression_loss: 1.4583 - classification_loss: 0.3009
 647/1000 [==================>...........] - ETA: 1:41 - loss: 1.7580 - regression_loss: 1.4573 - classification_loss: 0.3007
 648/1000 [==================>...........] - ETA: 1:40 - loss: 1.7582 - regression_loss: 1.4574 - classification_loss: 0.3008
 649/1000 [==================>...........] - ETA: 1:40 - loss: 1.7588 - regression_loss: 1.4579 - classification_loss: 0.3008
 650/1000 [==================>...........] - ETA: 1:40 - loss: 1.7592 - regression_loss: 1.4583 - classification_loss: 0.3009
 651/1000 [==================>...........] - ETA: 1:40 - loss: 1.7577 - regression_loss: 1.4570 - classification_loss: 0.3006
 652/1000 [==================>...........] - ETA: 1:39 - loss: 1.7576 - regression_loss: 1.4571 - classification_loss: 0.3005
 653/1000 [==================>...........] - ETA: 1:39 - loss: 1.7569 - regression_loss: 1.4565 - classification_loss: 0.3004
 654/1000 [==================>...........] - ETA: 1:39 - loss: 1.7578 - regression_loss: 1.4574 - classification_loss: 0.3004
 655/1000 [==================>...........] - ETA: 1:38 - loss: 1.7575 - regression_loss: 1.4571 - classification_loss: 0.3004
 656/1000 [==================>...........] - ETA: 1:38 - loss: 1.7587 - regression_loss: 1.4580 - classification_loss: 0.3007
 657/1000 [==================>...........] - ETA: 1:38 - loss: 1.7591 - regression_loss: 1.4584 - classification_loss: 0.3007
 658/1000 [==================>...........] - ETA: 1:38 - loss: 1.7589 - regression_loss: 1.4583 - classification_loss: 0.3006
 659/1000 [==================>...........] - ETA: 1:37 - loss: 1.7584 - regression_loss: 1.4579 - classification_loss: 0.3005
 660/1000 [==================>...........] - ETA: 1:37 - loss: 1.7580 - regression_loss: 1.4578 - classification_loss: 0.3003
 661/1000 [==================>...........] - ETA: 1:37 - loss: 1.7599 - regression_loss: 1.4595 - classification_loss: 0.3005
 662/1000 [==================>...........] - ETA: 1:36 - loss: 1.7592 - regression_loss: 1.4590 - classification_loss: 0.3002
 663/1000 [==================>...........] - ETA: 1:36 - loss: 1.7597 - regression_loss: 1.4594 - classification_loss: 0.3003
 664/1000 [==================>...........] - ETA: 1:36 - loss: 1.7618 - regression_loss: 1.4610 - classification_loss: 0.3008
 665/1000 [==================>...........] - ETA: 1:36 - loss: 1.7614 - regression_loss: 1.4607 - classification_loss: 0.3007
 666/1000 [==================>...........] - ETA: 1:35 - loss: 1.7608 - regression_loss: 1.4602 - classification_loss: 0.3006
 667/1000 [===================>..........] - ETA: 1:35 - loss: 1.7600 - regression_loss: 1.4596 - classification_loss: 0.3004
 668/1000 [===================>..........] - ETA: 1:35 - loss: 1.7593 - regression_loss: 1.4591 - classification_loss: 0.3002
 669/1000 [===================>..........] - ETA: 1:34 - loss: 1.7589 - regression_loss: 1.4589 - classification_loss: 0.3000
 670/1000 [===================>..........] - ETA: 1:34 - loss: 1.7593 - regression_loss: 1.4594 - classification_loss: 0.2999
 671/1000 [===================>..........] - ETA: 1:34 - loss: 1.7603 - regression_loss: 1.4602 - classification_loss: 0.3001
 672/1000 [===================>..........] - ETA: 1:34 - loss: 1.7595 - regression_loss: 1.4596 - classification_loss: 0.2999
 673/1000 [===================>..........] - ETA: 1:33 - loss: 1.7598 - regression_loss: 1.4594 - classification_loss: 0.3004
 674/1000 [===================>..........] - ETA: 1:33 - loss: 1.7598 - regression_loss: 1.4594 - classification_loss: 0.3004
 675/1000 [===================>..........] - ETA: 1:33 - loss: 1.7589 - regression_loss: 1.4588 - classification_loss: 0.3001
 676/1000 [===================>..........] - ETA: 1:32 - loss: 1.7578 - regression_loss: 1.4577 - classification_loss: 0.3000
 677/1000 [===================>..........] - ETA: 1:32 - loss: 1.7562 - regression_loss: 1.4565 - classification_loss: 0.2998
 678/1000 [===================>..........] - ETA: 1:32 - loss: 1.7571 - regression_loss: 1.4572 - classification_loss: 0.2999
 679/1000 [===================>..........] - ETA: 1:32 - loss: 1.7584 - regression_loss: 1.4585 - classification_loss: 0.2999
 680/1000 [===================>..........] - ETA: 1:31 - loss: 1.7576 - regression_loss: 1.4578 - classification_loss: 0.2998
 681/1000 [===================>..........] - ETA: 1:31 - loss: 1.7595 - regression_loss: 1.4592 - classification_loss: 0.3003
 682/1000 [===================>..........] - ETA: 1:31 - loss: 1.7581 - regression_loss: 1.4580 - classification_loss: 0.3001
 683/1000 [===================>..........] - ETA: 1:30 - loss: 1.7568 - regression_loss: 1.4569 - classification_loss: 0.2999
 684/1000 [===================>..........] - ETA: 1:30 - loss: 1.7571 - regression_loss: 1.4569 - classification_loss: 0.3002
 685/1000 [===================>..........] - ETA: 1:30 - loss: 1.7575 - regression_loss: 1.4572 - classification_loss: 0.3002
 686/1000 [===================>..........] - ETA: 1:30 - loss: 1.7573 - regression_loss: 1.4571 - classification_loss: 0.3002
 687/1000 [===================>..........] - ETA: 1:29 - loss: 1.7571 - regression_loss: 1.4571 - classification_loss: 0.3000
 688/1000 [===================>..........] - ETA: 1:29 - loss: 1.7566 - regression_loss: 1.4567 - classification_loss: 0.2999
 689/1000 [===================>..........] - ETA: 1:29 - loss: 1.7556 - regression_loss: 1.4559 - classification_loss: 0.2997
 690/1000 [===================>..........] - ETA: 1:28 - loss: 1.7548 - regression_loss: 1.4554 - classification_loss: 0.2994
 691/1000 [===================>..........] - ETA: 1:28 - loss: 1.7544 - regression_loss: 1.4550 - classification_loss: 0.2994
 692/1000 [===================>..........] - ETA: 1:28 - loss: 1.7558 - regression_loss: 1.4559 - classification_loss: 0.2999
 693/1000 [===================>..........] - ETA: 1:28 - loss: 1.7560 - regression_loss: 1.4561 - classification_loss: 0.2999
 694/1000 [===================>..........] - ETA: 1:27 - loss: 1.7555 - regression_loss: 1.4557 - classification_loss: 0.2997
 695/1000 [===================>..........] - ETA: 1:27 - loss: 1.7558 - regression_loss: 1.4559 - classification_loss: 0.2998
 696/1000 [===================>..........] - ETA: 1:27 - loss: 1.7548 - regression_loss: 1.4551 - classification_loss: 0.2997
 697/1000 [===================>..........] - ETA: 1:26 - loss: 1.7538 - regression_loss: 1.4543 - classification_loss: 0.2995
 698/1000 [===================>..........] - ETA: 1:26 - loss: 1.7524 - regression_loss: 1.4530 - classification_loss: 0.2994
 699/1000 [===================>..........] - ETA: 1:26 - loss: 1.7513 - regression_loss: 1.4521 - classification_loss: 0.2992
 700/1000 [====================>.........] - ETA: 1:26 - loss: 1.7532 - regression_loss: 1.4537 - classification_loss: 0.2995
 701/1000 [====================>.........] - ETA: 1:25 - loss: 1.7529 - regression_loss: 1.4534 - classification_loss: 0.2995
 702/1000 [====================>.........] - ETA: 1:25 - loss: 1.7527 - regression_loss: 1.4532 - classification_loss: 0.2995
 703/1000 [====================>.........] - ETA: 1:25 - loss: 1.7511 - regression_loss: 1.4518 - classification_loss: 0.2992
 704/1000 [====================>.........] - ETA: 1:24 - loss: 1.7501 - regression_loss: 1.4510 - classification_loss: 0.2991
 705/1000 [====================>.........] - ETA: 1:24 - loss: 1.7491 - regression_loss: 1.4502 - classification_loss: 0.2989
 706/1000 [====================>.........] - ETA: 1:24 - loss: 1.7499 - regression_loss: 1.4508 - classification_loss: 0.2991
 707/1000 [====================>.........] - ETA: 1:24 - loss: 1.7486 - regression_loss: 1.4497 - classification_loss: 0.2989
 708/1000 [====================>.........] - ETA: 1:23 - loss: 1.7499 - regression_loss: 1.4507 - classification_loss: 0.2992
 709/1000 [====================>.........] - ETA: 1:23 - loss: 1.7498 - regression_loss: 1.4507 - classification_loss: 0.2991
 710/1000 [====================>.........] - ETA: 1:23 - loss: 1.7497 - regression_loss: 1.4507 - classification_loss: 0.2990
 711/1000 [====================>.........] - ETA: 1:22 - loss: 1.7488 - regression_loss: 1.4498 - classification_loss: 0.2989
 712/1000 [====================>.........] - ETA: 1:22 - loss: 1.7487 - regression_loss: 1.4499 - classification_loss: 0.2988
 713/1000 [====================>.........] - ETA: 1:22 - loss: 1.7492 - regression_loss: 1.4498 - classification_loss: 0.2994
 714/1000 [====================>.........] - ETA: 1:21 - loss: 1.7495 - regression_loss: 1.4503 - classification_loss: 0.2993
 715/1000 [====================>.........] - ETA: 1:21 - loss: 1.7489 - regression_loss: 1.4498 - classification_loss: 0.2991
 716/1000 [====================>.........] - ETA: 1:21 - loss: 1.7486 - regression_loss: 1.4496 - classification_loss: 0.2990
 717/1000 [====================>.........] - ETA: 1:21 - loss: 1.7485 - regression_loss: 1.4497 - classification_loss: 0.2988
 718/1000 [====================>.........] - ETA: 1:20 - loss: 1.7474 - regression_loss: 1.4487 - classification_loss: 0.2987
 719/1000 [====================>.........] - ETA: 1:20 - loss: 1.7463 - regression_loss: 1.4478 - classification_loss: 0.2985
 720/1000 [====================>.........] - ETA: 1:20 - loss: 1.7457 - regression_loss: 1.4474 - classification_loss: 0.2983
 721/1000 [====================>.........] - ETA: 1:19 - loss: 1.7454 - regression_loss: 1.4470 - classification_loss: 0.2984
 722/1000 [====================>.........] - ETA: 1:19 - loss: 1.7448 - regression_loss: 1.4466 - classification_loss: 0.2982
 723/1000 [====================>.........] - ETA: 1:19 - loss: 1.7460 - regression_loss: 1.4478 - classification_loss: 0.2983
 724/1000 [====================>.........] - ETA: 1:19 - loss: 1.7456 - regression_loss: 1.4476 - classification_loss: 0.2981
 725/1000 [====================>.........] - ETA: 1:18 - loss: 1.7444 - regression_loss: 1.4464 - classification_loss: 0.2979
 726/1000 [====================>.........] - ETA: 1:18 - loss: 1.7448 - regression_loss: 1.4467 - classification_loss: 0.2981
 727/1000 [====================>.........] - ETA: 1:18 - loss: 1.7450 - regression_loss: 1.4468 - classification_loss: 0.2981
 728/1000 [====================>.........] - ETA: 1:17 - loss: 1.7448 - regression_loss: 1.4467 - classification_loss: 0.2981
 729/1000 [====================>.........] - ETA: 1:17 - loss: 1.7450 - regression_loss: 1.4470 - classification_loss: 0.2981
 730/1000 [====================>.........] - ETA: 1:17 - loss: 1.7454 - regression_loss: 1.4474 - classification_loss: 0.2980
 731/1000 [====================>.........] - ETA: 1:17 - loss: 1.7448 - regression_loss: 1.4468 - classification_loss: 0.2980
 732/1000 [====================>.........] - ETA: 1:16 - loss: 1.7451 - regression_loss: 1.4471 - classification_loss: 0.2980
 733/1000 [====================>.........] - ETA: 1:16 - loss: 1.7437 - regression_loss: 1.4459 - classification_loss: 0.2978
 734/1000 [=====================>........] - ETA: 1:16 - loss: 1.7436 - regression_loss: 1.4459 - classification_loss: 0.2978
 735/1000 [=====================>........] - ETA: 1:15 - loss: 1.7439 - regression_loss: 1.4462 - classification_loss: 0.2977
 736/1000 [=====================>........] - ETA: 1:15 - loss: 1.7429 - regression_loss: 1.4453 - classification_loss: 0.2976
 737/1000 [=====================>........] - ETA: 1:15 - loss: 1.7416 - regression_loss: 1.4441 - classification_loss: 0.2975
 738/1000 [=====================>........] - ETA: 1:15 - loss: 1.7427 - regression_loss: 1.4450 - classification_loss: 0.2977
 739/1000 [=====================>........] - ETA: 1:14 - loss: 1.7425 - regression_loss: 1.4449 - classification_loss: 0.2977
 740/1000 [=====================>........] - ETA: 1:14 - loss: 1.7424 - regression_loss: 1.4448 - classification_loss: 0.2976
 741/1000 [=====================>........] - ETA: 1:14 - loss: 1.7413 - regression_loss: 1.4439 - classification_loss: 0.2975
 742/1000 [=====================>........] - ETA: 1:13 - loss: 1.7405 - regression_loss: 1.4431 - classification_loss: 0.2974
 743/1000 [=====================>........] - ETA: 1:13 - loss: 1.7406 - regression_loss: 1.4433 - classification_loss: 0.2974
 744/1000 [=====================>........] - ETA: 1:13 - loss: 1.7406 - regression_loss: 1.4433 - classification_loss: 0.2973
 745/1000 [=====================>........] - ETA: 1:13 - loss: 1.7421 - regression_loss: 1.4442 - classification_loss: 0.2979
 746/1000 [=====================>........] - ETA: 1:12 - loss: 1.7430 - regression_loss: 1.4450 - classification_loss: 0.2980
 747/1000 [=====================>........] - ETA: 1:12 - loss: 1.7417 - regression_loss: 1.4430 - classification_loss: 0.2986
 748/1000 [=====================>........] - ETA: 1:12 - loss: 1.7414 - regression_loss: 1.4429 - classification_loss: 0.2986
 749/1000 [=====================>........] - ETA: 1:11 - loss: 1.7419 - regression_loss: 1.4434 - classification_loss: 0.2985
 750/1000 [=====================>........] - ETA: 1:11 - loss: 1.7417 - regression_loss: 1.4433 - classification_loss: 0.2985
 751/1000 [=====================>........] - ETA: 1:11 - loss: 1.7415 - regression_loss: 1.4431 - classification_loss: 0.2984
 752/1000 [=====================>........] - ETA: 1:11 - loss: 1.7415 - regression_loss: 1.4431 - classification_loss: 0.2983
 753/1000 [=====================>........] - ETA: 1:10 - loss: 1.7425 - regression_loss: 1.4438 - classification_loss: 0.2986
 754/1000 [=====================>........] - ETA: 1:10 - loss: 1.7420 - regression_loss: 1.4435 - classification_loss: 0.2985
 755/1000 [=====================>........] - ETA: 1:10 - loss: 1.7428 - regression_loss: 1.4440 - classification_loss: 0.2987
 756/1000 [=====================>........] - ETA: 1:09 - loss: 1.7423 - regression_loss: 1.4438 - classification_loss: 0.2985
 757/1000 [=====================>........] - ETA: 1:09 - loss: 1.7434 - regression_loss: 1.4446 - classification_loss: 0.2988
 758/1000 [=====================>........] - ETA: 1:09 - loss: 1.7432 - regression_loss: 1.4446 - classification_loss: 0.2986
 759/1000 [=====================>........] - ETA: 1:09 - loss: 1.7436 - regression_loss: 1.4449 - classification_loss: 0.2987
 760/1000 [=====================>........] - ETA: 1:08 - loss: 1.7440 - regression_loss: 1.4451 - classification_loss: 0.2989
 761/1000 [=====================>........] - ETA: 1:08 - loss: 1.7456 - regression_loss: 1.4462 - classification_loss: 0.2994
 762/1000 [=====================>........] - ETA: 1:08 - loss: 1.7463 - regression_loss: 1.4467 - classification_loss: 0.2996
 763/1000 [=====================>........] - ETA: 1:07 - loss: 1.7454 - regression_loss: 1.4460 - classification_loss: 0.2995
 764/1000 [=====================>........] - ETA: 1:07 - loss: 1.7449 - regression_loss: 1.4456 - classification_loss: 0.2992
 765/1000 [=====================>........] - ETA: 1:07 - loss: 1.7450 - regression_loss: 1.4457 - classification_loss: 0.2993
 766/1000 [=====================>........] - ETA: 1:07 - loss: 1.7467 - regression_loss: 1.4469 - classification_loss: 0.2998
 767/1000 [======================>.......] - ETA: 1:06 - loss: 1.7471 - regression_loss: 1.4473 - classification_loss: 0.2998
 768/1000 [======================>.......] - ETA: 1:06 - loss: 1.7467 - regression_loss: 1.4471 - classification_loss: 0.2996
 769/1000 [======================>.......] - ETA: 1:06 - loss: 1.7473 - regression_loss: 1.4473 - classification_loss: 0.3000
 770/1000 [======================>.......] - ETA: 1:05 - loss: 1.7480 - regression_loss: 1.4479 - classification_loss: 0.3002
 771/1000 [======================>.......] - ETA: 1:05 - loss: 1.7475 - regression_loss: 1.4475 - classification_loss: 0.3000
 772/1000 [======================>.......] - ETA: 1:05 - loss: 1.7471 - regression_loss: 1.4472 - classification_loss: 0.2999
 773/1000 [======================>.......] - ETA: 1:05 - loss: 1.7469 - regression_loss: 1.4470 - classification_loss: 0.2998
 774/1000 [======================>.......] - ETA: 1:04 - loss: 1.7474 - regression_loss: 1.4476 - classification_loss: 0.2999
 775/1000 [======================>.......] - ETA: 1:04 - loss: 1.7478 - regression_loss: 1.4479 - classification_loss: 0.2999
 776/1000 [======================>.......] - ETA: 1:04 - loss: 1.7477 - regression_loss: 1.4480 - classification_loss: 0.2997
 777/1000 [======================>.......] - ETA: 1:03 - loss: 1.7468 - regression_loss: 1.4470 - classification_loss: 0.2998
 778/1000 [======================>.......] - ETA: 1:03 - loss: 1.7459 - regression_loss: 1.4461 - classification_loss: 0.2998
 779/1000 [======================>.......] - ETA: 1:03 - loss: 1.7445 - regression_loss: 1.4449 - classification_loss: 0.2996
 780/1000 [======================>.......] - ETA: 1:03 - loss: 1.7454 - regression_loss: 1.4458 - classification_loss: 0.2996
 781/1000 [======================>.......] - ETA: 1:02 - loss: 1.7442 - regression_loss: 1.4449 - classification_loss: 0.2994
 782/1000 [======================>.......] - ETA: 1:02 - loss: 1.7448 - regression_loss: 1.4453 - classification_loss: 0.2995
 783/1000 [======================>.......] - ETA: 1:02 - loss: 1.7448 - regression_loss: 1.4454 - classification_loss: 0.2994
 784/1000 [======================>.......] - ETA: 1:01 - loss: 1.7454 - regression_loss: 1.4460 - classification_loss: 0.2995
 785/1000 [======================>.......] - ETA: 1:01 - loss: 1.7446 - regression_loss: 1.4453 - classification_loss: 0.2993
 786/1000 [======================>.......] - ETA: 1:01 - loss: 1.7458 - regression_loss: 1.4463 - classification_loss: 0.2995
 787/1000 [======================>.......] - ETA: 1:01 - loss: 1.7458 - regression_loss: 1.4465 - classification_loss: 0.2993
 788/1000 [======================>.......] - ETA: 1:00 - loss: 1.7448 - regression_loss: 1.4456 - classification_loss: 0.2991
 789/1000 [======================>.......] - ETA: 1:00 - loss: 1.7441 - regression_loss: 1.4451 - classification_loss: 0.2990
 790/1000 [======================>.......] - ETA: 1:00 - loss: 1.7435 - regression_loss: 1.4446 - classification_loss: 0.2988
 791/1000 [======================>.......] - ETA: 59s - loss: 1.7440 - regression_loss: 1.4451 - classification_loss: 0.2989 
 792/1000 [======================>.......] - ETA: 59s - loss: 1.7440 - regression_loss: 1.4451 - classification_loss: 0.2989
 793/1000 [======================>.......] - ETA: 59s - loss: 1.7434 - regression_loss: 1.4444 - classification_loss: 0.2989
 794/1000 [======================>.......] - ETA: 59s - loss: 1.7429 - regression_loss: 1.4441 - classification_loss: 0.2988
 795/1000 [======================>.......] - ETA: 58s - loss: 1.7436 - regression_loss: 1.4445 - classification_loss: 0.2990
 796/1000 [======================>.......] - ETA: 58s - loss: 1.7423 - regression_loss: 1.4435 - classification_loss: 0.2989
 797/1000 [======================>.......] - ETA: 58s - loss: 1.7416 - regression_loss: 1.4429 - classification_loss: 0.2987
 798/1000 [======================>.......] - ETA: 57s - loss: 1.7410 - regression_loss: 1.4425 - classification_loss: 0.2985
 799/1000 [======================>.......] - ETA: 57s - loss: 1.7400 - regression_loss: 1.4417 - classification_loss: 0.2983
 800/1000 [=======================>......] - ETA: 57s - loss: 1.7400 - regression_loss: 1.4413 - classification_loss: 0.2987
 801/1000 [=======================>......] - ETA: 57s - loss: 1.7388 - regression_loss: 1.4401 - classification_loss: 0.2987
 802/1000 [=======================>......] - ETA: 56s - loss: 1.7390 - regression_loss: 1.4404 - classification_loss: 0.2986
 803/1000 [=======================>......] - ETA: 56s - loss: 1.7390 - regression_loss: 1.4403 - classification_loss: 0.2986
 804/1000 [=======================>......] - ETA: 56s - loss: 1.7396 - regression_loss: 1.4409 - classification_loss: 0.2987
 805/1000 [=======================>......] - ETA: 55s - loss: 1.7396 - regression_loss: 1.4408 - classification_loss: 0.2988
 806/1000 [=======================>......] - ETA: 55s - loss: 1.7398 - regression_loss: 1.4410 - classification_loss: 0.2988
 807/1000 [=======================>......] - ETA: 55s - loss: 1.7407 - regression_loss: 1.4418 - classification_loss: 0.2989
 808/1000 [=======================>......] - ETA: 55s - loss: 1.7396 - regression_loss: 1.4409 - classification_loss: 0.2986
 809/1000 [=======================>......] - ETA: 54s - loss: 1.7399 - regression_loss: 1.4412 - classification_loss: 0.2987
 810/1000 [=======================>......] - ETA: 54s - loss: 1.7390 - regression_loss: 1.4404 - classification_loss: 0.2986
 811/1000 [=======================>......] - ETA: 54s - loss: 1.7382 - regression_loss: 1.4398 - classification_loss: 0.2984
 812/1000 [=======================>......] - ETA: 53s - loss: 1.7378 - regression_loss: 1.4396 - classification_loss: 0.2982
 813/1000 [=======================>......] - ETA: 53s - loss: 1.7383 - regression_loss: 1.4397 - classification_loss: 0.2986
 814/1000 [=======================>......] - ETA: 53s - loss: 1.7383 - regression_loss: 1.4398 - classification_loss: 0.2985
 815/1000 [=======================>......] - ETA: 53s - loss: 1.7374 - regression_loss: 1.4390 - classification_loss: 0.2983
 816/1000 [=======================>......] - ETA: 52s - loss: 1.7370 - regression_loss: 1.4388 - classification_loss: 0.2982
 817/1000 [=======================>......] - ETA: 52s - loss: 1.7361 - regression_loss: 1.4380 - classification_loss: 0.2980
 818/1000 [=======================>......] - ETA: 52s - loss: 1.7366 - regression_loss: 1.4387 - classification_loss: 0.2979
 819/1000 [=======================>......] - ETA: 51s - loss: 1.7362 - regression_loss: 1.4384 - classification_loss: 0.2978
 820/1000 [=======================>......] - ETA: 51s - loss: 1.7360 - regression_loss: 1.4382 - classification_loss: 0.2977
 821/1000 [=======================>......] - ETA: 51s - loss: 1.7361 - regression_loss: 1.4383 - classification_loss: 0.2978
 822/1000 [=======================>......] - ETA: 51s - loss: 1.7360 - regression_loss: 1.4384 - classification_loss: 0.2976
 823/1000 [=======================>......] - ETA: 50s - loss: 1.7355 - regression_loss: 1.4379 - classification_loss: 0.2977
 824/1000 [=======================>......] - ETA: 50s - loss: 1.7353 - regression_loss: 1.4377 - classification_loss: 0.2976
 825/1000 [=======================>......] - ETA: 50s - loss: 1.7346 - regression_loss: 1.4371 - classification_loss: 0.2975
 826/1000 [=======================>......] - ETA: 49s - loss: 1.7349 - regression_loss: 1.4374 - classification_loss: 0.2975
 827/1000 [=======================>......] - ETA: 49s - loss: 1.7367 - regression_loss: 1.4387 - classification_loss: 0.2979
 828/1000 [=======================>......] - ETA: 49s - loss: 1.7362 - regression_loss: 1.4384 - classification_loss: 0.2978
 829/1000 [=======================>......] - ETA: 49s - loss: 1.7360 - regression_loss: 1.4383 - classification_loss: 0.2977
 830/1000 [=======================>......] - ETA: 48s - loss: 1.7353 - regression_loss: 1.4377 - classification_loss: 0.2976
 831/1000 [=======================>......] - ETA: 48s - loss: 1.7346 - regression_loss: 1.4372 - classification_loss: 0.2974
 832/1000 [=======================>......] - ETA: 48s - loss: 1.7358 - regression_loss: 1.4381 - classification_loss: 0.2977
 833/1000 [=======================>......] - ETA: 47s - loss: 1.7350 - regression_loss: 1.4375 - classification_loss: 0.2975
 834/1000 [========================>.....] - ETA: 47s - loss: 1.7356 - regression_loss: 1.4381 - classification_loss: 0.2975
 835/1000 [========================>.....] - ETA: 47s - loss: 1.7353 - regression_loss: 1.4379 - classification_loss: 0.2974
 836/1000 [========================>.....] - ETA: 47s - loss: 1.7347 - regression_loss: 1.4374 - classification_loss: 0.2973
 837/1000 [========================>.....] - ETA: 46s - loss: 1.7344 - regression_loss: 1.4373 - classification_loss: 0.2971
 838/1000 [========================>.....] - ETA: 46s - loss: 1.7351 - regression_loss: 1.4380 - classification_loss: 0.2971
 839/1000 [========================>.....] - ETA: 46s - loss: 1.7350 - regression_loss: 1.4378 - classification_loss: 0.2973
 840/1000 [========================>.....] - ETA: 45s - loss: 1.7346 - regression_loss: 1.4373 - classification_loss: 0.2973
 841/1000 [========================>.....] - ETA: 45s - loss: 1.7342 - regression_loss: 1.4371 - classification_loss: 0.2971
 842/1000 [========================>.....] - ETA: 45s - loss: 1.7342 - regression_loss: 1.4370 - classification_loss: 0.2972
 843/1000 [========================>.....] - ETA: 45s - loss: 1.7347 - regression_loss: 1.4373 - classification_loss: 0.2974
 844/1000 [========================>.....] - ETA: 44s - loss: 1.7375 - regression_loss: 1.4393 - classification_loss: 0.2982
 845/1000 [========================>.....] - ETA: 44s - loss: 1.7373 - regression_loss: 1.4392 - classification_loss: 0.2981
 846/1000 [========================>.....] - ETA: 44s - loss: 1.7381 - regression_loss: 1.4399 - classification_loss: 0.2982
 847/1000 [========================>.....] - ETA: 43s - loss: 1.7395 - regression_loss: 1.4412 - classification_loss: 0.2982
 848/1000 [========================>.....] - ETA: 43s - loss: 1.7390 - regression_loss: 1.4409 - classification_loss: 0.2982
 849/1000 [========================>.....] - ETA: 43s - loss: 1.7384 - regression_loss: 1.4404 - classification_loss: 0.2981
 850/1000 [========================>.....] - ETA: 43s - loss: 1.7378 - regression_loss: 1.4398 - classification_loss: 0.2980
 851/1000 [========================>.....] - ETA: 42s - loss: 1.7375 - regression_loss: 1.4395 - classification_loss: 0.2980
 852/1000 [========================>.....] - ETA: 42s - loss: 1.7367 - regression_loss: 1.4388 - classification_loss: 0.2979
 853/1000 [========================>.....] - ETA: 42s - loss: 1.7368 - regression_loss: 1.4388 - classification_loss: 0.2980
 854/1000 [========================>.....] - ETA: 41s - loss: 1.7360 - regression_loss: 1.4381 - classification_loss: 0.2979
 855/1000 [========================>.....] - ETA: 41s - loss: 1.7368 - regression_loss: 1.4386 - classification_loss: 0.2982
 856/1000 [========================>.....] - ETA: 41s - loss: 1.7372 - regression_loss: 1.4390 - classification_loss: 0.2983
 857/1000 [========================>.....] - ETA: 41s - loss: 1.7363 - regression_loss: 1.4381 - classification_loss: 0.2981
 858/1000 [========================>.....] - ETA: 40s - loss: 1.7366 - regression_loss: 1.4384 - classification_loss: 0.2981
 859/1000 [========================>.....] - ETA: 40s - loss: 1.7372 - regression_loss: 1.4391 - classification_loss: 0.2981
 860/1000 [========================>.....] - ETA: 40s - loss: 1.7367 - regression_loss: 1.4386 - classification_loss: 0.2981
 861/1000 [========================>.....] - ETA: 39s - loss: 1.7368 - regression_loss: 1.4387 - classification_loss: 0.2981
 862/1000 [========================>.....] - ETA: 39s - loss: 1.7366 - regression_loss: 1.4386 - classification_loss: 0.2979
 863/1000 [========================>.....] - ETA: 39s - loss: 1.7357 - regression_loss: 1.4378 - classification_loss: 0.2979
 864/1000 [========================>.....] - ETA: 38s - loss: 1.7371 - regression_loss: 1.4387 - classification_loss: 0.2983
 865/1000 [========================>.....] - ETA: 38s - loss: 1.7369 - regression_loss: 1.4387 - classification_loss: 0.2982
 866/1000 [========================>.....] - ETA: 38s - loss: 1.7370 - regression_loss: 1.4388 - classification_loss: 0.2982
 867/1000 [=========================>....] - ETA: 38s - loss: 1.7365 - regression_loss: 1.4385 - classification_loss: 0.2980
 868/1000 [=========================>....] - ETA: 37s - loss: 1.7378 - regression_loss: 1.4395 - classification_loss: 0.2983
 869/1000 [=========================>....] - ETA: 37s - loss: 1.7376 - regression_loss: 1.4393 - classification_loss: 0.2983
 870/1000 [=========================>....] - ETA: 37s - loss: 1.7373 - regression_loss: 1.4390 - classification_loss: 0.2983
 871/1000 [=========================>....] - ETA: 36s - loss: 1.7371 - regression_loss: 1.4388 - classification_loss: 0.2983
 872/1000 [=========================>....] - ETA: 36s - loss: 1.7372 - regression_loss: 1.4388 - classification_loss: 0.2984
 873/1000 [=========================>....] - ETA: 36s - loss: 1.7368 - regression_loss: 1.4385 - classification_loss: 0.2983
 874/1000 [=========================>....] - ETA: 36s - loss: 1.7371 - regression_loss: 1.4388 - classification_loss: 0.2983
 875/1000 [=========================>....] - ETA: 35s - loss: 1.7364 - regression_loss: 1.4382 - classification_loss: 0.2982
 876/1000 [=========================>....] - ETA: 35s - loss: 1.7374 - regression_loss: 1.4393 - classification_loss: 0.2981
 877/1000 [=========================>....] - ETA: 35s - loss: 1.7380 - regression_loss: 1.4398 - classification_loss: 0.2982
 878/1000 [=========================>....] - ETA: 34s - loss: 1.7390 - regression_loss: 1.4406 - classification_loss: 0.2984
 879/1000 [=========================>....] - ETA: 34s - loss: 1.7384 - regression_loss: 1.4401 - classification_loss: 0.2982
 880/1000 [=========================>....] - ETA: 34s - loss: 1.7388 - regression_loss: 1.4406 - classification_loss: 0.2982
 881/1000 [=========================>....] - ETA: 34s - loss: 1.7390 - regression_loss: 1.4408 - classification_loss: 0.2981
 882/1000 [=========================>....] - ETA: 33s - loss: 1.7389 - regression_loss: 1.4409 - classification_loss: 0.2980
 883/1000 [=========================>....] - ETA: 33s - loss: 1.7397 - regression_loss: 1.4414 - classification_loss: 0.2983
 884/1000 [=========================>....] - ETA: 33s - loss: 1.7389 - regression_loss: 1.4407 - classification_loss: 0.2982
 885/1000 [=========================>....] - ETA: 32s - loss: 1.7390 - regression_loss: 1.4409 - classification_loss: 0.2981
 886/1000 [=========================>....] - ETA: 32s - loss: 1.7388 - regression_loss: 1.4406 - classification_loss: 0.2981
 887/1000 [=========================>....] - ETA: 32s - loss: 1.7379 - regression_loss: 1.4400 - classification_loss: 0.2980
 888/1000 [=========================>....] - ETA: 32s - loss: 1.7380 - regression_loss: 1.4401 - classification_loss: 0.2979
 889/1000 [=========================>....] - ETA: 31s - loss: 1.7377 - regression_loss: 1.4399 - classification_loss: 0.2977
 890/1000 [=========================>....] - ETA: 31s - loss: 1.7381 - regression_loss: 1.4403 - classification_loss: 0.2978
 891/1000 [=========================>....] - ETA: 31s - loss: 1.7373 - regression_loss: 1.4396 - classification_loss: 0.2976
 892/1000 [=========================>....] - ETA: 30s - loss: 1.7375 - regression_loss: 1.4398 - classification_loss: 0.2977
 893/1000 [=========================>....] - ETA: 30s - loss: 1.7370 - regression_loss: 1.4395 - classification_loss: 0.2975
 894/1000 [=========================>....] - ETA: 30s - loss: 1.7372 - regression_loss: 1.4395 - classification_loss: 0.2977
 895/1000 [=========================>....] - ETA: 30s - loss: 1.7378 - regression_loss: 1.4399 - classification_loss: 0.2979
 896/1000 [=========================>....] - ETA: 29s - loss: 1.7373 - regression_loss: 1.4394 - classification_loss: 0.2978
 897/1000 [=========================>....] - ETA: 29s - loss: 1.7380 - regression_loss: 1.4402 - classification_loss: 0.2978
 898/1000 [=========================>....] - ETA: 29s - loss: 1.7374 - regression_loss: 1.4396 - classification_loss: 0.2978
 899/1000 [=========================>....] - ETA: 28s - loss: 1.7372 - regression_loss: 1.4394 - classification_loss: 0.2978
 900/1000 [==========================>...] - ETA: 28s - loss: 1.7364 - regression_loss: 1.4388 - classification_loss: 0.2976
 901/1000 [==========================>...] - ETA: 28s - loss: 1.7376 - regression_loss: 1.4396 - classification_loss: 0.2980
 902/1000 [==========================>...] - ETA: 28s - loss: 1.7369 - regression_loss: 1.4391 - classification_loss: 0.2978
 903/1000 [==========================>...] - ETA: 27s - loss: 1.7362 - regression_loss: 1.4386 - classification_loss: 0.2977
 904/1000 [==========================>...] - ETA: 27s - loss: 1.7360 - regression_loss: 1.4382 - classification_loss: 0.2978
 905/1000 [==========================>...] - ETA: 27s - loss: 1.7357 - regression_loss: 1.4378 - classification_loss: 0.2978
 906/1000 [==========================>...] - ETA: 26s - loss: 1.7349 - regression_loss: 1.4372 - classification_loss: 0.2977
 907/1000 [==========================>...] - ETA: 26s - loss: 1.7349 - regression_loss: 1.4374 - classification_loss: 0.2976
 908/1000 [==========================>...] - ETA: 26s - loss: 1.7346 - regression_loss: 1.4371 - classification_loss: 0.2975
 909/1000 [==========================>...] - ETA: 26s - loss: 1.7347 - regression_loss: 1.4372 - classification_loss: 0.2975
 910/1000 [==========================>...] - ETA: 25s - loss: 1.7337 - regression_loss: 1.4364 - classification_loss: 0.2973
 911/1000 [==========================>...] - ETA: 25s - loss: 1.7333 - regression_loss: 1.4362 - classification_loss: 0.2971
 912/1000 [==========================>...] - ETA: 25s - loss: 1.7323 - regression_loss: 1.4353 - classification_loss: 0.2969
 913/1000 [==========================>...] - ETA: 24s - loss: 1.7323 - regression_loss: 1.4353 - classification_loss: 0.2970
 914/1000 [==========================>...] - ETA: 24s - loss: 1.7317 - regression_loss: 1.4348 - classification_loss: 0.2969
 915/1000 [==========================>...] - ETA: 24s - loss: 1.7313 - regression_loss: 1.4345 - classification_loss: 0.2968
 916/1000 [==========================>...] - ETA: 24s - loss: 1.7310 - regression_loss: 1.4343 - classification_loss: 0.2967
 917/1000 [==========================>...] - ETA: 23s - loss: 1.7309 - regression_loss: 1.4343 - classification_loss: 0.2966
 918/1000 [==========================>...] - ETA: 23s - loss: 1.7306 - regression_loss: 1.4341 - classification_loss: 0.2965
 919/1000 [==========================>...] - ETA: 23s - loss: 1.7296 - regression_loss: 1.4333 - classification_loss: 0.2963
 920/1000 [==========================>...] - ETA: 22s - loss: 1.7315 - regression_loss: 1.4350 - classification_loss: 0.2965
 921/1000 [==========================>...] - ETA: 22s - loss: 1.7312 - regression_loss: 1.4348 - classification_loss: 0.2964
 922/1000 [==========================>...] - ETA: 22s - loss: 1.7315 - regression_loss: 1.4350 - classification_loss: 0.2965
 923/1000 [==========================>...] - ETA: 22s - loss: 1.7308 - regression_loss: 1.4344 - classification_loss: 0.2963
 924/1000 [==========================>...] - ETA: 21s - loss: 1.7311 - regression_loss: 1.4347 - classification_loss: 0.2964
 925/1000 [==========================>...] - ETA: 21s - loss: 1.7308 - regression_loss: 1.4344 - classification_loss: 0.2964
 926/1000 [==========================>...] - ETA: 21s - loss: 1.7316 - regression_loss: 1.4351 - classification_loss: 0.2965
 927/1000 [==========================>...] - ETA: 20s - loss: 1.7313 - regression_loss: 1.4346 - classification_loss: 0.2967
 928/1000 [==========================>...] - ETA: 20s - loss: 1.7313 - regression_loss: 1.4345 - classification_loss: 0.2968
 929/1000 [==========================>...] - ETA: 20s - loss: 1.7324 - regression_loss: 1.4352 - classification_loss: 0.2971
 930/1000 [==========================>...] - ETA: 20s - loss: 1.7326 - regression_loss: 1.4353 - classification_loss: 0.2973
 931/1000 [==========================>...] - ETA: 19s - loss: 1.7324 - regression_loss: 1.4352 - classification_loss: 0.2972
 932/1000 [==========================>...] - ETA: 19s - loss: 1.7327 - regression_loss: 1.4355 - classification_loss: 0.2973
 933/1000 [==========================>...] - ETA: 19s - loss: 1.7332 - regression_loss: 1.4359 - classification_loss: 0.2973
 934/1000 [===========================>..] - ETA: 18s - loss: 1.7338 - regression_loss: 1.4364 - classification_loss: 0.2974
 935/1000 [===========================>..] - ETA: 18s - loss: 1.7339 - regression_loss: 1.4365 - classification_loss: 0.2975
 936/1000 [===========================>..] - ETA: 18s - loss: 1.7338 - regression_loss: 1.4365 - classification_loss: 0.2973
 937/1000 [===========================>..] - ETA: 18s - loss: 1.7332 - regression_loss: 1.4360 - classification_loss: 0.2972
 938/1000 [===========================>..] - ETA: 17s - loss: 1.7330 - regression_loss: 1.4357 - classification_loss: 0.2973
 939/1000 [===========================>..] - ETA: 17s - loss: 1.7331 - regression_loss: 1.4357 - classification_loss: 0.2973
 940/1000 [===========================>..] - ETA: 17s - loss: 1.7333 - regression_loss: 1.4361 - classification_loss: 0.2972
 941/1000 [===========================>..] - ETA: 16s - loss: 1.7337 - regression_loss: 1.4364 - classification_loss: 0.2973
 942/1000 [===========================>..] - ETA: 16s - loss: 1.7334 - regression_loss: 1.4362 - classification_loss: 0.2971
 943/1000 [===========================>..] - ETA: 16s - loss: 1.7348 - regression_loss: 1.4366 - classification_loss: 0.2982
 944/1000 [===========================>..] - ETA: 16s - loss: 1.7340 - regression_loss: 1.4359 - classification_loss: 0.2980
 945/1000 [===========================>..] - ETA: 15s - loss: 1.7340 - regression_loss: 1.4360 - classification_loss: 0.2980
 946/1000 [===========================>..] - ETA: 15s - loss: 1.7345 - regression_loss: 1.4363 - classification_loss: 0.2981
 947/1000 [===========================>..] - ETA: 15s - loss: 1.7339 - regression_loss: 1.4359 - classification_loss: 0.2980
 948/1000 [===========================>..] - ETA: 14s - loss: 1.7330 - regression_loss: 1.4352 - classification_loss: 0.2979
 949/1000 [===========================>..] - ETA: 14s - loss: 1.7334 - regression_loss: 1.4353 - classification_loss: 0.2981
 950/1000 [===========================>..] - ETA: 14s - loss: 1.7329 - regression_loss: 1.4349 - classification_loss: 0.2980
 951/1000 [===========================>..] - ETA: 14s - loss: 1.7320 - regression_loss: 1.4342 - classification_loss: 0.2979
 952/1000 [===========================>..] - ETA: 13s - loss: 1.7313 - regression_loss: 1.4336 - classification_loss: 0.2977
 953/1000 [===========================>..] - ETA: 13s - loss: 1.7315 - regression_loss: 1.4339 - classification_loss: 0.2976
 954/1000 [===========================>..] - ETA: 13s - loss: 1.7309 - regression_loss: 1.4334 - classification_loss: 0.2975
 955/1000 [===========================>..] - ETA: 12s - loss: 1.7310 - regression_loss: 1.4335 - classification_loss: 0.2974
 956/1000 [===========================>..] - ETA: 12s - loss: 1.7308 - regression_loss: 1.4333 - classification_loss: 0.2975
 957/1000 [===========================>..] - ETA: 12s - loss: 1.7303 - regression_loss: 1.4328 - classification_loss: 0.2975
 958/1000 [===========================>..] - ETA: 12s - loss: 1.7296 - regression_loss: 1.4322 - classification_loss: 0.2974
 959/1000 [===========================>..] - ETA: 11s - loss: 1.7292 - regression_loss: 1.4319 - classification_loss: 0.2973
 960/1000 [===========================>..] - ETA: 11s - loss: 1.7290 - regression_loss: 1.4318 - classification_loss: 0.2972
 961/1000 [===========================>..] - ETA: 11s - loss: 1.7288 - regression_loss: 1.4316 - classification_loss: 0.2972
 962/1000 [===========================>..] - ETA: 10s - loss: 1.7280 - regression_loss: 1.4309 - classification_loss: 0.2971
 963/1000 [===========================>..] - ETA: 10s - loss: 1.7286 - regression_loss: 1.4314 - classification_loss: 0.2972
 964/1000 [===========================>..] - ETA: 10s - loss: 1.7279 - regression_loss: 1.4308 - classification_loss: 0.2971
 965/1000 [===========================>..] - ETA: 10s - loss: 1.7283 - regression_loss: 1.4311 - classification_loss: 0.2972
 966/1000 [===========================>..] - ETA: 9s - loss: 1.7284 - regression_loss: 1.4312 - classification_loss: 0.2972 
 967/1000 [============================>.] - ETA: 9s - loss: 1.7274 - regression_loss: 1.4304 - classification_loss: 0.2971
 968/1000 [============================>.] - ETA: 9s - loss: 1.7275 - regression_loss: 1.4304 - classification_loss: 0.2971
 969/1000 [============================>.] - ETA: 8s - loss: 1.7274 - regression_loss: 1.4304 - classification_loss: 0.2971
 970/1000 [============================>.] - ETA: 8s - loss: 1.7277 - regression_loss: 1.4306 - classification_loss: 0.2971
 971/1000 [============================>.] - ETA: 8s - loss: 1.7266 - regression_loss: 1.4297 - classification_loss: 0.2969
 972/1000 [============================>.] - ETA: 8s - loss: 1.7259 - regression_loss: 1.4292 - classification_loss: 0.2967
 973/1000 [============================>.] - ETA: 7s - loss: 1.7261 - regression_loss: 1.4295 - classification_loss: 0.2966
 974/1000 [============================>.] - ETA: 7s - loss: 1.7253 - regression_loss: 1.4288 - classification_loss: 0.2965
 975/1000 [============================>.] - ETA: 7s - loss: 1.7250 - regression_loss: 1.4286 - classification_loss: 0.2964
 976/1000 [============================>.] - ETA: 6s - loss: 1.7254 - regression_loss: 1.4290 - classification_loss: 0.2964
 977/1000 [============================>.] - ETA: 6s - loss: 1.7255 - regression_loss: 1.4291 - classification_loss: 0.2964
 978/1000 [============================>.] - ETA: 6s - loss: 1.7243 - regression_loss: 1.4281 - classification_loss: 0.2962
 979/1000 [============================>.] - ETA: 6s - loss: 1.7241 - regression_loss: 1.4280 - classification_loss: 0.2961
 980/1000 [============================>.] - ETA: 5s - loss: 1.7234 - regression_loss: 1.4275 - classification_loss: 0.2959
 981/1000 [============================>.] - ETA: 5s - loss: 1.7247 - regression_loss: 1.4284 - classification_loss: 0.2963
 982/1000 [============================>.] - ETA: 5s - loss: 1.7240 - regression_loss: 1.4276 - classification_loss: 0.2964
 983/1000 [============================>.] - ETA: 4s - loss: 1.7250 - regression_loss: 1.4284 - classification_loss: 0.2967
 984/1000 [============================>.] - ETA: 4s - loss: 1.7245 - regression_loss: 1.4280 - classification_loss: 0.2965
 985/1000 [============================>.] - ETA: 4s - loss: 1.7246 - regression_loss: 1.4281 - classification_loss: 0.2965
 986/1000 [============================>.] - ETA: 4s - loss: 1.7243 - regression_loss: 1.4279 - classification_loss: 0.2964
 987/1000 [============================>.] - ETA: 3s - loss: 1.7245 - regression_loss: 1.4281 - classification_loss: 0.2965
 988/1000 [============================>.] - ETA: 3s - loss: 1.7242 - regression_loss: 1.4278 - classification_loss: 0.2964
 989/1000 [============================>.] - ETA: 3s - loss: 1.7239 - regression_loss: 1.4277 - classification_loss: 0.2962
 990/1000 [============================>.] - ETA: 2s - loss: 1.7237 - regression_loss: 1.4273 - classification_loss: 0.2964
 991/1000 [============================>.] - ETA: 2s - loss: 1.7234 - regression_loss: 1.4269 - classification_loss: 0.2964
 992/1000 [============================>.] - ETA: 2s - loss: 1.7236 - regression_loss: 1.4272 - classification_loss: 0.2964
 993/1000 [============================>.] - ETA: 2s - loss: 1.7236 - regression_loss: 1.4273 - classification_loss: 0.2963
 994/1000 [============================>.] - ETA: 1s - loss: 1.7239 - regression_loss: 1.4275 - classification_loss: 0.2964
 995/1000 [============================>.] - ETA: 1s - loss: 1.7235 - regression_loss: 1.4272 - classification_loss: 0.2963
 996/1000 [============================>.] - ETA: 1s - loss: 1.7233 - regression_loss: 1.4271 - classification_loss: 0.2962
 997/1000 [============================>.] - ETA: 0s - loss: 1.7236 - regression_loss: 1.4273 - classification_loss: 0.2963
 998/1000 [============================>.] - ETA: 0s - loss: 1.7243 - regression_loss: 1.4279 - classification_loss: 0.2964
 999/1000 [============================>.] - ETA: 0s - loss: 1.7240 - regression_loss: 1.4277 - classification_loss: 0.2963
1000/1000 [==============================] - 287s 287ms/step - loss: 1.7244 - regression_loss: 1.4282 - classification_loss: 0.2962

Epoch 00003: saving model to ./snapshots/resnet50_csv_03.h5
Epoch 4/10

   1/1000 [..............................] - ETA: 4:49 - loss: 2.0066 - regression_loss: 1.7942 - classification_loss: 0.2124
   2/1000 [..............................] - ETA: 4:47 - loss: 2.5771 - regression_loss: 2.1665 - classification_loss: 0.4106
   3/1000 [..............................] - ETA: 4:48 - loss: 2.0122 - regression_loss: 1.6927 - classification_loss: 0.3196
   4/1000 [..............................] - ETA: 4:49 - loss: 1.9061 - regression_loss: 1.5926 - classification_loss: 0.3135
   5/1000 [..............................] - ETA: 4:47 - loss: 1.9100 - regression_loss: 1.5885 - classification_loss: 0.3215
   6/1000 [..............................] - ETA: 4:46 - loss: 1.8085 - regression_loss: 1.5166 - classification_loss: 0.2919
   7/1000 [..............................] - ETA: 4:46 - loss: 1.7217 - regression_loss: 1.4492 - classification_loss: 0.2725
   8/1000 [..............................] - ETA: 4:45 - loss: 1.7887 - regression_loss: 1.5050 - classification_loss: 0.2837
   9/1000 [..............................] - ETA: 4:45 - loss: 1.7217 - regression_loss: 1.4544 - classification_loss: 0.2673
  10/1000 [..............................] - ETA: 4:45 - loss: 1.7809 - regression_loss: 1.4757 - classification_loss: 0.3051
  11/1000 [..............................] - ETA: 4:44 - loss: 1.7016 - regression_loss: 1.4096 - classification_loss: 0.2919
  12/1000 [..............................] - ETA: 4:44 - loss: 1.6654 - regression_loss: 1.3832 - classification_loss: 0.2822
  13/1000 [..............................] - ETA: 4:44 - loss: 1.6279 - regression_loss: 1.3574 - classification_loss: 0.2705
  14/1000 [..............................] - ETA: 4:43 - loss: 1.6678 - regression_loss: 1.3953 - classification_loss: 0.2725
  15/1000 [..............................] - ETA: 4:42 - loss: 1.6719 - regression_loss: 1.4042 - classification_loss: 0.2677
  16/1000 [..............................] - ETA: 4:42 - loss: 1.6793 - regression_loss: 1.4117 - classification_loss: 0.2676
  17/1000 [..............................] - ETA: 4:42 - loss: 1.6975 - regression_loss: 1.4318 - classification_loss: 0.2657
  18/1000 [..............................] - ETA: 4:42 - loss: 1.7580 - regression_loss: 1.4710 - classification_loss: 0.2870
  19/1000 [..............................] - ETA: 4:42 - loss: 1.7154 - regression_loss: 1.4378 - classification_loss: 0.2777
  20/1000 [..............................] - ETA: 4:42 - loss: 1.7139 - regression_loss: 1.4387 - classification_loss: 0.2752
  21/1000 [..............................] - ETA: 4:41 - loss: 1.6969 - regression_loss: 1.4238 - classification_loss: 0.2731
  22/1000 [..............................] - ETA: 4:41 - loss: 1.7350 - regression_loss: 1.4536 - classification_loss: 0.2813
  23/1000 [..............................] - ETA: 4:40 - loss: 1.7214 - regression_loss: 1.4449 - classification_loss: 0.2765
  24/1000 [..............................] - ETA: 4:40 - loss: 1.7271 - regression_loss: 1.4518 - classification_loss: 0.2753
  25/1000 [..............................] - ETA: 4:40 - loss: 1.7251 - regression_loss: 1.4400 - classification_loss: 0.2851
  26/1000 [..............................] - ETA: 4:40 - loss: 1.7260 - regression_loss: 1.4408 - classification_loss: 0.2852
  27/1000 [..............................] - ETA: 4:39 - loss: 1.7420 - regression_loss: 1.4530 - classification_loss: 0.2890
  28/1000 [..............................] - ETA: 4:39 - loss: 1.7205 - regression_loss: 1.4371 - classification_loss: 0.2834
  29/1000 [..............................] - ETA: 4:39 - loss: 1.7204 - regression_loss: 1.4408 - classification_loss: 0.2796
  30/1000 [..............................] - ETA: 4:38 - loss: 1.7244 - regression_loss: 1.4404 - classification_loss: 0.2840
  31/1000 [..............................] - ETA: 4:38 - loss: 1.7040 - regression_loss: 1.4243 - classification_loss: 0.2797
  32/1000 [..............................] - ETA: 4:38 - loss: 1.6836 - regression_loss: 1.4040 - classification_loss: 0.2796
  33/1000 [..............................] - ETA: 4:37 - loss: 1.6770 - regression_loss: 1.4007 - classification_loss: 0.2763
  34/1000 [>.............................] - ETA: 4:37 - loss: 1.6812 - regression_loss: 1.4053 - classification_loss: 0.2759
  35/1000 [>.............................] - ETA: 4:36 - loss: 1.6994 - regression_loss: 1.4212 - classification_loss: 0.2782
  36/1000 [>.............................] - ETA: 4:36 - loss: 1.7133 - regression_loss: 1.4327 - classification_loss: 0.2806
  37/1000 [>.............................] - ETA: 4:36 - loss: 1.7122 - regression_loss: 1.4322 - classification_loss: 0.2800
  38/1000 [>.............................] - ETA: 4:35 - loss: 1.7059 - regression_loss: 1.4277 - classification_loss: 0.2782
  39/1000 [>.............................] - ETA: 4:35 - loss: 1.6976 - regression_loss: 1.4224 - classification_loss: 0.2752
  40/1000 [>.............................] - ETA: 4:35 - loss: 1.7030 - regression_loss: 1.4274 - classification_loss: 0.2755
  41/1000 [>.............................] - ETA: 4:34 - loss: 1.7027 - regression_loss: 1.4252 - classification_loss: 0.2775
  42/1000 [>.............................] - ETA: 4:34 - loss: 1.6867 - regression_loss: 1.4125 - classification_loss: 0.2742
  43/1000 [>.............................] - ETA: 4:34 - loss: 1.6768 - regression_loss: 1.4052 - classification_loss: 0.2716
  44/1000 [>.............................] - ETA: 4:34 - loss: 1.6669 - regression_loss: 1.3962 - classification_loss: 0.2706
  45/1000 [>.............................] - ETA: 4:33 - loss: 1.6643 - regression_loss: 1.3965 - classification_loss: 0.2678
  46/1000 [>.............................] - ETA: 4:33 - loss: 1.6836 - regression_loss: 1.4156 - classification_loss: 0.2680
  47/1000 [>.............................] - ETA: 4:33 - loss: 1.6743 - regression_loss: 1.4069 - classification_loss: 0.2675
  48/1000 [>.............................] - ETA: 4:32 - loss: 1.7046 - regression_loss: 1.4229 - classification_loss: 0.2817
  49/1000 [>.............................] - ETA: 4:32 - loss: 1.6989 - regression_loss: 1.4161 - classification_loss: 0.2828
  50/1000 [>.............................] - ETA: 4:32 - loss: 1.7072 - regression_loss: 1.4211 - classification_loss: 0.2861
  51/1000 [>.............................] - ETA: 4:31 - loss: 1.7050 - regression_loss: 1.4198 - classification_loss: 0.2852
  52/1000 [>.............................] - ETA: 4:31 - loss: 1.6937 - regression_loss: 1.4105 - classification_loss: 0.2832
  53/1000 [>.............................] - ETA: 4:31 - loss: 1.6966 - regression_loss: 1.4109 - classification_loss: 0.2858
  54/1000 [>.............................] - ETA: 4:31 - loss: 1.7000 - regression_loss: 1.4133 - classification_loss: 0.2867
  55/1000 [>.............................] - ETA: 4:30 - loss: 1.7125 - regression_loss: 1.4266 - classification_loss: 0.2859
  56/1000 [>.............................] - ETA: 4:30 - loss: 1.7316 - regression_loss: 1.4419 - classification_loss: 0.2897
  57/1000 [>.............................] - ETA: 4:30 - loss: 1.7290 - regression_loss: 1.4373 - classification_loss: 0.2916
  58/1000 [>.............................] - ETA: 4:29 - loss: 1.7268 - regression_loss: 1.4351 - classification_loss: 0.2917
  59/1000 [>.............................] - ETA: 4:29 - loss: 1.7304 - regression_loss: 1.4358 - classification_loss: 0.2946
  60/1000 [>.............................] - ETA: 4:29 - loss: 1.7368 - regression_loss: 1.4413 - classification_loss: 0.2955
  61/1000 [>.............................] - ETA: 4:28 - loss: 1.7295 - regression_loss: 1.4345 - classification_loss: 0.2949
  62/1000 [>.............................] - ETA: 4:28 - loss: 1.7266 - regression_loss: 1.4318 - classification_loss: 0.2948
  63/1000 [>.............................] - ETA: 4:28 - loss: 1.7167 - regression_loss: 1.4239 - classification_loss: 0.2927
  64/1000 [>.............................] - ETA: 4:28 - loss: 1.7126 - regression_loss: 1.4211 - classification_loss: 0.2915
  65/1000 [>.............................] - ETA: 4:27 - loss: 1.7155 - regression_loss: 1.4211 - classification_loss: 0.2945
  66/1000 [>.............................] - ETA: 4:27 - loss: 1.7227 - regression_loss: 1.4274 - classification_loss: 0.2953
  67/1000 [=>............................] - ETA: 4:27 - loss: 1.7148 - regression_loss: 1.4210 - classification_loss: 0.2939
  68/1000 [=>............................] - ETA: 4:26 - loss: 1.7028 - regression_loss: 1.4111 - classification_loss: 0.2916
  69/1000 [=>............................] - ETA: 4:26 - loss: 1.6929 - regression_loss: 1.4019 - classification_loss: 0.2911
  70/1000 [=>............................] - ETA: 4:26 - loss: 1.6930 - regression_loss: 1.3998 - classification_loss: 0.2931
  71/1000 [=>............................] - ETA: 4:26 - loss: 1.6959 - regression_loss: 1.4021 - classification_loss: 0.2939
  72/1000 [=>............................] - ETA: 4:25 - loss: 1.6839 - regression_loss: 1.3921 - classification_loss: 0.2919
  73/1000 [=>............................] - ETA: 4:25 - loss: 1.6784 - regression_loss: 1.3869 - classification_loss: 0.2914
  74/1000 [=>............................] - ETA: 4:25 - loss: 1.6800 - regression_loss: 1.3897 - classification_loss: 0.2904
  75/1000 [=>............................] - ETA: 4:24 - loss: 1.6871 - regression_loss: 1.3919 - classification_loss: 0.2952
  76/1000 [=>............................] - ETA: 4:24 - loss: 1.6851 - regression_loss: 1.3894 - classification_loss: 0.2957
  77/1000 [=>............................] - ETA: 4:24 - loss: 1.6892 - regression_loss: 1.3947 - classification_loss: 0.2945
  78/1000 [=>............................] - ETA: 4:23 - loss: 1.6879 - regression_loss: 1.3929 - classification_loss: 0.2950
  79/1000 [=>............................] - ETA: 4:23 - loss: 1.6911 - regression_loss: 1.3961 - classification_loss: 0.2950
  80/1000 [=>............................] - ETA: 4:23 - loss: 1.6811 - regression_loss: 1.3886 - classification_loss: 0.2926
  81/1000 [=>............................] - ETA: 4:22 - loss: 1.6718 - regression_loss: 1.3811 - classification_loss: 0.2907
  82/1000 [=>............................] - ETA: 4:22 - loss: 1.6723 - regression_loss: 1.3826 - classification_loss: 0.2897
  83/1000 [=>............................] - ETA: 4:22 - loss: 1.6732 - regression_loss: 1.3830 - classification_loss: 0.2902
  84/1000 [=>............................] - ETA: 4:21 - loss: 1.6768 - regression_loss: 1.3870 - classification_loss: 0.2898
  85/1000 [=>............................] - ETA: 4:21 - loss: 1.6809 - regression_loss: 1.3905 - classification_loss: 0.2904
  86/1000 [=>............................] - ETA: 4:21 - loss: 1.6754 - regression_loss: 1.3865 - classification_loss: 0.2888
  87/1000 [=>............................] - ETA: 4:21 - loss: 1.6756 - regression_loss: 1.3861 - classification_loss: 0.2895
  88/1000 [=>............................] - ETA: 4:20 - loss: 1.6723 - regression_loss: 1.3825 - classification_loss: 0.2897
  89/1000 [=>............................] - ETA: 4:20 - loss: 1.6658 - regression_loss: 1.3780 - classification_loss: 0.2878
  90/1000 [=>............................] - ETA: 4:20 - loss: 1.6599 - regression_loss: 1.3719 - classification_loss: 0.2881
  91/1000 [=>............................] - ETA: 4:20 - loss: 1.6557 - regression_loss: 1.3687 - classification_loss: 0.2870
  92/1000 [=>............................] - ETA: 4:19 - loss: 1.6564 - regression_loss: 1.3695 - classification_loss: 0.2869
  93/1000 [=>............................] - ETA: 4:19 - loss: 1.6549 - regression_loss: 1.3680 - classification_loss: 0.2869
  94/1000 [=>............................] - ETA: 4:19 - loss: 1.6539 - regression_loss: 1.3679 - classification_loss: 0.2860
  95/1000 [=>............................] - ETA: 4:18 - loss: 1.6517 - regression_loss: 1.3663 - classification_loss: 0.2855
  96/1000 [=>............................] - ETA: 4:18 - loss: 1.6521 - regression_loss: 1.3670 - classification_loss: 0.2851
  97/1000 [=>............................] - ETA: 4:18 - loss: 1.6485 - regression_loss: 1.3638 - classification_loss: 0.2846
  98/1000 [=>............................] - ETA: 4:18 - loss: 1.6463 - regression_loss: 1.3621 - classification_loss: 0.2842
  99/1000 [=>............................] - ETA: 4:17 - loss: 1.6482 - regression_loss: 1.3643 - classification_loss: 0.2840
 100/1000 [==>...........................] - ETA: 4:17 - loss: 1.6500 - regression_loss: 1.3664 - classification_loss: 0.2836
 101/1000 [==>...........................] - ETA: 4:17 - loss: 1.6497 - regression_loss: 1.3670 - classification_loss: 0.2827
 102/1000 [==>...........................] - ETA: 4:17 - loss: 1.6441 - regression_loss: 1.3625 - classification_loss: 0.2816
 103/1000 [==>...........................] - ETA: 4:16 - loss: 1.6532 - regression_loss: 1.3695 - classification_loss: 0.2837
 104/1000 [==>...........................] - ETA: 4:16 - loss: 1.6645 - regression_loss: 1.3782 - classification_loss: 0.2864
 105/1000 [==>...........................] - ETA: 4:16 - loss: 1.6571 - regression_loss: 1.3704 - classification_loss: 0.2867
 106/1000 [==>...........................] - ETA: 4:15 - loss: 1.6585 - regression_loss: 1.3704 - classification_loss: 0.2881
 107/1000 [==>...........................] - ETA: 4:15 - loss: 1.6525 - regression_loss: 1.3656 - classification_loss: 0.2869
 108/1000 [==>...........................] - ETA: 4:15 - loss: 1.6572 - regression_loss: 1.3688 - classification_loss: 0.2884
 109/1000 [==>...........................] - ETA: 4:15 - loss: 1.6601 - regression_loss: 1.3714 - classification_loss: 0.2887
 110/1000 [==>...........................] - ETA: 4:14 - loss: 1.6592 - regression_loss: 1.3713 - classification_loss: 0.2878
 111/1000 [==>...........................] - ETA: 4:14 - loss: 1.6597 - regression_loss: 1.3717 - classification_loss: 0.2880
 112/1000 [==>...........................] - ETA: 4:14 - loss: 1.6586 - regression_loss: 1.3711 - classification_loss: 0.2874
 113/1000 [==>...........................] - ETA: 4:13 - loss: 1.6629 - regression_loss: 1.3753 - classification_loss: 0.2876
 114/1000 [==>...........................] - ETA: 4:13 - loss: 1.6664 - regression_loss: 1.3797 - classification_loss: 0.2867
 115/1000 [==>...........................] - ETA: 4:13 - loss: 1.6591 - regression_loss: 1.3736 - classification_loss: 0.2855
 116/1000 [==>...........................] - ETA: 4:13 - loss: 1.6622 - regression_loss: 1.3766 - classification_loss: 0.2856
 117/1000 [==>...........................] - ETA: 4:12 - loss: 1.6657 - regression_loss: 1.3797 - classification_loss: 0.2860
 118/1000 [==>...........................] - ETA: 4:12 - loss: 1.6692 - regression_loss: 1.3839 - classification_loss: 0.2853
 119/1000 [==>...........................] - ETA: 4:12 - loss: 1.6675 - regression_loss: 1.3822 - classification_loss: 0.2853
 120/1000 [==>...........................] - ETA: 4:11 - loss: 1.6609 - regression_loss: 1.3769 - classification_loss: 0.2840
 121/1000 [==>...........................] - ETA: 4:11 - loss: 1.6585 - regression_loss: 1.3745 - classification_loss: 0.2840
 122/1000 [==>...........................] - ETA: 4:11 - loss: 1.6511 - regression_loss: 1.3687 - classification_loss: 0.2824
 123/1000 [==>...........................] - ETA: 4:11 - loss: 1.6589 - regression_loss: 1.3747 - classification_loss: 0.2842
 124/1000 [==>...........................] - ETA: 4:10 - loss: 1.6630 - regression_loss: 1.3790 - classification_loss: 0.2841
 125/1000 [==>...........................] - ETA: 4:10 - loss: 1.6678 - regression_loss: 1.3809 - classification_loss: 0.2870
 126/1000 [==>...........................] - ETA: 4:10 - loss: 1.6770 - regression_loss: 1.3897 - classification_loss: 0.2873
 127/1000 [==>...........................] - ETA: 4:09 - loss: 1.6769 - regression_loss: 1.3902 - classification_loss: 0.2866
 128/1000 [==>...........................] - ETA: 4:09 - loss: 1.6822 - regression_loss: 1.3934 - classification_loss: 0.2888
 129/1000 [==>...........................] - ETA: 4:09 - loss: 1.6798 - regression_loss: 1.3920 - classification_loss: 0.2878
 130/1000 [==>...........................] - ETA: 4:09 - loss: 1.6826 - regression_loss: 1.3950 - classification_loss: 0.2876
 131/1000 [==>...........................] - ETA: 4:08 - loss: 1.6822 - regression_loss: 1.3953 - classification_loss: 0.2869
 132/1000 [==>...........................] - ETA: 4:08 - loss: 1.6775 - regression_loss: 1.3908 - classification_loss: 0.2868
 133/1000 [==>...........................] - ETA: 4:08 - loss: 1.6742 - regression_loss: 1.3881 - classification_loss: 0.2861
 134/1000 [===>..........................] - ETA: 4:08 - loss: 1.6793 - regression_loss: 1.3912 - classification_loss: 0.2880
 135/1000 [===>..........................] - ETA: 4:07 - loss: 1.6746 - regression_loss: 1.3877 - classification_loss: 0.2869
 136/1000 [===>..........................] - ETA: 4:07 - loss: 1.6773 - regression_loss: 1.3899 - classification_loss: 0.2874
 137/1000 [===>..........................] - ETA: 4:07 - loss: 1.6755 - regression_loss: 1.3885 - classification_loss: 0.2870
 138/1000 [===>..........................] - ETA: 4:06 - loss: 1.6787 - regression_loss: 1.3908 - classification_loss: 0.2879
 139/1000 [===>..........................] - ETA: 4:06 - loss: 1.6819 - regression_loss: 1.3927 - classification_loss: 0.2893
 140/1000 [===>..........................] - ETA: 4:06 - loss: 1.6826 - regression_loss: 1.3936 - classification_loss: 0.2890
 141/1000 [===>..........................] - ETA: 4:05 - loss: 1.6774 - regression_loss: 1.3893 - classification_loss: 0.2881
 142/1000 [===>..........................] - ETA: 4:05 - loss: 1.6908 - regression_loss: 1.4024 - classification_loss: 0.2884
 143/1000 [===>..........................] - ETA: 4:05 - loss: 1.6918 - regression_loss: 1.4035 - classification_loss: 0.2883
 144/1000 [===>..........................] - ETA: 4:05 - loss: 1.7004 - regression_loss: 1.4107 - classification_loss: 0.2897
 145/1000 [===>..........................] - ETA: 4:04 - loss: 1.7038 - regression_loss: 1.4137 - classification_loss: 0.2902
 146/1000 [===>..........................] - ETA: 4:04 - loss: 1.7012 - regression_loss: 1.4116 - classification_loss: 0.2896
 147/1000 [===>..........................] - ETA: 4:04 - loss: 1.7003 - regression_loss: 1.4119 - classification_loss: 0.2883
 148/1000 [===>..........................] - ETA: 4:03 - loss: 1.6984 - regression_loss: 1.4111 - classification_loss: 0.2873
 149/1000 [===>..........................] - ETA: 4:03 - loss: 1.6936 - regression_loss: 1.4076 - classification_loss: 0.2860
 150/1000 [===>..........................] - ETA: 4:03 - loss: 1.6888 - regression_loss: 1.4038 - classification_loss: 0.2850
 151/1000 [===>..........................] - ETA: 4:02 - loss: 1.6859 - regression_loss: 1.4012 - classification_loss: 0.2847
 152/1000 [===>..........................] - ETA: 4:02 - loss: 1.6881 - regression_loss: 1.4029 - classification_loss: 0.2852
 153/1000 [===>..........................] - ETA: 4:02 - loss: 1.6871 - regression_loss: 1.4020 - classification_loss: 0.2851
 154/1000 [===>..........................] - ETA: 4:02 - loss: 1.6889 - regression_loss: 1.4032 - classification_loss: 0.2857
 155/1000 [===>..........................] - ETA: 4:01 - loss: 1.6842 - regression_loss: 1.3996 - classification_loss: 0.2847
 156/1000 [===>..........................] - ETA: 4:01 - loss: 1.6870 - regression_loss: 1.4022 - classification_loss: 0.2848
 157/1000 [===>..........................] - ETA: 4:01 - loss: 1.6870 - regression_loss: 1.4017 - classification_loss: 0.2852
 158/1000 [===>..........................] - ETA: 4:00 - loss: 1.6874 - regression_loss: 1.4031 - classification_loss: 0.2843
 159/1000 [===>..........................] - ETA: 4:00 - loss: 1.6838 - regression_loss: 1.3994 - classification_loss: 0.2844
 160/1000 [===>..........................] - ETA: 4:00 - loss: 1.6807 - regression_loss: 1.3973 - classification_loss: 0.2834
 161/1000 [===>..........................] - ETA: 4:00 - loss: 1.6849 - regression_loss: 1.4015 - classification_loss: 0.2833
 162/1000 [===>..........................] - ETA: 3:59 - loss: 1.6793 - regression_loss: 1.3968 - classification_loss: 0.2825
 163/1000 [===>..........................] - ETA: 3:59 - loss: 1.6827 - regression_loss: 1.4006 - classification_loss: 0.2821
 164/1000 [===>..........................] - ETA: 3:59 - loss: 1.6812 - regression_loss: 1.3998 - classification_loss: 0.2814
 165/1000 [===>..........................] - ETA: 3:58 - loss: 1.6788 - regression_loss: 1.3981 - classification_loss: 0.2806
 166/1000 [===>..........................] - ETA: 3:58 - loss: 1.6811 - regression_loss: 1.3999 - classification_loss: 0.2813
 167/1000 [====>.........................] - ETA: 3:58 - loss: 1.6810 - regression_loss: 1.3998 - classification_loss: 0.2812
 168/1000 [====>.........................] - ETA: 3:58 - loss: 1.6780 - regression_loss: 1.3975 - classification_loss: 0.2804
 169/1000 [====>.........................] - ETA: 3:57 - loss: 1.6751 - regression_loss: 1.3953 - classification_loss: 0.2798
 170/1000 [====>.........................] - ETA: 3:57 - loss: 1.6772 - regression_loss: 1.3971 - classification_loss: 0.2801
 171/1000 [====>.........................] - ETA: 3:57 - loss: 1.6754 - regression_loss: 1.3959 - classification_loss: 0.2796
 172/1000 [====>.........................] - ETA: 3:56 - loss: 1.6682 - regression_loss: 1.3897 - classification_loss: 0.2786
 173/1000 [====>.........................] - ETA: 3:56 - loss: 1.6704 - regression_loss: 1.3923 - classification_loss: 0.2781
 174/1000 [====>.........................] - ETA: 3:56 - loss: 1.6700 - regression_loss: 1.3920 - classification_loss: 0.2780
 175/1000 [====>.........................] - ETA: 3:56 - loss: 1.6745 - regression_loss: 1.3949 - classification_loss: 0.2795
 176/1000 [====>.........................] - ETA: 3:55 - loss: 1.6692 - regression_loss: 1.3904 - classification_loss: 0.2788
 177/1000 [====>.........................] - ETA: 3:55 - loss: 1.6726 - regression_loss: 1.3932 - classification_loss: 0.2794
 178/1000 [====>.........................] - ETA: 3:55 - loss: 1.6786 - regression_loss: 1.3973 - classification_loss: 0.2813
 179/1000 [====>.........................] - ETA: 3:55 - loss: 1.6864 - regression_loss: 1.4031 - classification_loss: 0.2833
 180/1000 [====>.........................] - ETA: 3:54 - loss: 1.6826 - regression_loss: 1.4001 - classification_loss: 0.2825
 181/1000 [====>.........................] - ETA: 3:54 - loss: 1.6788 - regression_loss: 1.3971 - classification_loss: 0.2817
 182/1000 [====>.........................] - ETA: 3:54 - loss: 1.6851 - regression_loss: 1.4009 - classification_loss: 0.2841
 183/1000 [====>.........................] - ETA: 3:53 - loss: 1.6842 - regression_loss: 1.4006 - classification_loss: 0.2836
 184/1000 [====>.........................] - ETA: 3:53 - loss: 1.6853 - regression_loss: 1.4016 - classification_loss: 0.2837
 185/1000 [====>.........................] - ETA: 3:53 - loss: 1.6846 - regression_loss: 1.4014 - classification_loss: 0.2832
 186/1000 [====>.........................] - ETA: 3:52 - loss: 1.6867 - regression_loss: 1.4033 - classification_loss: 0.2834
 187/1000 [====>.........................] - ETA: 3:52 - loss: 1.6845 - regression_loss: 1.4017 - classification_loss: 0.2828
 188/1000 [====>.........................] - ETA: 3:52 - loss: 1.6795 - regression_loss: 1.3976 - classification_loss: 0.2819
 189/1000 [====>.........................] - ETA: 3:52 - loss: 1.6828 - regression_loss: 1.4003 - classification_loss: 0.2825
 190/1000 [====>.........................] - ETA: 3:51 - loss: 1.6793 - regression_loss: 1.3975 - classification_loss: 0.2818
 191/1000 [====>.........................] - ETA: 3:51 - loss: 1.6784 - regression_loss: 1.3968 - classification_loss: 0.2815
 192/1000 [====>.........................] - ETA: 3:51 - loss: 1.6789 - regression_loss: 1.3973 - classification_loss: 0.2815
 193/1000 [====>.........................] - ETA: 3:50 - loss: 1.6805 - regression_loss: 1.3989 - classification_loss: 0.2817
 194/1000 [====>.........................] - ETA: 3:50 - loss: 1.6792 - regression_loss: 1.3976 - classification_loss: 0.2816
 195/1000 [====>.........................] - ETA: 3:50 - loss: 1.6758 - regression_loss: 1.3946 - classification_loss: 0.2812
 196/1000 [====>.........................] - ETA: 3:50 - loss: 1.6786 - regression_loss: 1.3973 - classification_loss: 0.2813
 197/1000 [====>.........................] - ETA: 3:49 - loss: 1.6755 - regression_loss: 1.3948 - classification_loss: 0.2807
 198/1000 [====>.........................] - ETA: 3:49 - loss: 1.6753 - regression_loss: 1.3950 - classification_loss: 0.2803
 199/1000 [====>.........................] - ETA: 3:49 - loss: 1.6811 - regression_loss: 1.4007 - classification_loss: 0.2805
 200/1000 [=====>........................] - ETA: 3:48 - loss: 1.6814 - regression_loss: 1.4011 - classification_loss: 0.2803
 201/1000 [=====>........................] - ETA: 3:48 - loss: 1.6803 - regression_loss: 1.4006 - classification_loss: 0.2797
 202/1000 [=====>........................] - ETA: 3:48 - loss: 1.6786 - regression_loss: 1.3994 - classification_loss: 0.2792
 203/1000 [=====>........................] - ETA: 3:48 - loss: 1.6796 - regression_loss: 1.4005 - classification_loss: 0.2791
 204/1000 [=====>........................] - ETA: 3:47 - loss: 1.6814 - regression_loss: 1.4021 - classification_loss: 0.2793
 205/1000 [=====>........................] - ETA: 3:47 - loss: 1.6824 - regression_loss: 1.4030 - classification_loss: 0.2794
 206/1000 [=====>........................] - ETA: 3:47 - loss: 1.6848 - regression_loss: 1.4056 - classification_loss: 0.2792
 207/1000 [=====>........................] - ETA: 3:46 - loss: 1.6858 - regression_loss: 1.4059 - classification_loss: 0.2798
 208/1000 [=====>........................] - ETA: 3:46 - loss: 1.6837 - regression_loss: 1.4043 - classification_loss: 0.2794
 209/1000 [=====>........................] - ETA: 3:46 - loss: 1.6835 - regression_loss: 1.4044 - classification_loss: 0.2791
 210/1000 [=====>........................] - ETA: 3:45 - loss: 1.6842 - regression_loss: 1.4047 - classification_loss: 0.2795
 211/1000 [=====>........................] - ETA: 3:45 - loss: 1.6844 - regression_loss: 1.4047 - classification_loss: 0.2797
 212/1000 [=====>........................] - ETA: 3:45 - loss: 1.6800 - regression_loss: 1.4012 - classification_loss: 0.2788
 213/1000 [=====>........................] - ETA: 3:45 - loss: 1.6751 - regression_loss: 1.3967 - classification_loss: 0.2783
 214/1000 [=====>........................] - ETA: 3:44 - loss: 1.6732 - regression_loss: 1.3953 - classification_loss: 0.2778
 215/1000 [=====>........................] - ETA: 3:44 - loss: 1.6715 - regression_loss: 1.3938 - classification_loss: 0.2777
 216/1000 [=====>........................] - ETA: 3:44 - loss: 1.6742 - regression_loss: 1.3961 - classification_loss: 0.2781
 217/1000 [=====>........................] - ETA: 3:44 - loss: 1.6731 - regression_loss: 1.3953 - classification_loss: 0.2778
 218/1000 [=====>........................] - ETA: 3:43 - loss: 1.6743 - regression_loss: 1.3961 - classification_loss: 0.2782
 219/1000 [=====>........................] - ETA: 3:43 - loss: 1.6732 - regression_loss: 1.3948 - classification_loss: 0.2783
 220/1000 [=====>........................] - ETA: 3:43 - loss: 1.6690 - regression_loss: 1.3913 - classification_loss: 0.2778
 221/1000 [=====>........................] - ETA: 3:42 - loss: 1.6704 - regression_loss: 1.3922 - classification_loss: 0.2782
 222/1000 [=====>........................] - ETA: 3:42 - loss: 1.6693 - regression_loss: 1.3915 - classification_loss: 0.2778
 223/1000 [=====>........................] - ETA: 3:42 - loss: 1.6724 - regression_loss: 1.3930 - classification_loss: 0.2794
 224/1000 [=====>........................] - ETA: 3:42 - loss: 1.6719 - regression_loss: 1.3928 - classification_loss: 0.2791
 225/1000 [=====>........................] - ETA: 3:41 - loss: 1.6700 - regression_loss: 1.3912 - classification_loss: 0.2788
 226/1000 [=====>........................] - ETA: 3:41 - loss: 1.6686 - regression_loss: 1.3900 - classification_loss: 0.2785
 227/1000 [=====>........................] - ETA: 3:41 - loss: 1.6651 - regression_loss: 1.3872 - classification_loss: 0.2779
 228/1000 [=====>........................] - ETA: 3:40 - loss: 1.6644 - regression_loss: 1.3868 - classification_loss: 0.2776
 229/1000 [=====>........................] - ETA: 3:40 - loss: 1.6713 - regression_loss: 1.3912 - classification_loss: 0.2802
 230/1000 [=====>........................] - ETA: 3:40 - loss: 1.6751 - regression_loss: 1.3944 - classification_loss: 0.2808
 231/1000 [=====>........................] - ETA: 3:39 - loss: 1.6740 - regression_loss: 1.3935 - classification_loss: 0.2804
 232/1000 [=====>........................] - ETA: 3:39 - loss: 1.6751 - regression_loss: 1.3942 - classification_loss: 0.2809
 233/1000 [=====>........................] - ETA: 3:39 - loss: 1.6750 - regression_loss: 1.3940 - classification_loss: 0.2810
 234/1000 [======>.......................] - ETA: 3:39 - loss: 1.6752 - regression_loss: 1.3940 - classification_loss: 0.2812
 235/1000 [======>.......................] - ETA: 3:38 - loss: 1.6834 - regression_loss: 1.4001 - classification_loss: 0.2833
 236/1000 [======>.......................] - ETA: 3:38 - loss: 1.6810 - regression_loss: 1.3981 - classification_loss: 0.2829
 237/1000 [======>.......................] - ETA: 3:38 - loss: 1.6858 - regression_loss: 1.4024 - classification_loss: 0.2834
 238/1000 [======>.......................] - ETA: 3:38 - loss: 1.6857 - regression_loss: 1.4022 - classification_loss: 0.2836
 239/1000 [======>.......................] - ETA: 3:37 - loss: 1.6831 - regression_loss: 1.4001 - classification_loss: 0.2830
 240/1000 [======>.......................] - ETA: 3:37 - loss: 1.6803 - regression_loss: 1.3976 - classification_loss: 0.2827
 241/1000 [======>.......................] - ETA: 3:37 - loss: 1.6789 - regression_loss: 1.3965 - classification_loss: 0.2823
 242/1000 [======>.......................] - ETA: 3:36 - loss: 1.6773 - regression_loss: 1.3957 - classification_loss: 0.2816
 243/1000 [======>.......................] - ETA: 3:36 - loss: 1.6764 - regression_loss: 1.3953 - classification_loss: 0.2812
 244/1000 [======>.......................] - ETA: 3:36 - loss: 1.6784 - regression_loss: 1.3973 - classification_loss: 0.2812
 245/1000 [======>.......................] - ETA: 3:35 - loss: 1.6775 - regression_loss: 1.3963 - classification_loss: 0.2812
 246/1000 [======>.......................] - ETA: 3:35 - loss: 1.6769 - regression_loss: 1.3962 - classification_loss: 0.2807
 247/1000 [======>.......................] - ETA: 3:35 - loss: 1.6751 - regression_loss: 1.3943 - classification_loss: 0.2807
 248/1000 [======>.......................] - ETA: 3:35 - loss: 1.6727 - regression_loss: 1.3926 - classification_loss: 0.2801
 249/1000 [======>.......................] - ETA: 3:34 - loss: 1.6697 - regression_loss: 1.3900 - classification_loss: 0.2797
 250/1000 [======>.......................] - ETA: 3:34 - loss: 1.6699 - regression_loss: 1.3900 - classification_loss: 0.2799
 251/1000 [======>.......................] - ETA: 3:34 - loss: 1.6700 - regression_loss: 1.3901 - classification_loss: 0.2799
 252/1000 [======>.......................] - ETA: 3:33 - loss: 1.6719 - regression_loss: 1.3919 - classification_loss: 0.2801
 253/1000 [======>.......................] - ETA: 3:33 - loss: 1.6760 - regression_loss: 1.3946 - classification_loss: 0.2814
 254/1000 [======>.......................] - ETA: 3:33 - loss: 1.6793 - regression_loss: 1.3975 - classification_loss: 0.2818
 255/1000 [======>.......................] - ETA: 3:33 - loss: 1.6812 - regression_loss: 1.3993 - classification_loss: 0.2819
 256/1000 [======>.......................] - ETA: 3:32 - loss: 1.7020 - regression_loss: 1.3938 - classification_loss: 0.3082
 257/1000 [======>.......................] - ETA: 3:32 - loss: 1.7008 - regression_loss: 1.3934 - classification_loss: 0.3075
 258/1000 [======>.......................] - ETA: 3:32 - loss: 1.7055 - regression_loss: 1.3968 - classification_loss: 0.3086
 259/1000 [======>.......................] - ETA: 3:31 - loss: 1.7033 - regression_loss: 1.3954 - classification_loss: 0.3078
 260/1000 [======>.......................] - ETA: 3:31 - loss: 1.7001 - regression_loss: 1.3929 - classification_loss: 0.3072
 261/1000 [======>.......................] - ETA: 3:31 - loss: 1.7045 - regression_loss: 1.3959 - classification_loss: 0.3086
 262/1000 [======>.......................] - ETA: 3:31 - loss: 1.7026 - regression_loss: 1.3946 - classification_loss: 0.3080
 263/1000 [======>.......................] - ETA: 3:30 - loss: 1.7022 - regression_loss: 1.3945 - classification_loss: 0.3077
 264/1000 [======>.......................] - ETA: 3:30 - loss: 1.7021 - regression_loss: 1.3943 - classification_loss: 0.3078
 265/1000 [======>.......................] - ETA: 3:30 - loss: 1.7019 - regression_loss: 1.3944 - classification_loss: 0.3075
 266/1000 [======>.......................] - ETA: 3:29 - loss: 1.6997 - regression_loss: 1.3928 - classification_loss: 0.3069
 267/1000 [=======>......................] - ETA: 3:29 - loss: 1.6980 - regression_loss: 1.3918 - classification_loss: 0.3062
 268/1000 [=======>......................] - ETA: 3:29 - loss: 1.6960 - regression_loss: 1.3900 - classification_loss: 0.3061
 269/1000 [=======>......................] - ETA: 3:29 - loss: 1.6988 - regression_loss: 1.3927 - classification_loss: 0.3061
 270/1000 [=======>......................] - ETA: 3:28 - loss: 1.6989 - regression_loss: 1.3923 - classification_loss: 0.3066
 271/1000 [=======>......................] - ETA: 3:28 - loss: 1.6966 - regression_loss: 1.3901 - classification_loss: 0.3065
 272/1000 [=======>......................] - ETA: 3:28 - loss: 1.6951 - regression_loss: 1.3888 - classification_loss: 0.3063
 273/1000 [=======>......................] - ETA: 3:27 - loss: 1.6953 - regression_loss: 1.3889 - classification_loss: 0.3063
 274/1000 [=======>......................] - ETA: 3:27 - loss: 1.6940 - regression_loss: 1.3880 - classification_loss: 0.3060
 275/1000 [=======>......................] - ETA: 3:27 - loss: 1.6947 - regression_loss: 1.3883 - classification_loss: 0.3063
 276/1000 [=======>......................] - ETA: 3:27 - loss: 1.6920 - regression_loss: 1.3862 - classification_loss: 0.3058
 277/1000 [=======>......................] - ETA: 3:26 - loss: 1.6930 - regression_loss: 1.3871 - classification_loss: 0.3059
 278/1000 [=======>......................] - ETA: 3:26 - loss: 1.6921 - regression_loss: 1.3868 - classification_loss: 0.3053
 279/1000 [=======>......................] - ETA: 3:26 - loss: 1.6935 - regression_loss: 1.3884 - classification_loss: 0.3051
 280/1000 [=======>......................] - ETA: 3:25 - loss: 1.6959 - regression_loss: 1.3908 - classification_loss: 0.3052
 281/1000 [=======>......................] - ETA: 3:25 - loss: 1.6963 - regression_loss: 1.3912 - classification_loss: 0.3051
 282/1000 [=======>......................] - ETA: 3:25 - loss: 1.6937 - regression_loss: 1.3892 - classification_loss: 0.3045
 283/1000 [=======>......................] - ETA: 3:25 - loss: 1.6937 - regression_loss: 1.3891 - classification_loss: 0.3046
 284/1000 [=======>......................] - ETA: 3:24 - loss: 1.6926 - regression_loss: 1.3885 - classification_loss: 0.3041
 285/1000 [=======>......................] - ETA: 3:24 - loss: 1.6896 - regression_loss: 1.3855 - classification_loss: 0.3041
 286/1000 [=======>......................] - ETA: 3:24 - loss: 1.6872 - regression_loss: 1.3836 - classification_loss: 0.3036
 287/1000 [=======>......................] - ETA: 3:23 - loss: 1.6839 - regression_loss: 1.3809 - classification_loss: 0.3030
 288/1000 [=======>......................] - ETA: 3:23 - loss: 1.6822 - regression_loss: 1.3795 - classification_loss: 0.3028
 289/1000 [=======>......................] - ETA: 3:23 - loss: 1.6850 - regression_loss: 1.3816 - classification_loss: 0.3034
 290/1000 [=======>......................] - ETA: 3:23 - loss: 1.6828 - regression_loss: 1.3800 - classification_loss: 0.3028
 291/1000 [=======>......................] - ETA: 3:22 - loss: 1.6811 - regression_loss: 1.3787 - classification_loss: 0.3023
 292/1000 [=======>......................] - ETA: 3:22 - loss: 1.6799 - regression_loss: 1.3780 - classification_loss: 0.3019
 293/1000 [=======>......................] - ETA: 3:22 - loss: 1.6793 - regression_loss: 1.3780 - classification_loss: 0.3013
 294/1000 [=======>......................] - ETA: 3:21 - loss: 1.6793 - regression_loss: 1.3784 - classification_loss: 0.3009
 295/1000 [=======>......................] - ETA: 3:21 - loss: 1.6794 - regression_loss: 1.3788 - classification_loss: 0.3005
 296/1000 [=======>......................] - ETA: 3:21 - loss: 1.6770 - regression_loss: 1.3772 - classification_loss: 0.2999
 297/1000 [=======>......................] - ETA: 3:21 - loss: 1.6762 - regression_loss: 1.3766 - classification_loss: 0.2996
 298/1000 [=======>......................] - ETA: 3:20 - loss: 1.6741 - regression_loss: 1.3750 - classification_loss: 0.2991
 299/1000 [=======>......................] - ETA: 3:20 - loss: 1.6739 - regression_loss: 1.3752 - classification_loss: 0.2987
 300/1000 [========>.....................] - ETA: 3:20 - loss: 1.6781 - regression_loss: 1.3786 - classification_loss: 0.2995
 301/1000 [========>.....................] - ETA: 3:19 - loss: 1.6782 - regression_loss: 1.3789 - classification_loss: 0.2994
 302/1000 [========>.....................] - ETA: 3:19 - loss: 1.6769 - regression_loss: 1.3780 - classification_loss: 0.2989
 303/1000 [========>.....................] - ETA: 3:19 - loss: 1.6766 - regression_loss: 1.3776 - classification_loss: 0.2990
 304/1000 [========>.....................] - ETA: 3:19 - loss: 1.6811 - regression_loss: 1.3806 - classification_loss: 0.3006
 305/1000 [========>.....................] - ETA: 3:18 - loss: 1.6784 - regression_loss: 1.3783 - classification_loss: 0.3001
 306/1000 [========>.....................] - ETA: 3:18 - loss: 1.6790 - regression_loss: 1.3788 - classification_loss: 0.3001
 307/1000 [========>.....................] - ETA: 3:18 - loss: 1.6768 - regression_loss: 1.3772 - classification_loss: 0.2996
 308/1000 [========>.....................] - ETA: 3:17 - loss: 1.6744 - regression_loss: 1.3753 - classification_loss: 0.2990
 309/1000 [========>.....................] - ETA: 3:17 - loss: 1.6724 - regression_loss: 1.3740 - classification_loss: 0.2984
 310/1000 [========>.....................] - ETA: 3:17 - loss: 1.6711 - regression_loss: 1.3729 - classification_loss: 0.2982
 311/1000 [========>.....................] - ETA: 3:17 - loss: 1.6709 - regression_loss: 1.3732 - classification_loss: 0.2978
 312/1000 [========>.....................] - ETA: 3:16 - loss: 1.6697 - regression_loss: 1.3723 - classification_loss: 0.2975
 313/1000 [========>.....................] - ETA: 3:16 - loss: 1.6699 - regression_loss: 1.3723 - classification_loss: 0.2976
 314/1000 [========>.....................] - ETA: 3:16 - loss: 1.6678 - regression_loss: 1.3707 - classification_loss: 0.2971
 315/1000 [========>.....................] - ETA: 3:15 - loss: 1.6686 - regression_loss: 1.3714 - classification_loss: 0.2972
 316/1000 [========>.....................] - ETA: 3:15 - loss: 1.6705 - regression_loss: 1.3720 - classification_loss: 0.2985
 317/1000 [========>.....................] - ETA: 3:15 - loss: 1.6696 - regression_loss: 1.3707 - classification_loss: 0.2989
 318/1000 [========>.....................] - ETA: 3:15 - loss: 1.6707 - regression_loss: 1.3721 - classification_loss: 0.2986
 319/1000 [========>.....................] - ETA: 3:14 - loss: 1.6692 - regression_loss: 1.3708 - classification_loss: 0.2984
 320/1000 [========>.....................] - ETA: 3:14 - loss: 1.6685 - regression_loss: 1.3703 - classification_loss: 0.2982
 321/1000 [========>.....................] - ETA: 3:14 - loss: 1.6662 - regression_loss: 1.3686 - classification_loss: 0.2976
 322/1000 [========>.....................] - ETA: 3:13 - loss: 1.6636 - regression_loss: 1.3664 - classification_loss: 0.2972
 323/1000 [========>.....................] - ETA: 3:13 - loss: 1.6622 - regression_loss: 1.3654 - classification_loss: 0.2967
 324/1000 [========>.....................] - ETA: 3:13 - loss: 1.6609 - regression_loss: 1.3646 - classification_loss: 0.2963
 325/1000 [========>.....................] - ETA: 3:13 - loss: 1.6611 - regression_loss: 1.3646 - classification_loss: 0.2965
 326/1000 [========>.....................] - ETA: 3:12 - loss: 1.6614 - regression_loss: 1.3647 - classification_loss: 0.2967
 327/1000 [========>.....................] - ETA: 3:12 - loss: 1.6644 - regression_loss: 1.3664 - classification_loss: 0.2980
 328/1000 [========>.....................] - ETA: 3:12 - loss: 1.6662 - regression_loss: 1.3675 - classification_loss: 0.2987
 329/1000 [========>.....................] - ETA: 3:11 - loss: 1.6668 - regression_loss: 1.3678 - classification_loss: 0.2991
 330/1000 [========>.....................] - ETA: 3:11 - loss: 1.6674 - regression_loss: 1.3679 - classification_loss: 0.2995
 331/1000 [========>.....................] - ETA: 3:11 - loss: 1.6660 - regression_loss: 1.3669 - classification_loss: 0.2991
 332/1000 [========>.....................] - ETA: 3:11 - loss: 1.6662 - regression_loss: 1.3669 - classification_loss: 0.2993
 333/1000 [========>.....................] - ETA: 3:10 - loss: 1.6659 - regression_loss: 1.3667 - classification_loss: 0.2992
 334/1000 [=========>....................] - ETA: 3:10 - loss: 1.6658 - regression_loss: 1.3663 - classification_loss: 0.2995
 335/1000 [=========>....................] - ETA: 3:10 - loss: 1.6689 - regression_loss: 1.3684 - classification_loss: 0.3004
 336/1000 [=========>....................] - ETA: 3:09 - loss: 1.6682 - regression_loss: 1.3665 - classification_loss: 0.3017
 337/1000 [=========>....................] - ETA: 3:09 - loss: 1.6674 - regression_loss: 1.3659 - classification_loss: 0.3015
 338/1000 [=========>....................] - ETA: 3:09 - loss: 1.6653 - regression_loss: 1.3642 - classification_loss: 0.3011
 339/1000 [=========>....................] - ETA: 3:09 - loss: 1.6648 - regression_loss: 1.3640 - classification_loss: 0.3008
 340/1000 [=========>....................] - ETA: 3:08 - loss: 1.6656 - regression_loss: 1.3649 - classification_loss: 0.3007
 341/1000 [=========>....................] - ETA: 3:08 - loss: 1.6636 - regression_loss: 1.3634 - classification_loss: 0.3002
 342/1000 [=========>....................] - ETA: 3:08 - loss: 1.6614 - regression_loss: 1.3615 - classification_loss: 0.2999
 343/1000 [=========>....................] - ETA: 3:07 - loss: 1.6593 - regression_loss: 1.3599 - classification_loss: 0.2994
 344/1000 [=========>....................] - ETA: 3:07 - loss: 1.6586 - regression_loss: 1.3594 - classification_loss: 0.2992
 345/1000 [=========>....................] - ETA: 3:07 - loss: 1.6591 - regression_loss: 1.3596 - classification_loss: 0.2995
 346/1000 [=========>....................] - ETA: 3:07 - loss: 1.6591 - regression_loss: 1.3596 - classification_loss: 0.2995
 347/1000 [=========>....................] - ETA: 3:06 - loss: 1.6576 - regression_loss: 1.3581 - classification_loss: 0.2995
 348/1000 [=========>....................] - ETA: 3:06 - loss: 1.6583 - regression_loss: 1.3591 - classification_loss: 0.2992
 349/1000 [=========>....................] - ETA: 3:06 - loss: 1.6572 - regression_loss: 1.3582 - classification_loss: 0.2990
 350/1000 [=========>....................] - ETA: 3:05 - loss: 1.6575 - regression_loss: 1.3588 - classification_loss: 0.2986
 351/1000 [=========>....................] - ETA: 3:05 - loss: 1.6562 - regression_loss: 1.3579 - classification_loss: 0.2983
 352/1000 [=========>....................] - ETA: 3:05 - loss: 1.6553 - regression_loss: 1.3573 - classification_loss: 0.2980
 353/1000 [=========>....................] - ETA: 3:05 - loss: 1.6534 - regression_loss: 1.3559 - classification_loss: 0.2975
 354/1000 [=========>....................] - ETA: 3:04 - loss: 1.6516 - regression_loss: 1.3541 - classification_loss: 0.2975
 355/1000 [=========>....................] - ETA: 3:04 - loss: 1.6527 - regression_loss: 1.3550 - classification_loss: 0.2977
 356/1000 [=========>....................] - ETA: 3:04 - loss: 1.6512 - regression_loss: 1.3537 - classification_loss: 0.2975
 357/1000 [=========>....................] - ETA: 3:03 - loss: 1.6512 - regression_loss: 1.3539 - classification_loss: 0.2973
 358/1000 [=========>....................] - ETA: 3:03 - loss: 1.6514 - regression_loss: 1.3540 - classification_loss: 0.2974
 359/1000 [=========>....................] - ETA: 3:03 - loss: 1.6488 - regression_loss: 1.3518 - classification_loss: 0.2971
 360/1000 [=========>....................] - ETA: 3:03 - loss: 1.6488 - regression_loss: 1.3516 - classification_loss: 0.2973
 361/1000 [=========>....................] - ETA: 3:02 - loss: 1.6476 - regression_loss: 1.3508 - classification_loss: 0.2968
 362/1000 [=========>....................] - ETA: 3:02 - loss: 1.6462 - regression_loss: 1.3498 - classification_loss: 0.2964
 363/1000 [=========>....................] - ETA: 3:02 - loss: 1.6456 - regression_loss: 1.3495 - classification_loss: 0.2961
 364/1000 [=========>....................] - ETA: 3:01 - loss: 1.6434 - regression_loss: 1.3477 - classification_loss: 0.2956
 365/1000 [=========>....................] - ETA: 3:01 - loss: 1.6429 - regression_loss: 1.3476 - classification_loss: 0.2954
 366/1000 [=========>....................] - ETA: 3:01 - loss: 1.6413 - regression_loss: 1.3461 - classification_loss: 0.2952
 367/1000 [==========>...................] - ETA: 3:01 - loss: 1.6404 - regression_loss: 1.3453 - classification_loss: 0.2951
 368/1000 [==========>...................] - ETA: 3:00 - loss: 1.6419 - regression_loss: 1.3470 - classification_loss: 0.2950
 369/1000 [==========>...................] - ETA: 3:00 - loss: 1.6408 - regression_loss: 1.3461 - classification_loss: 0.2946
 370/1000 [==========>...................] - ETA: 3:00 - loss: 1.6438 - regression_loss: 1.3481 - classification_loss: 0.2957
 371/1000 [==========>...................] - ETA: 2:59 - loss: 1.6422 - regression_loss: 1.3469 - classification_loss: 0.2953
 372/1000 [==========>...................] - ETA: 2:59 - loss: 1.6424 - regression_loss: 1.3470 - classification_loss: 0.2954
 373/1000 [==========>...................] - ETA: 2:59 - loss: 1.6430 - regression_loss: 1.3477 - classification_loss: 0.2953
 374/1000 [==========>...................] - ETA: 2:59 - loss: 1.6455 - regression_loss: 1.3497 - classification_loss: 0.2958
 375/1000 [==========>...................] - ETA: 2:58 - loss: 1.6467 - regression_loss: 1.3509 - classification_loss: 0.2957
 376/1000 [==========>...................] - ETA: 2:58 - loss: 1.6489 - regression_loss: 1.3525 - classification_loss: 0.2963
 377/1000 [==========>...................] - ETA: 2:58 - loss: 1.6461 - regression_loss: 1.3502 - classification_loss: 0.2959
 378/1000 [==========>...................] - ETA: 2:57 - loss: 1.6477 - regression_loss: 1.3521 - classification_loss: 0.2956
 379/1000 [==========>...................] - ETA: 2:57 - loss: 1.6471 - regression_loss: 1.3518 - classification_loss: 0.2952
 380/1000 [==========>...................] - ETA: 2:57 - loss: 1.6484 - regression_loss: 1.3531 - classification_loss: 0.2953
 381/1000 [==========>...................] - ETA: 2:57 - loss: 1.6485 - regression_loss: 1.3532 - classification_loss: 0.2952
 382/1000 [==========>...................] - ETA: 2:56 - loss: 1.6489 - regression_loss: 1.3536 - classification_loss: 0.2953
 383/1000 [==========>...................] - ETA: 2:56 - loss: 1.6513 - regression_loss: 1.3554 - classification_loss: 0.2959
 384/1000 [==========>...................] - ETA: 2:56 - loss: 1.6523 - regression_loss: 1.3562 - classification_loss: 0.2960
 385/1000 [==========>...................] - ETA: 2:55 - loss: 1.6553 - regression_loss: 1.3593 - classification_loss: 0.2960
 386/1000 [==========>...................] - ETA: 2:55 - loss: 1.6530 - regression_loss: 1.3574 - classification_loss: 0.2956
 387/1000 [==========>...................] - ETA: 2:55 - loss: 1.6506 - regression_loss: 1.3555 - classification_loss: 0.2951
 388/1000 [==========>...................] - ETA: 2:55 - loss: 1.6499 - regression_loss: 1.3551 - classification_loss: 0.2948
 389/1000 [==========>...................] - ETA: 2:54 - loss: 1.6504 - regression_loss: 1.3556 - classification_loss: 0.2948
 390/1000 [==========>...................] - ETA: 2:54 - loss: 1.6498 - regression_loss: 1.3549 - classification_loss: 0.2949
 391/1000 [==========>...................] - ETA: 2:54 - loss: 1.6479 - regression_loss: 1.3535 - classification_loss: 0.2945
 392/1000 [==========>...................] - ETA: 2:53 - loss: 1.6471 - regression_loss: 1.3527 - classification_loss: 0.2944
 393/1000 [==========>...................] - ETA: 2:53 - loss: 1.6498 - regression_loss: 1.3548 - classification_loss: 0.2950
 394/1000 [==========>...................] - ETA: 2:53 - loss: 1.6476 - regression_loss: 1.3531 - classification_loss: 0.2946
 395/1000 [==========>...................] - ETA: 2:53 - loss: 1.6474 - regression_loss: 1.3530 - classification_loss: 0.2944
 396/1000 [==========>...................] - ETA: 2:52 - loss: 1.6467 - regression_loss: 1.3520 - classification_loss: 0.2946
 397/1000 [==========>...................] - ETA: 2:52 - loss: 1.6468 - regression_loss: 1.3521 - classification_loss: 0.2947
 398/1000 [==========>...................] - ETA: 2:52 - loss: 1.6468 - regression_loss: 1.3522 - classification_loss: 0.2946
 399/1000 [==========>...................] - ETA: 2:51 - loss: 1.6448 - regression_loss: 1.3506 - classification_loss: 0.2942
 400/1000 [===========>..................] - ETA: 2:51 - loss: 1.6443 - regression_loss: 1.3504 - classification_loss: 0.2939
 401/1000 [===========>..................] - ETA: 2:51 - loss: 1.6437 - regression_loss: 1.3498 - classification_loss: 0.2939
 402/1000 [===========>..................] - ETA: 2:51 - loss: 1.6434 - regression_loss: 1.3497 - classification_loss: 0.2938
 403/1000 [===========>..................] - ETA: 2:50 - loss: 1.6430 - regression_loss: 1.3495 - classification_loss: 0.2935
 404/1000 [===========>..................] - ETA: 2:50 - loss: 1.6422 - regression_loss: 1.3491 - classification_loss: 0.2931
 405/1000 [===========>..................] - ETA: 2:50 - loss: 1.6419 - regression_loss: 1.3489 - classification_loss: 0.2929
 406/1000 [===========>..................] - ETA: 2:49 - loss: 1.6395 - regression_loss: 1.3470 - classification_loss: 0.2925
 407/1000 [===========>..................] - ETA: 2:49 - loss: 1.6382 - regression_loss: 1.3461 - classification_loss: 0.2922
 408/1000 [===========>..................] - ETA: 2:49 - loss: 1.6390 - regression_loss: 1.3468 - classification_loss: 0.2922
 409/1000 [===========>..................] - ETA: 2:49 - loss: 1.6382 - regression_loss: 1.3463 - classification_loss: 0.2919
 410/1000 [===========>..................] - ETA: 2:48 - loss: 1.6406 - regression_loss: 1.3481 - classification_loss: 0.2924
 411/1000 [===========>..................] - ETA: 2:48 - loss: 1.6410 - regression_loss: 1.3488 - classification_loss: 0.2921
 412/1000 [===========>..................] - ETA: 2:48 - loss: 1.6409 - regression_loss: 1.3491 - classification_loss: 0.2917
 413/1000 [===========>..................] - ETA: 2:47 - loss: 1.6440 - regression_loss: 1.3518 - classification_loss: 0.2922
 414/1000 [===========>..................] - ETA: 2:47 - loss: 1.6436 - regression_loss: 1.3515 - classification_loss: 0.2921
 415/1000 [===========>..................] - ETA: 2:47 - loss: 1.6426 - regression_loss: 1.3505 - classification_loss: 0.2921
 416/1000 [===========>..................] - ETA: 2:46 - loss: 1.6410 - regression_loss: 1.3492 - classification_loss: 0.2918
 417/1000 [===========>..................] - ETA: 2:46 - loss: 1.6465 - regression_loss: 1.3538 - classification_loss: 0.2928
 418/1000 [===========>..................] - ETA: 2:46 - loss: 1.6456 - regression_loss: 1.3532 - classification_loss: 0.2924
 419/1000 [===========>..................] - ETA: 2:46 - loss: 1.6476 - regression_loss: 1.3552 - classification_loss: 0.2925
 420/1000 [===========>..................] - ETA: 2:45 - loss: 1.6509 - regression_loss: 1.3584 - classification_loss: 0.2925
 421/1000 [===========>..................] - ETA: 2:45 - loss: 1.6504 - regression_loss: 1.3580 - classification_loss: 0.2924
 422/1000 [===========>..................] - ETA: 2:45 - loss: 1.6495 - regression_loss: 1.3574 - classification_loss: 0.2921
 423/1000 [===========>..................] - ETA: 2:45 - loss: 1.6519 - regression_loss: 1.3596 - classification_loss: 0.2923
 424/1000 [===========>..................] - ETA: 2:44 - loss: 1.6512 - regression_loss: 1.3591 - classification_loss: 0.2921
 425/1000 [===========>..................] - ETA: 2:44 - loss: 1.6529 - regression_loss: 1.3607 - classification_loss: 0.2921
 426/1000 [===========>..................] - ETA: 2:44 - loss: 1.6526 - regression_loss: 1.3607 - classification_loss: 0.2919
 427/1000 [===========>..................] - ETA: 2:43 - loss: 1.6525 - regression_loss: 1.3608 - classification_loss: 0.2917
 428/1000 [===========>..................] - ETA: 2:43 - loss: 1.6513 - regression_loss: 1.3599 - classification_loss: 0.2913
 429/1000 [===========>..................] - ETA: 2:43 - loss: 1.6501 - regression_loss: 1.3591 - classification_loss: 0.2910
 430/1000 [===========>..................] - ETA: 2:43 - loss: 1.6489 - regression_loss: 1.3574 - classification_loss: 0.2915
 431/1000 [===========>..................] - ETA: 2:42 - loss: 1.6496 - regression_loss: 1.3580 - classification_loss: 0.2917
 432/1000 [===========>..................] - ETA: 2:42 - loss: 1.6519 - regression_loss: 1.3598 - classification_loss: 0.2921
 433/1000 [===========>..................] - ETA: 2:42 - loss: 1.6525 - regression_loss: 1.3604 - classification_loss: 0.2921
 434/1000 [============>.................] - ETA: 2:41 - loss: 1.6538 - regression_loss: 1.3615 - classification_loss: 0.2923
 435/1000 [============>.................] - ETA: 2:41 - loss: 1.6542 - regression_loss: 1.3620 - classification_loss: 0.2923
 436/1000 [============>.................] - ETA: 2:41 - loss: 1.6517 - regression_loss: 1.3588 - classification_loss: 0.2929
 437/1000 [============>.................] - ETA: 2:41 - loss: 1.6510 - regression_loss: 1.3581 - classification_loss: 0.2929
 438/1000 [============>.................] - ETA: 2:40 - loss: 1.6521 - regression_loss: 1.3589 - classification_loss: 0.2932
 439/1000 [============>.................] - ETA: 2:40 - loss: 1.6517 - regression_loss: 1.3585 - classification_loss: 0.2932
 440/1000 [============>.................] - ETA: 2:40 - loss: 1.6510 - regression_loss: 1.3581 - classification_loss: 0.2929
 441/1000 [============>.................] - ETA: 2:39 - loss: 1.6501 - regression_loss: 1.3572 - classification_loss: 0.2929
 442/1000 [============>.................] - ETA: 2:39 - loss: 1.6508 - regression_loss: 1.3579 - classification_loss: 0.2929
 443/1000 [============>.................] - ETA: 2:39 - loss: 1.6520 - regression_loss: 1.3589 - classification_loss: 0.2932
 444/1000 [============>.................] - ETA: 2:39 - loss: 1.6524 - regression_loss: 1.3593 - classification_loss: 0.2931
 445/1000 [============>.................] - ETA: 2:38 - loss: 1.6533 - regression_loss: 1.3603 - classification_loss: 0.2930
 446/1000 [============>.................] - ETA: 2:38 - loss: 1.6539 - regression_loss: 1.3606 - classification_loss: 0.2933
 447/1000 [============>.................] - ETA: 2:38 - loss: 1.6548 - regression_loss: 1.3612 - classification_loss: 0.2936
 448/1000 [============>.................] - ETA: 2:37 - loss: 1.6545 - regression_loss: 1.3611 - classification_loss: 0.2934
 449/1000 [============>.................] - ETA: 2:37 - loss: 1.6531 - regression_loss: 1.3600 - classification_loss: 0.2931
 450/1000 [============>.................] - ETA: 2:37 - loss: 1.6531 - regression_loss: 1.3599 - classification_loss: 0.2933
 451/1000 [============>.................] - ETA: 2:37 - loss: 1.6536 - regression_loss: 1.3602 - classification_loss: 0.2934
 452/1000 [============>.................] - ETA: 2:36 - loss: 1.6537 - regression_loss: 1.3605 - classification_loss: 0.2932
 453/1000 [============>.................] - ETA: 2:36 - loss: 1.6529 - regression_loss: 1.3596 - classification_loss: 0.2933
 454/1000 [============>.................] - ETA: 2:36 - loss: 1.6508 - regression_loss: 1.3581 - classification_loss: 0.2928
 455/1000 [============>.................] - ETA: 2:35 - loss: 1.6499 - regression_loss: 1.3575 - classification_loss: 0.2925
 456/1000 [============>.................] - ETA: 2:35 - loss: 1.6482 - regression_loss: 1.3561 - classification_loss: 0.2921
 457/1000 [============>.................] - ETA: 2:35 - loss: 1.6491 - regression_loss: 1.3569 - classification_loss: 0.2922
 458/1000 [============>.................] - ETA: 2:35 - loss: 1.6521 - regression_loss: 1.3593 - classification_loss: 0.2929
 459/1000 [============>.................] - ETA: 2:34 - loss: 1.6506 - regression_loss: 1.3578 - classification_loss: 0.2928
 460/1000 [============>.................] - ETA: 2:34 - loss: 1.6500 - regression_loss: 1.3573 - classification_loss: 0.2927
 461/1000 [============>.................] - ETA: 2:34 - loss: 1.6493 - regression_loss: 1.3568 - classification_loss: 0.2926
 462/1000 [============>.................] - ETA: 2:33 - loss: 1.6473 - regression_loss: 1.3551 - classification_loss: 0.2922
 463/1000 [============>.................] - ETA: 2:33 - loss: 1.6455 - regression_loss: 1.3537 - classification_loss: 0.2918
 464/1000 [============>.................] - ETA: 2:33 - loss: 1.6465 - regression_loss: 1.3547 - classification_loss: 0.2918
 465/1000 [============>.................] - ETA: 2:33 - loss: 1.6458 - regression_loss: 1.3542 - classification_loss: 0.2916
 466/1000 [============>.................] - ETA: 2:32 - loss: 1.6461 - regression_loss: 1.3545 - classification_loss: 0.2916
 467/1000 [=============>................] - ETA: 2:32 - loss: 1.6464 - regression_loss: 1.3546 - classification_loss: 0.2918
 468/1000 [=============>................] - ETA: 2:32 - loss: 1.6450 - regression_loss: 1.3536 - classification_loss: 0.2914
 469/1000 [=============>................] - ETA: 2:31 - loss: 1.6458 - regression_loss: 1.3544 - classification_loss: 0.2914
 470/1000 [=============>................] - ETA: 2:31 - loss: 1.6466 - regression_loss: 1.3551 - classification_loss: 0.2915
 471/1000 [=============>................] - ETA: 2:31 - loss: 1.6463 - regression_loss: 1.3549 - classification_loss: 0.2914
 472/1000 [=============>................] - ETA: 2:31 - loss: 1.6458 - regression_loss: 1.3544 - classification_loss: 0.2913
 473/1000 [=============>................] - ETA: 2:30 - loss: 1.6447 - regression_loss: 1.3534 - classification_loss: 0.2913
 474/1000 [=============>................] - ETA: 2:30 - loss: 1.6450 - regression_loss: 1.3536 - classification_loss: 0.2914
 475/1000 [=============>................] - ETA: 2:30 - loss: 1.6454 - regression_loss: 1.3543 - classification_loss: 0.2911
 476/1000 [=============>................] - ETA: 2:29 - loss: 1.6446 - regression_loss: 1.3538 - classification_loss: 0.2908
 477/1000 [=============>................] - ETA: 2:29 - loss: 1.6456 - regression_loss: 1.3549 - classification_loss: 0.2907
 478/1000 [=============>................] - ETA: 2:29 - loss: 1.6446 - regression_loss: 1.3540 - classification_loss: 0.2906
 479/1000 [=============>................] - ETA: 2:29 - loss: 1.6433 - regression_loss: 1.3531 - classification_loss: 0.2902
 480/1000 [=============>................] - ETA: 2:28 - loss: 1.6430 - regression_loss: 1.3530 - classification_loss: 0.2901
 481/1000 [=============>................] - ETA: 2:28 - loss: 1.6427 - regression_loss: 1.3526 - classification_loss: 0.2901
 482/1000 [=============>................] - ETA: 2:28 - loss: 1.6431 - regression_loss: 1.3528 - classification_loss: 0.2903
 483/1000 [=============>................] - ETA: 2:27 - loss: 1.6417 - regression_loss: 1.3517 - classification_loss: 0.2900
 484/1000 [=============>................] - ETA: 2:27 - loss: 1.6400 - regression_loss: 1.3502 - classification_loss: 0.2898
 485/1000 [=============>................] - ETA: 2:27 - loss: 1.6406 - regression_loss: 1.3506 - classification_loss: 0.2900
 486/1000 [=============>................] - ETA: 2:27 - loss: 1.6405 - regression_loss: 1.3507 - classification_loss: 0.2898
 487/1000 [=============>................] - ETA: 2:26 - loss: 1.6388 - regression_loss: 1.3495 - classification_loss: 0.2893
 488/1000 [=============>................] - ETA: 2:26 - loss: 1.6388 - regression_loss: 1.3495 - classification_loss: 0.2893
 489/1000 [=============>................] - ETA: 2:26 - loss: 1.6377 - regression_loss: 1.3487 - classification_loss: 0.2890
 490/1000 [=============>................] - ETA: 2:25 - loss: 1.6384 - regression_loss: 1.3490 - classification_loss: 0.2894
 491/1000 [=============>................] - ETA: 2:25 - loss: 1.6379 - regression_loss: 1.3487 - classification_loss: 0.2892
 492/1000 [=============>................] - ETA: 2:25 - loss: 1.6362 - regression_loss: 1.3472 - classification_loss: 0.2890
 493/1000 [=============>................] - ETA: 2:25 - loss: 1.6354 - regression_loss: 1.3466 - classification_loss: 0.2888
 494/1000 [=============>................] - ETA: 2:24 - loss: 1.6361 - regression_loss: 1.3469 - classification_loss: 0.2891
 495/1000 [=============>................] - ETA: 2:24 - loss: 1.6372 - regression_loss: 1.3479 - classification_loss: 0.2893
 496/1000 [=============>................] - ETA: 2:24 - loss: 1.6354 - regression_loss: 1.3452 - classification_loss: 0.2902
 497/1000 [=============>................] - ETA: 2:23 - loss: 1.6363 - regression_loss: 1.3462 - classification_loss: 0.2901
 498/1000 [=============>................] - ETA: 2:23 - loss: 1.6367 - regression_loss: 1.3467 - classification_loss: 0.2900
 499/1000 [=============>................] - ETA: 2:23 - loss: 1.6360 - regression_loss: 1.3459 - classification_loss: 0.2900
 500/1000 [==============>...............] - ETA: 2:23 - loss: 1.6369 - regression_loss: 1.3467 - classification_loss: 0.2902
 501/1000 [==============>...............] - ETA: 2:22 - loss: 1.6356 - regression_loss: 1.3456 - classification_loss: 0.2900
 502/1000 [==============>...............] - ETA: 2:22 - loss: 1.6357 - regression_loss: 1.3456 - classification_loss: 0.2901
 503/1000 [==============>...............] - ETA: 2:22 - loss: 1.6351 - regression_loss: 1.3451 - classification_loss: 0.2900
 504/1000 [==============>...............] - ETA: 2:21 - loss: 1.6340 - regression_loss: 1.3443 - classification_loss: 0.2897
 505/1000 [==============>...............] - ETA: 2:21 - loss: 1.6346 - regression_loss: 1.3449 - classification_loss: 0.2897
 506/1000 [==============>...............] - ETA: 2:21 - loss: 1.6354 - regression_loss: 1.3456 - classification_loss: 0.2898
 507/1000 [==============>...............] - ETA: 2:21 - loss: 1.6362 - regression_loss: 1.3462 - classification_loss: 0.2900
 508/1000 [==============>...............] - ETA: 2:20 - loss: 1.6347 - regression_loss: 1.3451 - classification_loss: 0.2896
 509/1000 [==============>...............] - ETA: 2:20 - loss: 1.6331 - regression_loss: 1.3437 - classification_loss: 0.2894
 510/1000 [==============>...............] - ETA: 2:20 - loss: 1.6321 - regression_loss: 1.3428 - classification_loss: 0.2893
 511/1000 [==============>...............] - ETA: 2:19 - loss: 1.6350 - regression_loss: 1.3446 - classification_loss: 0.2904
 512/1000 [==============>...............] - ETA: 2:19 - loss: 1.6332 - regression_loss: 1.3430 - classification_loss: 0.2902
 513/1000 [==============>...............] - ETA: 2:19 - loss: 1.6321 - regression_loss: 1.3421 - classification_loss: 0.2900
 514/1000 [==============>...............] - ETA: 2:19 - loss: 1.6321 - regression_loss: 1.3420 - classification_loss: 0.2900
 515/1000 [==============>...............] - ETA: 2:18 - loss: 1.6312 - regression_loss: 1.3415 - classification_loss: 0.2897
 516/1000 [==============>...............] - ETA: 2:18 - loss: 1.6309 - regression_loss: 1.3410 - classification_loss: 0.2899
 517/1000 [==============>...............] - ETA: 2:18 - loss: 1.6319 - regression_loss: 1.3421 - classification_loss: 0.2898
 518/1000 [==============>...............] - ETA: 2:17 - loss: 1.6318 - regression_loss: 1.3419 - classification_loss: 0.2899
 519/1000 [==============>...............] - ETA: 2:17 - loss: 1.6318 - regression_loss: 1.3420 - classification_loss: 0.2898
 520/1000 [==============>...............] - ETA: 2:17 - loss: 1.6316 - regression_loss: 1.3420 - classification_loss: 0.2896
 521/1000 [==============>...............] - ETA: 2:17 - loss: 1.6311 - regression_loss: 1.3415 - classification_loss: 0.2896
 522/1000 [==============>...............] - ETA: 2:16 - loss: 1.6302 - regression_loss: 1.3410 - classification_loss: 0.2891
 523/1000 [==============>...............] - ETA: 2:16 - loss: 1.6301 - regression_loss: 1.3410 - classification_loss: 0.2891
 524/1000 [==============>...............] - ETA: 2:16 - loss: 1.6314 - regression_loss: 1.3421 - classification_loss: 0.2893
 525/1000 [==============>...............] - ETA: 2:15 - loss: 1.6303 - regression_loss: 1.3412 - classification_loss: 0.2890
 526/1000 [==============>...............] - ETA: 2:15 - loss: 1.6333 - regression_loss: 1.3437 - classification_loss: 0.2896
 527/1000 [==============>...............] - ETA: 2:15 - loss: 1.6334 - regression_loss: 1.3438 - classification_loss: 0.2896
 528/1000 [==============>...............] - ETA: 2:15 - loss: 1.6330 - regression_loss: 1.3436 - classification_loss: 0.2893
 529/1000 [==============>...............] - ETA: 2:14 - loss: 1.6325 - regression_loss: 1.3433 - classification_loss: 0.2892
 530/1000 [==============>...............] - ETA: 2:14 - loss: 1.6328 - regression_loss: 1.3438 - classification_loss: 0.2891
 531/1000 [==============>...............] - ETA: 2:14 - loss: 1.6330 - regression_loss: 1.3440 - classification_loss: 0.2890
 532/1000 [==============>...............] - ETA: 2:13 - loss: 1.6319 - regression_loss: 1.3429 - classification_loss: 0.2889
 533/1000 [==============>...............] - ETA: 2:13 - loss: 1.6324 - regression_loss: 1.3435 - classification_loss: 0.2889
 534/1000 [===============>..............] - ETA: 2:13 - loss: 1.6327 - regression_loss: 1.3438 - classification_loss: 0.2888
 535/1000 [===============>..............] - ETA: 2:13 - loss: 1.6314 - regression_loss: 1.3429 - classification_loss: 0.2886
 536/1000 [===============>..............] - ETA: 2:12 - loss: 1.6301 - regression_loss: 1.3418 - classification_loss: 0.2883
 537/1000 [===============>..............] - ETA: 2:12 - loss: 1.6302 - regression_loss: 1.3419 - classification_loss: 0.2882
 538/1000 [===============>..............] - ETA: 2:12 - loss: 1.6297 - regression_loss: 1.3417 - classification_loss: 0.2880
 539/1000 [===============>..............] - ETA: 2:11 - loss: 1.6288 - regression_loss: 1.3410 - classification_loss: 0.2878
 540/1000 [===============>..............] - ETA: 2:11 - loss: 1.6277 - regression_loss: 1.3400 - classification_loss: 0.2876
 541/1000 [===============>..............] - ETA: 2:11 - loss: 1.6293 - regression_loss: 1.3414 - classification_loss: 0.2879
 542/1000 [===============>..............] - ETA: 2:11 - loss: 1.6310 - regression_loss: 1.3420 - classification_loss: 0.2889
 543/1000 [===============>..............] - ETA: 2:10 - loss: 1.6314 - regression_loss: 1.3424 - classification_loss: 0.2890
 544/1000 [===============>..............] - ETA: 2:10 - loss: 1.6317 - regression_loss: 1.3428 - classification_loss: 0.2890
 545/1000 [===============>..............] - ETA: 2:10 - loss: 1.6304 - regression_loss: 1.3417 - classification_loss: 0.2887
 546/1000 [===============>..............] - ETA: 2:09 - loss: 1.6298 - regression_loss: 1.3410 - classification_loss: 0.2887
 547/1000 [===============>..............] - ETA: 2:09 - loss: 1.6308 - regression_loss: 1.3421 - classification_loss: 0.2886
 548/1000 [===============>..............] - ETA: 2:09 - loss: 1.6302 - regression_loss: 1.3415 - classification_loss: 0.2887
 549/1000 [===============>..............] - ETA: 2:09 - loss: 1.6314 - regression_loss: 1.3423 - classification_loss: 0.2891
 550/1000 [===============>..............] - ETA: 2:08 - loss: 1.6310 - regression_loss: 1.3421 - classification_loss: 0.2890
 551/1000 [===============>..............] - ETA: 2:08 - loss: 1.6311 - regression_loss: 1.3419 - classification_loss: 0.2892
 552/1000 [===============>..............] - ETA: 2:08 - loss: 1.6297 - regression_loss: 1.3408 - classification_loss: 0.2889
 553/1000 [===============>..............] - ETA: 2:07 - loss: 1.6294 - regression_loss: 1.3406 - classification_loss: 0.2888
 554/1000 [===============>..............] - ETA: 2:07 - loss: 1.6317 - regression_loss: 1.3421 - classification_loss: 0.2897
 555/1000 [===============>..............] - ETA: 2:07 - loss: 1.6317 - regression_loss: 1.3419 - classification_loss: 0.2898
 556/1000 [===============>..............] - ETA: 2:07 - loss: 1.6333 - regression_loss: 1.3431 - classification_loss: 0.2902
 557/1000 [===============>..............] - ETA: 2:06 - loss: 1.6325 - regression_loss: 1.3425 - classification_loss: 0.2901
 558/1000 [===============>..............] - ETA: 2:06 - loss: 1.6317 - regression_loss: 1.3419 - classification_loss: 0.2898
 559/1000 [===============>..............] - ETA: 2:06 - loss: 1.6305 - regression_loss: 1.3408 - classification_loss: 0.2897
 560/1000 [===============>..............] - ETA: 2:05 - loss: 1.6308 - regression_loss: 1.3412 - classification_loss: 0.2896
 561/1000 [===============>..............] - ETA: 2:05 - loss: 1.6323 - regression_loss: 1.3425 - classification_loss: 0.2898
 562/1000 [===============>..............] - ETA: 2:05 - loss: 1.6324 - regression_loss: 1.3426 - classification_loss: 0.2897
 563/1000 [===============>..............] - ETA: 2:05 - loss: 1.6340 - regression_loss: 1.3444 - classification_loss: 0.2896
 564/1000 [===============>..............] - ETA: 2:04 - loss: 1.6351 - regression_loss: 1.3451 - classification_loss: 0.2900
 565/1000 [===============>..............] - ETA: 2:04 - loss: 1.6353 - regression_loss: 1.3452 - classification_loss: 0.2900
 566/1000 [===============>..............] - ETA: 2:04 - loss: 1.6346 - regression_loss: 1.3448 - classification_loss: 0.2899
 567/1000 [================>.............] - ETA: 2:04 - loss: 1.6343 - regression_loss: 1.3444 - classification_loss: 0.2899
 568/1000 [================>.............] - ETA: 2:03 - loss: 1.6345 - regression_loss: 1.3447 - classification_loss: 0.2898
 569/1000 [================>.............] - ETA: 2:03 - loss: 1.6332 - regression_loss: 1.3437 - classification_loss: 0.2895
 570/1000 [================>.............] - ETA: 2:03 - loss: 1.6321 - regression_loss: 1.3428 - classification_loss: 0.2894
 571/1000 [================>.............] - ETA: 2:02 - loss: 1.6350 - regression_loss: 1.3452 - classification_loss: 0.2898
 572/1000 [================>.............] - ETA: 2:02 - loss: 1.6354 - regression_loss: 1.3457 - classification_loss: 0.2897
 573/1000 [================>.............] - ETA: 2:02 - loss: 1.6349 - regression_loss: 1.3454 - classification_loss: 0.2895
 574/1000 [================>.............] - ETA: 2:01 - loss: 1.6338 - regression_loss: 1.3444 - classification_loss: 0.2893
 575/1000 [================>.............] - ETA: 2:01 - loss: 1.6326 - regression_loss: 1.3434 - classification_loss: 0.2891
 576/1000 [================>.............] - ETA: 2:01 - loss: 1.6341 - regression_loss: 1.3443 - classification_loss: 0.2898
 577/1000 [================>.............] - ETA: 2:01 - loss: 1.6335 - regression_loss: 1.3440 - classification_loss: 0.2896
 578/1000 [================>.............] - ETA: 2:00 - loss: 1.6344 - regression_loss: 1.3447 - classification_loss: 0.2896
 579/1000 [================>.............] - ETA: 2:00 - loss: 1.6339 - regression_loss: 1.3445 - classification_loss: 0.2894
 580/1000 [================>.............] - ETA: 2:00 - loss: 1.6333 - regression_loss: 1.3441 - classification_loss: 0.2893
 581/1000 [================>.............] - ETA: 1:59 - loss: 1.6350 - regression_loss: 1.3455 - classification_loss: 0.2894
 582/1000 [================>.............] - ETA: 1:59 - loss: 1.6368 - regression_loss: 1.3466 - classification_loss: 0.2902
 583/1000 [================>.............] - ETA: 1:59 - loss: 1.6371 - regression_loss: 1.3466 - classification_loss: 0.2905
 584/1000 [================>.............] - ETA: 1:59 - loss: 1.6359 - regression_loss: 1.3456 - classification_loss: 0.2903
 585/1000 [================>.............] - ETA: 1:58 - loss: 1.6346 - regression_loss: 1.3446 - classification_loss: 0.2901
 586/1000 [================>.............] - ETA: 1:58 - loss: 1.6352 - regression_loss: 1.3451 - classification_loss: 0.2901
 587/1000 [================>.............] - ETA: 1:58 - loss: 1.6345 - regression_loss: 1.3447 - classification_loss: 0.2898
 588/1000 [================>.............] - ETA: 1:57 - loss: 1.6343 - regression_loss: 1.3447 - classification_loss: 0.2897
 589/1000 [================>.............] - ETA: 1:57 - loss: 1.6342 - regression_loss: 1.3445 - classification_loss: 0.2897
 590/1000 [================>.............] - ETA: 1:57 - loss: 1.6344 - regression_loss: 1.3449 - classification_loss: 0.2895
 591/1000 [================>.............] - ETA: 1:57 - loss: 1.6351 - regression_loss: 1.3455 - classification_loss: 0.2896
 592/1000 [================>.............] - ETA: 1:56 - loss: 1.6340 - regression_loss: 1.3446 - classification_loss: 0.2893
 593/1000 [================>.............] - ETA: 1:56 - loss: 1.6341 - regression_loss: 1.3446 - classification_loss: 0.2894
 594/1000 [================>.............] - ETA: 1:56 - loss: 1.6359 - regression_loss: 1.3464 - classification_loss: 0.2895
 595/1000 [================>.............] - ETA: 1:55 - loss: 1.6354 - regression_loss: 1.3460 - classification_loss: 0.2893
 596/1000 [================>.............] - ETA: 1:55 - loss: 1.6347 - regression_loss: 1.3455 - classification_loss: 0.2892
 597/1000 [================>.............] - ETA: 1:55 - loss: 1.6346 - regression_loss: 1.3455 - classification_loss: 0.2891
 598/1000 [================>.............] - ETA: 1:55 - loss: 1.6364 - regression_loss: 1.3467 - classification_loss: 0.2897
 599/1000 [================>.............] - ETA: 1:54 - loss: 1.6357 - regression_loss: 1.3462 - classification_loss: 0.2895
 600/1000 [=================>............] - ETA: 1:54 - loss: 1.6383 - regression_loss: 1.3478 - classification_loss: 0.2905
 601/1000 [=================>............] - ETA: 1:54 - loss: 1.6382 - regression_loss: 1.3479 - classification_loss: 0.2903
 602/1000 [=================>............] - ETA: 1:53 - loss: 1.6376 - regression_loss: 1.3474 - classification_loss: 0.2902
 603/1000 [=================>............] - ETA: 1:53 - loss: 1.6370 - regression_loss: 1.3470 - classification_loss: 0.2900
 604/1000 [=================>............] - ETA: 1:53 - loss: 1.6376 - regression_loss: 1.3473 - classification_loss: 0.2903
 605/1000 [=================>............] - ETA: 1:53 - loss: 1.6389 - regression_loss: 1.3485 - classification_loss: 0.2904
 606/1000 [=================>............] - ETA: 1:52 - loss: 1.6388 - regression_loss: 1.3484 - classification_loss: 0.2904
 607/1000 [=================>............] - ETA: 1:52 - loss: 1.6393 - regression_loss: 1.3488 - classification_loss: 0.2905
 608/1000 [=================>............] - ETA: 1:52 - loss: 1.6396 - regression_loss: 1.3489 - classification_loss: 0.2906
 609/1000 [=================>............] - ETA: 1:51 - loss: 1.6386 - regression_loss: 1.3482 - classification_loss: 0.2904
 610/1000 [=================>............] - ETA: 1:51 - loss: 1.6407 - regression_loss: 1.3498 - classification_loss: 0.2909
 611/1000 [=================>............] - ETA: 1:51 - loss: 1.6406 - regression_loss: 1.3496 - classification_loss: 0.2910
 612/1000 [=================>............] - ETA: 1:51 - loss: 1.6405 - regression_loss: 1.3496 - classification_loss: 0.2909
 613/1000 [=================>............] - ETA: 1:50 - loss: 1.6393 - regression_loss: 1.3486 - classification_loss: 0.2908
 614/1000 [=================>............] - ETA: 1:50 - loss: 1.6406 - regression_loss: 1.3495 - classification_loss: 0.2911
 615/1000 [=================>............] - ETA: 1:50 - loss: 1.6401 - regression_loss: 1.3492 - classification_loss: 0.2909
 616/1000 [=================>............] - ETA: 1:49 - loss: 1.6398 - regression_loss: 1.3491 - classification_loss: 0.2907
 617/1000 [=================>............] - ETA: 1:49 - loss: 1.6404 - regression_loss: 1.3497 - classification_loss: 0.2907
 618/1000 [=================>............] - ETA: 1:49 - loss: 1.6404 - regression_loss: 1.3498 - classification_loss: 0.2906
 619/1000 [=================>............] - ETA: 1:49 - loss: 1.6394 - regression_loss: 1.3490 - classification_loss: 0.2904
 620/1000 [=================>............] - ETA: 1:48 - loss: 1.6402 - regression_loss: 1.3496 - classification_loss: 0.2905
 621/1000 [=================>............] - ETA: 1:48 - loss: 1.6400 - regression_loss: 1.3496 - classification_loss: 0.2904
 622/1000 [=================>............] - ETA: 1:48 - loss: 1.6398 - regression_loss: 1.3496 - classification_loss: 0.2902
 623/1000 [=================>............] - ETA: 1:47 - loss: 1.6401 - regression_loss: 1.3500 - classification_loss: 0.2901
 624/1000 [=================>............] - ETA: 1:47 - loss: 1.6393 - regression_loss: 1.3495 - classification_loss: 0.2899
 625/1000 [=================>............] - ETA: 1:47 - loss: 1.6383 - regression_loss: 1.3484 - classification_loss: 0.2899
 626/1000 [=================>............] - ETA: 1:47 - loss: 1.6376 - regression_loss: 1.3478 - classification_loss: 0.2898
 627/1000 [=================>............] - ETA: 1:46 - loss: 1.6381 - regression_loss: 1.3483 - classification_loss: 0.2898
 628/1000 [=================>............] - ETA: 1:46 - loss: 1.6363 - regression_loss: 1.3467 - classification_loss: 0.2896
 629/1000 [=================>............] - ETA: 1:46 - loss: 1.6352 - regression_loss: 1.3459 - classification_loss: 0.2893
 630/1000 [=================>............] - ETA: 1:45 - loss: 1.6352 - regression_loss: 1.3458 - classification_loss: 0.2894
 631/1000 [=================>............] - ETA: 1:45 - loss: 1.6347 - regression_loss: 1.3454 - classification_loss: 0.2892
 632/1000 [=================>............] - ETA: 1:45 - loss: 1.6346 - regression_loss: 1.3454 - classification_loss: 0.2892
 633/1000 [=================>............] - ETA: 1:45 - loss: 1.6339 - regression_loss: 1.3449 - classification_loss: 0.2890
 634/1000 [==================>...........] - ETA: 1:44 - loss: 1.6331 - regression_loss: 1.3443 - classification_loss: 0.2888
 635/1000 [==================>...........] - ETA: 1:44 - loss: 1.6317 - regression_loss: 1.3432 - classification_loss: 0.2885
 636/1000 [==================>...........] - ETA: 1:44 - loss: 1.6310 - regression_loss: 1.3425 - classification_loss: 0.2885
 637/1000 [==================>...........] - ETA: 1:43 - loss: 1.6302 - regression_loss: 1.3419 - classification_loss: 0.2883
 638/1000 [==================>...........] - ETA: 1:43 - loss: 1.6305 - regression_loss: 1.3420 - classification_loss: 0.2884
 639/1000 [==================>...........] - ETA: 1:43 - loss: 1.6295 - regression_loss: 1.3412 - classification_loss: 0.2882
 640/1000 [==================>...........] - ETA: 1:43 - loss: 1.6299 - regression_loss: 1.3414 - classification_loss: 0.2885
 641/1000 [==================>...........] - ETA: 1:42 - loss: 1.6288 - regression_loss: 1.3406 - classification_loss: 0.2882
 642/1000 [==================>...........] - ETA: 1:42 - loss: 1.6293 - regression_loss: 1.3412 - classification_loss: 0.2881
 643/1000 [==================>...........] - ETA: 1:42 - loss: 1.6296 - regression_loss: 1.3415 - classification_loss: 0.2880
 644/1000 [==================>...........] - ETA: 1:41 - loss: 1.6288 - regression_loss: 1.3408 - classification_loss: 0.2880
 645/1000 [==================>...........] - ETA: 1:41 - loss: 1.6277 - regression_loss: 1.3399 - classification_loss: 0.2878
 646/1000 [==================>...........] - ETA: 1:41 - loss: 1.6261 - regression_loss: 1.3386 - classification_loss: 0.2875
 647/1000 [==================>...........] - ETA: 1:41 - loss: 1.6247 - regression_loss: 1.3374 - classification_loss: 0.2873
 648/1000 [==================>...........] - ETA: 1:40 - loss: 1.6242 - regression_loss: 1.3368 - classification_loss: 0.2873
 649/1000 [==================>...........] - ETA: 1:40 - loss: 1.6234 - regression_loss: 1.3364 - classification_loss: 0.2870
 650/1000 [==================>...........] - ETA: 1:40 - loss: 1.6235 - regression_loss: 1.3365 - classification_loss: 0.2870
 651/1000 [==================>...........] - ETA: 1:39 - loss: 1.6245 - regression_loss: 1.3373 - classification_loss: 0.2872
 652/1000 [==================>...........] - ETA: 1:39 - loss: 1.6239 - regression_loss: 1.3369 - classification_loss: 0.2870
 653/1000 [==================>...........] - ETA: 1:39 - loss: 1.6233 - regression_loss: 1.3364 - classification_loss: 0.2868
 654/1000 [==================>...........] - ETA: 1:39 - loss: 1.6245 - regression_loss: 1.3373 - classification_loss: 0.2872
 655/1000 [==================>...........] - ETA: 1:38 - loss: 1.6234 - regression_loss: 1.3364 - classification_loss: 0.2870
 656/1000 [==================>...........] - ETA: 1:38 - loss: 1.6238 - regression_loss: 1.3367 - classification_loss: 0.2871
 657/1000 [==================>...........] - ETA: 1:38 - loss: 1.6236 - regression_loss: 1.3366 - classification_loss: 0.2870
 658/1000 [==================>...........] - ETA: 1:37 - loss: 1.6240 - regression_loss: 1.3370 - classification_loss: 0.2870
 659/1000 [==================>...........] - ETA: 1:37 - loss: 1.6236 - regression_loss: 1.3368 - classification_loss: 0.2868
 660/1000 [==================>...........] - ETA: 1:37 - loss: 1.6241 - regression_loss: 1.3374 - classification_loss: 0.2868
 661/1000 [==================>...........] - ETA: 1:37 - loss: 1.6236 - regression_loss: 1.3369 - classification_loss: 0.2867
 662/1000 [==================>...........] - ETA: 1:36 - loss: 1.6238 - regression_loss: 1.3369 - classification_loss: 0.2869
 663/1000 [==================>...........] - ETA: 1:36 - loss: 1.6239 - regression_loss: 1.3371 - classification_loss: 0.2868
 664/1000 [==================>...........] - ETA: 1:36 - loss: 1.6245 - regression_loss: 1.3376 - classification_loss: 0.2869
 665/1000 [==================>...........] - ETA: 1:35 - loss: 1.6249 - regression_loss: 1.3379 - classification_loss: 0.2870
 666/1000 [==================>...........] - ETA: 1:35 - loss: 1.6248 - regression_loss: 1.3380 - classification_loss: 0.2868
 667/1000 [===================>..........] - ETA: 1:35 - loss: 1.6242 - regression_loss: 1.3376 - classification_loss: 0.2866
 668/1000 [===================>..........] - ETA: 1:35 - loss: 1.6238 - regression_loss: 1.3371 - classification_loss: 0.2867
 669/1000 [===================>..........] - ETA: 1:34 - loss: 1.6257 - regression_loss: 1.3385 - classification_loss: 0.2873
 670/1000 [===================>..........] - ETA: 1:34 - loss: 1.6255 - regression_loss: 1.3385 - classification_loss: 0.2870
 671/1000 [===================>..........] - ETA: 1:34 - loss: 1.6255 - regression_loss: 1.3386 - classification_loss: 0.2870
 672/1000 [===================>..........] - ETA: 1:33 - loss: 1.6251 - regression_loss: 1.3383 - classification_loss: 0.2868
 673/1000 [===================>..........] - ETA: 1:33 - loss: 1.6254 - regression_loss: 1.3386 - classification_loss: 0.2868
 674/1000 [===================>..........] - ETA: 1:33 - loss: 1.6260 - regression_loss: 1.3392 - classification_loss: 0.2868
 675/1000 [===================>..........] - ETA: 1:33 - loss: 1.6278 - regression_loss: 1.3410 - classification_loss: 0.2868
 676/1000 [===================>..........] - ETA: 1:32 - loss: 1.6281 - regression_loss: 1.3414 - classification_loss: 0.2867
 677/1000 [===================>..........] - ETA: 1:32 - loss: 1.6286 - regression_loss: 1.3418 - classification_loss: 0.2868
 678/1000 [===================>..........] - ETA: 1:32 - loss: 1.6286 - regression_loss: 1.3419 - classification_loss: 0.2866
 679/1000 [===================>..........] - ETA: 1:31 - loss: 1.6280 - regression_loss: 1.3415 - classification_loss: 0.2864
 680/1000 [===================>..........] - ETA: 1:31 - loss: 1.6277 - regression_loss: 1.3414 - classification_loss: 0.2863
 681/1000 [===================>..........] - ETA: 1:31 - loss: 1.6282 - regression_loss: 1.3420 - classification_loss: 0.2862
 682/1000 [===================>..........] - ETA: 1:31 - loss: 1.6279 - regression_loss: 1.3418 - classification_loss: 0.2861
 683/1000 [===================>..........] - ETA: 1:30 - loss: 1.6279 - regression_loss: 1.3419 - classification_loss: 0.2860
 684/1000 [===================>..........] - ETA: 1:30 - loss: 1.6273 - regression_loss: 1.3415 - classification_loss: 0.2858
 685/1000 [===================>..........] - ETA: 1:30 - loss: 1.6260 - regression_loss: 1.3405 - classification_loss: 0.2855
 686/1000 [===================>..........] - ETA: 1:29 - loss: 1.6253 - regression_loss: 1.3398 - classification_loss: 0.2855
 687/1000 [===================>..........] - ETA: 1:29 - loss: 1.6252 - regression_loss: 1.3397 - classification_loss: 0.2854
 688/1000 [===================>..........] - ETA: 1:29 - loss: 1.6257 - regression_loss: 1.3404 - classification_loss: 0.2853
 689/1000 [===================>..........] - ETA: 1:29 - loss: 1.6259 - regression_loss: 1.3406 - classification_loss: 0.2853
 690/1000 [===================>..........] - ETA: 1:28 - loss: 1.6255 - regression_loss: 1.3404 - classification_loss: 0.2851
 691/1000 [===================>..........] - ETA: 1:28 - loss: 1.6259 - regression_loss: 1.3405 - classification_loss: 0.2853
 692/1000 [===================>..........] - ETA: 1:28 - loss: 1.6258 - regression_loss: 1.3405 - classification_loss: 0.2853
 693/1000 [===================>..........] - ETA: 1:27 - loss: 1.6250 - regression_loss: 1.3400 - classification_loss: 0.2851
 694/1000 [===================>..........] - ETA: 1:27 - loss: 1.6240 - regression_loss: 1.3392 - classification_loss: 0.2848
 695/1000 [===================>..........] - ETA: 1:27 - loss: 1.6234 - regression_loss: 1.3382 - classification_loss: 0.2852
 696/1000 [===================>..........] - ETA: 1:27 - loss: 1.6229 - regression_loss: 1.3378 - classification_loss: 0.2850
 697/1000 [===================>..........] - ETA: 1:26 - loss: 1.6227 - regression_loss: 1.3377 - classification_loss: 0.2850
 698/1000 [===================>..........] - ETA: 1:26 - loss: 1.6235 - regression_loss: 1.3384 - classification_loss: 0.2852
 699/1000 [===================>..........] - ETA: 1:26 - loss: 1.6231 - regression_loss: 1.3380 - classification_loss: 0.2851
 700/1000 [====================>.........] - ETA: 1:25 - loss: 1.6224 - regression_loss: 1.3374 - classification_loss: 0.2850
 701/1000 [====================>.........] - ETA: 1:25 - loss: 1.6222 - regression_loss: 1.3372 - classification_loss: 0.2850
 702/1000 [====================>.........] - ETA: 1:25 - loss: 1.6215 - regression_loss: 1.3367 - classification_loss: 0.2848
 703/1000 [====================>.........] - ETA: 1:25 - loss: 1.6217 - regression_loss: 1.3369 - classification_loss: 0.2848
 704/1000 [====================>.........] - ETA: 1:24 - loss: 1.6208 - regression_loss: 1.3362 - classification_loss: 0.2845
 705/1000 [====================>.........] - ETA: 1:24 - loss: 1.6211 - regression_loss: 1.3365 - classification_loss: 0.2846
 706/1000 [====================>.........] - ETA: 1:24 - loss: 1.6206 - regression_loss: 1.3361 - classification_loss: 0.2845
 707/1000 [====================>.........] - ETA: 1:23 - loss: 1.6201 - regression_loss: 1.3357 - classification_loss: 0.2844
 708/1000 [====================>.........] - ETA: 1:23 - loss: 1.6204 - regression_loss: 1.3357 - classification_loss: 0.2846
 709/1000 [====================>.........] - ETA: 1:23 - loss: 1.6198 - regression_loss: 1.3353 - classification_loss: 0.2844
 710/1000 [====================>.........] - ETA: 1:23 - loss: 1.6200 - regression_loss: 1.3357 - classification_loss: 0.2843
 711/1000 [====================>.........] - ETA: 1:22 - loss: 1.6200 - regression_loss: 1.3357 - classification_loss: 0.2843
 712/1000 [====================>.........] - ETA: 1:22 - loss: 1.6194 - regression_loss: 1.3353 - classification_loss: 0.2842
 713/1000 [====================>.........] - ETA: 1:22 - loss: 1.6191 - regression_loss: 1.3351 - classification_loss: 0.2840
 714/1000 [====================>.........] - ETA: 1:21 - loss: 1.6190 - regression_loss: 1.3351 - classification_loss: 0.2839
 715/1000 [====================>.........] - ETA: 1:21 - loss: 1.6176 - regression_loss: 1.3339 - classification_loss: 0.2837
 716/1000 [====================>.........] - ETA: 1:21 - loss: 1.6175 - regression_loss: 1.3339 - classification_loss: 0.2835
 717/1000 [====================>.........] - ETA: 1:21 - loss: 1.6178 - regression_loss: 1.3340 - classification_loss: 0.2837
 718/1000 [====================>.........] - ETA: 1:20 - loss: 1.6190 - regression_loss: 1.3351 - classification_loss: 0.2839
 719/1000 [====================>.........] - ETA: 1:20 - loss: 1.6198 - regression_loss: 1.3357 - classification_loss: 0.2840
 720/1000 [====================>.........] - ETA: 1:20 - loss: 1.6197 - regression_loss: 1.3358 - classification_loss: 0.2839
 721/1000 [====================>.........] - ETA: 1:19 - loss: 1.6203 - regression_loss: 1.3362 - classification_loss: 0.2842
 722/1000 [====================>.........] - ETA: 1:19 - loss: 1.6199 - regression_loss: 1.3359 - classification_loss: 0.2840
 723/1000 [====================>.........] - ETA: 1:19 - loss: 1.6207 - regression_loss: 1.3365 - classification_loss: 0.2841
 724/1000 [====================>.........] - ETA: 1:19 - loss: 1.6222 - regression_loss: 1.3376 - classification_loss: 0.2847
 725/1000 [====================>.........] - ETA: 1:18 - loss: 1.6213 - regression_loss: 1.3369 - classification_loss: 0.2844
 726/1000 [====================>.........] - ETA: 1:18 - loss: 1.6211 - regression_loss: 1.3368 - classification_loss: 0.2843
 727/1000 [====================>.........] - ETA: 1:18 - loss: 1.6207 - regression_loss: 1.3365 - classification_loss: 0.2842
 728/1000 [====================>.........] - ETA: 1:17 - loss: 1.6210 - regression_loss: 1.3366 - classification_loss: 0.2844
 729/1000 [====================>.........] - ETA: 1:17 - loss: 1.6204 - regression_loss: 1.3362 - classification_loss: 0.2842
 730/1000 [====================>.........] - ETA: 1:17 - loss: 1.6196 - regression_loss: 1.3355 - classification_loss: 0.2841
 731/1000 [====================>.........] - ETA: 1:17 - loss: 1.6202 - regression_loss: 1.3361 - classification_loss: 0.2841
 732/1000 [====================>.........] - ETA: 1:16 - loss: 1.6196 - regression_loss: 1.3355 - classification_loss: 0.2840
 733/1000 [====================>.........] - ETA: 1:16 - loss: 1.6199 - regression_loss: 1.3357 - classification_loss: 0.2841
 734/1000 [=====================>........] - ETA: 1:16 - loss: 1.6205 - regression_loss: 1.3363 - classification_loss: 0.2842
 735/1000 [=====================>........] - ETA: 1:15 - loss: 1.6196 - regression_loss: 1.3356 - classification_loss: 0.2840
 736/1000 [=====================>........] - ETA: 1:15 - loss: 1.6189 - regression_loss: 1.3351 - classification_loss: 0.2838
 737/1000 [=====================>........] - ETA: 1:15 - loss: 1.6190 - regression_loss: 1.3353 - classification_loss: 0.2837
 738/1000 [=====================>........] - ETA: 1:15 - loss: 1.6180 - regression_loss: 1.3344 - classification_loss: 0.2837
 739/1000 [=====================>........] - ETA: 1:14 - loss: 1.6171 - regression_loss: 1.3336 - classification_loss: 0.2835
 740/1000 [=====================>........] - ETA: 1:14 - loss: 1.6168 - regression_loss: 1.3334 - classification_loss: 0.2834
 741/1000 [=====================>........] - ETA: 1:14 - loss: 1.6165 - regression_loss: 1.3331 - classification_loss: 0.2835
 742/1000 [=====================>........] - ETA: 1:13 - loss: 1.6158 - regression_loss: 1.3325 - classification_loss: 0.2833
 743/1000 [=====================>........] - ETA: 1:13 - loss: 1.6156 - regression_loss: 1.3325 - classification_loss: 0.2831
 744/1000 [=====================>........] - ETA: 1:13 - loss: 1.6164 - regression_loss: 1.3328 - classification_loss: 0.2836
 745/1000 [=====================>........] - ETA: 1:13 - loss: 1.6160 - regression_loss: 1.3322 - classification_loss: 0.2839
 746/1000 [=====================>........] - ETA: 1:12 - loss: 1.6162 - regression_loss: 1.3324 - classification_loss: 0.2838
 747/1000 [=====================>........] - ETA: 1:12 - loss: 1.6163 - regression_loss: 1.3324 - classification_loss: 0.2839
 748/1000 [=====================>........] - ETA: 1:12 - loss: 1.6159 - regression_loss: 1.3321 - classification_loss: 0.2838
 749/1000 [=====================>........] - ETA: 1:11 - loss: 1.6179 - regression_loss: 1.3336 - classification_loss: 0.2843
 750/1000 [=====================>........] - ETA: 1:11 - loss: 1.6180 - regression_loss: 1.3336 - classification_loss: 0.2844
 751/1000 [=====================>........] - ETA: 1:11 - loss: 1.6175 - regression_loss: 1.3332 - classification_loss: 0.2843
 752/1000 [=====================>........] - ETA: 1:11 - loss: 1.6198 - regression_loss: 1.3352 - classification_loss: 0.2846
 753/1000 [=====================>........] - ETA: 1:10 - loss: 1.6191 - regression_loss: 1.3346 - classification_loss: 0.2845
 754/1000 [=====================>........] - ETA: 1:10 - loss: 1.6187 - regression_loss: 1.3345 - classification_loss: 0.2842
 755/1000 [=====================>........] - ETA: 1:10 - loss: 1.6179 - regression_loss: 1.3338 - classification_loss: 0.2840
 756/1000 [=====================>........] - ETA: 1:09 - loss: 1.6184 - regression_loss: 1.3343 - classification_loss: 0.2841
 757/1000 [=====================>........] - ETA: 1:09 - loss: 1.6180 - regression_loss: 1.3341 - classification_loss: 0.2839
 758/1000 [=====================>........] - ETA: 1:09 - loss: 1.6179 - regression_loss: 1.3340 - classification_loss: 0.2839
 759/1000 [=====================>........] - ETA: 1:09 - loss: 1.6188 - regression_loss: 1.3346 - classification_loss: 0.2841
 760/1000 [=====================>........] - ETA: 1:08 - loss: 1.6197 - regression_loss: 1.3354 - classification_loss: 0.2843
 761/1000 [=====================>........] - ETA: 1:08 - loss: 1.6211 - regression_loss: 1.3364 - classification_loss: 0.2848
 762/1000 [=====================>........] - ETA: 1:08 - loss: 1.6216 - regression_loss: 1.3367 - classification_loss: 0.2849
 763/1000 [=====================>........] - ETA: 1:07 - loss: 1.6213 - regression_loss: 1.3365 - classification_loss: 0.2848
 764/1000 [=====================>........] - ETA: 1:07 - loss: 1.6203 - regression_loss: 1.3355 - classification_loss: 0.2848
 765/1000 [=====================>........] - ETA: 1:07 - loss: 1.6214 - regression_loss: 1.3365 - classification_loss: 0.2849
 766/1000 [=====================>........] - ETA: 1:07 - loss: 1.6212 - regression_loss: 1.3364 - classification_loss: 0.2848
 767/1000 [======================>.......] - ETA: 1:06 - loss: 1.6219 - regression_loss: 1.3370 - classification_loss: 0.2849
 768/1000 [======================>.......] - ETA: 1:06 - loss: 1.6218 - regression_loss: 1.3370 - classification_loss: 0.2848
 769/1000 [======================>.......] - ETA: 1:06 - loss: 1.6206 - regression_loss: 1.3360 - classification_loss: 0.2846
 770/1000 [======================>.......] - ETA: 1:05 - loss: 1.6208 - regression_loss: 1.3361 - classification_loss: 0.2848
 771/1000 [======================>.......] - ETA: 1:05 - loss: 1.6197 - regression_loss: 1.3352 - classification_loss: 0.2845
 772/1000 [======================>.......] - ETA: 1:05 - loss: 1.6194 - regression_loss: 1.3350 - classification_loss: 0.2844
 773/1000 [======================>.......] - ETA: 1:04 - loss: 1.6201 - regression_loss: 1.3354 - classification_loss: 0.2847
 774/1000 [======================>.......] - ETA: 1:04 - loss: 1.6197 - regression_loss: 1.3350 - classification_loss: 0.2847
 775/1000 [======================>.......] - ETA: 1:04 - loss: 1.6185 - regression_loss: 1.3340 - classification_loss: 0.2845
 776/1000 [======================>.......] - ETA: 1:04 - loss: 1.6174 - regression_loss: 1.3331 - classification_loss: 0.2843
 777/1000 [======================>.......] - ETA: 1:03 - loss: 1.6168 - regression_loss: 1.3325 - classification_loss: 0.2843
 778/1000 [======================>.......] - ETA: 1:03 - loss: 1.6175 - regression_loss: 1.3329 - classification_loss: 0.2847
 779/1000 [======================>.......] - ETA: 1:03 - loss: 1.6180 - regression_loss: 1.3333 - classification_loss: 0.2847
 780/1000 [======================>.......] - ETA: 1:02 - loss: 1.6175 - regression_loss: 1.3328 - classification_loss: 0.2846
 781/1000 [======================>.......] - ETA: 1:02 - loss: 1.6164 - regression_loss: 1.3319 - classification_loss: 0.2845
 782/1000 [======================>.......] - ETA: 1:02 - loss: 1.6159 - regression_loss: 1.3315 - classification_loss: 0.2844
 783/1000 [======================>.......] - ETA: 1:02 - loss: 1.6179 - regression_loss: 1.3332 - classification_loss: 0.2847
 784/1000 [======================>.......] - ETA: 1:01 - loss: 1.6169 - regression_loss: 1.3324 - classification_loss: 0.2845
 785/1000 [======================>.......] - ETA: 1:01 - loss: 1.6168 - regression_loss: 1.3323 - classification_loss: 0.2844
 786/1000 [======================>.......] - ETA: 1:01 - loss: 1.6161 - regression_loss: 1.3318 - classification_loss: 0.2843
 787/1000 [======================>.......] - ETA: 1:00 - loss: 1.6163 - regression_loss: 1.3319 - classification_loss: 0.2844
 788/1000 [======================>.......] - ETA: 1:00 - loss: 1.6156 - regression_loss: 1.3312 - classification_loss: 0.2843
 789/1000 [======================>.......] - ETA: 1:00 - loss: 1.6163 - regression_loss: 1.3319 - classification_loss: 0.2843
 790/1000 [======================>.......] - ETA: 1:00 - loss: 1.6155 - regression_loss: 1.3314 - classification_loss: 0.2841
 791/1000 [======================>.......] - ETA: 59s - loss: 1.6144 - regression_loss: 1.3304 - classification_loss: 0.2840 
 792/1000 [======================>.......] - ETA: 59s - loss: 1.6141 - regression_loss: 1.3303 - classification_loss: 0.2838
 793/1000 [======================>.......] - ETA: 59s - loss: 1.6147 - regression_loss: 1.3307 - classification_loss: 0.2840
 794/1000 [======================>.......] - ETA: 58s - loss: 1.6142 - regression_loss: 1.3305 - classification_loss: 0.2837
 795/1000 [======================>.......] - ETA: 58s - loss: 1.6135 - regression_loss: 1.3299 - classification_loss: 0.2836
 796/1000 [======================>.......] - ETA: 58s - loss: 1.6131 - regression_loss: 1.3296 - classification_loss: 0.2835
 797/1000 [======================>.......] - ETA: 58s - loss: 1.6131 - regression_loss: 1.3295 - classification_loss: 0.2836
 798/1000 [======================>.......] - ETA: 57s - loss: 1.6133 - regression_loss: 1.3296 - classification_loss: 0.2837
 799/1000 [======================>.......] - ETA: 57s - loss: 1.6130 - regression_loss: 1.3294 - classification_loss: 0.2837
 800/1000 [=======================>......] - ETA: 57s - loss: 1.6138 - regression_loss: 1.3300 - classification_loss: 0.2839
 801/1000 [=======================>......] - ETA: 56s - loss: 1.6138 - regression_loss: 1.3301 - classification_loss: 0.2837
 802/1000 [=======================>......] - ETA: 56s - loss: 1.6160 - regression_loss: 1.3321 - classification_loss: 0.2839
 803/1000 [=======================>......] - ETA: 56s - loss: 1.6160 - regression_loss: 1.3322 - classification_loss: 0.2838
 804/1000 [=======================>......] - ETA: 56s - loss: 1.6163 - regression_loss: 1.3325 - classification_loss: 0.2838
 805/1000 [=======================>......] - ETA: 55s - loss: 1.6159 - regression_loss: 1.3323 - classification_loss: 0.2836
 806/1000 [=======================>......] - ETA: 55s - loss: 1.6156 - regression_loss: 1.3321 - classification_loss: 0.2835
 807/1000 [=======================>......] - ETA: 55s - loss: 1.6170 - regression_loss: 1.3334 - classification_loss: 0.2836
 808/1000 [=======================>......] - ETA: 54s - loss: 1.6173 - regression_loss: 1.3337 - classification_loss: 0.2836
 809/1000 [=======================>......] - ETA: 54s - loss: 1.6185 - regression_loss: 1.3345 - classification_loss: 0.2840
 810/1000 [=======================>......] - ETA: 54s - loss: 1.6185 - regression_loss: 1.3345 - classification_loss: 0.2840
 811/1000 [=======================>......] - ETA: 54s - loss: 1.6181 - regression_loss: 1.3343 - classification_loss: 0.2839
 812/1000 [=======================>......] - ETA: 53s - loss: 1.6187 - regression_loss: 1.3348 - classification_loss: 0.2838
 813/1000 [=======================>......] - ETA: 53s - loss: 1.6184 - regression_loss: 1.3347 - classification_loss: 0.2837
 814/1000 [=======================>......] - ETA: 53s - loss: 1.6185 - regression_loss: 1.3348 - classification_loss: 0.2837
 815/1000 [=======================>......] - ETA: 52s - loss: 1.6184 - regression_loss: 1.3347 - classification_loss: 0.2837
 816/1000 [=======================>......] - ETA: 52s - loss: 1.6189 - regression_loss: 1.3353 - classification_loss: 0.2836
 817/1000 [=======================>......] - ETA: 52s - loss: 1.6188 - regression_loss: 1.3352 - classification_loss: 0.2836
 818/1000 [=======================>......] - ETA: 52s - loss: 1.6181 - regression_loss: 1.3347 - classification_loss: 0.2834
 819/1000 [=======================>......] - ETA: 51s - loss: 1.6188 - regression_loss: 1.3354 - classification_loss: 0.2834
 820/1000 [=======================>......] - ETA: 51s - loss: 1.6180 - regression_loss: 1.3348 - classification_loss: 0.2832
 821/1000 [=======================>......] - ETA: 51s - loss: 1.6174 - regression_loss: 1.3345 - classification_loss: 0.2830
 822/1000 [=======================>......] - ETA: 50s - loss: 1.6173 - regression_loss: 1.3344 - classification_loss: 0.2829
 823/1000 [=======================>......] - ETA: 50s - loss: 1.6166 - regression_loss: 1.3338 - classification_loss: 0.2828
 824/1000 [=======================>......] - ETA: 50s - loss: 1.6167 - regression_loss: 1.3339 - classification_loss: 0.2829
 825/1000 [=======================>......] - ETA: 50s - loss: 1.6160 - regression_loss: 1.3332 - classification_loss: 0.2827
 826/1000 [=======================>......] - ETA: 49s - loss: 1.6167 - regression_loss: 1.3338 - classification_loss: 0.2829
 827/1000 [=======================>......] - ETA: 49s - loss: 1.6158 - regression_loss: 1.3331 - classification_loss: 0.2827
 828/1000 [=======================>......] - ETA: 49s - loss: 1.6152 - regression_loss: 1.3326 - classification_loss: 0.2826
 829/1000 [=======================>......] - ETA: 48s - loss: 1.6150 - regression_loss: 1.3324 - classification_loss: 0.2826
 830/1000 [=======================>......] - ETA: 48s - loss: 1.6153 - regression_loss: 1.3326 - classification_loss: 0.2826
 831/1000 [=======================>......] - ETA: 48s - loss: 1.6156 - regression_loss: 1.3331 - classification_loss: 0.2825
 832/1000 [=======================>......] - ETA: 48s - loss: 1.6150 - regression_loss: 1.3326 - classification_loss: 0.2824
 833/1000 [=======================>......] - ETA: 47s - loss: 1.6144 - regression_loss: 1.3320 - classification_loss: 0.2823
 834/1000 [========================>.....] - ETA: 47s - loss: 1.6143 - regression_loss: 1.3319 - classification_loss: 0.2823
 835/1000 [========================>.....] - ETA: 47s - loss: 1.6151 - regression_loss: 1.3323 - classification_loss: 0.2828
 836/1000 [========================>.....] - ETA: 46s - loss: 1.6150 - regression_loss: 1.3323 - classification_loss: 0.2827
 837/1000 [========================>.....] - ETA: 46s - loss: 1.6148 - regression_loss: 1.3322 - classification_loss: 0.2826
 838/1000 [========================>.....] - ETA: 46s - loss: 1.6162 - regression_loss: 1.3332 - classification_loss: 0.2830
 839/1000 [========================>.....] - ETA: 46s - loss: 1.6172 - regression_loss: 1.3341 - classification_loss: 0.2831
 840/1000 [========================>.....] - ETA: 45s - loss: 1.6168 - regression_loss: 1.3338 - classification_loss: 0.2830
 841/1000 [========================>.....] - ETA: 45s - loss: 1.6174 - regression_loss: 1.3343 - classification_loss: 0.2831
 842/1000 [========================>.....] - ETA: 45s - loss: 1.6166 - regression_loss: 1.3336 - classification_loss: 0.2830
 843/1000 [========================>.....] - ETA: 44s - loss: 1.6174 - regression_loss: 1.3344 - classification_loss: 0.2830
 844/1000 [========================>.....] - ETA: 44s - loss: 1.6187 - regression_loss: 1.3354 - classification_loss: 0.2833
 845/1000 [========================>.....] - ETA: 44s - loss: 1.6199 - regression_loss: 1.3365 - classification_loss: 0.2834
 846/1000 [========================>.....] - ETA: 44s - loss: 1.6205 - regression_loss: 1.3366 - classification_loss: 0.2839
 847/1000 [========================>.....] - ETA: 43s - loss: 1.6204 - regression_loss: 1.3367 - classification_loss: 0.2837
 848/1000 [========================>.....] - ETA: 43s - loss: 1.6206 - regression_loss: 1.3368 - classification_loss: 0.2838
 849/1000 [========================>.....] - ETA: 43s - loss: 1.6197 - regression_loss: 1.3361 - classification_loss: 0.2837
 850/1000 [========================>.....] - ETA: 42s - loss: 1.6192 - regression_loss: 1.3357 - classification_loss: 0.2835
 851/1000 [========================>.....] - ETA: 42s - loss: 1.6190 - regression_loss: 1.3355 - classification_loss: 0.2834
 852/1000 [========================>.....] - ETA: 42s - loss: 1.6181 - regression_loss: 1.3348 - classification_loss: 0.2832
 853/1000 [========================>.....] - ETA: 42s - loss: 1.6179 - regression_loss: 1.3347 - classification_loss: 0.2832
 854/1000 [========================>.....] - ETA: 41s - loss: 1.6198 - regression_loss: 1.3359 - classification_loss: 0.2839
 855/1000 [========================>.....] - ETA: 41s - loss: 1.6212 - regression_loss: 1.3370 - classification_loss: 0.2842
 856/1000 [========================>.....] - ETA: 41s - loss: 1.6212 - regression_loss: 1.3370 - classification_loss: 0.2842
 857/1000 [========================>.....] - ETA: 40s - loss: 1.6216 - regression_loss: 1.3373 - classification_loss: 0.2843
 858/1000 [========================>.....] - ETA: 40s - loss: 1.6213 - regression_loss: 1.3371 - classification_loss: 0.2842
 859/1000 [========================>.....] - ETA: 40s - loss: 1.6208 - regression_loss: 1.3368 - classification_loss: 0.2840
 860/1000 [========================>.....] - ETA: 40s - loss: 1.6208 - regression_loss: 1.3369 - classification_loss: 0.2838
 861/1000 [========================>.....] - ETA: 39s - loss: 1.6206 - regression_loss: 1.3369 - classification_loss: 0.2838
 862/1000 [========================>.....] - ETA: 39s - loss: 1.6199 - regression_loss: 1.3364 - classification_loss: 0.2836
 863/1000 [========================>.....] - ETA: 39s - loss: 1.6200 - regression_loss: 1.3364 - classification_loss: 0.2836
 864/1000 [========================>.....] - ETA: 38s - loss: 1.6200 - regression_loss: 1.3364 - classification_loss: 0.2836
 865/1000 [========================>.....] - ETA: 38s - loss: 1.6189 - regression_loss: 1.3354 - classification_loss: 0.2835
 866/1000 [========================>.....] - ETA: 38s - loss: 1.6189 - regression_loss: 1.3355 - classification_loss: 0.2834
 867/1000 [=========================>....] - ETA: 38s - loss: 1.6193 - regression_loss: 1.3355 - classification_loss: 0.2838
 868/1000 [=========================>....] - ETA: 37s - loss: 1.6199 - regression_loss: 1.3357 - classification_loss: 0.2841
 869/1000 [=========================>....] - ETA: 37s - loss: 1.6194 - regression_loss: 1.3353 - classification_loss: 0.2841
 870/1000 [=========================>....] - ETA: 37s - loss: 1.6197 - regression_loss: 1.3356 - classification_loss: 0.2841
 871/1000 [=========================>....] - ETA: 36s - loss: 1.6196 - regression_loss: 1.3355 - classification_loss: 0.2841
 872/1000 [=========================>....] - ETA: 36s - loss: 1.6191 - regression_loss: 1.3351 - classification_loss: 0.2840
 873/1000 [=========================>....] - ETA: 36s - loss: 1.6179 - regression_loss: 1.3341 - classification_loss: 0.2838
 874/1000 [=========================>....] - ETA: 36s - loss: 1.6174 - regression_loss: 1.3337 - classification_loss: 0.2837
 875/1000 [=========================>....] - ETA: 35s - loss: 1.6170 - regression_loss: 1.3333 - classification_loss: 0.2836
 876/1000 [=========================>....] - ETA: 35s - loss: 1.6163 - regression_loss: 1.3328 - classification_loss: 0.2835
 877/1000 [=========================>....] - ETA: 35s - loss: 1.6160 - regression_loss: 1.3325 - classification_loss: 0.2835
 878/1000 [=========================>....] - ETA: 34s - loss: 1.6153 - regression_loss: 1.3320 - classification_loss: 0.2833
 879/1000 [=========================>....] - ETA: 34s - loss: 1.6149 - regression_loss: 1.3315 - classification_loss: 0.2834
 880/1000 [=========================>....] - ETA: 34s - loss: 1.6152 - regression_loss: 1.3317 - classification_loss: 0.2835
 881/1000 [=========================>....] - ETA: 34s - loss: 1.6157 - regression_loss: 1.3323 - classification_loss: 0.2834
 882/1000 [=========================>....] - ETA: 33s - loss: 1.6150 - regression_loss: 1.3318 - classification_loss: 0.2832
 883/1000 [=========================>....] - ETA: 33s - loss: 1.6146 - regression_loss: 1.3315 - classification_loss: 0.2831
 884/1000 [=========================>....] - ETA: 33s - loss: 1.6146 - regression_loss: 1.3314 - classification_loss: 0.2832
 885/1000 [=========================>....] - ETA: 32s - loss: 1.6144 - regression_loss: 1.3312 - classification_loss: 0.2832
 886/1000 [=========================>....] - ETA: 32s - loss: 1.6147 - regression_loss: 1.3315 - classification_loss: 0.2832
 887/1000 [=========================>....] - ETA: 32s - loss: 1.6142 - regression_loss: 1.3312 - classification_loss: 0.2830
 888/1000 [=========================>....] - ETA: 32s - loss: 1.6143 - regression_loss: 1.3312 - classification_loss: 0.2831
 889/1000 [=========================>....] - ETA: 31s - loss: 1.6144 - regression_loss: 1.3314 - classification_loss: 0.2830
 890/1000 [=========================>....] - ETA: 31s - loss: 1.6144 - regression_loss: 1.3313 - classification_loss: 0.2831
 891/1000 [=========================>....] - ETA: 31s - loss: 1.6135 - regression_loss: 1.3307 - classification_loss: 0.2828
 892/1000 [=========================>....] - ETA: 30s - loss: 1.6127 - regression_loss: 1.3301 - classification_loss: 0.2826
 893/1000 [=========================>....] - ETA: 30s - loss: 1.6123 - regression_loss: 1.3298 - classification_loss: 0.2825
 894/1000 [=========================>....] - ETA: 30s - loss: 1.6121 - regression_loss: 1.3297 - classification_loss: 0.2824
 895/1000 [=========================>....] - ETA: 30s - loss: 1.6116 - regression_loss: 1.3293 - classification_loss: 0.2823
 896/1000 [=========================>....] - ETA: 29s - loss: 1.6113 - regression_loss: 1.3291 - classification_loss: 0.2823
 897/1000 [=========================>....] - ETA: 29s - loss: 1.6134 - regression_loss: 1.3306 - classification_loss: 0.2828
 898/1000 [=========================>....] - ETA: 29s - loss: 1.6126 - regression_loss: 1.3299 - classification_loss: 0.2827
 899/1000 [=========================>....] - ETA: 28s - loss: 1.6128 - regression_loss: 1.3300 - classification_loss: 0.2828
 900/1000 [==========================>...] - ETA: 28s - loss: 1.6127 - regression_loss: 1.3299 - classification_loss: 0.2828
 901/1000 [==========================>...] - ETA: 28s - loss: 1.6125 - regression_loss: 1.3298 - classification_loss: 0.2828
 902/1000 [==========================>...] - ETA: 28s - loss: 1.6125 - regression_loss: 1.3297 - classification_loss: 0.2829
 903/1000 [==========================>...] - ETA: 27s - loss: 1.6120 - regression_loss: 1.3292 - classification_loss: 0.2828
 904/1000 [==========================>...] - ETA: 27s - loss: 1.6115 - regression_loss: 1.3289 - classification_loss: 0.2827
 905/1000 [==========================>...] - ETA: 27s - loss: 1.6105 - regression_loss: 1.3280 - classification_loss: 0.2825
 906/1000 [==========================>...] - ETA: 26s - loss: 1.6113 - regression_loss: 1.3288 - classification_loss: 0.2825
 907/1000 [==========================>...] - ETA: 26s - loss: 1.6105 - regression_loss: 1.3281 - classification_loss: 0.2824
 908/1000 [==========================>...] - ETA: 26s - loss: 1.6100 - regression_loss: 1.3276 - classification_loss: 0.2823
 909/1000 [==========================>...] - ETA: 26s - loss: 1.6094 - regression_loss: 1.3271 - classification_loss: 0.2823
 910/1000 [==========================>...] - ETA: 25s - loss: 1.6090 - regression_loss: 1.3268 - classification_loss: 0.2822
 911/1000 [==========================>...] - ETA: 25s - loss: 1.6083 - regression_loss: 1.3263 - classification_loss: 0.2821
 912/1000 [==========================>...] - ETA: 25s - loss: 1.6075 - regression_loss: 1.3256 - classification_loss: 0.2820
 913/1000 [==========================>...] - ETA: 24s - loss: 1.6071 - regression_loss: 1.3253 - classification_loss: 0.2818
 914/1000 [==========================>...] - ETA: 24s - loss: 1.6072 - regression_loss: 1.3254 - classification_loss: 0.2817
 915/1000 [==========================>...] - ETA: 24s - loss: 1.6064 - regression_loss: 1.3248 - classification_loss: 0.2815
 916/1000 [==========================>...] - ETA: 24s - loss: 1.6065 - regression_loss: 1.3250 - classification_loss: 0.2815
 917/1000 [==========================>...] - ETA: 23s - loss: 1.6067 - regression_loss: 1.3252 - classification_loss: 0.2815
 918/1000 [==========================>...] - ETA: 23s - loss: 1.6069 - regression_loss: 1.3255 - classification_loss: 0.2814
 919/1000 [==========================>...] - ETA: 23s - loss: 1.6073 - regression_loss: 1.3258 - classification_loss: 0.2815
 920/1000 [==========================>...] - ETA: 22s - loss: 1.6069 - regression_loss: 1.3255 - classification_loss: 0.2814
 921/1000 [==========================>...] - ETA: 22s - loss: 1.6072 - regression_loss: 1.3256 - classification_loss: 0.2817
 922/1000 [==========================>...] - ETA: 22s - loss: 1.6063 - regression_loss: 1.3247 - classification_loss: 0.2816
 923/1000 [==========================>...] - ETA: 22s - loss: 1.6077 - regression_loss: 1.3258 - classification_loss: 0.2819
 924/1000 [==========================>...] - ETA: 21s - loss: 1.6077 - regression_loss: 1.3259 - classification_loss: 0.2819
 925/1000 [==========================>...] - ETA: 21s - loss: 1.6083 - regression_loss: 1.3264 - classification_loss: 0.2819
 926/1000 [==========================>...] - ETA: 21s - loss: 1.6089 - regression_loss: 1.3270 - classification_loss: 0.2819
 927/1000 [==========================>...] - ETA: 20s - loss: 1.6091 - regression_loss: 1.3271 - classification_loss: 0.2820
 928/1000 [==========================>...] - ETA: 20s - loss: 1.6096 - regression_loss: 1.3277 - classification_loss: 0.2820
 929/1000 [==========================>...] - ETA: 20s - loss: 1.6087 - regression_loss: 1.3269 - classification_loss: 0.2818
 930/1000 [==========================>...] - ETA: 20s - loss: 1.6094 - regression_loss: 1.3276 - classification_loss: 0.2818
 931/1000 [==========================>...] - ETA: 19s - loss: 1.6099 - regression_loss: 1.3282 - classification_loss: 0.2817
 932/1000 [==========================>...] - ETA: 19s - loss: 1.6100 - regression_loss: 1.3282 - classification_loss: 0.2817
 933/1000 [==========================>...] - ETA: 19s - loss: 1.6094 - regression_loss: 1.3278 - classification_loss: 0.2816
 934/1000 [===========================>..] - ETA: 18s - loss: 1.6091 - regression_loss: 1.3276 - classification_loss: 0.2815
 935/1000 [===========================>..] - ETA: 18s - loss: 1.6083 - regression_loss: 1.3270 - classification_loss: 0.2813
 936/1000 [===========================>..] - ETA: 18s - loss: 1.6075 - regression_loss: 1.3264 - classification_loss: 0.2811
 937/1000 [===========================>..] - ETA: 18s - loss: 1.6074 - regression_loss: 1.3263 - classification_loss: 0.2811
 938/1000 [===========================>..] - ETA: 17s - loss: 1.6078 - regression_loss: 1.3267 - classification_loss: 0.2812
 939/1000 [===========================>..] - ETA: 17s - loss: 1.6077 - regression_loss: 1.3267 - classification_loss: 0.2811
 940/1000 [===========================>..] - ETA: 17s - loss: 1.6082 - regression_loss: 1.3272 - classification_loss: 0.2810
 941/1000 [===========================>..] - ETA: 16s - loss: 1.6075 - regression_loss: 1.3266 - classification_loss: 0.2808
 942/1000 [===========================>..] - ETA: 16s - loss: 1.6068 - regression_loss: 1.3261 - classification_loss: 0.2807
 943/1000 [===========================>..] - ETA: 16s - loss: 1.6060 - regression_loss: 1.3255 - classification_loss: 0.2805
 944/1000 [===========================>..] - ETA: 16s - loss: 1.6066 - regression_loss: 1.3261 - classification_loss: 0.2805
 945/1000 [===========================>..] - ETA: 15s - loss: 1.6069 - regression_loss: 1.3266 - classification_loss: 0.2803
 946/1000 [===========================>..] - ETA: 15s - loss: 1.6065 - regression_loss: 1.3263 - classification_loss: 0.2802
 947/1000 [===========================>..] - ETA: 15s - loss: 1.6065 - regression_loss: 1.3263 - classification_loss: 0.2801
 948/1000 [===========================>..] - ETA: 14s - loss: 1.6063 - regression_loss: 1.3262 - classification_loss: 0.2801
 949/1000 [===========================>..] - ETA: 14s - loss: 1.6065 - regression_loss: 1.3264 - classification_loss: 0.2801
 950/1000 [===========================>..] - ETA: 14s - loss: 1.6062 - regression_loss: 1.3261 - classification_loss: 0.2801
 951/1000 [===========================>..] - ETA: 14s - loss: 1.6056 - regression_loss: 1.3257 - classification_loss: 0.2799
 952/1000 [===========================>..] - ETA: 13s - loss: 1.6056 - regression_loss: 1.3257 - classification_loss: 0.2799
 953/1000 [===========================>..] - ETA: 13s - loss: 1.6047 - regression_loss: 1.3250 - classification_loss: 0.2797
 954/1000 [===========================>..] - ETA: 13s - loss: 1.6036 - regression_loss: 1.3241 - classification_loss: 0.2795
 955/1000 [===========================>..] - ETA: 12s - loss: 1.6034 - regression_loss: 1.3240 - classification_loss: 0.2794
 956/1000 [===========================>..] - ETA: 12s - loss: 1.6025 - regression_loss: 1.3232 - classification_loss: 0.2792
 957/1000 [===========================>..] - ETA: 12s - loss: 1.6025 - regression_loss: 1.3233 - classification_loss: 0.2792
 958/1000 [===========================>..] - ETA: 12s - loss: 1.6025 - regression_loss: 1.3233 - classification_loss: 0.2792
 959/1000 [===========================>..] - ETA: 11s - loss: 1.6021 - regression_loss: 1.3231 - classification_loss: 0.2791
 960/1000 [===========================>..] - ETA: 11s - loss: 1.6019 - regression_loss: 1.3228 - classification_loss: 0.2791
 961/1000 [===========================>..] - ETA: 11s - loss: 1.6015 - regression_loss: 1.3225 - classification_loss: 0.2790
 962/1000 [===========================>..] - ETA: 10s - loss: 1.6009 - regression_loss: 1.3220 - classification_loss: 0.2789
 963/1000 [===========================>..] - ETA: 10s - loss: 1.6003 - regression_loss: 1.3215 - classification_loss: 0.2787
 964/1000 [===========================>..] - ETA: 10s - loss: 1.5998 - regression_loss: 1.3211 - classification_loss: 0.2787
 965/1000 [===========================>..] - ETA: 10s - loss: 1.5996 - regression_loss: 1.3210 - classification_loss: 0.2786
 966/1000 [===========================>..] - ETA: 9s - loss: 1.5988 - regression_loss: 1.3203 - classification_loss: 0.2785 
 967/1000 [============================>.] - ETA: 9s - loss: 1.5981 - regression_loss: 1.3198 - classification_loss: 0.2783
 968/1000 [============================>.] - ETA: 9s - loss: 1.5983 - regression_loss: 1.3199 - classification_loss: 0.2785
 969/1000 [============================>.] - ETA: 8s - loss: 1.5976 - regression_loss: 1.3194 - classification_loss: 0.2783
 970/1000 [============================>.] - ETA: 8s - loss: 1.5981 - regression_loss: 1.3199 - classification_loss: 0.2783
 971/1000 [============================>.] - ETA: 8s - loss: 1.5983 - regression_loss: 1.3200 - classification_loss: 0.2783
 972/1000 [============================>.] - ETA: 8s - loss: 1.5989 - regression_loss: 1.3205 - classification_loss: 0.2784
 973/1000 [============================>.] - ETA: 7s - loss: 1.5987 - regression_loss: 1.3203 - classification_loss: 0.2784
 974/1000 [============================>.] - ETA: 7s - loss: 1.5987 - regression_loss: 1.3203 - classification_loss: 0.2784
 975/1000 [============================>.] - ETA: 7s - loss: 1.5987 - regression_loss: 1.3203 - classification_loss: 0.2784
 976/1000 [============================>.] - ETA: 6s - loss: 1.5980 - regression_loss: 1.3196 - classification_loss: 0.2784
 977/1000 [============================>.] - ETA: 6s - loss: 1.5983 - regression_loss: 1.3199 - classification_loss: 0.2785
 978/1000 [============================>.] - ETA: 6s - loss: 1.5976 - regression_loss: 1.3192 - classification_loss: 0.2783
 979/1000 [============================>.] - ETA: 6s - loss: 1.5977 - regression_loss: 1.3191 - classification_loss: 0.2786
 980/1000 [============================>.] - ETA: 5s - loss: 1.5979 - regression_loss: 1.3192 - classification_loss: 0.2787
 981/1000 [============================>.] - ETA: 5s - loss: 1.5978 - regression_loss: 1.3190 - classification_loss: 0.2787
 982/1000 [============================>.] - ETA: 5s - loss: 1.5978 - regression_loss: 1.3190 - classification_loss: 0.2789
 983/1000 [============================>.] - ETA: 4s - loss: 1.5972 - regression_loss: 1.3185 - classification_loss: 0.2787
 984/1000 [============================>.] - ETA: 4s - loss: 1.5973 - regression_loss: 1.3185 - classification_loss: 0.2788
 985/1000 [============================>.] - ETA: 4s - loss: 1.5971 - regression_loss: 1.3184 - classification_loss: 0.2787
 986/1000 [============================>.] - ETA: 4s - loss: 1.5972 - regression_loss: 1.3185 - classification_loss: 0.2786
 987/1000 [============================>.] - ETA: 3s - loss: 1.5975 - regression_loss: 1.3188 - classification_loss: 0.2787
 988/1000 [============================>.] - ETA: 3s - loss: 1.5972 - regression_loss: 1.3186 - classification_loss: 0.2786
 989/1000 [============================>.] - ETA: 3s - loss: 1.5976 - regression_loss: 1.3190 - classification_loss: 0.2786
 990/1000 [============================>.] - ETA: 2s - loss: 1.5975 - regression_loss: 1.3189 - classification_loss: 0.2786
 991/1000 [============================>.] - ETA: 2s - loss: 1.5987 - regression_loss: 1.3200 - classification_loss: 0.2787
 992/1000 [============================>.] - ETA: 2s - loss: 1.5985 - regression_loss: 1.3198 - classification_loss: 0.2786
 993/1000 [============================>.] - ETA: 2s - loss: 1.5986 - regression_loss: 1.3200 - classification_loss: 0.2786
 994/1000 [============================>.] - ETA: 1s - loss: 1.5981 - regression_loss: 1.3196 - classification_loss: 0.2784
 995/1000 [============================>.] - ETA: 1s - loss: 1.5973 - regression_loss: 1.3189 - classification_loss: 0.2783
 996/1000 [============================>.] - ETA: 1s - loss: 1.5965 - regression_loss: 1.3183 - classification_loss: 0.2782
 997/1000 [============================>.] - ETA: 0s - loss: 1.5961 - regression_loss: 1.3179 - classification_loss: 0.2782
 998/1000 [============================>.] - ETA: 0s - loss: 1.5964 - regression_loss: 1.3179 - classification_loss: 0.2786
 999/1000 [============================>.] - ETA: 0s - loss: 1.5968 - regression_loss: 1.3180 - classification_loss: 0.2787
1000/1000 [==============================] - 286s 286ms/step - loss: 1.5968 - regression_loss: 1.3181 - classification_loss: 0.2787

Epoch 00004: saving model to ./snapshots/resnet50_csv_04.h5
Epoch 5/10

   1/1000 [..............................] - ETA: 4:46 - loss: 1.3693 - regression_loss: 1.2147 - classification_loss: 0.1546
   2/1000 [..............................] - ETA: 4:50 - loss: 1.5268 - regression_loss: 1.3723 - classification_loss: 0.1544
   3/1000 [..............................] - ETA: 4:48 - loss: 1.6164 - regression_loss: 1.4227 - classification_loss: 0.1937
   4/1000 [..............................] - ETA: 4:50 - loss: 1.6663 - regression_loss: 1.4749 - classification_loss: 0.1914
   5/1000 [..............................] - ETA: 4:48 - loss: 1.7706 - regression_loss: 1.5282 - classification_loss: 0.2424
   6/1000 [..............................] - ETA: 4:48 - loss: 1.6826 - regression_loss: 1.4545 - classification_loss: 0.2281
   7/1000 [..............................] - ETA: 4:47 - loss: 1.6817 - regression_loss: 1.4544 - classification_loss: 0.2272
   8/1000 [..............................] - ETA: 4:47 - loss: 1.6381 - regression_loss: 1.4097 - classification_loss: 0.2284
   9/1000 [..............................] - ETA: 4:45 - loss: 1.7261 - regression_loss: 1.4831 - classification_loss: 0.2430
  10/1000 [..............................] - ETA: 4:45 - loss: 1.7083 - regression_loss: 1.4648 - classification_loss: 0.2435
  11/1000 [..............................] - ETA: 4:44 - loss: 1.7727 - regression_loss: 1.5126 - classification_loss: 0.2601
  12/1000 [..............................] - ETA: 4:44 - loss: 1.6968 - regression_loss: 1.4501 - classification_loss: 0.2467
  13/1000 [..............................] - ETA: 4:43 - loss: 1.6149 - regression_loss: 1.3795 - classification_loss: 0.2354
  14/1000 [..............................] - ETA: 4:42 - loss: 1.5861 - regression_loss: 1.3530 - classification_loss: 0.2331
  15/1000 [..............................] - ETA: 4:42 - loss: 1.5874 - regression_loss: 1.3496 - classification_loss: 0.2379
  16/1000 [..............................] - ETA: 4:41 - loss: 1.6058 - regression_loss: 1.3476 - classification_loss: 0.2582
  17/1000 [..............................] - ETA: 4:41 - loss: 1.6341 - regression_loss: 1.3732 - classification_loss: 0.2609
  18/1000 [..............................] - ETA: 4:41 - loss: 1.6844 - regression_loss: 1.4073 - classification_loss: 0.2771
  19/1000 [..............................] - ETA: 4:40 - loss: 1.8110 - regression_loss: 1.4837 - classification_loss: 0.3273
  20/1000 [..............................] - ETA: 4:40 - loss: 1.8083 - regression_loss: 1.4860 - classification_loss: 0.3224
  21/1000 [..............................] - ETA: 4:39 - loss: 1.7746 - regression_loss: 1.4619 - classification_loss: 0.3127
  22/1000 [..............................] - ETA: 4:40 - loss: 1.8261 - regression_loss: 1.5005 - classification_loss: 0.3257
  23/1000 [..............................] - ETA: 4:39 - loss: 1.8350 - regression_loss: 1.5093 - classification_loss: 0.3258
  24/1000 [..............................] - ETA: 4:39 - loss: 1.8018 - regression_loss: 1.4828 - classification_loss: 0.3190
  25/1000 [..............................] - ETA: 4:39 - loss: 1.8181 - regression_loss: 1.5017 - classification_loss: 0.3165
  26/1000 [..............................] - ETA: 4:38 - loss: 1.8210 - regression_loss: 1.5083 - classification_loss: 0.3127
  27/1000 [..............................] - ETA: 4:38 - loss: 1.7909 - regression_loss: 1.4865 - classification_loss: 0.3044
  28/1000 [..............................] - ETA: 4:38 - loss: 1.7697 - regression_loss: 1.4704 - classification_loss: 0.2993
  29/1000 [..............................] - ETA: 4:37 - loss: 1.7475 - regression_loss: 1.4515 - classification_loss: 0.2961
  30/1000 [..............................] - ETA: 4:37 - loss: 1.7221 - regression_loss: 1.4276 - classification_loss: 0.2945
  31/1000 [..............................] - ETA: 4:37 - loss: 1.6975 - regression_loss: 1.4062 - classification_loss: 0.2912
  32/1000 [..............................] - ETA: 4:37 - loss: 1.7284 - regression_loss: 1.4239 - classification_loss: 0.3045
  33/1000 [..............................] - ETA: 4:37 - loss: 1.7064 - regression_loss: 1.4049 - classification_loss: 0.3015
  34/1000 [>.............................] - ETA: 4:37 - loss: 1.6982 - regression_loss: 1.3995 - classification_loss: 0.2987
  35/1000 [>.............................] - ETA: 4:37 - loss: 1.6860 - regression_loss: 1.3919 - classification_loss: 0.2941
  36/1000 [>.............................] - ETA: 4:36 - loss: 1.6748 - regression_loss: 1.3857 - classification_loss: 0.2891
  37/1000 [>.............................] - ETA: 4:36 - loss: 1.6736 - regression_loss: 1.3851 - classification_loss: 0.2885
  38/1000 [>.............................] - ETA: 4:35 - loss: 1.6861 - regression_loss: 1.3934 - classification_loss: 0.2927
  39/1000 [>.............................] - ETA: 4:35 - loss: 1.6922 - regression_loss: 1.4004 - classification_loss: 0.2918
  40/1000 [>.............................] - ETA: 4:35 - loss: 1.6746 - regression_loss: 1.3868 - classification_loss: 0.2877
  41/1000 [>.............................] - ETA: 4:34 - loss: 1.6608 - regression_loss: 1.3762 - classification_loss: 0.2845
  42/1000 [>.............................] - ETA: 4:34 - loss: 1.6785 - regression_loss: 1.3853 - classification_loss: 0.2932
  43/1000 [>.............................] - ETA: 4:34 - loss: 1.6726 - regression_loss: 1.3822 - classification_loss: 0.2904
  44/1000 [>.............................] - ETA: 4:34 - loss: 1.6591 - regression_loss: 1.3724 - classification_loss: 0.2867
  45/1000 [>.............................] - ETA: 4:33 - loss: 1.6521 - regression_loss: 1.3647 - classification_loss: 0.2875
  46/1000 [>.............................] - ETA: 4:33 - loss: 1.6512 - regression_loss: 1.3637 - classification_loss: 0.2875
  47/1000 [>.............................] - ETA: 4:33 - loss: 1.6463 - regression_loss: 1.3589 - classification_loss: 0.2875
  48/1000 [>.............................] - ETA: 4:32 - loss: 1.6338 - regression_loss: 1.3487 - classification_loss: 0.2851
  49/1000 [>.............................] - ETA: 4:32 - loss: 1.6190 - regression_loss: 1.3371 - classification_loss: 0.2820
  50/1000 [>.............................] - ETA: 4:32 - loss: 1.6034 - regression_loss: 1.3241 - classification_loss: 0.2793
  51/1000 [>.............................] - ETA: 4:31 - loss: 1.5991 - regression_loss: 1.3215 - classification_loss: 0.2776
  52/1000 [>.............................] - ETA: 4:31 - loss: 1.5835 - regression_loss: 1.3084 - classification_loss: 0.2751
  53/1000 [>.............................] - ETA: 4:31 - loss: 1.5965 - regression_loss: 1.3202 - classification_loss: 0.2763
  54/1000 [>.............................] - ETA: 4:30 - loss: 1.5853 - regression_loss: 1.3110 - classification_loss: 0.2743
  55/1000 [>.............................] - ETA: 4:30 - loss: 1.5718 - regression_loss: 1.3005 - classification_loss: 0.2713
  56/1000 [>.............................] - ETA: 4:30 - loss: 1.5655 - regression_loss: 1.2965 - classification_loss: 0.2689
  57/1000 [>.............................] - ETA: 4:30 - loss: 1.5630 - regression_loss: 1.2958 - classification_loss: 0.2672
  58/1000 [>.............................] - ETA: 4:30 - loss: 1.5558 - regression_loss: 1.2900 - classification_loss: 0.2658
  59/1000 [>.............................] - ETA: 4:29 - loss: 1.5674 - regression_loss: 1.3000 - classification_loss: 0.2673
  60/1000 [>.............................] - ETA: 4:29 - loss: 1.5581 - regression_loss: 1.2925 - classification_loss: 0.2656
  61/1000 [>.............................] - ETA: 4:28 - loss: 1.5707 - regression_loss: 1.3022 - classification_loss: 0.2685
  62/1000 [>.............................] - ETA: 4:28 - loss: 1.5938 - regression_loss: 1.3239 - classification_loss: 0.2699
  63/1000 [>.............................] - ETA: 4:28 - loss: 1.5802 - regression_loss: 1.3132 - classification_loss: 0.2669
  64/1000 [>.............................] - ETA: 4:28 - loss: 1.6033 - regression_loss: 1.3286 - classification_loss: 0.2746
  65/1000 [>.............................] - ETA: 4:28 - loss: 1.6088 - regression_loss: 1.3289 - classification_loss: 0.2799
  66/1000 [>.............................] - ETA: 4:27 - loss: 1.6071 - regression_loss: 1.3265 - classification_loss: 0.2806
  67/1000 [=>............................] - ETA: 4:27 - loss: 1.6018 - regression_loss: 1.3219 - classification_loss: 0.2799
  68/1000 [=>............................] - ETA: 4:27 - loss: 1.6007 - regression_loss: 1.3211 - classification_loss: 0.2796
  69/1000 [=>............................] - ETA: 4:26 - loss: 1.6018 - regression_loss: 1.3225 - classification_loss: 0.2794
  70/1000 [=>............................] - ETA: 4:26 - loss: 1.6145 - regression_loss: 1.3302 - classification_loss: 0.2843
  71/1000 [=>............................] - ETA: 4:26 - loss: 1.6239 - regression_loss: 1.3388 - classification_loss: 0.2851
  72/1000 [=>............................] - ETA: 4:25 - loss: 1.6273 - regression_loss: 1.3412 - classification_loss: 0.2860
  73/1000 [=>............................] - ETA: 4:25 - loss: 1.6156 - regression_loss: 1.3320 - classification_loss: 0.2836
  74/1000 [=>............................] - ETA: 4:25 - loss: 1.6093 - regression_loss: 1.3280 - classification_loss: 0.2813
  75/1000 [=>............................] - ETA: 4:24 - loss: 1.6052 - regression_loss: 1.3249 - classification_loss: 0.2804
  76/1000 [=>............................] - ETA: 4:24 - loss: 1.6128 - regression_loss: 1.3334 - classification_loss: 0.2795
  77/1000 [=>............................] - ETA: 4:24 - loss: 1.6112 - regression_loss: 1.3327 - classification_loss: 0.2785
  78/1000 [=>............................] - ETA: 4:24 - loss: 1.6261 - regression_loss: 1.3415 - classification_loss: 0.2846
  79/1000 [=>............................] - ETA: 4:23 - loss: 1.6324 - regression_loss: 1.3475 - classification_loss: 0.2850
  80/1000 [=>............................] - ETA: 4:23 - loss: 1.6282 - regression_loss: 1.3442 - classification_loss: 0.2840
  81/1000 [=>............................] - ETA: 4:23 - loss: 1.6165 - regression_loss: 1.3349 - classification_loss: 0.2816
  82/1000 [=>............................] - ETA: 4:22 - loss: 1.6145 - regression_loss: 1.3338 - classification_loss: 0.2807
  83/1000 [=>............................] - ETA: 4:22 - loss: 1.6191 - regression_loss: 1.3393 - classification_loss: 0.2798
  84/1000 [=>............................] - ETA: 4:22 - loss: 1.6261 - regression_loss: 1.3459 - classification_loss: 0.2801
  85/1000 [=>............................] - ETA: 4:22 - loss: 1.6319 - regression_loss: 1.3503 - classification_loss: 0.2816
  86/1000 [=>............................] - ETA: 4:21 - loss: 1.6237 - regression_loss: 1.3436 - classification_loss: 0.2801
  87/1000 [=>............................] - ETA: 4:21 - loss: 1.6175 - regression_loss: 1.3387 - classification_loss: 0.2788
  88/1000 [=>............................] - ETA: 4:21 - loss: 1.6157 - regression_loss: 1.3376 - classification_loss: 0.2781
  89/1000 [=>............................] - ETA: 4:21 - loss: 1.6127 - regression_loss: 1.3360 - classification_loss: 0.2767
  90/1000 [=>............................] - ETA: 4:20 - loss: 1.6131 - regression_loss: 1.3360 - classification_loss: 0.2772
  91/1000 [=>............................] - ETA: 4:20 - loss: 1.6150 - regression_loss: 1.3362 - classification_loss: 0.2788
  92/1000 [=>............................] - ETA: 4:20 - loss: 1.6045 - regression_loss: 1.3270 - classification_loss: 0.2775
  93/1000 [=>............................] - ETA: 4:19 - loss: 1.6122 - regression_loss: 1.3344 - classification_loss: 0.2777
  94/1000 [=>............................] - ETA: 4:19 - loss: 1.6078 - regression_loss: 1.3295 - classification_loss: 0.2783
  95/1000 [=>............................] - ETA: 4:19 - loss: 1.6034 - regression_loss: 1.3267 - classification_loss: 0.2768
  96/1000 [=>............................] - ETA: 4:18 - loss: 1.6009 - regression_loss: 1.3253 - classification_loss: 0.2755
  97/1000 [=>............................] - ETA: 4:18 - loss: 1.5973 - regression_loss: 1.3227 - classification_loss: 0.2746
  98/1000 [=>............................] - ETA: 4:18 - loss: 1.5867 - regression_loss: 1.3143 - classification_loss: 0.2724
  99/1000 [=>............................] - ETA: 4:18 - loss: 1.5874 - regression_loss: 1.3153 - classification_loss: 0.2721
 100/1000 [==>...........................] - ETA: 4:17 - loss: 1.5797 - regression_loss: 1.3090 - classification_loss: 0.2708
 101/1000 [==>...........................] - ETA: 4:17 - loss: 1.5870 - regression_loss: 1.3153 - classification_loss: 0.2717
 102/1000 [==>...........................] - ETA: 4:17 - loss: 1.5780 - regression_loss: 1.3081 - classification_loss: 0.2699
 103/1000 [==>...........................] - ETA: 4:16 - loss: 1.5796 - regression_loss: 1.3096 - classification_loss: 0.2700
 104/1000 [==>...........................] - ETA: 4:16 - loss: 1.5791 - regression_loss: 1.3095 - classification_loss: 0.2697
 105/1000 [==>...........................] - ETA: 4:16 - loss: 1.5825 - regression_loss: 1.3124 - classification_loss: 0.2701
 106/1000 [==>...........................] - ETA: 4:16 - loss: 1.5803 - regression_loss: 1.3103 - classification_loss: 0.2700
 107/1000 [==>...........................] - ETA: 4:15 - loss: 1.5768 - regression_loss: 1.3076 - classification_loss: 0.2691
 108/1000 [==>...........................] - ETA: 4:15 - loss: 1.5779 - regression_loss: 1.3092 - classification_loss: 0.2687
 109/1000 [==>...........................] - ETA: 4:15 - loss: 1.5829 - regression_loss: 1.3136 - classification_loss: 0.2693
 110/1000 [==>...........................] - ETA: 4:15 - loss: 1.5822 - regression_loss: 1.3125 - classification_loss: 0.2697
 111/1000 [==>...........................] - ETA: 4:14 - loss: 1.5740 - regression_loss: 1.3057 - classification_loss: 0.2683
 112/1000 [==>...........................] - ETA: 4:14 - loss: 1.5705 - regression_loss: 1.3029 - classification_loss: 0.2676
 113/1000 [==>...........................] - ETA: 4:14 - loss: 1.5674 - regression_loss: 1.3010 - classification_loss: 0.2664
 114/1000 [==>...........................] - ETA: 4:13 - loss: 1.5656 - regression_loss: 1.2992 - classification_loss: 0.2664
 115/1000 [==>...........................] - ETA: 4:13 - loss: 1.5675 - regression_loss: 1.3004 - classification_loss: 0.2672
 116/1000 [==>...........................] - ETA: 4:13 - loss: 1.5678 - regression_loss: 1.3004 - classification_loss: 0.2674
 117/1000 [==>...........................] - ETA: 4:13 - loss: 1.5664 - regression_loss: 1.2998 - classification_loss: 0.2666
 118/1000 [==>...........................] - ETA: 4:12 - loss: 1.5605 - regression_loss: 1.2954 - classification_loss: 0.2652
 119/1000 [==>...........................] - ETA: 4:12 - loss: 1.5620 - regression_loss: 1.2970 - classification_loss: 0.2650
 120/1000 [==>...........................] - ETA: 4:12 - loss: 1.5654 - regression_loss: 1.3001 - classification_loss: 0.2653
 121/1000 [==>...........................] - ETA: 4:12 - loss: 1.5630 - regression_loss: 1.2982 - classification_loss: 0.2648
 122/1000 [==>...........................] - ETA: 4:11 - loss: 1.5655 - regression_loss: 1.3001 - classification_loss: 0.2654
 123/1000 [==>...........................] - ETA: 4:11 - loss: 1.5731 - regression_loss: 1.3049 - classification_loss: 0.2682
 124/1000 [==>...........................] - ETA: 4:11 - loss: 1.5700 - regression_loss: 1.3018 - classification_loss: 0.2682
 125/1000 [==>...........................] - ETA: 4:10 - loss: 1.5755 - regression_loss: 1.3053 - classification_loss: 0.2702
 126/1000 [==>...........................] - ETA: 4:10 - loss: 1.5718 - regression_loss: 1.3025 - classification_loss: 0.2693
 127/1000 [==>...........................] - ETA: 4:10 - loss: 1.5713 - regression_loss: 1.3022 - classification_loss: 0.2691
 128/1000 [==>...........................] - ETA: 4:10 - loss: 1.5688 - regression_loss: 1.3005 - classification_loss: 0.2682
 129/1000 [==>...........................] - ETA: 4:09 - loss: 1.5742 - regression_loss: 1.3060 - classification_loss: 0.2682
 130/1000 [==>...........................] - ETA: 4:09 - loss: 1.5734 - regression_loss: 1.3051 - classification_loss: 0.2682
 131/1000 [==>...........................] - ETA: 4:09 - loss: 1.5718 - regression_loss: 1.3048 - classification_loss: 0.2670
 132/1000 [==>...........................] - ETA: 4:08 - loss: 1.5667 - regression_loss: 1.3005 - classification_loss: 0.2661
 133/1000 [==>...........................] - ETA: 4:08 - loss: 1.5646 - regression_loss: 1.2994 - classification_loss: 0.2652
 134/1000 [===>..........................] - ETA: 4:08 - loss: 1.5670 - regression_loss: 1.3019 - classification_loss: 0.2652
 135/1000 [===>..........................] - ETA: 4:08 - loss: 1.5703 - regression_loss: 1.3042 - classification_loss: 0.2661
 136/1000 [===>..........................] - ETA: 4:07 - loss: 1.5743 - regression_loss: 1.3068 - classification_loss: 0.2675
 137/1000 [===>..........................] - ETA: 4:07 - loss: 1.5703 - regression_loss: 1.3027 - classification_loss: 0.2676
 138/1000 [===>..........................] - ETA: 4:07 - loss: 1.5731 - regression_loss: 1.3049 - classification_loss: 0.2682
 139/1000 [===>..........................] - ETA: 4:06 - loss: 1.5699 - regression_loss: 1.3025 - classification_loss: 0.2673
 140/1000 [===>..........................] - ETA: 4:06 - loss: 1.5683 - regression_loss: 1.3014 - classification_loss: 0.2669
 141/1000 [===>..........................] - ETA: 4:06 - loss: 1.5706 - regression_loss: 1.3036 - classification_loss: 0.2670
 142/1000 [===>..........................] - ETA: 4:05 - loss: 1.5684 - regression_loss: 1.3018 - classification_loss: 0.2666
 143/1000 [===>..........................] - ETA: 4:05 - loss: 1.5746 - regression_loss: 1.3080 - classification_loss: 0.2666
 144/1000 [===>..........................] - ETA: 4:05 - loss: 1.5699 - regression_loss: 1.3036 - classification_loss: 0.2664
 145/1000 [===>..........................] - ETA: 4:05 - loss: 1.5658 - regression_loss: 1.3004 - classification_loss: 0.2654
 146/1000 [===>..........................] - ETA: 4:04 - loss: 1.5661 - regression_loss: 1.3014 - classification_loss: 0.2647
 147/1000 [===>..........................] - ETA: 4:04 - loss: 1.5632 - regression_loss: 1.2971 - classification_loss: 0.2661
 148/1000 [===>..........................] - ETA: 4:04 - loss: 1.5611 - regression_loss: 1.2945 - classification_loss: 0.2666
 149/1000 [===>..........................] - ETA: 4:03 - loss: 1.5584 - regression_loss: 1.2921 - classification_loss: 0.2664
 150/1000 [===>..........................] - ETA: 4:03 - loss: 1.5554 - regression_loss: 1.2899 - classification_loss: 0.2655
 151/1000 [===>..........................] - ETA: 4:03 - loss: 1.5512 - regression_loss: 1.2869 - classification_loss: 0.2643
 152/1000 [===>..........................] - ETA: 4:03 - loss: 1.5497 - regression_loss: 1.2859 - classification_loss: 0.2639
 153/1000 [===>..........................] - ETA: 4:02 - loss: 1.5527 - regression_loss: 1.2877 - classification_loss: 0.2650
 154/1000 [===>..........................] - ETA: 4:02 - loss: 1.5625 - regression_loss: 1.2958 - classification_loss: 0.2668
 155/1000 [===>..........................] - ETA: 4:02 - loss: 1.5630 - regression_loss: 1.2964 - classification_loss: 0.2666
 156/1000 [===>..........................] - ETA: 4:02 - loss: 1.5623 - regression_loss: 1.2968 - classification_loss: 0.2656
 157/1000 [===>..........................] - ETA: 4:01 - loss: 1.5679 - regression_loss: 1.3014 - classification_loss: 0.2665
 158/1000 [===>..........................] - ETA: 4:01 - loss: 1.5685 - regression_loss: 1.3022 - classification_loss: 0.2663
 159/1000 [===>..........................] - ETA: 4:01 - loss: 1.5630 - regression_loss: 1.2970 - classification_loss: 0.2660
 160/1000 [===>..........................] - ETA: 4:00 - loss: 1.5616 - regression_loss: 1.2960 - classification_loss: 0.2657
 161/1000 [===>..........................] - ETA: 4:00 - loss: 1.5623 - regression_loss: 1.2966 - classification_loss: 0.2657
 162/1000 [===>..........................] - ETA: 4:00 - loss: 1.5587 - regression_loss: 1.2940 - classification_loss: 0.2647
 163/1000 [===>..........................] - ETA: 4:00 - loss: 1.5536 - regression_loss: 1.2899 - classification_loss: 0.2637
 164/1000 [===>..........................] - ETA: 3:59 - loss: 1.5524 - regression_loss: 1.2893 - classification_loss: 0.2631
 165/1000 [===>..........................] - ETA: 3:59 - loss: 1.5513 - regression_loss: 1.2886 - classification_loss: 0.2627
 166/1000 [===>..........................] - ETA: 3:59 - loss: 1.5517 - regression_loss: 1.2892 - classification_loss: 0.2625
 167/1000 [====>.........................] - ETA: 3:58 - loss: 1.5555 - regression_loss: 1.2922 - classification_loss: 0.2632
 168/1000 [====>.........................] - ETA: 3:58 - loss: 1.5585 - regression_loss: 1.2953 - classification_loss: 0.2633
 169/1000 [====>.........................] - ETA: 3:58 - loss: 1.5603 - regression_loss: 1.2975 - classification_loss: 0.2628
 170/1000 [====>.........................] - ETA: 3:58 - loss: 1.5584 - regression_loss: 1.2927 - classification_loss: 0.2657
 171/1000 [====>.........................] - ETA: 3:57 - loss: 1.5572 - regression_loss: 1.2923 - classification_loss: 0.2649
 172/1000 [====>.........................] - ETA: 3:57 - loss: 1.5541 - regression_loss: 1.2880 - classification_loss: 0.2661
 173/1000 [====>.........................] - ETA: 3:57 - loss: 1.5546 - regression_loss: 1.2879 - classification_loss: 0.2666
 174/1000 [====>.........................] - ETA: 3:56 - loss: 1.5518 - regression_loss: 1.2862 - classification_loss: 0.2657
 175/1000 [====>.........................] - ETA: 3:56 - loss: 1.5539 - regression_loss: 1.2879 - classification_loss: 0.2660
 176/1000 [====>.........................] - ETA: 3:56 - loss: 1.5499 - regression_loss: 1.2844 - classification_loss: 0.2655
 177/1000 [====>.........................] - ETA: 3:56 - loss: 1.5532 - regression_loss: 1.2868 - classification_loss: 0.2664
 178/1000 [====>.........................] - ETA: 3:55 - loss: 1.5605 - regression_loss: 1.2919 - classification_loss: 0.2686
 179/1000 [====>.........................] - ETA: 3:55 - loss: 1.5630 - regression_loss: 1.2939 - classification_loss: 0.2691
 180/1000 [====>.........................] - ETA: 3:55 - loss: 1.5606 - regression_loss: 1.2915 - classification_loss: 0.2692
 181/1000 [====>.........................] - ETA: 3:54 - loss: 1.5661 - regression_loss: 1.2955 - classification_loss: 0.2706
 182/1000 [====>.........................] - ETA: 3:54 - loss: 1.5702 - regression_loss: 1.2985 - classification_loss: 0.2717
 183/1000 [====>.........................] - ETA: 3:54 - loss: 1.5714 - regression_loss: 1.2991 - classification_loss: 0.2723
 184/1000 [====>.........................] - ETA: 3:54 - loss: 1.5700 - regression_loss: 1.2981 - classification_loss: 0.2719
 185/1000 [====>.........................] - ETA: 3:53 - loss: 1.5681 - regression_loss: 1.2968 - classification_loss: 0.2713
 186/1000 [====>.........................] - ETA: 3:53 - loss: 1.5710 - regression_loss: 1.2994 - classification_loss: 0.2717
 187/1000 [====>.........................] - ETA: 3:53 - loss: 1.5714 - regression_loss: 1.3003 - classification_loss: 0.2711
 188/1000 [====>.........................] - ETA: 3:52 - loss: 1.5725 - regression_loss: 1.3020 - classification_loss: 0.2705
 189/1000 [====>.........................] - ETA: 3:52 - loss: 1.5746 - regression_loss: 1.3038 - classification_loss: 0.2708
 190/1000 [====>.........................] - ETA: 3:52 - loss: 1.5763 - regression_loss: 1.3052 - classification_loss: 0.2711
 191/1000 [====>.........................] - ETA: 3:51 - loss: 1.5773 - regression_loss: 1.3058 - classification_loss: 0.2715
 192/1000 [====>.........................] - ETA: 3:51 - loss: 1.5767 - regression_loss: 1.3048 - classification_loss: 0.2719
 193/1000 [====>.........................] - ETA: 3:51 - loss: 1.5722 - regression_loss: 1.3010 - classification_loss: 0.2712
 194/1000 [====>.........................] - ETA: 3:51 - loss: 1.5715 - regression_loss: 1.3006 - classification_loss: 0.2709
 195/1000 [====>.........................] - ETA: 3:50 - loss: 1.5682 - regression_loss: 1.2979 - classification_loss: 0.2703
 196/1000 [====>.........................] - ETA: 3:50 - loss: 1.5688 - regression_loss: 1.2982 - classification_loss: 0.2706
 197/1000 [====>.........................] - ETA: 3:50 - loss: 1.5645 - regression_loss: 1.2948 - classification_loss: 0.2697
 198/1000 [====>.........................] - ETA: 3:50 - loss: 1.5638 - regression_loss: 1.2944 - classification_loss: 0.2694
 199/1000 [====>.........................] - ETA: 3:49 - loss: 1.5649 - regression_loss: 1.2936 - classification_loss: 0.2713
 200/1000 [=====>........................] - ETA: 3:49 - loss: 1.5618 - regression_loss: 1.2909 - classification_loss: 0.2708
 201/1000 [=====>........................] - ETA: 3:49 - loss: 1.5596 - regression_loss: 1.2895 - classification_loss: 0.2701
 202/1000 [=====>........................] - ETA: 3:48 - loss: 1.5573 - regression_loss: 1.2878 - classification_loss: 0.2695
 203/1000 [=====>........................] - ETA: 3:48 - loss: 1.5565 - regression_loss: 1.2870 - classification_loss: 0.2695
 204/1000 [=====>........................] - ETA: 3:48 - loss: 1.5540 - regression_loss: 1.2853 - classification_loss: 0.2687
 205/1000 [=====>........................] - ETA: 3:47 - loss: 1.5579 - regression_loss: 1.2894 - classification_loss: 0.2685
 206/1000 [=====>........................] - ETA: 3:47 - loss: 1.5585 - regression_loss: 1.2897 - classification_loss: 0.2687
 207/1000 [=====>........................] - ETA: 3:47 - loss: 1.5556 - regression_loss: 1.2871 - classification_loss: 0.2685
 208/1000 [=====>........................] - ETA: 3:47 - loss: 1.5523 - regression_loss: 1.2843 - classification_loss: 0.2681
 209/1000 [=====>........................] - ETA: 3:46 - loss: 1.5472 - regression_loss: 1.2798 - classification_loss: 0.2674
 210/1000 [=====>........................] - ETA: 3:46 - loss: 1.5555 - regression_loss: 1.2860 - classification_loss: 0.2696
 211/1000 [=====>........................] - ETA: 3:46 - loss: 1.5619 - regression_loss: 1.2902 - classification_loss: 0.2717
 212/1000 [=====>........................] - ETA: 3:45 - loss: 1.5581 - regression_loss: 1.2870 - classification_loss: 0.2711
 213/1000 [=====>........................] - ETA: 3:45 - loss: 1.5544 - regression_loss: 1.2842 - classification_loss: 0.2702
 214/1000 [=====>........................] - ETA: 3:45 - loss: 1.5527 - regression_loss: 1.2827 - classification_loss: 0.2699
 215/1000 [=====>........................] - ETA: 3:45 - loss: 1.5502 - regression_loss: 1.2809 - classification_loss: 0.2694
 216/1000 [=====>........................] - ETA: 3:44 - loss: 1.5497 - regression_loss: 1.2808 - classification_loss: 0.2689
 217/1000 [=====>........................] - ETA: 3:44 - loss: 1.5481 - regression_loss: 1.2793 - classification_loss: 0.2688
 218/1000 [=====>........................] - ETA: 3:44 - loss: 1.5466 - regression_loss: 1.2781 - classification_loss: 0.2685
 219/1000 [=====>........................] - ETA: 3:43 - loss: 1.5470 - regression_loss: 1.2782 - classification_loss: 0.2688
 220/1000 [=====>........................] - ETA: 3:43 - loss: 1.5484 - regression_loss: 1.2792 - classification_loss: 0.2692
 221/1000 [=====>........................] - ETA: 3:43 - loss: 1.5452 - regression_loss: 1.2765 - classification_loss: 0.2687
 222/1000 [=====>........................] - ETA: 3:43 - loss: 1.5433 - regression_loss: 1.2751 - classification_loss: 0.2681
 223/1000 [=====>........................] - ETA: 3:42 - loss: 1.5418 - regression_loss: 1.2737 - classification_loss: 0.2681
 224/1000 [=====>........................] - ETA: 3:42 - loss: 1.5443 - regression_loss: 1.2760 - classification_loss: 0.2683
 225/1000 [=====>........................] - ETA: 3:42 - loss: 1.5427 - regression_loss: 1.2749 - classification_loss: 0.2678
 226/1000 [=====>........................] - ETA: 3:41 - loss: 1.5436 - regression_loss: 1.2755 - classification_loss: 0.2681
 227/1000 [=====>........................] - ETA: 3:41 - loss: 1.5404 - regression_loss: 1.2730 - classification_loss: 0.2675
 228/1000 [=====>........................] - ETA: 3:41 - loss: 1.5411 - regression_loss: 1.2735 - classification_loss: 0.2676
 229/1000 [=====>........................] - ETA: 3:41 - loss: 1.5451 - regression_loss: 1.2769 - classification_loss: 0.2681
 230/1000 [=====>........................] - ETA: 3:40 - loss: 1.5461 - regression_loss: 1.2781 - classification_loss: 0.2680
 231/1000 [=====>........................] - ETA: 3:40 - loss: 1.5462 - regression_loss: 1.2783 - classification_loss: 0.2679
 232/1000 [=====>........................] - ETA: 3:40 - loss: 1.5465 - regression_loss: 1.2788 - classification_loss: 0.2678
 233/1000 [=====>........................] - ETA: 3:39 - loss: 1.5477 - regression_loss: 1.2798 - classification_loss: 0.2679
 234/1000 [======>.......................] - ETA: 3:39 - loss: 1.5517 - regression_loss: 1.2831 - classification_loss: 0.2687
 235/1000 [======>.......................] - ETA: 3:39 - loss: 1.5523 - regression_loss: 1.2839 - classification_loss: 0.2684
 236/1000 [======>.......................] - ETA: 3:39 - loss: 1.5544 - regression_loss: 1.2851 - classification_loss: 0.2692
 237/1000 [======>.......................] - ETA: 3:38 - loss: 1.5541 - regression_loss: 1.2848 - classification_loss: 0.2693
 238/1000 [======>.......................] - ETA: 3:38 - loss: 1.5563 - regression_loss: 1.2863 - classification_loss: 0.2700
 239/1000 [======>.......................] - ETA: 3:38 - loss: 1.5573 - regression_loss: 1.2868 - classification_loss: 0.2704
 240/1000 [======>.......................] - ETA: 3:37 - loss: 1.5561 - regression_loss: 1.2860 - classification_loss: 0.2702
 241/1000 [======>.......................] - ETA: 3:37 - loss: 1.5548 - regression_loss: 1.2847 - classification_loss: 0.2701
 242/1000 [======>.......................] - ETA: 3:37 - loss: 1.5520 - regression_loss: 1.2826 - classification_loss: 0.2694
 243/1000 [======>.......................] - ETA: 3:37 - loss: 1.5514 - regression_loss: 1.2825 - classification_loss: 0.2689
 244/1000 [======>.......................] - ETA: 3:36 - loss: 1.5475 - regression_loss: 1.2792 - classification_loss: 0.2683
 245/1000 [======>.......................] - ETA: 3:36 - loss: 1.5443 - regression_loss: 1.2765 - classification_loss: 0.2677
 246/1000 [======>.......................] - ETA: 3:36 - loss: 1.5424 - regression_loss: 1.2752 - classification_loss: 0.2672
 247/1000 [======>.......................] - ETA: 3:35 - loss: 1.5417 - regression_loss: 1.2748 - classification_loss: 0.2669
 248/1000 [======>.......................] - ETA: 3:35 - loss: 1.5413 - regression_loss: 1.2747 - classification_loss: 0.2666
 249/1000 [======>.......................] - ETA: 3:35 - loss: 1.5427 - regression_loss: 1.2758 - classification_loss: 0.2668
 250/1000 [======>.......................] - ETA: 3:35 - loss: 1.5425 - regression_loss: 1.2758 - classification_loss: 0.2667
 251/1000 [======>.......................] - ETA: 3:34 - loss: 1.5462 - regression_loss: 1.2782 - classification_loss: 0.2681
 252/1000 [======>.......................] - ETA: 3:34 - loss: 1.5461 - regression_loss: 1.2781 - classification_loss: 0.2680
 253/1000 [======>.......................] - ETA: 3:34 - loss: 1.5505 - regression_loss: 1.2814 - classification_loss: 0.2691
 254/1000 [======>.......................] - ETA: 3:33 - loss: 1.5474 - regression_loss: 1.2788 - classification_loss: 0.2685
 255/1000 [======>.......................] - ETA: 3:33 - loss: 1.5461 - regression_loss: 1.2780 - classification_loss: 0.2681
 256/1000 [======>.......................] - ETA: 3:33 - loss: 1.5463 - regression_loss: 1.2784 - classification_loss: 0.2679
 257/1000 [======>.......................] - ETA: 3:33 - loss: 1.5432 - regression_loss: 1.2759 - classification_loss: 0.2672
 258/1000 [======>.......................] - ETA: 3:32 - loss: 1.5439 - regression_loss: 1.2768 - classification_loss: 0.2671
 259/1000 [======>.......................] - ETA: 3:32 - loss: 1.5432 - regression_loss: 1.2763 - classification_loss: 0.2669
 260/1000 [======>.......................] - ETA: 3:32 - loss: 1.5408 - regression_loss: 1.2746 - classification_loss: 0.2661
 261/1000 [======>.......................] - ETA: 3:31 - loss: 1.5413 - regression_loss: 1.2752 - classification_loss: 0.2661
 262/1000 [======>.......................] - ETA: 3:31 - loss: 1.5428 - regression_loss: 1.2763 - classification_loss: 0.2665
 263/1000 [======>.......................] - ETA: 3:31 - loss: 1.5468 - regression_loss: 1.2794 - classification_loss: 0.2674
 264/1000 [======>.......................] - ETA: 3:30 - loss: 1.5468 - regression_loss: 1.2795 - classification_loss: 0.2673
 265/1000 [======>.......................] - ETA: 3:30 - loss: 1.5481 - regression_loss: 1.2811 - classification_loss: 0.2669
 266/1000 [======>.......................] - ETA: 3:30 - loss: 1.5462 - regression_loss: 1.2798 - classification_loss: 0.2664
 267/1000 [=======>......................] - ETA: 3:30 - loss: 1.5437 - regression_loss: 1.2777 - classification_loss: 0.2660
 268/1000 [=======>......................] - ETA: 3:29 - loss: 1.5424 - regression_loss: 1.2765 - classification_loss: 0.2658
 269/1000 [=======>......................] - ETA: 3:29 - loss: 1.5444 - regression_loss: 1.2784 - classification_loss: 0.2660
 270/1000 [=======>......................] - ETA: 3:29 - loss: 1.5427 - regression_loss: 1.2769 - classification_loss: 0.2658
 271/1000 [=======>......................] - ETA: 3:28 - loss: 1.5430 - regression_loss: 1.2770 - classification_loss: 0.2660
 272/1000 [=======>......................] - ETA: 3:28 - loss: 1.5442 - regression_loss: 1.2785 - classification_loss: 0.2657
 273/1000 [=======>......................] - ETA: 3:28 - loss: 1.5408 - regression_loss: 1.2757 - classification_loss: 0.2651
 274/1000 [=======>......................] - ETA: 3:28 - loss: 1.5400 - regression_loss: 1.2752 - classification_loss: 0.2648
 275/1000 [=======>......................] - ETA: 3:27 - loss: 1.5400 - regression_loss: 1.2756 - classification_loss: 0.2644
 276/1000 [=======>......................] - ETA: 3:27 - loss: 1.5380 - regression_loss: 1.2742 - classification_loss: 0.2638
 277/1000 [=======>......................] - ETA: 3:27 - loss: 1.5384 - regression_loss: 1.2748 - classification_loss: 0.2636
 278/1000 [=======>......................] - ETA: 3:26 - loss: 1.5375 - regression_loss: 1.2743 - classification_loss: 0.2633
 279/1000 [=======>......................] - ETA: 3:26 - loss: 1.5428 - regression_loss: 1.2784 - classification_loss: 0.2644
 280/1000 [=======>......................] - ETA: 3:26 - loss: 1.5404 - regression_loss: 1.2761 - classification_loss: 0.2642
 281/1000 [=======>......................] - ETA: 3:26 - loss: 1.5433 - regression_loss: 1.2772 - classification_loss: 0.2661
 282/1000 [=======>......................] - ETA: 3:25 - loss: 1.5464 - regression_loss: 1.2799 - classification_loss: 0.2665
 283/1000 [=======>......................] - ETA: 3:25 - loss: 1.5458 - regression_loss: 1.2797 - classification_loss: 0.2661
 284/1000 [=======>......................] - ETA: 3:25 - loss: 1.5466 - regression_loss: 1.2802 - classification_loss: 0.2664
 285/1000 [=======>......................] - ETA: 3:24 - loss: 1.5480 - regression_loss: 1.2811 - classification_loss: 0.2670
 286/1000 [=======>......................] - ETA: 3:24 - loss: 1.5502 - regression_loss: 1.2828 - classification_loss: 0.2675
 287/1000 [=======>......................] - ETA: 3:24 - loss: 1.5483 - regression_loss: 1.2813 - classification_loss: 0.2670
 288/1000 [=======>......................] - ETA: 3:24 - loss: 1.5480 - regression_loss: 1.2808 - classification_loss: 0.2673
 289/1000 [=======>......................] - ETA: 3:23 - loss: 1.5446 - regression_loss: 1.2779 - classification_loss: 0.2666
 290/1000 [=======>......................] - ETA: 3:23 - loss: 1.5446 - regression_loss: 1.2784 - classification_loss: 0.2662
 291/1000 [=======>......................] - ETA: 3:23 - loss: 1.5465 - regression_loss: 1.2802 - classification_loss: 0.2663
 292/1000 [=======>......................] - ETA: 3:22 - loss: 1.5450 - regression_loss: 1.2789 - classification_loss: 0.2660
 293/1000 [=======>......................] - ETA: 3:22 - loss: 1.5447 - regression_loss: 1.2790 - classification_loss: 0.2657
 294/1000 [=======>......................] - ETA: 3:22 - loss: 1.5457 - regression_loss: 1.2797 - classification_loss: 0.2660
 295/1000 [=======>......................] - ETA: 3:22 - loss: 1.5497 - regression_loss: 1.2828 - classification_loss: 0.2669
 296/1000 [=======>......................] - ETA: 3:21 - loss: 1.5485 - regression_loss: 1.2820 - classification_loss: 0.2664
 297/1000 [=======>......................] - ETA: 3:21 - loss: 1.5480 - regression_loss: 1.2815 - classification_loss: 0.2665
 298/1000 [=======>......................] - ETA: 3:21 - loss: 1.5472 - regression_loss: 1.2806 - classification_loss: 0.2667
 299/1000 [=======>......................] - ETA: 3:20 - loss: 1.5502 - regression_loss: 1.2827 - classification_loss: 0.2675
 300/1000 [========>.....................] - ETA: 3:20 - loss: 1.5497 - regression_loss: 1.2820 - classification_loss: 0.2677
 301/1000 [========>.....................] - ETA: 3:20 - loss: 1.5493 - regression_loss: 1.2821 - classification_loss: 0.2672
 302/1000 [========>.....................] - ETA: 3:20 - loss: 1.5497 - regression_loss: 1.2821 - classification_loss: 0.2676
 303/1000 [========>.....................] - ETA: 3:19 - loss: 1.5487 - regression_loss: 1.2817 - classification_loss: 0.2670
 304/1000 [========>.....................] - ETA: 3:19 - loss: 1.5483 - regression_loss: 1.2816 - classification_loss: 0.2667
 305/1000 [========>.....................] - ETA: 3:19 - loss: 1.5529 - regression_loss: 1.2850 - classification_loss: 0.2678
 306/1000 [========>.....................] - ETA: 3:18 - loss: 1.5515 - regression_loss: 1.2837 - classification_loss: 0.2678
 307/1000 [========>.....................] - ETA: 3:18 - loss: 1.5506 - regression_loss: 1.2831 - classification_loss: 0.2675
 308/1000 [========>.....................] - ETA: 3:18 - loss: 1.5475 - regression_loss: 1.2804 - classification_loss: 0.2670
 309/1000 [========>.....................] - ETA: 3:18 - loss: 1.5459 - regression_loss: 1.2789 - classification_loss: 0.2670
 310/1000 [========>.....................] - ETA: 3:17 - loss: 1.5484 - regression_loss: 1.2814 - classification_loss: 0.2670
 311/1000 [========>.....................] - ETA: 3:17 - loss: 1.5471 - regression_loss: 1.2804 - classification_loss: 0.2667
 312/1000 [========>.....................] - ETA: 3:17 - loss: 1.5468 - regression_loss: 1.2801 - classification_loss: 0.2667
 313/1000 [========>.....................] - ETA: 3:16 - loss: 1.5458 - regression_loss: 1.2793 - classification_loss: 0.2664
 314/1000 [========>.....................] - ETA: 3:16 - loss: 1.5475 - regression_loss: 1.2807 - classification_loss: 0.2667
 315/1000 [========>.....................] - ETA: 3:16 - loss: 1.5475 - regression_loss: 1.2811 - classification_loss: 0.2664
 316/1000 [========>.....................] - ETA: 3:15 - loss: 1.5443 - regression_loss: 1.2785 - classification_loss: 0.2658
 317/1000 [========>.....................] - ETA: 3:15 - loss: 1.5443 - regression_loss: 1.2784 - classification_loss: 0.2658
 318/1000 [========>.....................] - ETA: 3:15 - loss: 1.5425 - regression_loss: 1.2768 - classification_loss: 0.2657
 319/1000 [========>.....................] - ETA: 3:15 - loss: 1.5410 - regression_loss: 1.2755 - classification_loss: 0.2656
 320/1000 [========>.....................] - ETA: 3:14 - loss: 1.5401 - regression_loss: 1.2749 - classification_loss: 0.2652
 321/1000 [========>.....................] - ETA: 3:14 - loss: 1.5386 - regression_loss: 1.2732 - classification_loss: 0.2654
 322/1000 [========>.....................] - ETA: 3:14 - loss: 1.5408 - regression_loss: 1.2755 - classification_loss: 0.2653
 323/1000 [========>.....................] - ETA: 3:13 - loss: 1.5389 - regression_loss: 1.2739 - classification_loss: 0.2650
 324/1000 [========>.....................] - ETA: 3:13 - loss: 1.5376 - regression_loss: 1.2731 - classification_loss: 0.2645
 325/1000 [========>.....................] - ETA: 3:13 - loss: 1.5369 - regression_loss: 1.2727 - classification_loss: 0.2642
 326/1000 [========>.....................] - ETA: 3:13 - loss: 1.5377 - regression_loss: 1.2734 - classification_loss: 0.2643
 327/1000 [========>.....................] - ETA: 3:12 - loss: 1.5372 - regression_loss: 1.2728 - classification_loss: 0.2644
 328/1000 [========>.....................] - ETA: 3:12 - loss: 1.5398 - regression_loss: 1.2747 - classification_loss: 0.2651
 329/1000 [========>.....................] - ETA: 3:12 - loss: 1.5385 - regression_loss: 1.2736 - classification_loss: 0.2648
 330/1000 [========>.....................] - ETA: 3:11 - loss: 1.5395 - regression_loss: 1.2745 - classification_loss: 0.2649
 331/1000 [========>.....................] - ETA: 3:11 - loss: 1.5400 - regression_loss: 1.2753 - classification_loss: 0.2646
 332/1000 [========>.....................] - ETA: 3:11 - loss: 1.5374 - regression_loss: 1.2733 - classification_loss: 0.2641
 333/1000 [========>.....................] - ETA: 3:11 - loss: 1.5380 - regression_loss: 1.2740 - classification_loss: 0.2640
 334/1000 [=========>....................] - ETA: 3:10 - loss: 1.5378 - regression_loss: 1.2738 - classification_loss: 0.2640
 335/1000 [=========>....................] - ETA: 3:10 - loss: 1.5369 - regression_loss: 1.2726 - classification_loss: 0.2643
 336/1000 [=========>....................] - ETA: 3:10 - loss: 1.5347 - regression_loss: 1.2705 - classification_loss: 0.2642
 337/1000 [=========>....................] - ETA: 3:09 - loss: 1.5332 - regression_loss: 1.2693 - classification_loss: 0.2639
 338/1000 [=========>....................] - ETA: 3:09 - loss: 1.5329 - regression_loss: 1.2692 - classification_loss: 0.2637
 339/1000 [=========>....................] - ETA: 3:09 - loss: 1.5325 - regression_loss: 1.2689 - classification_loss: 0.2636
 340/1000 [=========>....................] - ETA: 3:09 - loss: 1.5328 - regression_loss: 1.2691 - classification_loss: 0.2636
 341/1000 [=========>....................] - ETA: 3:08 - loss: 1.5303 - regression_loss: 1.2670 - classification_loss: 0.2633
 342/1000 [=========>....................] - ETA: 3:08 - loss: 1.5285 - regression_loss: 1.2656 - classification_loss: 0.2629
 343/1000 [=========>....................] - ETA: 3:08 - loss: 1.5276 - regression_loss: 1.2651 - classification_loss: 0.2625
 344/1000 [=========>....................] - ETA: 3:07 - loss: 1.5261 - regression_loss: 1.2639 - classification_loss: 0.2622
 345/1000 [=========>....................] - ETA: 3:07 - loss: 1.5236 - regression_loss: 1.2617 - classification_loss: 0.2619
 346/1000 [=========>....................] - ETA: 3:07 - loss: 1.5257 - regression_loss: 1.2631 - classification_loss: 0.2626
 347/1000 [=========>....................] - ETA: 3:07 - loss: 1.5262 - regression_loss: 1.2636 - classification_loss: 0.2626
 348/1000 [=========>....................] - ETA: 3:06 - loss: 1.5271 - regression_loss: 1.2644 - classification_loss: 0.2627
 349/1000 [=========>....................] - ETA: 3:06 - loss: 1.5258 - regression_loss: 1.2634 - classification_loss: 0.2624
 350/1000 [=========>....................] - ETA: 3:06 - loss: 1.5248 - regression_loss: 1.2624 - classification_loss: 0.2624
 351/1000 [=========>....................] - ETA: 3:05 - loss: 1.5250 - regression_loss: 1.2625 - classification_loss: 0.2626
 352/1000 [=========>....................] - ETA: 3:05 - loss: 1.5269 - regression_loss: 1.2638 - classification_loss: 0.2631
 353/1000 [=========>....................] - ETA: 3:05 - loss: 1.5261 - regression_loss: 1.2629 - classification_loss: 0.2631
 354/1000 [=========>....................] - ETA: 3:05 - loss: 1.5243 - regression_loss: 1.2615 - classification_loss: 0.2628
 355/1000 [=========>....................] - ETA: 3:04 - loss: 1.5225 - regression_loss: 1.2600 - classification_loss: 0.2625
 356/1000 [=========>....................] - ETA: 3:04 - loss: 1.5231 - regression_loss: 1.2602 - classification_loss: 0.2629
 357/1000 [=========>....................] - ETA: 3:04 - loss: 1.5263 - regression_loss: 1.2623 - classification_loss: 0.2640
 358/1000 [=========>....................] - ETA: 3:03 - loss: 1.5260 - regression_loss: 1.2614 - classification_loss: 0.2647
 359/1000 [=========>....................] - ETA: 3:03 - loss: 1.5244 - regression_loss: 1.2599 - classification_loss: 0.2645
 360/1000 [=========>....................] - ETA: 3:03 - loss: 1.5250 - regression_loss: 1.2605 - classification_loss: 0.2645
 361/1000 [=========>....................] - ETA: 3:03 - loss: 1.5225 - regression_loss: 1.2584 - classification_loss: 0.2641
 362/1000 [=========>....................] - ETA: 3:02 - loss: 1.5205 - regression_loss: 1.2567 - classification_loss: 0.2638
 363/1000 [=========>....................] - ETA: 3:02 - loss: 1.5218 - regression_loss: 1.2580 - classification_loss: 0.2638
 364/1000 [=========>....................] - ETA: 3:02 - loss: 1.5207 - regression_loss: 1.2572 - classification_loss: 0.2635
 365/1000 [=========>....................] - ETA: 3:01 - loss: 1.5194 - regression_loss: 1.2557 - classification_loss: 0.2637
 366/1000 [=========>....................] - ETA: 3:01 - loss: 1.5184 - regression_loss: 1.2550 - classification_loss: 0.2634
 367/1000 [==========>...................] - ETA: 3:01 - loss: 1.5187 - regression_loss: 1.2553 - classification_loss: 0.2634
 368/1000 [==========>...................] - ETA: 3:01 - loss: 1.5179 - regression_loss: 1.2548 - classification_loss: 0.2631
 369/1000 [==========>...................] - ETA: 3:00 - loss: 1.5158 - regression_loss: 1.2531 - classification_loss: 0.2627
 370/1000 [==========>...................] - ETA: 3:00 - loss: 1.5174 - regression_loss: 1.2545 - classification_loss: 0.2629
 371/1000 [==========>...................] - ETA: 3:00 - loss: 1.5166 - regression_loss: 1.2539 - classification_loss: 0.2627
 372/1000 [==========>...................] - ETA: 2:59 - loss: 1.5160 - regression_loss: 1.2534 - classification_loss: 0.2626
 373/1000 [==========>...................] - ETA: 2:59 - loss: 1.5170 - regression_loss: 1.2543 - classification_loss: 0.2627
 374/1000 [==========>...................] - ETA: 2:59 - loss: 1.5156 - regression_loss: 1.2532 - classification_loss: 0.2625
 375/1000 [==========>...................] - ETA: 2:59 - loss: 1.5128 - regression_loss: 1.2498 - classification_loss: 0.2630
 376/1000 [==========>...................] - ETA: 2:58 - loss: 1.5143 - regression_loss: 1.2512 - classification_loss: 0.2631
 377/1000 [==========>...................] - ETA: 2:58 - loss: 1.5156 - regression_loss: 1.2524 - classification_loss: 0.2632
 378/1000 [==========>...................] - ETA: 2:58 - loss: 1.5182 - regression_loss: 1.2548 - classification_loss: 0.2635
 379/1000 [==========>...................] - ETA: 2:57 - loss: 1.5209 - regression_loss: 1.2571 - classification_loss: 0.2638
 380/1000 [==========>...................] - ETA: 2:57 - loss: 1.5213 - regression_loss: 1.2574 - classification_loss: 0.2639
 381/1000 [==========>...................] - ETA: 2:57 - loss: 1.5200 - regression_loss: 1.2563 - classification_loss: 0.2637
 382/1000 [==========>...................] - ETA: 2:57 - loss: 1.5196 - regression_loss: 1.2560 - classification_loss: 0.2637
 383/1000 [==========>...................] - ETA: 2:56 - loss: 1.5204 - regression_loss: 1.2566 - classification_loss: 0.2638
 384/1000 [==========>...................] - ETA: 2:56 - loss: 1.5200 - regression_loss: 1.2562 - classification_loss: 0.2638
 385/1000 [==========>...................] - ETA: 2:56 - loss: 1.5209 - regression_loss: 1.2568 - classification_loss: 0.2641
 386/1000 [==========>...................] - ETA: 2:55 - loss: 1.5230 - regression_loss: 1.2583 - classification_loss: 0.2646
 387/1000 [==========>...................] - ETA: 2:55 - loss: 1.5209 - regression_loss: 1.2566 - classification_loss: 0.2643
 388/1000 [==========>...................] - ETA: 2:55 - loss: 1.5210 - regression_loss: 1.2568 - classification_loss: 0.2642
 389/1000 [==========>...................] - ETA: 2:55 - loss: 1.5202 - regression_loss: 1.2561 - classification_loss: 0.2641
 390/1000 [==========>...................] - ETA: 2:54 - loss: 1.5207 - regression_loss: 1.2562 - classification_loss: 0.2644
 391/1000 [==========>...................] - ETA: 2:54 - loss: 1.5195 - regression_loss: 1.2553 - classification_loss: 0.2642
 392/1000 [==========>...................] - ETA: 2:54 - loss: 1.5195 - regression_loss: 1.2553 - classification_loss: 0.2642
 393/1000 [==========>...................] - ETA: 2:53 - loss: 1.5204 - regression_loss: 1.2556 - classification_loss: 0.2648
 394/1000 [==========>...................] - ETA: 2:53 - loss: 1.5201 - regression_loss: 1.2554 - classification_loss: 0.2647
 395/1000 [==========>...................] - ETA: 2:53 - loss: 1.5183 - regression_loss: 1.2539 - classification_loss: 0.2645
 396/1000 [==========>...................] - ETA: 2:53 - loss: 1.5180 - regression_loss: 1.2534 - classification_loss: 0.2645
 397/1000 [==========>...................] - ETA: 2:52 - loss: 1.5193 - regression_loss: 1.2545 - classification_loss: 0.2648
 398/1000 [==========>...................] - ETA: 2:52 - loss: 1.5182 - regression_loss: 1.2537 - classification_loss: 0.2646
 399/1000 [==========>...................] - ETA: 2:52 - loss: 1.5171 - regression_loss: 1.2528 - classification_loss: 0.2642
 400/1000 [===========>..................] - ETA: 2:51 - loss: 1.5175 - regression_loss: 1.2532 - classification_loss: 0.2643
 401/1000 [===========>..................] - ETA: 2:51 - loss: 1.5190 - regression_loss: 1.2543 - classification_loss: 0.2647
 402/1000 [===========>..................] - ETA: 2:51 - loss: 1.5205 - regression_loss: 1.2558 - classification_loss: 0.2648
 403/1000 [===========>..................] - ETA: 2:51 - loss: 1.5208 - regression_loss: 1.2553 - classification_loss: 0.2655
 404/1000 [===========>..................] - ETA: 2:50 - loss: 1.5223 - regression_loss: 1.2567 - classification_loss: 0.2656
 405/1000 [===========>..................] - ETA: 2:50 - loss: 1.5223 - regression_loss: 1.2567 - classification_loss: 0.2656
 406/1000 [===========>..................] - ETA: 2:50 - loss: 1.5204 - regression_loss: 1.2553 - classification_loss: 0.2651
 407/1000 [===========>..................] - ETA: 2:49 - loss: 1.5193 - regression_loss: 1.2543 - classification_loss: 0.2650
 408/1000 [===========>..................] - ETA: 2:49 - loss: 1.5182 - regression_loss: 1.2535 - classification_loss: 0.2647
 409/1000 [===========>..................] - ETA: 2:49 - loss: 1.5195 - regression_loss: 1.2544 - classification_loss: 0.2651
 410/1000 [===========>..................] - ETA: 2:49 - loss: 1.5196 - regression_loss: 1.2546 - classification_loss: 0.2650
 411/1000 [===========>..................] - ETA: 2:48 - loss: 1.5186 - regression_loss: 1.2539 - classification_loss: 0.2647
 412/1000 [===========>..................] - ETA: 2:48 - loss: 1.5219 - regression_loss: 1.2565 - classification_loss: 0.2654
 413/1000 [===========>..................] - ETA: 2:48 - loss: 1.5204 - regression_loss: 1.2551 - classification_loss: 0.2653
 414/1000 [===========>..................] - ETA: 2:47 - loss: 1.5189 - regression_loss: 1.2538 - classification_loss: 0.2651
 415/1000 [===========>..................] - ETA: 2:47 - loss: 1.5198 - regression_loss: 1.2547 - classification_loss: 0.2652
 416/1000 [===========>..................] - ETA: 2:47 - loss: 1.5206 - regression_loss: 1.2555 - classification_loss: 0.2651
 417/1000 [===========>..................] - ETA: 2:47 - loss: 1.5198 - regression_loss: 1.2549 - classification_loss: 0.2649
 418/1000 [===========>..................] - ETA: 2:46 - loss: 1.5214 - regression_loss: 1.2565 - classification_loss: 0.2649
 419/1000 [===========>..................] - ETA: 2:46 - loss: 1.5220 - regression_loss: 1.2569 - classification_loss: 0.2651
 420/1000 [===========>..................] - ETA: 2:46 - loss: 1.5223 - regression_loss: 1.2572 - classification_loss: 0.2651
 421/1000 [===========>..................] - ETA: 2:45 - loss: 1.5221 - regression_loss: 1.2572 - classification_loss: 0.2649
 422/1000 [===========>..................] - ETA: 2:45 - loss: 1.5229 - regression_loss: 1.2581 - classification_loss: 0.2648
 423/1000 [===========>..................] - ETA: 2:45 - loss: 1.5230 - regression_loss: 1.2583 - classification_loss: 0.2647
 424/1000 [===========>..................] - ETA: 2:45 - loss: 1.5215 - regression_loss: 1.2570 - classification_loss: 0.2645
 425/1000 [===========>..................] - ETA: 2:44 - loss: 1.5203 - regression_loss: 1.2560 - classification_loss: 0.2642
 426/1000 [===========>..................] - ETA: 2:44 - loss: 1.5181 - regression_loss: 1.2543 - classification_loss: 0.2638
 427/1000 [===========>..................] - ETA: 2:44 - loss: 1.5183 - regression_loss: 1.2546 - classification_loss: 0.2637
 428/1000 [===========>..................] - ETA: 2:43 - loss: 1.5171 - regression_loss: 1.2535 - classification_loss: 0.2636
 429/1000 [===========>..................] - ETA: 2:43 - loss: 1.5154 - regression_loss: 1.2522 - classification_loss: 0.2633
 430/1000 [===========>..................] - ETA: 2:43 - loss: 1.5155 - regression_loss: 1.2523 - classification_loss: 0.2631
 431/1000 [===========>..................] - ETA: 2:43 - loss: 1.5151 - regression_loss: 1.2522 - classification_loss: 0.2629
 432/1000 [===========>..................] - ETA: 2:42 - loss: 1.5162 - regression_loss: 1.2531 - classification_loss: 0.2631
 433/1000 [===========>..................] - ETA: 2:42 - loss: 1.5165 - regression_loss: 1.2535 - classification_loss: 0.2630
 434/1000 [============>.................] - ETA: 2:42 - loss: 1.5161 - regression_loss: 1.2534 - classification_loss: 0.2627
 435/1000 [============>.................] - ETA: 2:41 - loss: 1.5149 - regression_loss: 1.2524 - classification_loss: 0.2625
 436/1000 [============>.................] - ETA: 2:41 - loss: 1.5160 - regression_loss: 1.2530 - classification_loss: 0.2630
 437/1000 [============>.................] - ETA: 2:41 - loss: 1.5158 - regression_loss: 1.2528 - classification_loss: 0.2630
 438/1000 [============>.................] - ETA: 2:41 - loss: 1.5185 - regression_loss: 1.2547 - classification_loss: 0.2639
 439/1000 [============>.................] - ETA: 2:40 - loss: 1.5181 - regression_loss: 1.2545 - classification_loss: 0.2636
 440/1000 [============>.................] - ETA: 2:40 - loss: 1.5163 - regression_loss: 1.2531 - classification_loss: 0.2632
 441/1000 [============>.................] - ETA: 2:40 - loss: 1.5178 - regression_loss: 1.2543 - classification_loss: 0.2634
 442/1000 [============>.................] - ETA: 2:39 - loss: 1.5164 - regression_loss: 1.2532 - classification_loss: 0.2632
 443/1000 [============>.................] - ETA: 2:39 - loss: 1.5151 - regression_loss: 1.2522 - classification_loss: 0.2629
 444/1000 [============>.................] - ETA: 2:39 - loss: 1.5139 - regression_loss: 1.2512 - classification_loss: 0.2626
 445/1000 [============>.................] - ETA: 2:39 - loss: 1.5137 - regression_loss: 1.2512 - classification_loss: 0.2625
 446/1000 [============>.................] - ETA: 2:38 - loss: 1.5147 - regression_loss: 1.2519 - classification_loss: 0.2627
 447/1000 [============>.................] - ETA: 2:38 - loss: 1.5160 - regression_loss: 1.2526 - classification_loss: 0.2634
 448/1000 [============>.................] - ETA: 2:38 - loss: 1.5148 - regression_loss: 1.2516 - classification_loss: 0.2632
 449/1000 [============>.................] - ETA: 2:37 - loss: 1.5147 - regression_loss: 1.2515 - classification_loss: 0.2633
 450/1000 [============>.................] - ETA: 2:37 - loss: 1.5131 - regression_loss: 1.2496 - classification_loss: 0.2635
 451/1000 [============>.................] - ETA: 2:37 - loss: 1.5128 - regression_loss: 1.2495 - classification_loss: 0.2633
 452/1000 [============>.................] - ETA: 2:37 - loss: 1.5145 - regression_loss: 1.2510 - classification_loss: 0.2635
 453/1000 [============>.................] - ETA: 2:36 - loss: 1.5142 - regression_loss: 1.2507 - classification_loss: 0.2635
 454/1000 [============>.................] - ETA: 2:36 - loss: 1.5140 - regression_loss: 1.2506 - classification_loss: 0.2634
 455/1000 [============>.................] - ETA: 2:36 - loss: 1.5127 - regression_loss: 1.2495 - classification_loss: 0.2632
 456/1000 [============>.................] - ETA: 2:35 - loss: 1.5123 - regression_loss: 1.2494 - classification_loss: 0.2629
 457/1000 [============>.................] - ETA: 2:35 - loss: 1.5123 - regression_loss: 1.2492 - classification_loss: 0.2631
 458/1000 [============>.................] - ETA: 2:35 - loss: 1.5127 - regression_loss: 1.2494 - classification_loss: 0.2633
 459/1000 [============>.................] - ETA: 2:35 - loss: 1.5122 - regression_loss: 1.2489 - classification_loss: 0.2632
 460/1000 [============>.................] - ETA: 2:34 - loss: 1.5106 - regression_loss: 1.2478 - classification_loss: 0.2628
 461/1000 [============>.................] - ETA: 2:34 - loss: 1.5119 - regression_loss: 1.2490 - classification_loss: 0.2628
 462/1000 [============>.................] - ETA: 2:34 - loss: 1.5102 - regression_loss: 1.2475 - classification_loss: 0.2628
 463/1000 [============>.................] - ETA: 2:33 - loss: 1.5095 - regression_loss: 1.2469 - classification_loss: 0.2626
 464/1000 [============>.................] - ETA: 2:33 - loss: 1.5097 - regression_loss: 1.2470 - classification_loss: 0.2627
 465/1000 [============>.................] - ETA: 2:33 - loss: 1.5098 - regression_loss: 1.2471 - classification_loss: 0.2627
 466/1000 [============>.................] - ETA: 2:33 - loss: 1.5106 - regression_loss: 1.2480 - classification_loss: 0.2626
 467/1000 [=============>................] - ETA: 2:32 - loss: 1.5098 - regression_loss: 1.2475 - classification_loss: 0.2624
 468/1000 [=============>................] - ETA: 2:32 - loss: 1.5087 - regression_loss: 1.2466 - classification_loss: 0.2621
 469/1000 [=============>................] - ETA: 2:32 - loss: 1.5109 - regression_loss: 1.2481 - classification_loss: 0.2628
 470/1000 [=============>................] - ETA: 2:31 - loss: 1.5102 - regression_loss: 1.2474 - classification_loss: 0.2629
 471/1000 [=============>................] - ETA: 2:31 - loss: 1.5102 - regression_loss: 1.2474 - classification_loss: 0.2628
 472/1000 [=============>................] - ETA: 2:31 - loss: 1.5102 - regression_loss: 1.2476 - classification_loss: 0.2626
 473/1000 [=============>................] - ETA: 2:31 - loss: 1.5097 - regression_loss: 1.2472 - classification_loss: 0.2624
 474/1000 [=============>................] - ETA: 2:30 - loss: 1.5086 - regression_loss: 1.2466 - classification_loss: 0.2621
 475/1000 [=============>................] - ETA: 2:30 - loss: 1.5071 - regression_loss: 1.2453 - classification_loss: 0.2618
 476/1000 [=============>................] - ETA: 2:30 - loss: 1.5082 - regression_loss: 1.2463 - classification_loss: 0.2620
 477/1000 [=============>................] - ETA: 2:29 - loss: 1.5077 - regression_loss: 1.2455 - classification_loss: 0.2622
 478/1000 [=============>................] - ETA: 2:29 - loss: 1.5087 - regression_loss: 1.2464 - classification_loss: 0.2623
 479/1000 [=============>................] - ETA: 2:29 - loss: 1.5101 - regression_loss: 1.2475 - classification_loss: 0.2626
 480/1000 [=============>................] - ETA: 2:29 - loss: 1.5107 - regression_loss: 1.2481 - classification_loss: 0.2626
 481/1000 [=============>................] - ETA: 2:28 - loss: 1.5103 - regression_loss: 1.2478 - classification_loss: 0.2624
 482/1000 [=============>................] - ETA: 2:28 - loss: 1.5092 - regression_loss: 1.2471 - classification_loss: 0.2621
 483/1000 [=============>................] - ETA: 2:28 - loss: 1.5088 - regression_loss: 1.2468 - classification_loss: 0.2619
 484/1000 [=============>................] - ETA: 2:27 - loss: 1.5086 - regression_loss: 1.2469 - classification_loss: 0.2617
 485/1000 [=============>................] - ETA: 2:27 - loss: 1.5079 - regression_loss: 1.2464 - classification_loss: 0.2615
 486/1000 [=============>................] - ETA: 2:27 - loss: 1.5074 - regression_loss: 1.2461 - classification_loss: 0.2614
 487/1000 [=============>................] - ETA: 2:27 - loss: 1.5273 - regression_loss: 1.2435 - classification_loss: 0.2838
 488/1000 [=============>................] - ETA: 2:26 - loss: 1.5279 - regression_loss: 1.2443 - classification_loss: 0.2836
 489/1000 [=============>................] - ETA: 2:26 - loss: 1.5264 - regression_loss: 1.2429 - classification_loss: 0.2836
 490/1000 [=============>................] - ETA: 2:26 - loss: 1.5258 - regression_loss: 1.2424 - classification_loss: 0.2834
 491/1000 [=============>................] - ETA: 2:25 - loss: 1.5257 - regression_loss: 1.2426 - classification_loss: 0.2831
 492/1000 [=============>................] - ETA: 2:25 - loss: 1.5250 - regression_loss: 1.2421 - classification_loss: 0.2829
 493/1000 [=============>................] - ETA: 2:25 - loss: 1.5246 - regression_loss: 1.2418 - classification_loss: 0.2828
 494/1000 [=============>................] - ETA: 2:25 - loss: 1.5232 - regression_loss: 1.2406 - classification_loss: 0.2826
 495/1000 [=============>................] - ETA: 2:24 - loss: 1.5246 - regression_loss: 1.2420 - classification_loss: 0.2827
 496/1000 [=============>................] - ETA: 2:24 - loss: 1.5256 - regression_loss: 1.2427 - classification_loss: 0.2829
 497/1000 [=============>................] - ETA: 2:24 - loss: 1.5280 - regression_loss: 1.2446 - classification_loss: 0.2834
 498/1000 [=============>................] - ETA: 2:23 - loss: 1.5276 - regression_loss: 1.2442 - classification_loss: 0.2834
 499/1000 [=============>................] - ETA: 2:23 - loss: 1.5261 - regression_loss: 1.2430 - classification_loss: 0.2831
 500/1000 [==============>...............] - ETA: 2:23 - loss: 1.5251 - regression_loss: 1.2424 - classification_loss: 0.2827
 501/1000 [==============>...............] - ETA: 2:23 - loss: 1.5247 - regression_loss: 1.2423 - classification_loss: 0.2824
 502/1000 [==============>...............] - ETA: 2:22 - loss: 1.5244 - regression_loss: 1.2421 - classification_loss: 0.2822
 503/1000 [==============>...............] - ETA: 2:22 - loss: 1.5241 - regression_loss: 1.2420 - classification_loss: 0.2821
 504/1000 [==============>...............] - ETA: 2:22 - loss: 1.5245 - regression_loss: 1.2424 - classification_loss: 0.2821
 505/1000 [==============>...............] - ETA: 2:21 - loss: 1.5234 - regression_loss: 1.2416 - classification_loss: 0.2818
 506/1000 [==============>...............] - ETA: 2:21 - loss: 1.5273 - regression_loss: 1.2443 - classification_loss: 0.2830
 507/1000 [==============>...............] - ETA: 2:21 - loss: 1.5296 - regression_loss: 1.2462 - classification_loss: 0.2834
 508/1000 [==============>...............] - ETA: 2:21 - loss: 1.5292 - regression_loss: 1.2459 - classification_loss: 0.2832
 509/1000 [==============>...............] - ETA: 2:20 - loss: 1.5285 - regression_loss: 1.2455 - classification_loss: 0.2830
 510/1000 [==============>...............] - ETA: 2:20 - loss: 1.5286 - regression_loss: 1.2457 - classification_loss: 0.2830
 511/1000 [==============>...............] - ETA: 2:20 - loss: 1.5293 - regression_loss: 1.2463 - classification_loss: 0.2830
 512/1000 [==============>...............] - ETA: 2:19 - loss: 1.5300 - regression_loss: 1.2470 - classification_loss: 0.2830
 513/1000 [==============>...............] - ETA: 2:19 - loss: 1.5323 - regression_loss: 1.2487 - classification_loss: 0.2836
 514/1000 [==============>...............] - ETA: 2:19 - loss: 1.5316 - regression_loss: 1.2482 - classification_loss: 0.2833
 515/1000 [==============>...............] - ETA: 2:19 - loss: 1.5306 - regression_loss: 1.2474 - classification_loss: 0.2832
 516/1000 [==============>...............] - ETA: 2:18 - loss: 1.5320 - regression_loss: 1.2485 - classification_loss: 0.2835
 517/1000 [==============>...............] - ETA: 2:18 - loss: 1.5307 - regression_loss: 1.2474 - classification_loss: 0.2833
 518/1000 [==============>...............] - ETA: 2:18 - loss: 1.5304 - regression_loss: 1.2473 - classification_loss: 0.2830
 519/1000 [==============>...............] - ETA: 2:17 - loss: 1.5291 - regression_loss: 1.2463 - classification_loss: 0.2828
 520/1000 [==============>...............] - ETA: 2:17 - loss: 1.5286 - regression_loss: 1.2460 - classification_loss: 0.2827
 521/1000 [==============>...............] - ETA: 2:17 - loss: 1.5296 - regression_loss: 1.2469 - classification_loss: 0.2827
 522/1000 [==============>...............] - ETA: 2:17 - loss: 1.5286 - regression_loss: 1.2460 - classification_loss: 0.2826
 523/1000 [==============>...............] - ETA: 2:16 - loss: 1.5271 - regression_loss: 1.2448 - classification_loss: 0.2823
 524/1000 [==============>...............] - ETA: 2:16 - loss: 1.5262 - regression_loss: 1.2442 - classification_loss: 0.2820
 525/1000 [==============>...............] - ETA: 2:16 - loss: 1.5257 - regression_loss: 1.2438 - classification_loss: 0.2819
 526/1000 [==============>...............] - ETA: 2:15 - loss: 1.5262 - regression_loss: 1.2442 - classification_loss: 0.2821
 527/1000 [==============>...............] - ETA: 2:15 - loss: 1.5250 - regression_loss: 1.2432 - classification_loss: 0.2818
 528/1000 [==============>...............] - ETA: 2:15 - loss: 1.5252 - regression_loss: 1.2434 - classification_loss: 0.2818
 529/1000 [==============>...............] - ETA: 2:15 - loss: 1.5255 - regression_loss: 1.2439 - classification_loss: 0.2816
 530/1000 [==============>...............] - ETA: 2:14 - loss: 1.5259 - regression_loss: 1.2443 - classification_loss: 0.2816
 531/1000 [==============>...............] - ETA: 2:14 - loss: 1.5269 - regression_loss: 1.2452 - classification_loss: 0.2817
 532/1000 [==============>...............] - ETA: 2:14 - loss: 1.5268 - regression_loss: 1.2448 - classification_loss: 0.2819
 533/1000 [==============>...............] - ETA: 2:13 - loss: 1.5279 - regression_loss: 1.2458 - classification_loss: 0.2821
 534/1000 [===============>..............] - ETA: 2:13 - loss: 1.5271 - regression_loss: 1.2452 - classification_loss: 0.2819
 535/1000 [===============>..............] - ETA: 2:13 - loss: 1.5258 - regression_loss: 1.2441 - classification_loss: 0.2817
 536/1000 [===============>..............] - ETA: 2:13 - loss: 1.5248 - regression_loss: 1.2433 - classification_loss: 0.2815
 537/1000 [===============>..............] - ETA: 2:12 - loss: 1.5236 - regression_loss: 1.2421 - classification_loss: 0.2815
 538/1000 [===============>..............] - ETA: 2:12 - loss: 1.5243 - regression_loss: 1.2428 - classification_loss: 0.2815
 539/1000 [===============>..............] - ETA: 2:12 - loss: 1.5237 - regression_loss: 1.2425 - classification_loss: 0.2813
 540/1000 [===============>..............] - ETA: 2:11 - loss: 1.5226 - regression_loss: 1.2416 - classification_loss: 0.2810
 541/1000 [===============>..............] - ETA: 2:11 - loss: 1.5241 - regression_loss: 1.2428 - classification_loss: 0.2813
 542/1000 [===============>..............] - ETA: 2:11 - loss: 1.5229 - regression_loss: 1.2418 - classification_loss: 0.2812
 543/1000 [===============>..............] - ETA: 2:10 - loss: 1.5234 - regression_loss: 1.2421 - classification_loss: 0.2812
 544/1000 [===============>..............] - ETA: 2:10 - loss: 1.5247 - regression_loss: 1.2432 - classification_loss: 0.2815
 545/1000 [===============>..............] - ETA: 2:10 - loss: 1.5252 - regression_loss: 1.2437 - classification_loss: 0.2815
 546/1000 [===============>..............] - ETA: 2:10 - loss: 1.5247 - regression_loss: 1.2435 - classification_loss: 0.2813
 547/1000 [===============>..............] - ETA: 2:09 - loss: 1.5251 - regression_loss: 1.2440 - classification_loss: 0.2810
 548/1000 [===============>..............] - ETA: 2:09 - loss: 1.5259 - regression_loss: 1.2449 - classification_loss: 0.2810
 549/1000 [===============>..............] - ETA: 2:09 - loss: 1.5249 - regression_loss: 1.2443 - classification_loss: 0.2807
 550/1000 [===============>..............] - ETA: 2:08 - loss: 1.5248 - regression_loss: 1.2440 - classification_loss: 0.2808
 551/1000 [===============>..............] - ETA: 2:08 - loss: 1.5239 - regression_loss: 1.2434 - classification_loss: 0.2805
 552/1000 [===============>..............] - ETA: 2:08 - loss: 1.5228 - regression_loss: 1.2427 - classification_loss: 0.2801
 553/1000 [===============>..............] - ETA: 2:08 - loss: 1.5221 - regression_loss: 1.2423 - classification_loss: 0.2799
 554/1000 [===============>..............] - ETA: 2:07 - loss: 1.5210 - regression_loss: 1.2414 - classification_loss: 0.2796
 555/1000 [===============>..............] - ETA: 2:07 - loss: 1.5208 - regression_loss: 1.2414 - classification_loss: 0.2794
 556/1000 [===============>..............] - ETA: 2:07 - loss: 1.5215 - regression_loss: 1.2421 - classification_loss: 0.2794
 557/1000 [===============>..............] - ETA: 2:06 - loss: 1.5208 - regression_loss: 1.2415 - classification_loss: 0.2793
 558/1000 [===============>..............] - ETA: 2:06 - loss: 1.5210 - regression_loss: 1.2418 - classification_loss: 0.2792
 559/1000 [===============>..............] - ETA: 2:06 - loss: 1.5195 - regression_loss: 1.2405 - classification_loss: 0.2789
 560/1000 [===============>..............] - ETA: 2:06 - loss: 1.5194 - regression_loss: 1.2406 - classification_loss: 0.2788
 561/1000 [===============>..............] - ETA: 2:05 - loss: 1.5194 - regression_loss: 1.2408 - classification_loss: 0.2785
 562/1000 [===============>..............] - ETA: 2:05 - loss: 1.5196 - regression_loss: 1.2411 - classification_loss: 0.2784
 563/1000 [===============>..............] - ETA: 2:05 - loss: 1.5203 - regression_loss: 1.2420 - classification_loss: 0.2783
 564/1000 [===============>..............] - ETA: 2:04 - loss: 1.5201 - regression_loss: 1.2417 - classification_loss: 0.2784
 565/1000 [===============>..............] - ETA: 2:04 - loss: 1.5202 - regression_loss: 1.2419 - classification_loss: 0.2783
 566/1000 [===============>..............] - ETA: 2:04 - loss: 1.5225 - regression_loss: 1.2436 - classification_loss: 0.2789
 567/1000 [================>.............] - ETA: 2:04 - loss: 1.5230 - regression_loss: 1.2442 - classification_loss: 0.2788
 568/1000 [================>.............] - ETA: 2:03 - loss: 1.5229 - regression_loss: 1.2443 - classification_loss: 0.2786
 569/1000 [================>.............] - ETA: 2:03 - loss: 1.5242 - regression_loss: 1.2456 - classification_loss: 0.2786
 570/1000 [================>.............] - ETA: 2:03 - loss: 1.5251 - regression_loss: 1.2466 - classification_loss: 0.2785
 571/1000 [================>.............] - ETA: 2:02 - loss: 1.5272 - regression_loss: 1.2484 - classification_loss: 0.2788
 572/1000 [================>.............] - ETA: 2:02 - loss: 1.5286 - regression_loss: 1.2498 - classification_loss: 0.2788
 573/1000 [================>.............] - ETA: 2:02 - loss: 1.5281 - regression_loss: 1.2495 - classification_loss: 0.2786
 574/1000 [================>.............] - ETA: 2:02 - loss: 1.5275 - regression_loss: 1.2490 - classification_loss: 0.2784
 575/1000 [================>.............] - ETA: 2:01 - loss: 1.5268 - regression_loss: 1.2485 - classification_loss: 0.2783
 576/1000 [================>.............] - ETA: 2:01 - loss: 1.5265 - regression_loss: 1.2483 - classification_loss: 0.2781
 577/1000 [================>.............] - ETA: 2:01 - loss: 1.5264 - regression_loss: 1.2485 - classification_loss: 0.2780
 578/1000 [================>.............] - ETA: 2:00 - loss: 1.5268 - regression_loss: 1.2490 - classification_loss: 0.2778
 579/1000 [================>.............] - ETA: 2:00 - loss: 1.5255 - regression_loss: 1.2480 - classification_loss: 0.2775
 580/1000 [================>.............] - ETA: 2:00 - loss: 1.5240 - regression_loss: 1.2468 - classification_loss: 0.2771
 581/1000 [================>.............] - ETA: 2:00 - loss: 1.5236 - regression_loss: 1.2466 - classification_loss: 0.2769
 582/1000 [================>.............] - ETA: 1:59 - loss: 1.5233 - regression_loss: 1.2466 - classification_loss: 0.2767
 583/1000 [================>.............] - ETA: 1:59 - loss: 1.5227 - regression_loss: 1.2462 - classification_loss: 0.2765
 584/1000 [================>.............] - ETA: 1:59 - loss: 1.5228 - regression_loss: 1.2463 - classification_loss: 0.2765
 585/1000 [================>.............] - ETA: 1:58 - loss: 1.5225 - regression_loss: 1.2461 - classification_loss: 0.2764
 586/1000 [================>.............] - ETA: 1:58 - loss: 1.5233 - regression_loss: 1.2469 - classification_loss: 0.2764
 587/1000 [================>.............] - ETA: 1:58 - loss: 1.5246 - regression_loss: 1.2478 - classification_loss: 0.2767
 588/1000 [================>.............] - ETA: 1:58 - loss: 1.5248 - regression_loss: 1.2482 - classification_loss: 0.2767
 589/1000 [================>.............] - ETA: 1:57 - loss: 1.5247 - regression_loss: 1.2482 - classification_loss: 0.2765
 590/1000 [================>.............] - ETA: 1:57 - loss: 1.5245 - regression_loss: 1.2481 - classification_loss: 0.2764
 591/1000 [================>.............] - ETA: 1:57 - loss: 1.5241 - regression_loss: 1.2476 - classification_loss: 0.2765
 592/1000 [================>.............] - ETA: 1:56 - loss: 1.5248 - regression_loss: 1.2484 - classification_loss: 0.2765
 593/1000 [================>.............] - ETA: 1:56 - loss: 1.5249 - regression_loss: 1.2485 - classification_loss: 0.2764
 594/1000 [================>.............] - ETA: 1:56 - loss: 1.5244 - regression_loss: 1.2482 - classification_loss: 0.2762
 595/1000 [================>.............] - ETA: 1:56 - loss: 1.5240 - regression_loss: 1.2480 - classification_loss: 0.2760
 596/1000 [================>.............] - ETA: 1:55 - loss: 1.5254 - regression_loss: 1.2494 - classification_loss: 0.2761
 597/1000 [================>.............] - ETA: 1:55 - loss: 1.5256 - regression_loss: 1.2495 - classification_loss: 0.2760
 598/1000 [================>.............] - ETA: 1:55 - loss: 1.5261 - regression_loss: 1.2500 - classification_loss: 0.2761
 599/1000 [================>.............] - ETA: 1:54 - loss: 1.5273 - regression_loss: 1.2509 - classification_loss: 0.2764
 600/1000 [=================>............] - ETA: 1:54 - loss: 1.5280 - regression_loss: 1.2516 - classification_loss: 0.2764
 601/1000 [=================>............] - ETA: 1:54 - loss: 1.5279 - regression_loss: 1.2516 - classification_loss: 0.2763
 602/1000 [=================>............] - ETA: 1:54 - loss: 1.5283 - regression_loss: 1.2518 - classification_loss: 0.2765
 603/1000 [=================>............] - ETA: 1:53 - loss: 1.5271 - regression_loss: 1.2507 - classification_loss: 0.2763
 604/1000 [=================>............] - ETA: 1:53 - loss: 1.5263 - regression_loss: 1.2501 - classification_loss: 0.2762
 605/1000 [=================>............] - ETA: 1:53 - loss: 1.5281 - regression_loss: 1.2514 - classification_loss: 0.2767
 606/1000 [=================>............] - ETA: 1:52 - loss: 1.5292 - regression_loss: 1.2520 - classification_loss: 0.2772
 607/1000 [=================>............] - ETA: 1:52 - loss: 1.5286 - regression_loss: 1.2515 - classification_loss: 0.2772
 608/1000 [=================>............] - ETA: 1:52 - loss: 1.5280 - regression_loss: 1.2508 - classification_loss: 0.2771
 609/1000 [=================>............] - ETA: 1:52 - loss: 1.5282 - regression_loss: 1.2513 - classification_loss: 0.2770
 610/1000 [=================>............] - ETA: 1:51 - loss: 1.5285 - regression_loss: 1.2515 - classification_loss: 0.2770
 611/1000 [=================>............] - ETA: 1:51 - loss: 1.5284 - regression_loss: 1.2512 - classification_loss: 0.2772
 612/1000 [=================>............] - ETA: 1:51 - loss: 1.5295 - regression_loss: 1.2518 - classification_loss: 0.2776
 613/1000 [=================>............] - ETA: 1:50 - loss: 1.5292 - regression_loss: 1.2518 - classification_loss: 0.2774
 614/1000 [=================>............] - ETA: 1:50 - loss: 1.5277 - regression_loss: 1.2507 - classification_loss: 0.2771
 615/1000 [=================>............] - ETA: 1:50 - loss: 1.5285 - regression_loss: 1.2515 - classification_loss: 0.2770
 616/1000 [=================>............] - ETA: 1:50 - loss: 1.5275 - regression_loss: 1.2507 - classification_loss: 0.2768
 617/1000 [=================>............] - ETA: 1:49 - loss: 1.5267 - regression_loss: 1.2501 - classification_loss: 0.2765
 618/1000 [=================>............] - ETA: 1:49 - loss: 1.5269 - regression_loss: 1.2504 - classification_loss: 0.2765
 619/1000 [=================>............] - ETA: 1:49 - loss: 1.5283 - regression_loss: 1.2520 - classification_loss: 0.2763
 620/1000 [=================>............] - ETA: 1:48 - loss: 1.5272 - regression_loss: 1.2512 - classification_loss: 0.2761
 621/1000 [=================>............] - ETA: 1:48 - loss: 1.5260 - regression_loss: 1.2501 - classification_loss: 0.2759
 622/1000 [=================>............] - ETA: 1:48 - loss: 1.5267 - regression_loss: 1.2499 - classification_loss: 0.2767
 623/1000 [=================>............] - ETA: 1:48 - loss: 1.5263 - regression_loss: 1.2497 - classification_loss: 0.2766
 624/1000 [=================>............] - ETA: 1:47 - loss: 1.5257 - regression_loss: 1.2494 - classification_loss: 0.2764
 625/1000 [=================>............] - ETA: 1:47 - loss: 1.5246 - regression_loss: 1.2484 - classification_loss: 0.2762
 626/1000 [=================>............] - ETA: 1:47 - loss: 1.5244 - regression_loss: 1.2483 - classification_loss: 0.2761
 627/1000 [=================>............] - ETA: 1:46 - loss: 1.5250 - regression_loss: 1.2488 - classification_loss: 0.2762
 628/1000 [=================>............] - ETA: 1:46 - loss: 1.5241 - regression_loss: 1.2481 - classification_loss: 0.2760
 629/1000 [=================>............] - ETA: 1:46 - loss: 1.5243 - regression_loss: 1.2481 - classification_loss: 0.2762
 630/1000 [=================>............] - ETA: 1:46 - loss: 1.5234 - regression_loss: 1.2475 - classification_loss: 0.2760
 631/1000 [=================>............] - ETA: 1:45 - loss: 1.5237 - regression_loss: 1.2478 - classification_loss: 0.2760
 632/1000 [=================>............] - ETA: 1:45 - loss: 1.5236 - regression_loss: 1.2476 - classification_loss: 0.2760
 633/1000 [=================>............] - ETA: 1:45 - loss: 1.5234 - regression_loss: 1.2475 - classification_loss: 0.2759
 634/1000 [==================>...........] - ETA: 1:44 - loss: 1.5241 - regression_loss: 1.2481 - classification_loss: 0.2760
 635/1000 [==================>...........] - ETA: 1:44 - loss: 1.5231 - regression_loss: 1.2473 - classification_loss: 0.2758
 636/1000 [==================>...........] - ETA: 1:44 - loss: 1.5234 - regression_loss: 1.2476 - classification_loss: 0.2758
 637/1000 [==================>...........] - ETA: 1:44 - loss: 1.5234 - regression_loss: 1.2477 - classification_loss: 0.2757
 638/1000 [==================>...........] - ETA: 1:43 - loss: 1.5224 - regression_loss: 1.2469 - classification_loss: 0.2755
 639/1000 [==================>...........] - ETA: 1:43 - loss: 1.5222 - regression_loss: 1.2470 - classification_loss: 0.2752
 640/1000 [==================>...........] - ETA: 1:43 - loss: 1.5212 - regression_loss: 1.2462 - classification_loss: 0.2749
 641/1000 [==================>...........] - ETA: 1:42 - loss: 1.5215 - regression_loss: 1.2465 - classification_loss: 0.2749
 642/1000 [==================>...........] - ETA: 1:42 - loss: 1.5194 - regression_loss: 1.2446 - classification_loss: 0.2748
 643/1000 [==================>...........] - ETA: 1:42 - loss: 1.5201 - regression_loss: 1.2453 - classification_loss: 0.2748
 644/1000 [==================>...........] - ETA: 1:42 - loss: 1.5213 - regression_loss: 1.2464 - classification_loss: 0.2749
 645/1000 [==================>...........] - ETA: 1:41 - loss: 1.5210 - regression_loss: 1.2462 - classification_loss: 0.2748
 646/1000 [==================>...........] - ETA: 1:41 - loss: 1.5201 - regression_loss: 1.2453 - classification_loss: 0.2748
 647/1000 [==================>...........] - ETA: 1:41 - loss: 1.5213 - regression_loss: 1.2463 - classification_loss: 0.2750
 648/1000 [==================>...........] - ETA: 1:40 - loss: 1.5200 - regression_loss: 1.2453 - classification_loss: 0.2748
 649/1000 [==================>...........] - ETA: 1:40 - loss: 1.5198 - regression_loss: 1.2451 - classification_loss: 0.2747
 650/1000 [==================>...........] - ETA: 1:40 - loss: 1.5188 - regression_loss: 1.2443 - classification_loss: 0.2745
 651/1000 [==================>...........] - ETA: 1:40 - loss: 1.5186 - regression_loss: 1.2442 - classification_loss: 0.2744
 652/1000 [==================>...........] - ETA: 1:39 - loss: 1.5194 - regression_loss: 1.2447 - classification_loss: 0.2747
 653/1000 [==================>...........] - ETA: 1:39 - loss: 1.5184 - regression_loss: 1.2440 - classification_loss: 0.2744
 654/1000 [==================>...........] - ETA: 1:39 - loss: 1.5178 - regression_loss: 1.2436 - classification_loss: 0.2742
 655/1000 [==================>...........] - ETA: 1:38 - loss: 1.5171 - regression_loss: 1.2431 - classification_loss: 0.2741
 656/1000 [==================>...........] - ETA: 1:38 - loss: 1.5163 - regression_loss: 1.2425 - classification_loss: 0.2738
 657/1000 [==================>...........] - ETA: 1:38 - loss: 1.5159 - regression_loss: 1.2422 - classification_loss: 0.2738
 658/1000 [==================>...........] - ETA: 1:38 - loss: 1.5173 - regression_loss: 1.2430 - classification_loss: 0.2743
 659/1000 [==================>...........] - ETA: 1:37 - loss: 1.5178 - regression_loss: 1.2433 - classification_loss: 0.2746
 660/1000 [==================>...........] - ETA: 1:37 - loss: 1.5167 - regression_loss: 1.2424 - classification_loss: 0.2743
 661/1000 [==================>...........] - ETA: 1:37 - loss: 1.5163 - regression_loss: 1.2420 - classification_loss: 0.2743
 662/1000 [==================>...........] - ETA: 1:36 - loss: 1.5157 - regression_loss: 1.2414 - classification_loss: 0.2743
 663/1000 [==================>...........] - ETA: 1:36 - loss: 1.5142 - regression_loss: 1.2401 - classification_loss: 0.2741
 664/1000 [==================>...........] - ETA: 1:36 - loss: 1.5158 - regression_loss: 1.2413 - classification_loss: 0.2744
 665/1000 [==================>...........] - ETA: 1:36 - loss: 1.5162 - regression_loss: 1.2417 - classification_loss: 0.2745
 666/1000 [==================>...........] - ETA: 1:35 - loss: 1.5158 - regression_loss: 1.2415 - classification_loss: 0.2743
 667/1000 [===================>..........] - ETA: 1:35 - loss: 1.5156 - regression_loss: 1.2413 - classification_loss: 0.2743
 668/1000 [===================>..........] - ETA: 1:35 - loss: 1.5147 - regression_loss: 1.2405 - classification_loss: 0.2742
 669/1000 [===================>..........] - ETA: 1:34 - loss: 1.5149 - regression_loss: 1.2405 - classification_loss: 0.2744
 670/1000 [===================>..........] - ETA: 1:34 - loss: 1.5160 - regression_loss: 1.2416 - classification_loss: 0.2743
 671/1000 [===================>..........] - ETA: 1:34 - loss: 1.5157 - regression_loss: 1.2413 - classification_loss: 0.2744
 672/1000 [===================>..........] - ETA: 1:34 - loss: 1.5161 - regression_loss: 1.2419 - classification_loss: 0.2742
 673/1000 [===================>..........] - ETA: 1:33 - loss: 1.5154 - regression_loss: 1.2412 - classification_loss: 0.2742
 674/1000 [===================>..........] - ETA: 1:33 - loss: 1.5173 - regression_loss: 1.2423 - classification_loss: 0.2750
 675/1000 [===================>..........] - ETA: 1:33 - loss: 1.5173 - regression_loss: 1.2424 - classification_loss: 0.2749
 676/1000 [===================>..........] - ETA: 1:32 - loss: 1.5171 - regression_loss: 1.2421 - classification_loss: 0.2750
 677/1000 [===================>..........] - ETA: 1:32 - loss: 1.5158 - regression_loss: 1.2410 - classification_loss: 0.2748
 678/1000 [===================>..........] - ETA: 1:32 - loss: 1.5157 - regression_loss: 1.2410 - classification_loss: 0.2747
 679/1000 [===================>..........] - ETA: 1:32 - loss: 1.5151 - regression_loss: 1.2405 - classification_loss: 0.2746
 680/1000 [===================>..........] - ETA: 1:31 - loss: 1.5146 - regression_loss: 1.2402 - classification_loss: 0.2744
 681/1000 [===================>..........] - ETA: 1:31 - loss: 1.5154 - regression_loss: 1.2410 - classification_loss: 0.2744
 682/1000 [===================>..........] - ETA: 1:31 - loss: 1.5152 - regression_loss: 1.2409 - classification_loss: 0.2743
 683/1000 [===================>..........] - ETA: 1:30 - loss: 1.5158 - regression_loss: 1.2411 - classification_loss: 0.2746
 684/1000 [===================>..........] - ETA: 1:30 - loss: 1.5147 - regression_loss: 1.2401 - classification_loss: 0.2745
 685/1000 [===================>..........] - ETA: 1:30 - loss: 1.5153 - regression_loss: 1.2404 - classification_loss: 0.2750
 686/1000 [===================>..........] - ETA: 1:30 - loss: 1.5145 - regression_loss: 1.2396 - classification_loss: 0.2750
 687/1000 [===================>..........] - ETA: 1:29 - loss: 1.5142 - regression_loss: 1.2393 - classification_loss: 0.2748
 688/1000 [===================>..........] - ETA: 1:29 - loss: 1.5138 - regression_loss: 1.2391 - classification_loss: 0.2748
 689/1000 [===================>..........] - ETA: 1:29 - loss: 1.5138 - regression_loss: 1.2391 - classification_loss: 0.2747
 690/1000 [===================>..........] - ETA: 1:28 - loss: 1.5185 - regression_loss: 1.2373 - classification_loss: 0.2812
 691/1000 [===================>..........] - ETA: 1:28 - loss: 1.5178 - regression_loss: 1.2367 - classification_loss: 0.2810
 692/1000 [===================>..........] - ETA: 1:28 - loss: 1.5176 - regression_loss: 1.2366 - classification_loss: 0.2809
 693/1000 [===================>..........] - ETA: 1:27 - loss: 1.5181 - regression_loss: 1.2370 - classification_loss: 0.2811
 694/1000 [===================>..........] - ETA: 1:27 - loss: 1.5205 - regression_loss: 1.2389 - classification_loss: 0.2816
 695/1000 [===================>..........] - ETA: 1:27 - loss: 1.5199 - regression_loss: 1.2383 - classification_loss: 0.2815
 696/1000 [===================>..........] - ETA: 1:27 - loss: 1.5197 - regression_loss: 1.2382 - classification_loss: 0.2814
 697/1000 [===================>..........] - ETA: 1:26 - loss: 1.5181 - regression_loss: 1.2370 - classification_loss: 0.2811
 698/1000 [===================>..........] - ETA: 1:26 - loss: 1.5169 - regression_loss: 1.2360 - classification_loss: 0.2808
 699/1000 [===================>..........] - ETA: 1:26 - loss: 1.5157 - regression_loss: 1.2343 - classification_loss: 0.2814
 700/1000 [====================>.........] - ETA: 1:25 - loss: 1.5148 - regression_loss: 1.2335 - classification_loss: 0.2813
 701/1000 [====================>.........] - ETA: 1:25 - loss: 1.5148 - regression_loss: 1.2336 - classification_loss: 0.2812
 702/1000 [====================>.........] - ETA: 1:25 - loss: 1.5146 - regression_loss: 1.2334 - classification_loss: 0.2812
 703/1000 [====================>.........] - ETA: 1:25 - loss: 1.5164 - regression_loss: 1.2349 - classification_loss: 0.2814
 704/1000 [====================>.........] - ETA: 1:24 - loss: 1.5173 - regression_loss: 1.2357 - classification_loss: 0.2816
 705/1000 [====================>.........] - ETA: 1:24 - loss: 1.5167 - regression_loss: 1.2353 - classification_loss: 0.2814
 706/1000 [====================>.........] - ETA: 1:24 - loss: 1.5175 - regression_loss: 1.2359 - classification_loss: 0.2817
 707/1000 [====================>.........] - ETA: 1:23 - loss: 1.5188 - regression_loss: 1.2368 - classification_loss: 0.2820
 708/1000 [====================>.........] - ETA: 1:23 - loss: 1.5207 - regression_loss: 1.2384 - classification_loss: 0.2823
 709/1000 [====================>.........] - ETA: 1:23 - loss: 1.5204 - regression_loss: 1.2381 - classification_loss: 0.2822
 710/1000 [====================>.........] - ETA: 1:23 - loss: 1.5199 - regression_loss: 1.2379 - classification_loss: 0.2820
 711/1000 [====================>.........] - ETA: 1:22 - loss: 1.5202 - regression_loss: 1.2382 - classification_loss: 0.2821
 712/1000 [====================>.........] - ETA: 1:22 - loss: 1.5196 - regression_loss: 1.2378 - classification_loss: 0.2818
 713/1000 [====================>.........] - ETA: 1:22 - loss: 1.5191 - regression_loss: 1.2374 - classification_loss: 0.2816
 714/1000 [====================>.........] - ETA: 1:21 - loss: 1.5214 - regression_loss: 1.2392 - classification_loss: 0.2822
 715/1000 [====================>.........] - ETA: 1:21 - loss: 1.5202 - regression_loss: 1.2382 - classification_loss: 0.2820
 716/1000 [====================>.........] - ETA: 1:21 - loss: 1.5210 - regression_loss: 1.2387 - classification_loss: 0.2823
 717/1000 [====================>.........] - ETA: 1:21 - loss: 1.5216 - regression_loss: 1.2391 - classification_loss: 0.2824
 718/1000 [====================>.........] - ETA: 1:20 - loss: 1.5206 - regression_loss: 1.2384 - classification_loss: 0.2822
 719/1000 [====================>.........] - ETA: 1:20 - loss: 1.5209 - regression_loss: 1.2385 - classification_loss: 0.2824
 720/1000 [====================>.........] - ETA: 1:20 - loss: 1.5199 - regression_loss: 1.2377 - classification_loss: 0.2822
 721/1000 [====================>.........] - ETA: 1:19 - loss: 1.5196 - regression_loss: 1.2374 - classification_loss: 0.2822
 722/1000 [====================>.........] - ETA: 1:19 - loss: 1.5199 - regression_loss: 1.2378 - classification_loss: 0.2821
 723/1000 [====================>.........] - ETA: 1:19 - loss: 1.5197 - regression_loss: 1.2376 - classification_loss: 0.2821
 724/1000 [====================>.........] - ETA: 1:19 - loss: 1.5192 - regression_loss: 1.2373 - classification_loss: 0.2819
 725/1000 [====================>.........] - ETA: 1:18 - loss: 1.5189 - regression_loss: 1.2371 - classification_loss: 0.2818
 726/1000 [====================>.........] - ETA: 1:18 - loss: 1.5183 - regression_loss: 1.2368 - classification_loss: 0.2815
 727/1000 [====================>.........] - ETA: 1:18 - loss: 1.5179 - regression_loss: 1.2366 - classification_loss: 0.2813
 728/1000 [====================>.........] - ETA: 1:17 - loss: 1.5178 - regression_loss: 1.2363 - classification_loss: 0.2815
 729/1000 [====================>.........] - ETA: 1:17 - loss: 1.5176 - regression_loss: 1.2363 - classification_loss: 0.2814
 730/1000 [====================>.........] - ETA: 1:17 - loss: 1.5181 - regression_loss: 1.2367 - classification_loss: 0.2814
 731/1000 [====================>.........] - ETA: 1:17 - loss: 1.5183 - regression_loss: 1.2365 - classification_loss: 0.2817
 732/1000 [====================>.........] - ETA: 1:16 - loss: 1.5172 - regression_loss: 1.2358 - classification_loss: 0.2815
 733/1000 [====================>.........] - ETA: 1:16 - loss: 1.5161 - regression_loss: 1.2348 - classification_loss: 0.2814
 734/1000 [=====================>........] - ETA: 1:16 - loss: 1.5152 - regression_loss: 1.2341 - classification_loss: 0.2811
 735/1000 [=====================>........] - ETA: 1:15 - loss: 1.5151 - regression_loss: 1.2341 - classification_loss: 0.2810
 736/1000 [=====================>........] - ETA: 1:15 - loss: 1.5150 - regression_loss: 1.2340 - classification_loss: 0.2810
 737/1000 [=====================>........] - ETA: 1:15 - loss: 1.5159 - regression_loss: 1.2349 - classification_loss: 0.2811
 738/1000 [=====================>........] - ETA: 1:15 - loss: 1.5147 - regression_loss: 1.2339 - classification_loss: 0.2808
 739/1000 [=====================>........] - ETA: 1:14 - loss: 1.5148 - regression_loss: 1.2340 - classification_loss: 0.2808
 740/1000 [=====================>........] - ETA: 1:14 - loss: 1.5133 - regression_loss: 1.2327 - classification_loss: 0.2806
 741/1000 [=====================>........] - ETA: 1:14 - loss: 1.5133 - regression_loss: 1.2328 - classification_loss: 0.2805
 742/1000 [=====================>........] - ETA: 1:13 - loss: 1.5141 - regression_loss: 1.2334 - classification_loss: 0.2807
 743/1000 [=====================>........] - ETA: 1:13 - loss: 1.5140 - regression_loss: 1.2334 - classification_loss: 0.2806
 744/1000 [=====================>........] - ETA: 1:13 - loss: 1.5137 - regression_loss: 1.2333 - classification_loss: 0.2805
 745/1000 [=====================>........] - ETA: 1:13 - loss: 1.5132 - regression_loss: 1.2328 - classification_loss: 0.2804
 746/1000 [=====================>........] - ETA: 1:12 - loss: 1.5130 - regression_loss: 1.2326 - classification_loss: 0.2804
 747/1000 [=====================>........] - ETA: 1:12 - loss: 1.5124 - regression_loss: 1.2322 - classification_loss: 0.2803
 748/1000 [=====================>........] - ETA: 1:12 - loss: 1.5117 - regression_loss: 1.2316 - classification_loss: 0.2801
 749/1000 [=====================>........] - ETA: 1:11 - loss: 1.5108 - regression_loss: 1.2309 - classification_loss: 0.2799
 750/1000 [=====================>........] - ETA: 1:11 - loss: 1.5108 - regression_loss: 1.2310 - classification_loss: 0.2798
 751/1000 [=====================>........] - ETA: 1:11 - loss: 1.5109 - regression_loss: 1.2312 - classification_loss: 0.2797
 752/1000 [=====================>........] - ETA: 1:11 - loss: 1.5101 - regression_loss: 1.2307 - classification_loss: 0.2795
 753/1000 [=====================>........] - ETA: 1:10 - loss: 1.5114 - regression_loss: 1.2315 - classification_loss: 0.2799
 754/1000 [=====================>........] - ETA: 1:10 - loss: 1.5105 - regression_loss: 1.2308 - classification_loss: 0.2797
 755/1000 [=====================>........] - ETA: 1:10 - loss: 1.5101 - regression_loss: 1.2305 - classification_loss: 0.2795
 756/1000 [=====================>........] - ETA: 1:09 - loss: 1.5095 - regression_loss: 1.2301 - classification_loss: 0.2794
 757/1000 [=====================>........] - ETA: 1:09 - loss: 1.5095 - regression_loss: 1.2302 - classification_loss: 0.2793
 758/1000 [=====================>........] - ETA: 1:09 - loss: 1.5087 - regression_loss: 1.2295 - classification_loss: 0.2792
 759/1000 [=====================>........] - ETA: 1:09 - loss: 1.5081 - regression_loss: 1.2291 - classification_loss: 0.2790
 760/1000 [=====================>........] - ETA: 1:08 - loss: 1.5087 - regression_loss: 1.2296 - classification_loss: 0.2792
 761/1000 [=====================>........] - ETA: 1:08 - loss: 1.5078 - regression_loss: 1.2289 - classification_loss: 0.2790
 762/1000 [=====================>........] - ETA: 1:08 - loss: 1.5074 - regression_loss: 1.2285 - classification_loss: 0.2789
 763/1000 [=====================>........] - ETA: 1:07 - loss: 1.5075 - regression_loss: 1.2288 - classification_loss: 0.2787
 764/1000 [=====================>........] - ETA: 1:07 - loss: 1.5074 - regression_loss: 1.2287 - classification_loss: 0.2787
 765/1000 [=====================>........] - ETA: 1:07 - loss: 1.5072 - regression_loss: 1.2287 - classification_loss: 0.2785
 766/1000 [=====================>........] - ETA: 1:07 - loss: 1.5084 - regression_loss: 1.2297 - classification_loss: 0.2787
 767/1000 [======================>.......] - ETA: 1:06 - loss: 1.5079 - regression_loss: 1.2294 - classification_loss: 0.2785
 768/1000 [======================>.......] - ETA: 1:06 - loss: 1.5077 - regression_loss: 1.2293 - classification_loss: 0.2785
 769/1000 [======================>.......] - ETA: 1:06 - loss: 1.5072 - regression_loss: 1.2289 - classification_loss: 0.2783
 770/1000 [======================>.......] - ETA: 1:05 - loss: 1.5075 - regression_loss: 1.2292 - classification_loss: 0.2783
 771/1000 [======================>.......] - ETA: 1:05 - loss: 1.5073 - regression_loss: 1.2291 - classification_loss: 0.2782
 772/1000 [======================>.......] - ETA: 1:05 - loss: 1.5061 - regression_loss: 1.2282 - classification_loss: 0.2779
 773/1000 [======================>.......] - ETA: 1:05 - loss: 1.5055 - regression_loss: 1.2276 - classification_loss: 0.2779
 774/1000 [======================>.......] - ETA: 1:04 - loss: 1.5046 - regression_loss: 1.2269 - classification_loss: 0.2777
 775/1000 [======================>.......] - ETA: 1:04 - loss: 1.5055 - regression_loss: 1.2276 - classification_loss: 0.2779
 776/1000 [======================>.......] - ETA: 1:04 - loss: 1.5047 - regression_loss: 1.2269 - classification_loss: 0.2778
 777/1000 [======================>.......] - ETA: 1:03 - loss: 1.5041 - regression_loss: 1.2266 - classification_loss: 0.2776
 778/1000 [======================>.......] - ETA: 1:03 - loss: 1.5038 - regression_loss: 1.2264 - classification_loss: 0.2774
 779/1000 [======================>.......] - ETA: 1:03 - loss: 1.5028 - regression_loss: 1.2255 - classification_loss: 0.2773
 780/1000 [======================>.......] - ETA: 1:03 - loss: 1.5029 - regression_loss: 1.2257 - classification_loss: 0.2772
 781/1000 [======================>.......] - ETA: 1:02 - loss: 1.5017 - regression_loss: 1.2247 - classification_loss: 0.2770
 782/1000 [======================>.......] - ETA: 1:02 - loss: 1.5006 - regression_loss: 1.2239 - classification_loss: 0.2768
 783/1000 [======================>.......] - ETA: 1:02 - loss: 1.5013 - regression_loss: 1.2243 - classification_loss: 0.2770
 784/1000 [======================>.......] - ETA: 1:01 - loss: 1.5008 - regression_loss: 1.2239 - classification_loss: 0.2769
 785/1000 [======================>.......] - ETA: 1:01 - loss: 1.5005 - regression_loss: 1.2237 - classification_loss: 0.2768
 786/1000 [======================>.......] - ETA: 1:01 - loss: 1.5010 - regression_loss: 1.2243 - classification_loss: 0.2767
 787/1000 [======================>.......] - ETA: 1:01 - loss: 1.5001 - regression_loss: 1.2236 - classification_loss: 0.2765
 788/1000 [======================>.......] - ETA: 1:00 - loss: 1.4991 - regression_loss: 1.2229 - classification_loss: 0.2762
 789/1000 [======================>.......] - ETA: 1:00 - loss: 1.4979 - regression_loss: 1.2219 - classification_loss: 0.2760
 790/1000 [======================>.......] - ETA: 1:00 - loss: 1.4976 - regression_loss: 1.2217 - classification_loss: 0.2759
 791/1000 [======================>.......] - ETA: 59s - loss: 1.4968 - regression_loss: 1.2211 - classification_loss: 0.2757 
 792/1000 [======================>.......] - ETA: 59s - loss: 1.4960 - regression_loss: 1.2205 - classification_loss: 0.2755
 793/1000 [======================>.......] - ETA: 59s - loss: 1.4957 - regression_loss: 1.2203 - classification_loss: 0.2754
 794/1000 [======================>.......] - ETA: 59s - loss: 1.4957 - regression_loss: 1.2204 - classification_loss: 0.2753
 795/1000 [======================>.......] - ETA: 58s - loss: 1.4960 - regression_loss: 1.2206 - classification_loss: 0.2755
 796/1000 [======================>.......] - ETA: 58s - loss: 1.4962 - regression_loss: 1.2207 - classification_loss: 0.2755
 797/1000 [======================>.......] - ETA: 58s - loss: 1.4957 - regression_loss: 1.2204 - classification_loss: 0.2753
 798/1000 [======================>.......] - ETA: 57s - loss: 1.4953 - regression_loss: 1.2201 - classification_loss: 0.2753
 799/1000 [======================>.......] - ETA: 57s - loss: 1.4943 - regression_loss: 1.2192 - classification_loss: 0.2750
 800/1000 [=======================>......] - ETA: 57s - loss: 1.4958 - regression_loss: 1.2205 - classification_loss: 0.2753
 801/1000 [=======================>......] - ETA: 57s - loss: 1.4953 - regression_loss: 1.2201 - classification_loss: 0.2752
 802/1000 [=======================>......] - ETA: 56s - loss: 1.4958 - regression_loss: 1.2206 - classification_loss: 0.2752
 803/1000 [=======================>......] - ETA: 56s - loss: 1.4956 - regression_loss: 1.2205 - classification_loss: 0.2751
 804/1000 [=======================>......] - ETA: 56s - loss: 1.4966 - regression_loss: 1.2215 - classification_loss: 0.2752
 805/1000 [=======================>......] - ETA: 55s - loss: 1.4966 - regression_loss: 1.2214 - classification_loss: 0.2752
 806/1000 [=======================>......] - ETA: 55s - loss: 1.4969 - regression_loss: 1.2217 - classification_loss: 0.2752
 807/1000 [=======================>......] - ETA: 55s - loss: 1.4970 - regression_loss: 1.2218 - classification_loss: 0.2752
 808/1000 [=======================>......] - ETA: 55s - loss: 1.4965 - regression_loss: 1.2214 - classification_loss: 0.2751
 809/1000 [=======================>......] - ETA: 54s - loss: 1.4961 - regression_loss: 1.2210 - classification_loss: 0.2751
 810/1000 [=======================>......] - ETA: 54s - loss: 1.4963 - regression_loss: 1.2212 - classification_loss: 0.2752
 811/1000 [=======================>......] - ETA: 54s - loss: 1.4958 - regression_loss: 1.2207 - classification_loss: 0.2751
 812/1000 [=======================>......] - ETA: 53s - loss: 1.4948 - regression_loss: 1.2199 - classification_loss: 0.2749
 813/1000 [=======================>......] - ETA: 53s - loss: 1.4947 - regression_loss: 1.2197 - classification_loss: 0.2750
 814/1000 [=======================>......] - ETA: 53s - loss: 1.4940 - regression_loss: 1.2190 - classification_loss: 0.2750
 815/1000 [=======================>......] - ETA: 53s - loss: 1.4934 - regression_loss: 1.2185 - classification_loss: 0.2749
 816/1000 [=======================>......] - ETA: 52s - loss: 1.4928 - regression_loss: 1.2181 - classification_loss: 0.2747
 817/1000 [=======================>......] - ETA: 52s - loss: 1.4925 - regression_loss: 1.2178 - classification_loss: 0.2747
 818/1000 [=======================>......] - ETA: 52s - loss: 1.4926 - regression_loss: 1.2180 - classification_loss: 0.2745
 819/1000 [=======================>......] - ETA: 51s - loss: 1.4924 - regression_loss: 1.2180 - classification_loss: 0.2745
 820/1000 [=======================>......] - ETA: 51s - loss: 1.4923 - regression_loss: 1.2178 - classification_loss: 0.2745
 821/1000 [=======================>......] - ETA: 51s - loss: 1.4924 - regression_loss: 1.2180 - classification_loss: 0.2744
 822/1000 [=======================>......] - ETA: 51s - loss: 1.4918 - regression_loss: 1.2175 - classification_loss: 0.2743
 823/1000 [=======================>......] - ETA: 50s - loss: 1.4911 - regression_loss: 1.2170 - classification_loss: 0.2741
 824/1000 [=======================>......] - ETA: 50s - loss: 1.4908 - regression_loss: 1.2168 - classification_loss: 0.2740
 825/1000 [=======================>......] - ETA: 50s - loss: 1.4904 - regression_loss: 1.2163 - classification_loss: 0.2740
 826/1000 [=======================>......] - ETA: 49s - loss: 1.4899 - regression_loss: 1.2160 - classification_loss: 0.2739
 827/1000 [=======================>......] - ETA: 49s - loss: 1.4898 - regression_loss: 1.2159 - classification_loss: 0.2740
 828/1000 [=======================>......] - ETA: 49s - loss: 1.4890 - regression_loss: 1.2151 - classification_loss: 0.2739
 829/1000 [=======================>......] - ETA: 49s - loss: 1.4886 - regression_loss: 1.2148 - classification_loss: 0.2737
 830/1000 [=======================>......] - ETA: 48s - loss: 1.4895 - regression_loss: 1.2154 - classification_loss: 0.2741
 831/1000 [=======================>......] - ETA: 48s - loss: 1.4886 - regression_loss: 1.2145 - classification_loss: 0.2741
 832/1000 [=======================>......] - ETA: 48s - loss: 1.4879 - regression_loss: 1.2140 - classification_loss: 0.2740
 833/1000 [=======================>......] - ETA: 47s - loss: 1.4872 - regression_loss: 1.2132 - classification_loss: 0.2739
 834/1000 [========================>.....] - ETA: 47s - loss: 1.4865 - regression_loss: 1.2127 - classification_loss: 0.2739
 835/1000 [========================>.....] - ETA: 47s - loss: 1.4861 - regression_loss: 1.2124 - classification_loss: 0.2737
 836/1000 [========================>.....] - ETA: 47s - loss: 1.4865 - regression_loss: 1.2129 - classification_loss: 0.2736
 837/1000 [========================>.....] - ETA: 46s - loss: 1.4857 - regression_loss: 1.2123 - classification_loss: 0.2734
 838/1000 [========================>.....] - ETA: 46s - loss: 1.4865 - regression_loss: 1.2128 - classification_loss: 0.2737
 839/1000 [========================>.....] - ETA: 46s - loss: 1.4860 - regression_loss: 1.2125 - classification_loss: 0.2736
 840/1000 [========================>.....] - ETA: 45s - loss: 1.4868 - regression_loss: 1.2129 - classification_loss: 0.2739
 841/1000 [========================>.....] - ETA: 45s - loss: 1.4861 - regression_loss: 1.2125 - classification_loss: 0.2737
 842/1000 [========================>.....] - ETA: 45s - loss: 1.4858 - regression_loss: 1.2123 - classification_loss: 0.2736
 843/1000 [========================>.....] - ETA: 44s - loss: 1.4853 - regression_loss: 1.2117 - classification_loss: 0.2735
 844/1000 [========================>.....] - ETA: 44s - loss: 1.4849 - regression_loss: 1.2116 - classification_loss: 0.2733
 845/1000 [========================>.....] - ETA: 44s - loss: 1.4849 - regression_loss: 1.2116 - classification_loss: 0.2733
 846/1000 [========================>.....] - ETA: 44s - loss: 1.4848 - regression_loss: 1.2116 - classification_loss: 0.2732
 847/1000 [========================>.....] - ETA: 43s - loss: 1.4840 - regression_loss: 1.2110 - classification_loss: 0.2730
 848/1000 [========================>.....] - ETA: 43s - loss: 1.4836 - regression_loss: 1.2108 - classification_loss: 0.2728
 849/1000 [========================>.....] - ETA: 43s - loss: 1.4848 - regression_loss: 1.2117 - classification_loss: 0.2731
 850/1000 [========================>.....] - ETA: 42s - loss: 1.4864 - regression_loss: 1.2131 - classification_loss: 0.2733
 851/1000 [========================>.....] - ETA: 42s - loss: 1.4861 - regression_loss: 1.2130 - classification_loss: 0.2731
 852/1000 [========================>.....] - ETA: 42s - loss: 1.4866 - regression_loss: 1.2133 - classification_loss: 0.2733
 853/1000 [========================>.....] - ETA: 42s - loss: 1.4860 - regression_loss: 1.2128 - classification_loss: 0.2731
 854/1000 [========================>.....] - ETA: 41s - loss: 1.4850 - regression_loss: 1.2121 - classification_loss: 0.2729
 855/1000 [========================>.....] - ETA: 41s - loss: 1.4846 - regression_loss: 1.2119 - classification_loss: 0.2728
 856/1000 [========================>.....] - ETA: 41s - loss: 1.4845 - regression_loss: 1.2116 - classification_loss: 0.2729
 857/1000 [========================>.....] - ETA: 40s - loss: 1.4838 - regression_loss: 1.2110 - classification_loss: 0.2727
 858/1000 [========================>.....] - ETA: 40s - loss: 1.4846 - regression_loss: 1.2119 - classification_loss: 0.2728
 859/1000 [========================>.....] - ETA: 40s - loss: 1.4842 - regression_loss: 1.2116 - classification_loss: 0.2726
 860/1000 [========================>.....] - ETA: 40s - loss: 1.4842 - regression_loss: 1.2117 - classification_loss: 0.2725
 861/1000 [========================>.....] - ETA: 39s - loss: 1.4850 - regression_loss: 1.2124 - classification_loss: 0.2726
 862/1000 [========================>.....] - ETA: 39s - loss: 1.4848 - regression_loss: 1.2123 - classification_loss: 0.2725
 863/1000 [========================>.....] - ETA: 39s - loss: 1.4849 - regression_loss: 1.2125 - classification_loss: 0.2725
 864/1000 [========================>.....] - ETA: 38s - loss: 1.4838 - regression_loss: 1.2115 - classification_loss: 0.2723
 865/1000 [========================>.....] - ETA: 38s - loss: 1.4828 - regression_loss: 1.2107 - classification_loss: 0.2721
 866/1000 [========================>.....] - ETA: 38s - loss: 1.4825 - regression_loss: 1.2106 - classification_loss: 0.2719
 867/1000 [=========================>....] - ETA: 38s - loss: 1.4814 - regression_loss: 1.2097 - classification_loss: 0.2718
 868/1000 [=========================>....] - ETA: 37s - loss: 1.4812 - regression_loss: 1.2093 - classification_loss: 0.2719
 869/1000 [=========================>....] - ETA: 37s - loss: 1.4809 - regression_loss: 1.2091 - classification_loss: 0.2718
 870/1000 [=========================>....] - ETA: 37s - loss: 1.4804 - regression_loss: 1.2087 - classification_loss: 0.2717
 871/1000 [=========================>....] - ETA: 36s - loss: 1.4799 - regression_loss: 1.2084 - classification_loss: 0.2715
 872/1000 [=========================>....] - ETA: 36s - loss: 1.4793 - regression_loss: 1.2080 - classification_loss: 0.2713
 873/1000 [=========================>....] - ETA: 36s - loss: 1.4797 - regression_loss: 1.2084 - classification_loss: 0.2713
 874/1000 [=========================>....] - ETA: 36s - loss: 1.4803 - regression_loss: 1.2091 - classification_loss: 0.2713
 875/1000 [=========================>....] - ETA: 35s - loss: 1.4804 - regression_loss: 1.2091 - classification_loss: 0.2713
 876/1000 [=========================>....] - ETA: 35s - loss: 1.4801 - regression_loss: 1.2088 - classification_loss: 0.2713
 877/1000 [=========================>....] - ETA: 35s - loss: 1.4817 - regression_loss: 1.2100 - classification_loss: 0.2718
 878/1000 [=========================>....] - ETA: 34s - loss: 1.4817 - regression_loss: 1.2101 - classification_loss: 0.2716
 879/1000 [=========================>....] - ETA: 34s - loss: 1.4823 - regression_loss: 1.2106 - classification_loss: 0.2717
 880/1000 [=========================>....] - ETA: 34s - loss: 1.4820 - regression_loss: 1.2104 - classification_loss: 0.2716
 881/1000 [=========================>....] - ETA: 34s - loss: 1.4830 - regression_loss: 1.2112 - classification_loss: 0.2718
 882/1000 [=========================>....] - ETA: 33s - loss: 1.4834 - regression_loss: 1.2116 - classification_loss: 0.2718
 883/1000 [=========================>....] - ETA: 33s - loss: 1.4829 - regression_loss: 1.2113 - classification_loss: 0.2717
 884/1000 [=========================>....] - ETA: 33s - loss: 1.4828 - regression_loss: 1.2112 - classification_loss: 0.2716
 885/1000 [=========================>....] - ETA: 32s - loss: 1.4827 - regression_loss: 1.2113 - classification_loss: 0.2714
 886/1000 [=========================>....] - ETA: 32s - loss: 1.4829 - regression_loss: 1.2114 - classification_loss: 0.2715
 887/1000 [=========================>....] - ETA: 32s - loss: 1.4825 - regression_loss: 1.2111 - classification_loss: 0.2714
 888/1000 [=========================>....] - ETA: 32s - loss: 1.4826 - regression_loss: 1.2112 - classification_loss: 0.2713
 889/1000 [=========================>....] - ETA: 31s - loss: 1.4831 - regression_loss: 1.2118 - classification_loss: 0.2713
 890/1000 [=========================>....] - ETA: 31s - loss: 1.4830 - regression_loss: 1.2115 - classification_loss: 0.2714
 891/1000 [=========================>....] - ETA: 31s - loss: 1.4828 - regression_loss: 1.2113 - classification_loss: 0.2714
 892/1000 [=========================>....] - ETA: 30s - loss: 1.4827 - regression_loss: 1.2114 - classification_loss: 0.2713
 893/1000 [=========================>....] - ETA: 30s - loss: 1.4829 - regression_loss: 1.2116 - classification_loss: 0.2713
 894/1000 [=========================>....] - ETA: 30s - loss: 1.4826 - regression_loss: 1.2114 - classification_loss: 0.2712
 895/1000 [=========================>....] - ETA: 30s - loss: 1.4816 - regression_loss: 1.2106 - classification_loss: 0.2710
 896/1000 [=========================>....] - ETA: 29s - loss: 1.4820 - regression_loss: 1.2110 - classification_loss: 0.2710
 897/1000 [=========================>....] - ETA: 29s - loss: 1.4822 - regression_loss: 1.2112 - classification_loss: 0.2709
 898/1000 [=========================>....] - ETA: 29s - loss: 1.4819 - regression_loss: 1.2111 - classification_loss: 0.2709
 899/1000 [=========================>....] - ETA: 28s - loss: 1.4820 - regression_loss: 1.2111 - classification_loss: 0.2709
 900/1000 [==========================>...] - ETA: 28s - loss: 1.4822 - regression_loss: 1.2113 - classification_loss: 0.2709
 901/1000 [==========================>...] - ETA: 28s - loss: 1.4818 - regression_loss: 1.2110 - classification_loss: 0.2708
 902/1000 [==========================>...] - ETA: 28s - loss: 1.4824 - regression_loss: 1.2114 - classification_loss: 0.2709
 903/1000 [==========================>...] - ETA: 27s - loss: 1.4816 - regression_loss: 1.2108 - classification_loss: 0.2708
 904/1000 [==========================>...] - ETA: 27s - loss: 1.4826 - regression_loss: 1.2118 - classification_loss: 0.2708
 905/1000 [==========================>...] - ETA: 27s - loss: 1.4831 - regression_loss: 1.2125 - classification_loss: 0.2707
 906/1000 [==========================>...] - ETA: 26s - loss: 1.4837 - regression_loss: 1.2129 - classification_loss: 0.2707
 907/1000 [==========================>...] - ETA: 26s - loss: 1.4830 - regression_loss: 1.2124 - classification_loss: 0.2706
 908/1000 [==========================>...] - ETA: 26s - loss: 1.4835 - regression_loss: 1.2126 - classification_loss: 0.2709
 909/1000 [==========================>...] - ETA: 26s - loss: 1.4832 - regression_loss: 1.2124 - classification_loss: 0.2708
 910/1000 [==========================>...] - ETA: 25s - loss: 1.4834 - regression_loss: 1.2126 - classification_loss: 0.2708
 911/1000 [==========================>...] - ETA: 25s - loss: 1.4829 - regression_loss: 1.2123 - classification_loss: 0.2706
 912/1000 [==========================>...] - ETA: 25s - loss: 1.4823 - regression_loss: 1.2119 - classification_loss: 0.2704
 913/1000 [==========================>...] - ETA: 24s - loss: 1.4827 - regression_loss: 1.2123 - classification_loss: 0.2704
 914/1000 [==========================>...] - ETA: 24s - loss: 1.4828 - regression_loss: 1.2125 - classification_loss: 0.2703
 915/1000 [==========================>...] - ETA: 24s - loss: 1.4826 - regression_loss: 1.2125 - classification_loss: 0.2701
 916/1000 [==========================>...] - ETA: 24s - loss: 1.4821 - regression_loss: 1.2122 - classification_loss: 0.2700
 917/1000 [==========================>...] - ETA: 23s - loss: 1.4815 - regression_loss: 1.2118 - classification_loss: 0.2698
 918/1000 [==========================>...] - ETA: 23s - loss: 1.4813 - regression_loss: 1.2115 - classification_loss: 0.2697
 919/1000 [==========================>...] - ETA: 23s - loss: 1.4808 - regression_loss: 1.2112 - classification_loss: 0.2696
 920/1000 [==========================>...] - ETA: 22s - loss: 1.4815 - regression_loss: 1.2117 - classification_loss: 0.2698
 921/1000 [==========================>...] - ETA: 22s - loss: 1.4823 - regression_loss: 1.2125 - classification_loss: 0.2698
 922/1000 [==========================>...] - ETA: 22s - loss: 1.4823 - regression_loss: 1.2125 - classification_loss: 0.2698
 923/1000 [==========================>...] - ETA: 22s - loss: 1.4821 - regression_loss: 1.2124 - classification_loss: 0.2697
 924/1000 [==========================>...] - ETA: 21s - loss: 1.4824 - regression_loss: 1.2126 - classification_loss: 0.2697
 925/1000 [==========================>...] - ETA: 21s - loss: 1.4823 - regression_loss: 1.2125 - classification_loss: 0.2699
 926/1000 [==========================>...] - ETA: 21s - loss: 1.4836 - regression_loss: 1.2135 - classification_loss: 0.2701
 927/1000 [==========================>...] - ETA: 20s - loss: 1.4828 - regression_loss: 1.2129 - classification_loss: 0.2699
 928/1000 [==========================>...] - ETA: 20s - loss: 1.4827 - regression_loss: 1.2128 - classification_loss: 0.2699
 929/1000 [==========================>...] - ETA: 20s - loss: 1.4826 - regression_loss: 1.2128 - classification_loss: 0.2697
 930/1000 [==========================>...] - ETA: 20s - loss: 1.4825 - regression_loss: 1.2128 - classification_loss: 0.2697
 931/1000 [==========================>...] - ETA: 19s - loss: 1.4825 - regression_loss: 1.2129 - classification_loss: 0.2696
 932/1000 [==========================>...] - ETA: 19s - loss: 1.4826 - regression_loss: 1.2132 - classification_loss: 0.2694
 933/1000 [==========================>...] - ETA: 19s - loss: 1.4832 - regression_loss: 1.2137 - classification_loss: 0.2695
 934/1000 [===========================>..] - ETA: 18s - loss: 1.4829 - regression_loss: 1.2132 - classification_loss: 0.2697
 935/1000 [===========================>..] - ETA: 18s - loss: 1.4832 - regression_loss: 1.2135 - classification_loss: 0.2697
 936/1000 [===========================>..] - ETA: 18s - loss: 1.4834 - regression_loss: 1.2136 - classification_loss: 0.2698
 937/1000 [===========================>..] - ETA: 18s - loss: 1.4831 - regression_loss: 1.2135 - classification_loss: 0.2696
 938/1000 [===========================>..] - ETA: 17s - loss: 1.4841 - regression_loss: 1.2143 - classification_loss: 0.2698
 939/1000 [===========================>..] - ETA: 17s - loss: 1.4840 - regression_loss: 1.2142 - classification_loss: 0.2698
 940/1000 [===========================>..] - ETA: 17s - loss: 1.4844 - regression_loss: 1.2147 - classification_loss: 0.2697
 941/1000 [===========================>..] - ETA: 16s - loss: 1.4840 - regression_loss: 1.2144 - classification_loss: 0.2696
 942/1000 [===========================>..] - ETA: 16s - loss: 1.4837 - regression_loss: 1.2142 - classification_loss: 0.2695
 943/1000 [===========================>..] - ETA: 16s - loss: 1.4831 - regression_loss: 1.2138 - classification_loss: 0.2694
 944/1000 [===========================>..] - ETA: 16s - loss: 1.4827 - regression_loss: 1.2134 - classification_loss: 0.2693
 945/1000 [===========================>..] - ETA: 15s - loss: 1.4827 - regression_loss: 1.2133 - classification_loss: 0.2693
 946/1000 [===========================>..] - ETA: 15s - loss: 1.4830 - regression_loss: 1.2136 - classification_loss: 0.2694
 947/1000 [===========================>..] - ETA: 15s - loss: 1.4831 - regression_loss: 1.2137 - classification_loss: 0.2693
 948/1000 [===========================>..] - ETA: 14s - loss: 1.4825 - regression_loss: 1.2131 - classification_loss: 0.2693
 949/1000 [===========================>..] - ETA: 14s - loss: 1.4834 - regression_loss: 1.2140 - classification_loss: 0.2694
 950/1000 [===========================>..] - ETA: 14s - loss: 1.4832 - regression_loss: 1.2137 - classification_loss: 0.2694
 951/1000 [===========================>..] - ETA: 14s - loss: 1.4836 - regression_loss: 1.2142 - classification_loss: 0.2694
 952/1000 [===========================>..] - ETA: 13s - loss: 1.4829 - regression_loss: 1.2137 - classification_loss: 0.2692
 953/1000 [===========================>..] - ETA: 13s - loss: 1.4860 - regression_loss: 1.2152 - classification_loss: 0.2708
 954/1000 [===========================>..] - ETA: 13s - loss: 1.4853 - regression_loss: 1.2147 - classification_loss: 0.2707
 955/1000 [===========================>..] - ETA: 12s - loss: 1.4846 - regression_loss: 1.2141 - classification_loss: 0.2705
 956/1000 [===========================>..] - ETA: 12s - loss: 1.4850 - regression_loss: 1.2145 - classification_loss: 0.2705
 957/1000 [===========================>..] - ETA: 12s - loss: 1.4852 - regression_loss: 1.2149 - classification_loss: 0.2704
 958/1000 [===========================>..] - ETA: 12s - loss: 1.4848 - regression_loss: 1.2146 - classification_loss: 0.2703
 959/1000 [===========================>..] - ETA: 11s - loss: 1.4840 - regression_loss: 1.2139 - classification_loss: 0.2701
 960/1000 [===========================>..] - ETA: 11s - loss: 1.4832 - regression_loss: 1.2133 - classification_loss: 0.2700
 961/1000 [===========================>..] - ETA: 11s - loss: 1.4829 - regression_loss: 1.2130 - classification_loss: 0.2699
 962/1000 [===========================>..] - ETA: 10s - loss: 1.4825 - regression_loss: 1.2127 - classification_loss: 0.2698
 963/1000 [===========================>..] - ETA: 10s - loss: 1.4823 - regression_loss: 1.2126 - classification_loss: 0.2697
 964/1000 [===========================>..] - ETA: 10s - loss: 1.4824 - regression_loss: 1.2127 - classification_loss: 0.2697
 965/1000 [===========================>..] - ETA: 10s - loss: 1.4827 - regression_loss: 1.2130 - classification_loss: 0.2697
 966/1000 [===========================>..] - ETA: 9s - loss: 1.4822 - regression_loss: 1.2126 - classification_loss: 0.2696 
 967/1000 [============================>.] - ETA: 9s - loss: 1.4830 - regression_loss: 1.2133 - classification_loss: 0.2697
 968/1000 [============================>.] - ETA: 9s - loss: 1.4831 - regression_loss: 1.2135 - classification_loss: 0.2697
 969/1000 [============================>.] - ETA: 8s - loss: 1.4829 - regression_loss: 1.2132 - classification_loss: 0.2697
 970/1000 [============================>.] - ETA: 8s - loss: 1.4830 - regression_loss: 1.2133 - classification_loss: 0.2697
 971/1000 [============================>.] - ETA: 8s - loss: 1.4826 - regression_loss: 1.2131 - classification_loss: 0.2695
 972/1000 [============================>.] - ETA: 8s - loss: 1.4845 - regression_loss: 1.2145 - classification_loss: 0.2700
 973/1000 [============================>.] - ETA: 7s - loss: 1.4844 - regression_loss: 1.2144 - classification_loss: 0.2700
 974/1000 [============================>.] - ETA: 7s - loss: 1.4843 - regression_loss: 1.2145 - classification_loss: 0.2699
 975/1000 [============================>.] - ETA: 7s - loss: 1.4840 - regression_loss: 1.2143 - classification_loss: 0.2698
 976/1000 [============================>.] - ETA: 6s - loss: 1.4845 - regression_loss: 1.2147 - classification_loss: 0.2698
 977/1000 [============================>.] - ETA: 6s - loss: 1.4846 - regression_loss: 1.2149 - classification_loss: 0.2698
 978/1000 [============================>.] - ETA: 6s - loss: 1.4840 - regression_loss: 1.2143 - classification_loss: 0.2697
 979/1000 [============================>.] - ETA: 6s - loss: 1.4831 - regression_loss: 1.2136 - classification_loss: 0.2695
 980/1000 [============================>.] - ETA: 5s - loss: 1.4832 - regression_loss: 1.2137 - classification_loss: 0.2695
 981/1000 [============================>.] - ETA: 5s - loss: 1.4831 - regression_loss: 1.2137 - classification_loss: 0.2694
 982/1000 [============================>.] - ETA: 5s - loss: 1.4836 - regression_loss: 1.2143 - classification_loss: 0.2693
 983/1000 [============================>.] - ETA: 4s - loss: 1.4830 - regression_loss: 1.2138 - classification_loss: 0.2692
 984/1000 [============================>.] - ETA: 4s - loss: 1.4845 - regression_loss: 1.2151 - classification_loss: 0.2694
 985/1000 [============================>.] - ETA: 4s - loss: 1.4847 - regression_loss: 1.2152 - classification_loss: 0.2695
 986/1000 [============================>.] - ETA: 4s - loss: 1.4851 - regression_loss: 1.2157 - classification_loss: 0.2695
 987/1000 [============================>.] - ETA: 3s - loss: 1.4850 - regression_loss: 1.2155 - classification_loss: 0.2695
 988/1000 [============================>.] - ETA: 3s - loss: 1.4852 - regression_loss: 1.2158 - classification_loss: 0.2694
 989/1000 [============================>.] - ETA: 3s - loss: 1.4855 - regression_loss: 1.2160 - classification_loss: 0.2695
 990/1000 [============================>.] - ETA: 2s - loss: 1.4853 - regression_loss: 1.2158 - classification_loss: 0.2695
 991/1000 [============================>.] - ETA: 2s - loss: 1.4848 - regression_loss: 1.2155 - classification_loss: 0.2693
 992/1000 [============================>.] - ETA: 2s - loss: 1.4848 - regression_loss: 1.2155 - classification_loss: 0.2693
 993/1000 [============================>.] - ETA: 2s - loss: 1.4850 - regression_loss: 1.2157 - classification_loss: 0.2692
 994/1000 [============================>.] - ETA: 1s - loss: 1.4847 - regression_loss: 1.2155 - classification_loss: 0.2692
 995/1000 [============================>.] - ETA: 1s - loss: 1.4852 - regression_loss: 1.2159 - classification_loss: 0.2692
 996/1000 [============================>.] - ETA: 1s - loss: 1.4851 - regression_loss: 1.2159 - classification_loss: 0.2692
 997/1000 [============================>.] - ETA: 0s - loss: 1.4857 - regression_loss: 1.2164 - classification_loss: 0.2693
 998/1000 [============================>.] - ETA: 0s - loss: 1.4851 - regression_loss: 1.2160 - classification_loss: 0.2692
 999/1000 [============================>.] - ETA: 0s - loss: 1.4854 - regression_loss: 1.2163 - classification_loss: 0.2692
1000/1000 [==============================] - 287s 287ms/step - loss: 1.4851 - regression_loss: 1.2160 - classification_loss: 0.2691

Epoch 00005: saving model to ./snapshots/resnet50_csv_05.h5
Epoch 6/10

   1/1000 [..............................] - ETA: 4:51 - loss: 1.4844 - regression_loss: 1.2817 - classification_loss: 0.2027
   2/1000 [..............................] - ETA: 4:47 - loss: 1.5869 - regression_loss: 1.3207 - classification_loss: 0.2662
   3/1000 [..............................] - ETA: 4:49 - loss: 1.4915 - regression_loss: 1.2392 - classification_loss: 0.2523
   4/1000 [..............................] - ETA: 4:48 - loss: 1.3463 - regression_loss: 1.1267 - classification_loss: 0.2196
   5/1000 [..............................] - ETA: 4:47 - loss: 1.2580 - regression_loss: 1.0591 - classification_loss: 0.1990
   6/1000 [..............................] - ETA: 4:48 - loss: 1.2704 - regression_loss: 1.0771 - classification_loss: 0.1933
   7/1000 [..............................] - ETA: 4:47 - loss: 1.3258 - regression_loss: 1.0959 - classification_loss: 0.2299
   8/1000 [..............................] - ETA: 4:47 - loss: 1.3020 - regression_loss: 1.0840 - classification_loss: 0.2179
   9/1000 [..............................] - ETA: 4:46 - loss: 1.3232 - regression_loss: 1.0981 - classification_loss: 0.2252
  10/1000 [..............................] - ETA: 4:45 - loss: 1.3417 - regression_loss: 1.1042 - classification_loss: 0.2375
  11/1000 [..............................] - ETA: 4:45 - loss: 1.3720 - regression_loss: 1.1395 - classification_loss: 0.2325
  12/1000 [..............................] - ETA: 4:44 - loss: 1.4191 - regression_loss: 1.1796 - classification_loss: 0.2395
  13/1000 [..............................] - ETA: 4:44 - loss: 1.4061 - regression_loss: 1.1638 - classification_loss: 0.2422
  14/1000 [..............................] - ETA: 4:44 - loss: 1.3859 - regression_loss: 1.1467 - classification_loss: 0.2392
  15/1000 [..............................] - ETA: 4:43 - loss: 1.4372 - regression_loss: 1.1927 - classification_loss: 0.2445
  16/1000 [..............................] - ETA: 4:43 - loss: 1.4576 - regression_loss: 1.2081 - classification_loss: 0.2495
  17/1000 [..............................] - ETA: 4:42 - loss: 1.5068 - regression_loss: 1.2543 - classification_loss: 0.2525
  18/1000 [..............................] - ETA: 4:42 - loss: 1.5236 - regression_loss: 1.2610 - classification_loss: 0.2626
  19/1000 [..............................] - ETA: 4:41 - loss: 1.4869 - regression_loss: 1.2287 - classification_loss: 0.2582
  20/1000 [..............................] - ETA: 4:41 - loss: 1.4575 - regression_loss: 1.2041 - classification_loss: 0.2535
  21/1000 [..............................] - ETA: 4:40 - loss: 1.4411 - regression_loss: 1.1906 - classification_loss: 0.2505
  22/1000 [..............................] - ETA: 4:39 - loss: 1.4478 - regression_loss: 1.1997 - classification_loss: 0.2482
  23/1000 [..............................] - ETA: 4:39 - loss: 1.4791 - regression_loss: 1.2323 - classification_loss: 0.2468
  24/1000 [..............................] - ETA: 4:39 - loss: 1.4666 - regression_loss: 1.2216 - classification_loss: 0.2450
  25/1000 [..............................] - ETA: 4:38 - loss: 1.4581 - regression_loss: 1.2145 - classification_loss: 0.2436
  26/1000 [..............................] - ETA: 4:38 - loss: 1.4889 - regression_loss: 1.2427 - classification_loss: 0.2462
  27/1000 [..............................] - ETA: 4:38 - loss: 1.4625 - regression_loss: 1.2217 - classification_loss: 0.2408
  28/1000 [..............................] - ETA: 4:37 - loss: 1.4437 - regression_loss: 1.2039 - classification_loss: 0.2398
  29/1000 [..............................] - ETA: 4:37 - loss: 1.4440 - regression_loss: 1.2062 - classification_loss: 0.2378
  30/1000 [..............................] - ETA: 4:37 - loss: 1.4283 - regression_loss: 1.1944 - classification_loss: 0.2338
  31/1000 [..............................] - ETA: 4:37 - loss: 1.4333 - regression_loss: 1.2013 - classification_loss: 0.2319
  32/1000 [..............................] - ETA: 4:36 - loss: 1.4122 - regression_loss: 1.1831 - classification_loss: 0.2291
  33/1000 [..............................] - ETA: 4:36 - loss: 1.4024 - regression_loss: 1.1729 - classification_loss: 0.2295
  34/1000 [>.............................] - ETA: 4:36 - loss: 1.3854 - regression_loss: 1.1601 - classification_loss: 0.2254
  35/1000 [>.............................] - ETA: 4:36 - loss: 1.3855 - regression_loss: 1.1612 - classification_loss: 0.2243
  36/1000 [>.............................] - ETA: 4:36 - loss: 1.3873 - regression_loss: 1.1587 - classification_loss: 0.2286
  37/1000 [>.............................] - ETA: 4:35 - loss: 1.3810 - regression_loss: 1.1505 - classification_loss: 0.2306
  38/1000 [>.............................] - ETA: 4:35 - loss: 1.3928 - regression_loss: 1.1592 - classification_loss: 0.2336
  39/1000 [>.............................] - ETA: 4:35 - loss: 1.4069 - regression_loss: 1.1693 - classification_loss: 0.2376
  40/1000 [>.............................] - ETA: 4:34 - loss: 1.4126 - regression_loss: 1.1736 - classification_loss: 0.2390
  41/1000 [>.............................] - ETA: 4:34 - loss: 1.4098 - regression_loss: 1.1726 - classification_loss: 0.2372
  42/1000 [>.............................] - ETA: 4:34 - loss: 1.4102 - regression_loss: 1.1751 - classification_loss: 0.2351
  43/1000 [>.............................] - ETA: 4:33 - loss: 1.3956 - regression_loss: 1.1632 - classification_loss: 0.2324
  44/1000 [>.............................] - ETA: 4:33 - loss: 1.3994 - regression_loss: 1.1649 - classification_loss: 0.2345
  45/1000 [>.............................] - ETA: 4:33 - loss: 1.4071 - regression_loss: 1.1716 - classification_loss: 0.2355
  46/1000 [>.............................] - ETA: 4:32 - loss: 1.4185 - regression_loss: 1.1793 - classification_loss: 0.2392
  47/1000 [>.............................] - ETA: 4:32 - loss: 1.4191 - regression_loss: 1.1818 - classification_loss: 0.2373
  48/1000 [>.............................] - ETA: 4:32 - loss: 1.4085 - regression_loss: 1.1741 - classification_loss: 0.2344
  49/1000 [>.............................] - ETA: 4:32 - loss: 1.4018 - regression_loss: 1.1690 - classification_loss: 0.2328
  50/1000 [>.............................] - ETA: 4:32 - loss: 1.3949 - regression_loss: 1.1628 - classification_loss: 0.2322
  51/1000 [>.............................] - ETA: 4:31 - loss: 1.3954 - regression_loss: 1.1636 - classification_loss: 0.2318
  52/1000 [>.............................] - ETA: 4:31 - loss: 1.3813 - regression_loss: 1.1513 - classification_loss: 0.2300
  53/1000 [>.............................] - ETA: 4:31 - loss: 1.3892 - regression_loss: 1.1587 - classification_loss: 0.2306
  54/1000 [>.............................] - ETA: 4:30 - loss: 1.3858 - regression_loss: 1.1558 - classification_loss: 0.2300
  55/1000 [>.............................] - ETA: 4:30 - loss: 1.4113 - regression_loss: 1.1745 - classification_loss: 0.2368
  56/1000 [>.............................] - ETA: 4:30 - loss: 1.4124 - regression_loss: 1.1757 - classification_loss: 0.2367
  57/1000 [>.............................] - ETA: 4:29 - loss: 1.3998 - regression_loss: 1.1657 - classification_loss: 0.2341
  58/1000 [>.............................] - ETA: 4:29 - loss: 1.4109 - regression_loss: 1.1734 - classification_loss: 0.2375
  59/1000 [>.............................] - ETA: 4:29 - loss: 1.4309 - regression_loss: 1.1870 - classification_loss: 0.2440
  60/1000 [>.............................] - ETA: 4:29 - loss: 1.4224 - regression_loss: 1.1807 - classification_loss: 0.2417
  61/1000 [>.............................] - ETA: 4:28 - loss: 1.4084 - regression_loss: 1.1694 - classification_loss: 0.2390
  62/1000 [>.............................] - ETA: 4:28 - loss: 1.3940 - regression_loss: 1.1574 - classification_loss: 0.2365
  63/1000 [>.............................] - ETA: 4:28 - loss: 1.3995 - regression_loss: 1.1564 - classification_loss: 0.2431
  64/1000 [>.............................] - ETA: 4:27 - loss: 1.3929 - regression_loss: 1.1518 - classification_loss: 0.2411
  65/1000 [>.............................] - ETA: 4:27 - loss: 1.3896 - regression_loss: 1.1469 - classification_loss: 0.2427
  66/1000 [>.............................] - ETA: 4:27 - loss: 1.3889 - regression_loss: 1.1448 - classification_loss: 0.2441
  67/1000 [=>............................] - ETA: 4:26 - loss: 1.3996 - regression_loss: 1.1535 - classification_loss: 0.2461
  68/1000 [=>............................] - ETA: 4:26 - loss: 1.4175 - regression_loss: 1.1674 - classification_loss: 0.2501
  69/1000 [=>............................] - ETA: 4:26 - loss: 1.4023 - regression_loss: 1.1546 - classification_loss: 0.2477
  70/1000 [=>............................] - ETA: 4:26 - loss: 1.3947 - regression_loss: 1.1482 - classification_loss: 0.2465
  71/1000 [=>............................] - ETA: 4:25 - loss: 1.3914 - regression_loss: 1.1457 - classification_loss: 0.2456
  72/1000 [=>............................] - ETA: 4:25 - loss: 1.3941 - regression_loss: 1.1473 - classification_loss: 0.2468
  73/1000 [=>............................] - ETA: 4:25 - loss: 1.3894 - regression_loss: 1.1437 - classification_loss: 0.2456
  74/1000 [=>............................] - ETA: 4:24 - loss: 1.3861 - regression_loss: 1.1427 - classification_loss: 0.2434
  75/1000 [=>............................] - ETA: 4:24 - loss: 1.3781 - regression_loss: 1.1366 - classification_loss: 0.2415
  76/1000 [=>............................] - ETA: 4:24 - loss: 1.3834 - regression_loss: 1.1407 - classification_loss: 0.2427
  77/1000 [=>............................] - ETA: 4:24 - loss: 1.3917 - regression_loss: 1.1465 - classification_loss: 0.2451
  78/1000 [=>............................] - ETA: 4:23 - loss: 1.3988 - regression_loss: 1.1536 - classification_loss: 0.2451
  79/1000 [=>............................] - ETA: 4:23 - loss: 1.3972 - regression_loss: 1.1524 - classification_loss: 0.2448
  80/1000 [=>............................] - ETA: 4:23 - loss: 1.4072 - regression_loss: 1.1619 - classification_loss: 0.2453
  81/1000 [=>............................] - ETA: 4:23 - loss: 1.4019 - regression_loss: 1.1554 - classification_loss: 0.2464
  82/1000 [=>............................] - ETA: 4:22 - loss: 1.3958 - regression_loss: 1.1503 - classification_loss: 0.2454
  83/1000 [=>............................] - ETA: 4:22 - loss: 1.3933 - regression_loss: 1.1494 - classification_loss: 0.2439
  84/1000 [=>............................] - ETA: 4:22 - loss: 1.3887 - regression_loss: 1.1436 - classification_loss: 0.2450
  85/1000 [=>............................] - ETA: 4:22 - loss: 1.3797 - regression_loss: 1.1366 - classification_loss: 0.2431
  86/1000 [=>............................] - ETA: 4:21 - loss: 1.3717 - regression_loss: 1.1302 - classification_loss: 0.2414
  87/1000 [=>............................] - ETA: 4:21 - loss: 1.3756 - regression_loss: 1.1326 - classification_loss: 0.2430
  88/1000 [=>............................] - ETA: 4:21 - loss: 1.3803 - regression_loss: 1.1350 - classification_loss: 0.2453
  89/1000 [=>............................] - ETA: 4:20 - loss: 1.3781 - regression_loss: 1.1324 - classification_loss: 0.2457
  90/1000 [=>............................] - ETA: 4:20 - loss: 1.3836 - regression_loss: 1.1382 - classification_loss: 0.2454
  91/1000 [=>............................] - ETA: 4:20 - loss: 1.3836 - regression_loss: 1.1384 - classification_loss: 0.2453
  92/1000 [=>............................] - ETA: 4:20 - loss: 1.3804 - regression_loss: 1.1341 - classification_loss: 0.2463
  93/1000 [=>............................] - ETA: 4:19 - loss: 1.3819 - regression_loss: 1.1347 - classification_loss: 0.2472
  94/1000 [=>............................] - ETA: 4:19 - loss: 1.3812 - regression_loss: 1.1346 - classification_loss: 0.2466
  95/1000 [=>............................] - ETA: 4:19 - loss: 1.3981 - regression_loss: 1.1513 - classification_loss: 0.2468
  96/1000 [=>............................] - ETA: 4:19 - loss: 1.4047 - regression_loss: 1.1571 - classification_loss: 0.2476
  97/1000 [=>............................] - ETA: 4:18 - loss: 1.4183 - regression_loss: 1.1688 - classification_loss: 0.2495
  98/1000 [=>............................] - ETA: 4:18 - loss: 1.4263 - regression_loss: 1.1732 - classification_loss: 0.2531
  99/1000 [=>............................] - ETA: 4:18 - loss: 1.4212 - regression_loss: 1.1689 - classification_loss: 0.2523
 100/1000 [==>...........................] - ETA: 4:18 - loss: 1.4190 - regression_loss: 1.1669 - classification_loss: 0.2521
 101/1000 [==>...........................] - ETA: 4:17 - loss: 1.4133 - regression_loss: 1.1614 - classification_loss: 0.2518
 102/1000 [==>...........................] - ETA: 4:17 - loss: 1.4100 - regression_loss: 1.1591 - classification_loss: 0.2510
 103/1000 [==>...........................] - ETA: 4:17 - loss: 1.4120 - regression_loss: 1.1608 - classification_loss: 0.2511
 104/1000 [==>...........................] - ETA: 4:16 - loss: 1.4083 - regression_loss: 1.1583 - classification_loss: 0.2501
 105/1000 [==>...........................] - ETA: 4:16 - loss: 1.4059 - regression_loss: 1.1568 - classification_loss: 0.2491
 106/1000 [==>...........................] - ETA: 4:16 - loss: 1.4094 - regression_loss: 1.1593 - classification_loss: 0.2501
 107/1000 [==>...........................] - ETA: 4:16 - loss: 1.4008 - regression_loss: 1.1524 - classification_loss: 0.2484
 108/1000 [==>...........................] - ETA: 4:15 - loss: 1.4126 - regression_loss: 1.1582 - classification_loss: 0.2544
 109/1000 [==>...........................] - ETA: 4:19 - loss: 1.4155 - regression_loss: 1.1608 - classification_loss: 0.2547
 110/1000 [==>...........................] - ETA: 4:19 - loss: 1.4204 - regression_loss: 1.1640 - classification_loss: 0.2564
 111/1000 [==>...........................] - ETA: 4:19 - loss: 1.4288 - regression_loss: 1.1702 - classification_loss: 0.2585
 112/1000 [==>...........................] - ETA: 4:18 - loss: 1.4223 - regression_loss: 1.1649 - classification_loss: 0.2575
 113/1000 [==>...........................] - ETA: 4:18 - loss: 1.4169 - regression_loss: 1.1606 - classification_loss: 0.2563
 114/1000 [==>...........................] - ETA: 4:18 - loss: 1.4189 - regression_loss: 1.1629 - classification_loss: 0.2561
 115/1000 [==>...........................] - ETA: 4:17 - loss: 1.4135 - regression_loss: 1.1583 - classification_loss: 0.2552
 116/1000 [==>...........................] - ETA: 4:17 - loss: 1.4131 - regression_loss: 1.1590 - classification_loss: 0.2541
 117/1000 [==>...........................] - ETA: 4:17 - loss: 1.4217 - regression_loss: 1.1666 - classification_loss: 0.2551
 118/1000 [==>...........................] - ETA: 4:17 - loss: 1.4210 - regression_loss: 1.1659 - classification_loss: 0.2552
 119/1000 [==>...........................] - ETA: 4:16 - loss: 1.4142 - regression_loss: 1.1600 - classification_loss: 0.2543
 120/1000 [==>...........................] - ETA: 4:16 - loss: 1.4154 - regression_loss: 1.1617 - classification_loss: 0.2538
 121/1000 [==>...........................] - ETA: 4:16 - loss: 1.4154 - regression_loss: 1.1616 - classification_loss: 0.2537
 122/1000 [==>...........................] - ETA: 4:15 - loss: 1.4271 - regression_loss: 1.1696 - classification_loss: 0.2575
 123/1000 [==>...........................] - ETA: 4:15 - loss: 1.4257 - regression_loss: 1.1684 - classification_loss: 0.2573
 124/1000 [==>...........................] - ETA: 4:15 - loss: 1.4259 - regression_loss: 1.1685 - classification_loss: 0.2574
 125/1000 [==>...........................] - ETA: 4:14 - loss: 1.4216 - regression_loss: 1.1649 - classification_loss: 0.2567
 126/1000 [==>...........................] - ETA: 4:14 - loss: 1.4181 - regression_loss: 1.1625 - classification_loss: 0.2556
 127/1000 [==>...........................] - ETA: 4:14 - loss: 1.4235 - regression_loss: 1.1673 - classification_loss: 0.2562
 128/1000 [==>...........................] - ETA: 4:13 - loss: 1.4188 - regression_loss: 1.1638 - classification_loss: 0.2549
 129/1000 [==>...........................] - ETA: 4:13 - loss: 1.4170 - regression_loss: 1.1621 - classification_loss: 0.2549
 130/1000 [==>...........................] - ETA: 4:13 - loss: 1.4136 - regression_loss: 1.1596 - classification_loss: 0.2540
 131/1000 [==>...........................] - ETA: 4:12 - loss: 1.4193 - regression_loss: 1.1616 - classification_loss: 0.2577
 132/1000 [==>...........................] - ETA: 4:12 - loss: 1.4159 - regression_loss: 1.1588 - classification_loss: 0.2571
 133/1000 [==>...........................] - ETA: 4:12 - loss: 1.4346 - regression_loss: 1.1703 - classification_loss: 0.2643
 134/1000 [===>..........................] - ETA: 4:11 - loss: 1.4341 - regression_loss: 1.1701 - classification_loss: 0.2640
 135/1000 [===>..........................] - ETA: 4:11 - loss: 1.4455 - regression_loss: 1.1781 - classification_loss: 0.2673
 136/1000 [===>..........................] - ETA: 4:11 - loss: 1.4467 - regression_loss: 1.1799 - classification_loss: 0.2667
 137/1000 [===>..........................] - ETA: 4:10 - loss: 1.4477 - regression_loss: 1.1815 - classification_loss: 0.2661
 138/1000 [===>..........................] - ETA: 4:10 - loss: 1.4529 - regression_loss: 1.1855 - classification_loss: 0.2674
 139/1000 [===>..........................] - ETA: 4:10 - loss: 1.4462 - regression_loss: 1.1802 - classification_loss: 0.2660
 140/1000 [===>..........................] - ETA: 4:09 - loss: 1.4421 - regression_loss: 1.1765 - classification_loss: 0.2656
 141/1000 [===>..........................] - ETA: 4:09 - loss: 1.4457 - regression_loss: 1.1793 - classification_loss: 0.2664
 142/1000 [===>..........................] - ETA: 4:09 - loss: 1.4463 - regression_loss: 1.1799 - classification_loss: 0.2665
 143/1000 [===>..........................] - ETA: 4:08 - loss: 1.4468 - regression_loss: 1.1808 - classification_loss: 0.2661
 144/1000 [===>..........................] - ETA: 4:08 - loss: 1.4497 - regression_loss: 1.1814 - classification_loss: 0.2682
 145/1000 [===>..........................] - ETA: 4:08 - loss: 1.4524 - regression_loss: 1.1837 - classification_loss: 0.2686
 146/1000 [===>..........................] - ETA: 4:07 - loss: 1.4528 - regression_loss: 1.1850 - classification_loss: 0.2679
 147/1000 [===>..........................] - ETA: 4:07 - loss: 1.4522 - regression_loss: 1.1847 - classification_loss: 0.2675
 148/1000 [===>..........................] - ETA: 4:07 - loss: 1.4518 - regression_loss: 1.1836 - classification_loss: 0.2682
 149/1000 [===>..........................] - ETA: 4:06 - loss: 1.4460 - regression_loss: 1.1788 - classification_loss: 0.2672
 150/1000 [===>..........................] - ETA: 4:06 - loss: 1.4477 - regression_loss: 1.1799 - classification_loss: 0.2677
 151/1000 [===>..........................] - ETA: 4:06 - loss: 1.4514 - regression_loss: 1.1835 - classification_loss: 0.2679
 152/1000 [===>..........................] - ETA: 4:05 - loss: 1.4534 - regression_loss: 1.1854 - classification_loss: 0.2680
 153/1000 [===>..........................] - ETA: 4:05 - loss: 1.4496 - regression_loss: 1.1824 - classification_loss: 0.2673
 154/1000 [===>..........................] - ETA: 4:05 - loss: 1.4518 - regression_loss: 1.1839 - classification_loss: 0.2679
 155/1000 [===>..........................] - ETA: 4:05 - loss: 1.4574 - regression_loss: 1.1879 - classification_loss: 0.2695
 156/1000 [===>..........................] - ETA: 4:04 - loss: 1.4541 - regression_loss: 1.1856 - classification_loss: 0.2684
 157/1000 [===>..........................] - ETA: 4:04 - loss: 1.4510 - regression_loss: 1.1835 - classification_loss: 0.2675
 158/1000 [===>..........................] - ETA: 4:04 - loss: 1.4453 - regression_loss: 1.1780 - classification_loss: 0.2672
 159/1000 [===>..........................] - ETA: 4:03 - loss: 1.4421 - regression_loss: 1.1757 - classification_loss: 0.2664
 160/1000 [===>..........................] - ETA: 4:03 - loss: 1.4403 - regression_loss: 1.1745 - classification_loss: 0.2658
 161/1000 [===>..........................] - ETA: 4:03 - loss: 1.4362 - regression_loss: 1.1716 - classification_loss: 0.2646
 162/1000 [===>..........................] - ETA: 4:02 - loss: 1.4355 - regression_loss: 1.1714 - classification_loss: 0.2641
 163/1000 [===>..........................] - ETA: 4:02 - loss: 1.4471 - regression_loss: 1.1795 - classification_loss: 0.2676
 164/1000 [===>..........................] - ETA: 4:02 - loss: 1.4427 - regression_loss: 1.1757 - classification_loss: 0.2670
 165/1000 [===>..........................] - ETA: 4:01 - loss: 1.4413 - regression_loss: 1.1750 - classification_loss: 0.2663
 166/1000 [===>..........................] - ETA: 4:01 - loss: 1.4450 - regression_loss: 1.1779 - classification_loss: 0.2671
 167/1000 [====>.........................] - ETA: 4:01 - loss: 1.4423 - regression_loss: 1.1745 - classification_loss: 0.2679
 168/1000 [====>.........................] - ETA: 4:01 - loss: 1.4430 - regression_loss: 1.1749 - classification_loss: 0.2681
 169/1000 [====>.........................] - ETA: 4:00 - loss: 1.4499 - regression_loss: 1.1798 - classification_loss: 0.2701
 170/1000 [====>.........................] - ETA: 4:00 - loss: 1.4499 - regression_loss: 1.1797 - classification_loss: 0.2702
 171/1000 [====>.........................] - ETA: 4:00 - loss: 1.4462 - regression_loss: 1.1768 - classification_loss: 0.2695
 172/1000 [====>.........................] - ETA: 3:59 - loss: 1.4457 - regression_loss: 1.1758 - classification_loss: 0.2699
 173/1000 [====>.........................] - ETA: 3:59 - loss: 1.4508 - regression_loss: 1.1796 - classification_loss: 0.2712
 174/1000 [====>.........................] - ETA: 3:59 - loss: 1.4548 - regression_loss: 1.1827 - classification_loss: 0.2720
 175/1000 [====>.........................] - ETA: 3:58 - loss: 1.4543 - regression_loss: 1.1828 - classification_loss: 0.2715
 176/1000 [====>.........................] - ETA: 3:58 - loss: 1.4537 - regression_loss: 1.1823 - classification_loss: 0.2714
 177/1000 [====>.........................] - ETA: 3:58 - loss: 1.4504 - regression_loss: 1.1794 - classification_loss: 0.2710
 178/1000 [====>.........................] - ETA: 3:57 - loss: 1.4494 - regression_loss: 1.1784 - classification_loss: 0.2710
 179/1000 [====>.........................] - ETA: 3:57 - loss: 1.4525 - regression_loss: 1.1812 - classification_loss: 0.2713
 180/1000 [====>.........................] - ETA: 3:57 - loss: 1.4560 - regression_loss: 1.1839 - classification_loss: 0.2721
 181/1000 [====>.........................] - ETA: 3:57 - loss: 1.4589 - regression_loss: 1.1866 - classification_loss: 0.2723
 182/1000 [====>.........................] - ETA: 3:56 - loss: 1.4548 - regression_loss: 1.1836 - classification_loss: 0.2713
 183/1000 [====>.........................] - ETA: 3:56 - loss: 1.4590 - regression_loss: 1.1877 - classification_loss: 0.2713
 184/1000 [====>.........................] - ETA: 3:56 - loss: 1.4550 - regression_loss: 1.1847 - classification_loss: 0.2703
 185/1000 [====>.........................] - ETA: 3:55 - loss: 1.4493 - regression_loss: 1.1801 - classification_loss: 0.2692
 186/1000 [====>.........................] - ETA: 3:55 - loss: 1.4542 - regression_loss: 1.1798 - classification_loss: 0.2744
 187/1000 [====>.........................] - ETA: 3:55 - loss: 1.4563 - regression_loss: 1.1798 - classification_loss: 0.2764
 188/1000 [====>.........................] - ETA: 3:54 - loss: 1.4536 - regression_loss: 1.1776 - classification_loss: 0.2759
 189/1000 [====>.........................] - ETA: 3:54 - loss: 1.4601 - regression_loss: 1.1823 - classification_loss: 0.2778
 190/1000 [====>.........................] - ETA: 3:54 - loss: 1.4603 - regression_loss: 1.1829 - classification_loss: 0.2773
 191/1000 [====>.........................] - ETA: 3:53 - loss: 1.4622 - regression_loss: 1.1846 - classification_loss: 0.2776
 192/1000 [====>.........................] - ETA: 3:53 - loss: 1.4631 - regression_loss: 1.1855 - classification_loss: 0.2776
 193/1000 [====>.........................] - ETA: 3:53 - loss: 1.4633 - regression_loss: 1.1854 - classification_loss: 0.2779
 194/1000 [====>.........................] - ETA: 3:53 - loss: 1.4629 - regression_loss: 1.1853 - classification_loss: 0.2776
 195/1000 [====>.........................] - ETA: 3:52 - loss: 1.4600 - regression_loss: 1.1833 - classification_loss: 0.2767
 196/1000 [====>.........................] - ETA: 3:52 - loss: 1.4591 - regression_loss: 1.1829 - classification_loss: 0.2762
 197/1000 [====>.........................] - ETA: 3:52 - loss: 1.4553 - regression_loss: 1.1795 - classification_loss: 0.2757
 198/1000 [====>.........................] - ETA: 3:51 - loss: 1.4571 - regression_loss: 1.1803 - classification_loss: 0.2768
 199/1000 [====>.........................] - ETA: 3:51 - loss: 1.4537 - regression_loss: 1.1777 - classification_loss: 0.2760
 200/1000 [=====>........................] - ETA: 3:51 - loss: 1.4519 - regression_loss: 1.1751 - classification_loss: 0.2768
 201/1000 [=====>........................] - ETA: 3:50 - loss: 1.4507 - regression_loss: 1.1739 - classification_loss: 0.2769
 202/1000 [=====>........................] - ETA: 3:50 - loss: 1.4467 - regression_loss: 1.1705 - classification_loss: 0.2762
 203/1000 [=====>........................] - ETA: 3:50 - loss: 1.4469 - regression_loss: 1.1712 - classification_loss: 0.2757
 204/1000 [=====>........................] - ETA: 3:50 - loss: 1.4509 - regression_loss: 1.1753 - classification_loss: 0.2756
 205/1000 [=====>........................] - ETA: 3:49 - loss: 1.4483 - regression_loss: 1.1733 - classification_loss: 0.2751
 206/1000 [=====>........................] - ETA: 3:49 - loss: 1.4481 - regression_loss: 1.1735 - classification_loss: 0.2746
 207/1000 [=====>........................] - ETA: 3:49 - loss: 1.4538 - regression_loss: 1.1792 - classification_loss: 0.2746
 208/1000 [=====>........................] - ETA: 3:48 - loss: 1.4516 - regression_loss: 1.1773 - classification_loss: 0.2743
 209/1000 [=====>........................] - ETA: 3:48 - loss: 1.4489 - regression_loss: 1.1751 - classification_loss: 0.2738
 210/1000 [=====>........................] - ETA: 3:48 - loss: 1.4517 - regression_loss: 1.1780 - classification_loss: 0.2736
 211/1000 [=====>........................] - ETA: 3:48 - loss: 1.4546 - regression_loss: 1.1805 - classification_loss: 0.2740
 212/1000 [=====>........................] - ETA: 3:47 - loss: 1.4614 - regression_loss: 1.1854 - classification_loss: 0.2760
 213/1000 [=====>........................] - ETA: 3:47 - loss: 1.4608 - regression_loss: 1.1855 - classification_loss: 0.2753
 214/1000 [=====>........................] - ETA: 3:47 - loss: 1.4603 - regression_loss: 1.1853 - classification_loss: 0.2750
 215/1000 [=====>........................] - ETA: 3:46 - loss: 1.4618 - regression_loss: 1.1860 - classification_loss: 0.2758
 216/1000 [=====>........................] - ETA: 3:46 - loss: 1.4579 - regression_loss: 1.1827 - classification_loss: 0.2752
 217/1000 [=====>........................] - ETA: 3:46 - loss: 1.4572 - regression_loss: 1.1825 - classification_loss: 0.2747
 218/1000 [=====>........................] - ETA: 3:45 - loss: 1.4599 - regression_loss: 1.1846 - classification_loss: 0.2753
 219/1000 [=====>........................] - ETA: 3:45 - loss: 1.4577 - regression_loss: 1.1828 - classification_loss: 0.2750
 220/1000 [=====>........................] - ETA: 3:45 - loss: 1.4587 - regression_loss: 1.1832 - classification_loss: 0.2755
 221/1000 [=====>........................] - ETA: 3:45 - loss: 1.4601 - regression_loss: 1.1848 - classification_loss: 0.2753
 222/1000 [=====>........................] - ETA: 3:44 - loss: 1.4585 - regression_loss: 1.1840 - classification_loss: 0.2746
 223/1000 [=====>........................] - ETA: 3:44 - loss: 1.4589 - regression_loss: 1.1844 - classification_loss: 0.2745
 224/1000 [=====>........................] - ETA: 3:44 - loss: 1.4609 - regression_loss: 1.1864 - classification_loss: 0.2745
 225/1000 [=====>........................] - ETA: 3:43 - loss: 1.4623 - regression_loss: 1.1873 - classification_loss: 0.2750
 226/1000 [=====>........................] - ETA: 3:43 - loss: 1.4615 - regression_loss: 1.1868 - classification_loss: 0.2747
 227/1000 [=====>........................] - ETA: 3:43 - loss: 1.4615 - regression_loss: 1.1867 - classification_loss: 0.2747
 228/1000 [=====>........................] - ETA: 3:42 - loss: 1.4598 - regression_loss: 1.1857 - classification_loss: 0.2741
 229/1000 [=====>........................] - ETA: 3:42 - loss: 1.4566 - regression_loss: 1.1830 - classification_loss: 0.2735
 230/1000 [=====>........................] - ETA: 3:42 - loss: 1.4542 - regression_loss: 1.1813 - classification_loss: 0.2728
 231/1000 [=====>........................] - ETA: 3:42 - loss: 1.4543 - regression_loss: 1.1819 - classification_loss: 0.2723
 232/1000 [=====>........................] - ETA: 3:41 - loss: 1.4561 - regression_loss: 1.1838 - classification_loss: 0.2723
 233/1000 [=====>........................] - ETA: 3:41 - loss: 1.4541 - regression_loss: 1.1826 - classification_loss: 0.2715
 234/1000 [======>.......................] - ETA: 3:41 - loss: 1.4511 - regression_loss: 1.1804 - classification_loss: 0.2707
 235/1000 [======>.......................] - ETA: 3:40 - loss: 1.4532 - regression_loss: 1.1828 - classification_loss: 0.2704
 236/1000 [======>.......................] - ETA: 3:40 - loss: 1.4589 - regression_loss: 1.1871 - classification_loss: 0.2718
 237/1000 [======>.......................] - ETA: 3:40 - loss: 1.4606 - regression_loss: 1.1884 - classification_loss: 0.2722
 238/1000 [======>.......................] - ETA: 3:40 - loss: 1.4633 - regression_loss: 1.1908 - classification_loss: 0.2726
 239/1000 [======>.......................] - ETA: 3:39 - loss: 1.4661 - regression_loss: 1.1932 - classification_loss: 0.2730
 240/1000 [======>.......................] - ETA: 3:39 - loss: 1.4647 - regression_loss: 1.1924 - classification_loss: 0.2723
 241/1000 [======>.......................] - ETA: 3:39 - loss: 1.4661 - regression_loss: 1.1937 - classification_loss: 0.2724
 242/1000 [======>.......................] - ETA: 3:38 - loss: 1.4649 - regression_loss: 1.1929 - classification_loss: 0.2720
 243/1000 [======>.......................] - ETA: 3:38 - loss: 1.4641 - regression_loss: 1.1925 - classification_loss: 0.2717
 244/1000 [======>.......................] - ETA: 3:38 - loss: 1.4655 - regression_loss: 1.1939 - classification_loss: 0.2716
 245/1000 [======>.......................] - ETA: 3:37 - loss: 1.4638 - regression_loss: 1.1929 - classification_loss: 0.2709
 246/1000 [======>.......................] - ETA: 3:37 - loss: 1.4606 - regression_loss: 1.1898 - classification_loss: 0.2708
 247/1000 [======>.......................] - ETA: 3:37 - loss: 1.4592 - regression_loss: 1.1882 - classification_loss: 0.2710
 248/1000 [======>.......................] - ETA: 3:37 - loss: 1.4610 - regression_loss: 1.1896 - classification_loss: 0.2714
 249/1000 [======>.......................] - ETA: 3:36 - loss: 1.4588 - regression_loss: 1.1880 - classification_loss: 0.2708
 250/1000 [======>.......................] - ETA: 3:36 - loss: 1.4567 - regression_loss: 1.1865 - classification_loss: 0.2702
 251/1000 [======>.......................] - ETA: 3:36 - loss: 1.4562 - regression_loss: 1.1865 - classification_loss: 0.2697
 252/1000 [======>.......................] - ETA: 3:35 - loss: 1.4526 - regression_loss: 1.1836 - classification_loss: 0.2690
 253/1000 [======>.......................] - ETA: 3:35 - loss: 1.4531 - regression_loss: 1.1839 - classification_loss: 0.2692
 254/1000 [======>.......................] - ETA: 3:35 - loss: 1.4509 - regression_loss: 1.1820 - classification_loss: 0.2688
 255/1000 [======>.......................] - ETA: 3:34 - loss: 1.4508 - regression_loss: 1.1820 - classification_loss: 0.2687
 256/1000 [======>.......................] - ETA: 3:34 - loss: 1.4476 - regression_loss: 1.1795 - classification_loss: 0.2681
 257/1000 [======>.......................] - ETA: 3:34 - loss: 1.4500 - regression_loss: 1.1819 - classification_loss: 0.2681
 258/1000 [======>.......................] - ETA: 3:34 - loss: 1.4491 - regression_loss: 1.1815 - classification_loss: 0.2677
 259/1000 [======>.......................] - ETA: 3:33 - loss: 1.4453 - regression_loss: 1.1783 - classification_loss: 0.2670
 260/1000 [======>.......................] - ETA: 3:33 - loss: 1.4431 - regression_loss: 1.1769 - classification_loss: 0.2662
 261/1000 [======>.......................] - ETA: 3:33 - loss: 1.4428 - regression_loss: 1.1766 - classification_loss: 0.2662
 262/1000 [======>.......................] - ETA: 3:32 - loss: 1.4438 - regression_loss: 1.1777 - classification_loss: 0.2661
 263/1000 [======>.......................] - ETA: 3:32 - loss: 1.4440 - regression_loss: 1.1780 - classification_loss: 0.2660
 264/1000 [======>.......................] - ETA: 3:32 - loss: 1.4428 - regression_loss: 1.1773 - classification_loss: 0.2656
 265/1000 [======>.......................] - ETA: 3:32 - loss: 1.4407 - regression_loss: 1.1755 - classification_loss: 0.2652
 266/1000 [======>.......................] - ETA: 3:31 - loss: 1.4382 - regression_loss: 1.1735 - classification_loss: 0.2647
 267/1000 [=======>......................] - ETA: 3:31 - loss: 1.4366 - regression_loss: 1.1724 - classification_loss: 0.2641
 268/1000 [=======>......................] - ETA: 3:31 - loss: 1.4380 - regression_loss: 1.1735 - classification_loss: 0.2645
 269/1000 [=======>......................] - ETA: 3:30 - loss: 1.4375 - regression_loss: 1.1730 - classification_loss: 0.2645
 270/1000 [=======>......................] - ETA: 3:30 - loss: 1.4375 - regression_loss: 1.1735 - classification_loss: 0.2640
 271/1000 [=======>......................] - ETA: 3:30 - loss: 1.4382 - regression_loss: 1.1741 - classification_loss: 0.2641
 272/1000 [=======>......................] - ETA: 3:29 - loss: 1.4377 - regression_loss: 1.1738 - classification_loss: 0.2639
 273/1000 [=======>......................] - ETA: 3:29 - loss: 1.4355 - regression_loss: 1.1721 - classification_loss: 0.2635
 274/1000 [=======>......................] - ETA: 3:29 - loss: 1.4330 - regression_loss: 1.1702 - classification_loss: 0.2628
 275/1000 [=======>......................] - ETA: 3:29 - loss: 1.4301 - regression_loss: 1.1678 - classification_loss: 0.2623
 276/1000 [=======>......................] - ETA: 3:28 - loss: 1.4281 - regression_loss: 1.1664 - classification_loss: 0.2617
 277/1000 [=======>......................] - ETA: 3:28 - loss: 1.4307 - regression_loss: 1.1691 - classification_loss: 0.2617
 278/1000 [=======>......................] - ETA: 3:28 - loss: 1.4293 - regression_loss: 1.1676 - classification_loss: 0.2617
 279/1000 [=======>......................] - ETA: 3:27 - loss: 1.4312 - regression_loss: 1.1680 - classification_loss: 0.2632
 280/1000 [=======>......................] - ETA: 3:27 - loss: 1.4312 - regression_loss: 1.1680 - classification_loss: 0.2632
 281/1000 [=======>......................] - ETA: 3:27 - loss: 1.4290 - regression_loss: 1.1659 - classification_loss: 0.2631
 282/1000 [=======>......................] - ETA: 3:26 - loss: 1.4270 - regression_loss: 1.1642 - classification_loss: 0.2628
 283/1000 [=======>......................] - ETA: 3:26 - loss: 1.4279 - regression_loss: 1.1649 - classification_loss: 0.2630
 284/1000 [=======>......................] - ETA: 3:26 - loss: 1.4288 - regression_loss: 1.1659 - classification_loss: 0.2628
 285/1000 [=======>......................] - ETA: 3:26 - loss: 1.4281 - regression_loss: 1.1655 - classification_loss: 0.2626
 286/1000 [=======>......................] - ETA: 3:25 - loss: 1.4287 - regression_loss: 1.1657 - classification_loss: 0.2629
 287/1000 [=======>......................] - ETA: 3:25 - loss: 1.4286 - regression_loss: 1.1656 - classification_loss: 0.2630
 288/1000 [=======>......................] - ETA: 3:25 - loss: 1.4286 - regression_loss: 1.1658 - classification_loss: 0.2628
 289/1000 [=======>......................] - ETA: 3:24 - loss: 1.4326 - regression_loss: 1.1692 - classification_loss: 0.2634
 290/1000 [=======>......................] - ETA: 3:24 - loss: 1.4377 - regression_loss: 1.1732 - classification_loss: 0.2645
 291/1000 [=======>......................] - ETA: 3:24 - loss: 1.4383 - regression_loss: 1.1734 - classification_loss: 0.2649
 292/1000 [=======>......................] - ETA: 3:24 - loss: 1.4366 - regression_loss: 1.1721 - classification_loss: 0.2645
 293/1000 [=======>......................] - ETA: 3:23 - loss: 1.4368 - regression_loss: 1.1723 - classification_loss: 0.2645
 294/1000 [=======>......................] - ETA: 3:23 - loss: 1.4342 - regression_loss: 1.1699 - classification_loss: 0.2643
 295/1000 [=======>......................] - ETA: 3:23 - loss: 1.4323 - regression_loss: 1.1684 - classification_loss: 0.2639
 296/1000 [=======>......................] - ETA: 3:22 - loss: 1.4315 - regression_loss: 1.1681 - classification_loss: 0.2634
 297/1000 [=======>......................] - ETA: 3:22 - loss: 1.4327 - regression_loss: 1.1697 - classification_loss: 0.2631
 298/1000 [=======>......................] - ETA: 3:22 - loss: 1.4354 - regression_loss: 1.1720 - classification_loss: 0.2633
 299/1000 [=======>......................] - ETA: 3:22 - loss: 1.4366 - regression_loss: 1.1729 - classification_loss: 0.2637
 300/1000 [========>.....................] - ETA: 3:21 - loss: 1.4412 - regression_loss: 1.1765 - classification_loss: 0.2646
 301/1000 [========>.....................] - ETA: 3:21 - loss: 1.4444 - regression_loss: 1.1793 - classification_loss: 0.2651
 302/1000 [========>.....................] - ETA: 3:21 - loss: 1.4443 - regression_loss: 1.1796 - classification_loss: 0.2647
 303/1000 [========>.....................] - ETA: 3:20 - loss: 1.4432 - regression_loss: 1.1788 - classification_loss: 0.2644
 304/1000 [========>.....................] - ETA: 3:20 - loss: 1.4415 - regression_loss: 1.1773 - classification_loss: 0.2642
 305/1000 [========>.....................] - ETA: 3:20 - loss: 1.4400 - regression_loss: 1.1761 - classification_loss: 0.2639
 306/1000 [========>.....................] - ETA: 3:19 - loss: 1.4380 - regression_loss: 1.1747 - classification_loss: 0.2633
 307/1000 [========>.....................] - ETA: 3:19 - loss: 1.4428 - regression_loss: 1.1790 - classification_loss: 0.2638
 308/1000 [========>.....................] - ETA: 3:19 - loss: 1.4429 - regression_loss: 1.1789 - classification_loss: 0.2639
 309/1000 [========>.....................] - ETA: 3:19 - loss: 1.4403 - regression_loss: 1.1770 - classification_loss: 0.2633
 310/1000 [========>.....................] - ETA: 3:18 - loss: 1.4391 - regression_loss: 1.1761 - classification_loss: 0.2630
 311/1000 [========>.....................] - ETA: 3:18 - loss: 1.4394 - regression_loss: 1.1762 - classification_loss: 0.2631
 312/1000 [========>.....................] - ETA: 3:18 - loss: 1.4380 - regression_loss: 1.1754 - classification_loss: 0.2626
 313/1000 [========>.....................] - ETA: 3:17 - loss: 1.4391 - regression_loss: 1.1763 - classification_loss: 0.2628
 314/1000 [========>.....................] - ETA: 3:17 - loss: 1.4371 - regression_loss: 1.1745 - classification_loss: 0.2625
 315/1000 [========>.....................] - ETA: 3:17 - loss: 1.4367 - regression_loss: 1.1743 - classification_loss: 0.2624
 316/1000 [========>.....................] - ETA: 3:17 - loss: 1.4361 - regression_loss: 1.1738 - classification_loss: 0.2624
 317/1000 [========>.....................] - ETA: 3:16 - loss: 1.4355 - regression_loss: 1.1734 - classification_loss: 0.2621
 318/1000 [========>.....................] - ETA: 3:16 - loss: 1.4355 - regression_loss: 1.1734 - classification_loss: 0.2621
 319/1000 [========>.....................] - ETA: 3:16 - loss: 1.4340 - regression_loss: 1.1724 - classification_loss: 0.2616
 320/1000 [========>.....................] - ETA: 3:15 - loss: 1.4332 - regression_loss: 1.1714 - classification_loss: 0.2618
 321/1000 [========>.....................] - ETA: 3:15 - loss: 1.4352 - regression_loss: 1.1733 - classification_loss: 0.2619
 322/1000 [========>.....................] - ETA: 3:15 - loss: 1.4356 - regression_loss: 1.1737 - classification_loss: 0.2619
 323/1000 [========>.....................] - ETA: 3:15 - loss: 1.4380 - regression_loss: 1.1760 - classification_loss: 0.2620
 324/1000 [========>.....................] - ETA: 3:14 - loss: 1.4370 - regression_loss: 1.1754 - classification_loss: 0.2616
 325/1000 [========>.....................] - ETA: 3:14 - loss: 1.4353 - regression_loss: 1.1737 - classification_loss: 0.2616
 326/1000 [========>.....................] - ETA: 3:14 - loss: 1.4380 - regression_loss: 1.1761 - classification_loss: 0.2619
 327/1000 [========>.....................] - ETA: 3:13 - loss: 1.4387 - regression_loss: 1.1772 - classification_loss: 0.2615
 328/1000 [========>.....................] - ETA: 3:13 - loss: 1.4366 - regression_loss: 1.1755 - classification_loss: 0.2611
 329/1000 [========>.....................] - ETA: 3:13 - loss: 1.4383 - regression_loss: 1.1772 - classification_loss: 0.2610
 330/1000 [========>.....................] - ETA: 3:13 - loss: 1.4369 - regression_loss: 1.1762 - classification_loss: 0.2607
 331/1000 [========>.....................] - ETA: 3:12 - loss: 1.4420 - regression_loss: 1.1802 - classification_loss: 0.2618
 332/1000 [========>.....................] - ETA: 3:12 - loss: 1.4400 - regression_loss: 1.1786 - classification_loss: 0.2613
 333/1000 [========>.....................] - ETA: 3:12 - loss: 1.4375 - regression_loss: 1.1767 - classification_loss: 0.2608
 334/1000 [=========>....................] - ETA: 3:11 - loss: 1.4373 - regression_loss: 1.1752 - classification_loss: 0.2622
 335/1000 [=========>....................] - ETA: 3:11 - loss: 1.4365 - regression_loss: 1.1739 - classification_loss: 0.2625
 336/1000 [=========>....................] - ETA: 3:11 - loss: 1.4377 - regression_loss: 1.1750 - classification_loss: 0.2627
 337/1000 [=========>....................] - ETA: 3:11 - loss: 1.4391 - regression_loss: 1.1762 - classification_loss: 0.2628
 338/1000 [=========>....................] - ETA: 3:10 - loss: 1.4363 - regression_loss: 1.1740 - classification_loss: 0.2624
 339/1000 [=========>....................] - ETA: 3:10 - loss: 1.4377 - regression_loss: 1.1752 - classification_loss: 0.2626
 340/1000 [=========>....................] - ETA: 3:10 - loss: 1.4397 - regression_loss: 1.1767 - classification_loss: 0.2630
 341/1000 [=========>....................] - ETA: 3:09 - loss: 1.4411 - regression_loss: 1.1781 - classification_loss: 0.2630
 342/1000 [=========>....................] - ETA: 3:09 - loss: 1.4388 - regression_loss: 1.1762 - classification_loss: 0.2626
 343/1000 [=========>....................] - ETA: 3:09 - loss: 1.4377 - regression_loss: 1.1755 - classification_loss: 0.2622
 344/1000 [=========>....................] - ETA: 3:08 - loss: 1.4396 - regression_loss: 1.1772 - classification_loss: 0.2624
 345/1000 [=========>....................] - ETA: 3:08 - loss: 1.4433 - regression_loss: 1.1798 - classification_loss: 0.2635
 346/1000 [=========>....................] - ETA: 3:08 - loss: 1.4436 - regression_loss: 1.1803 - classification_loss: 0.2633
 347/1000 [=========>....................] - ETA: 3:08 - loss: 1.4432 - regression_loss: 1.1802 - classification_loss: 0.2630
 348/1000 [=========>....................] - ETA: 3:07 - loss: 1.4451 - regression_loss: 1.1820 - classification_loss: 0.2631
 349/1000 [=========>....................] - ETA: 3:07 - loss: 1.4448 - regression_loss: 1.1819 - classification_loss: 0.2629
 350/1000 [=========>....................] - ETA: 3:07 - loss: 1.4455 - regression_loss: 1.1827 - classification_loss: 0.2627
 351/1000 [=========>....................] - ETA: 3:06 - loss: 1.4440 - regression_loss: 1.1816 - classification_loss: 0.2624
 352/1000 [=========>....................] - ETA: 3:06 - loss: 1.4444 - regression_loss: 1.1819 - classification_loss: 0.2625
 353/1000 [=========>....................] - ETA: 3:06 - loss: 1.4439 - regression_loss: 1.1810 - classification_loss: 0.2629
 354/1000 [=========>....................] - ETA: 3:06 - loss: 1.4447 - regression_loss: 1.1812 - classification_loss: 0.2636
 355/1000 [=========>....................] - ETA: 3:05 - loss: 1.4430 - regression_loss: 1.1797 - classification_loss: 0.2633
 356/1000 [=========>....................] - ETA: 3:05 - loss: 1.4402 - regression_loss: 1.1775 - classification_loss: 0.2627
 357/1000 [=========>....................] - ETA: 3:05 - loss: 1.4382 - regression_loss: 1.1760 - classification_loss: 0.2622
 358/1000 [=========>....................] - ETA: 3:04 - loss: 1.4414 - regression_loss: 1.1781 - classification_loss: 0.2633
 359/1000 [=========>....................] - ETA: 3:04 - loss: 1.4401 - regression_loss: 1.1772 - classification_loss: 0.2629
 360/1000 [=========>....................] - ETA: 3:04 - loss: 1.4389 - regression_loss: 1.1764 - classification_loss: 0.2625
 361/1000 [=========>....................] - ETA: 3:04 - loss: 1.4377 - regression_loss: 1.1755 - classification_loss: 0.2622
 362/1000 [=========>....................] - ETA: 3:03 - loss: 1.4371 - regression_loss: 1.1752 - classification_loss: 0.2618
 363/1000 [=========>....................] - ETA: 3:03 - loss: 1.4375 - regression_loss: 1.1759 - classification_loss: 0.2616
 364/1000 [=========>....................] - ETA: 3:03 - loss: 1.4364 - regression_loss: 1.1751 - classification_loss: 0.2613
 365/1000 [=========>....................] - ETA: 3:02 - loss: 1.4343 - regression_loss: 1.1733 - classification_loss: 0.2609
 366/1000 [=========>....................] - ETA: 3:02 - loss: 1.4347 - regression_loss: 1.1737 - classification_loss: 0.2609
 367/1000 [==========>...................] - ETA: 3:02 - loss: 1.4334 - regression_loss: 1.1728 - classification_loss: 0.2606
 368/1000 [==========>...................] - ETA: 3:02 - loss: 1.4326 - regression_loss: 1.1724 - classification_loss: 0.2601
 369/1000 [==========>...................] - ETA: 3:01 - loss: 1.4317 - regression_loss: 1.1718 - classification_loss: 0.2599
 370/1000 [==========>...................] - ETA: 3:01 - loss: 1.4306 - regression_loss: 1.1710 - classification_loss: 0.2596
 371/1000 [==========>...................] - ETA: 3:01 - loss: 1.4287 - regression_loss: 1.1696 - classification_loss: 0.2591
 372/1000 [==========>...................] - ETA: 3:00 - loss: 1.4268 - regression_loss: 1.1682 - classification_loss: 0.2587
 373/1000 [==========>...................] - ETA: 3:00 - loss: 1.4281 - regression_loss: 1.1693 - classification_loss: 0.2588
 374/1000 [==========>...................] - ETA: 3:00 - loss: 1.4288 - regression_loss: 1.1700 - classification_loss: 0.2588
 375/1000 [==========>...................] - ETA: 3:00 - loss: 1.4266 - regression_loss: 1.1683 - classification_loss: 0.2583
 376/1000 [==========>...................] - ETA: 2:59 - loss: 1.4265 - regression_loss: 1.1683 - classification_loss: 0.2581
 377/1000 [==========>...................] - ETA: 2:59 - loss: 1.4269 - regression_loss: 1.1690 - classification_loss: 0.2580
 378/1000 [==========>...................] - ETA: 2:59 - loss: 1.4294 - regression_loss: 1.1711 - classification_loss: 0.2583
 379/1000 [==========>...................] - ETA: 2:58 - loss: 1.4309 - regression_loss: 1.1725 - classification_loss: 0.2584
 380/1000 [==========>...................] - ETA: 2:58 - loss: 1.4306 - regression_loss: 1.1725 - classification_loss: 0.2581
 381/1000 [==========>...................] - ETA: 2:58 - loss: 1.4299 - regression_loss: 1.1719 - classification_loss: 0.2580
 382/1000 [==========>...................] - ETA: 2:58 - loss: 1.4308 - regression_loss: 1.1729 - classification_loss: 0.2579
 383/1000 [==========>...................] - ETA: 2:57 - loss: 1.4301 - regression_loss: 1.1724 - classification_loss: 0.2577
 384/1000 [==========>...................] - ETA: 2:57 - loss: 1.4281 - regression_loss: 1.1708 - classification_loss: 0.2573
 385/1000 [==========>...................] - ETA: 2:57 - loss: 1.4272 - regression_loss: 1.1702 - classification_loss: 0.2569
 386/1000 [==========>...................] - ETA: 2:56 - loss: 1.4288 - regression_loss: 1.1712 - classification_loss: 0.2576
 387/1000 [==========>...................] - ETA: 2:56 - loss: 1.4305 - regression_loss: 1.1726 - classification_loss: 0.2579
 388/1000 [==========>...................] - ETA: 2:56 - loss: 1.4292 - regression_loss: 1.1716 - classification_loss: 0.2576
 389/1000 [==========>...................] - ETA: 2:56 - loss: 1.4292 - regression_loss: 1.1716 - classification_loss: 0.2576
 390/1000 [==========>...................] - ETA: 2:55 - loss: 1.4299 - regression_loss: 1.1724 - classification_loss: 0.2575
 391/1000 [==========>...................] - ETA: 2:55 - loss: 1.4312 - regression_loss: 1.1735 - classification_loss: 0.2576
 392/1000 [==========>...................] - ETA: 2:55 - loss: 1.4347 - regression_loss: 1.1755 - classification_loss: 0.2593
 393/1000 [==========>...................] - ETA: 2:54 - loss: 1.4369 - regression_loss: 1.1774 - classification_loss: 0.2595
 394/1000 [==========>...................] - ETA: 2:54 - loss: 1.4374 - regression_loss: 1.1773 - classification_loss: 0.2601
 395/1000 [==========>...................] - ETA: 2:54 - loss: 1.4371 - regression_loss: 1.1769 - classification_loss: 0.2602
 396/1000 [==========>...................] - ETA: 2:53 - loss: 1.4363 - regression_loss: 1.1765 - classification_loss: 0.2598
 397/1000 [==========>...................] - ETA: 2:53 - loss: 1.4362 - regression_loss: 1.1764 - classification_loss: 0.2598
 398/1000 [==========>...................] - ETA: 2:53 - loss: 1.4354 - regression_loss: 1.1759 - classification_loss: 0.2595
 399/1000 [==========>...................] - ETA: 2:53 - loss: 1.4362 - regression_loss: 1.1765 - classification_loss: 0.2598
 400/1000 [===========>..................] - ETA: 2:52 - loss: 1.4373 - regression_loss: 1.1773 - classification_loss: 0.2600
 401/1000 [===========>..................] - ETA: 2:52 - loss: 1.4362 - regression_loss: 1.1762 - classification_loss: 0.2600
 402/1000 [===========>..................] - ETA: 2:52 - loss: 1.4365 - regression_loss: 1.1765 - classification_loss: 0.2599
 403/1000 [===========>..................] - ETA: 2:51 - loss: 1.4375 - regression_loss: 1.1772 - classification_loss: 0.2603
 404/1000 [===========>..................] - ETA: 2:51 - loss: 1.4352 - regression_loss: 1.1753 - classification_loss: 0.2598
 405/1000 [===========>..................] - ETA: 2:51 - loss: 1.4343 - regression_loss: 1.1747 - classification_loss: 0.2596
 406/1000 [===========>..................] - ETA: 2:51 - loss: 1.4333 - regression_loss: 1.1738 - classification_loss: 0.2595
 407/1000 [===========>..................] - ETA: 2:50 - loss: 1.4328 - regression_loss: 1.1735 - classification_loss: 0.2593
 408/1000 [===========>..................] - ETA: 2:50 - loss: 1.4324 - regression_loss: 1.1732 - classification_loss: 0.2592
 409/1000 [===========>..................] - ETA: 2:50 - loss: 1.4329 - regression_loss: 1.1738 - classification_loss: 0.2591
 410/1000 [===========>..................] - ETA: 2:49 - loss: 1.4330 - regression_loss: 1.1741 - classification_loss: 0.2589
 411/1000 [===========>..................] - ETA: 2:49 - loss: 1.4329 - regression_loss: 1.1740 - classification_loss: 0.2589
 412/1000 [===========>..................] - ETA: 2:49 - loss: 1.4330 - regression_loss: 1.1742 - classification_loss: 0.2588
 413/1000 [===========>..................] - ETA: 2:49 - loss: 1.4321 - regression_loss: 1.1736 - classification_loss: 0.2584
 414/1000 [===========>..................] - ETA: 2:48 - loss: 1.4308 - regression_loss: 1.1727 - classification_loss: 0.2581
 415/1000 [===========>..................] - ETA: 2:48 - loss: 1.4323 - regression_loss: 1.1739 - classification_loss: 0.2585
 416/1000 [===========>..................] - ETA: 2:48 - loss: 1.4324 - regression_loss: 1.1741 - classification_loss: 0.2583
 417/1000 [===========>..................] - ETA: 2:47 - loss: 1.4309 - regression_loss: 1.1731 - classification_loss: 0.2579
 418/1000 [===========>..................] - ETA: 2:47 - loss: 1.4321 - regression_loss: 1.1741 - classification_loss: 0.2580
 419/1000 [===========>..................] - ETA: 2:47 - loss: 1.4310 - regression_loss: 1.1731 - classification_loss: 0.2579
 420/1000 [===========>..................] - ETA: 2:46 - loss: 1.4296 - regression_loss: 1.1721 - classification_loss: 0.2575
 421/1000 [===========>..................] - ETA: 2:46 - loss: 1.4301 - regression_loss: 1.1726 - classification_loss: 0.2575
 422/1000 [===========>..................] - ETA: 2:46 - loss: 1.4289 - regression_loss: 1.1717 - classification_loss: 0.2572
 423/1000 [===========>..................] - ETA: 2:46 - loss: 1.4303 - regression_loss: 1.1731 - classification_loss: 0.2572
 424/1000 [===========>..................] - ETA: 2:45 - loss: 1.4308 - regression_loss: 1.1736 - classification_loss: 0.2571
 425/1000 [===========>..................] - ETA: 2:45 - loss: 1.4304 - regression_loss: 1.1733 - classification_loss: 0.2571
 426/1000 [===========>..................] - ETA: 2:45 - loss: 1.4292 - regression_loss: 1.1724 - classification_loss: 0.2568
 427/1000 [===========>..................] - ETA: 2:44 - loss: 1.4293 - regression_loss: 1.1727 - classification_loss: 0.2566
 428/1000 [===========>..................] - ETA: 2:44 - loss: 1.4279 - regression_loss: 1.1716 - classification_loss: 0.2563
 429/1000 [===========>..................] - ETA: 2:44 - loss: 1.4283 - regression_loss: 1.1717 - classification_loss: 0.2566
 430/1000 [===========>..................] - ETA: 2:44 - loss: 1.4269 - regression_loss: 1.1707 - classification_loss: 0.2562
 431/1000 [===========>..................] - ETA: 2:43 - loss: 1.4289 - regression_loss: 1.1727 - classification_loss: 0.2562
 432/1000 [===========>..................] - ETA: 2:43 - loss: 1.4297 - regression_loss: 1.1734 - classification_loss: 0.2563
 433/1000 [===========>..................] - ETA: 2:43 - loss: 1.4292 - regression_loss: 1.1732 - classification_loss: 0.2560
 434/1000 [============>.................] - ETA: 2:42 - loss: 1.4291 - regression_loss: 1.1730 - classification_loss: 0.2561
 435/1000 [============>.................] - ETA: 2:42 - loss: 1.4288 - regression_loss: 1.1730 - classification_loss: 0.2558
 436/1000 [============>.................] - ETA: 2:42 - loss: 1.4282 - regression_loss: 1.1725 - classification_loss: 0.2557
 437/1000 [============>.................] - ETA: 2:42 - loss: 1.4292 - regression_loss: 1.1735 - classification_loss: 0.2557
 438/1000 [============>.................] - ETA: 2:41 - loss: 1.4297 - regression_loss: 1.1740 - classification_loss: 0.2557
 439/1000 [============>.................] - ETA: 2:41 - loss: 1.4293 - regression_loss: 1.1733 - classification_loss: 0.2560
 440/1000 [============>.................] - ETA: 2:41 - loss: 1.4319 - regression_loss: 1.1740 - classification_loss: 0.2579
 441/1000 [============>.................] - ETA: 2:40 - loss: 1.4357 - regression_loss: 1.1765 - classification_loss: 0.2592
 442/1000 [============>.................] - ETA: 2:40 - loss: 1.4366 - regression_loss: 1.1775 - classification_loss: 0.2591
 443/1000 [============>.................] - ETA: 2:40 - loss: 1.4352 - regression_loss: 1.1764 - classification_loss: 0.2588
 444/1000 [============>.................] - ETA: 2:40 - loss: 1.4349 - regression_loss: 1.1763 - classification_loss: 0.2585
 445/1000 [============>.................] - ETA: 2:39 - loss: 1.4339 - regression_loss: 1.1755 - classification_loss: 0.2584
 446/1000 [============>.................] - ETA: 2:39 - loss: 1.4344 - regression_loss: 1.1760 - classification_loss: 0.2584
 447/1000 [============>.................] - ETA: 2:39 - loss: 1.4330 - regression_loss: 1.1749 - classification_loss: 0.2581
 448/1000 [============>.................] - ETA: 2:38 - loss: 1.4322 - regression_loss: 1.1744 - classification_loss: 0.2578
 449/1000 [============>.................] - ETA: 2:38 - loss: 1.4309 - regression_loss: 1.1732 - classification_loss: 0.2576
 450/1000 [============>.................] - ETA: 2:38 - loss: 1.4300 - regression_loss: 1.1725 - classification_loss: 0.2575
 451/1000 [============>.................] - ETA: 2:38 - loss: 1.4304 - regression_loss: 1.1727 - classification_loss: 0.2577
 452/1000 [============>.................] - ETA: 2:37 - loss: 1.4294 - regression_loss: 1.1720 - classification_loss: 0.2574
 453/1000 [============>.................] - ETA: 2:37 - loss: 1.4294 - regression_loss: 1.1721 - classification_loss: 0.2573
 454/1000 [============>.................] - ETA: 2:37 - loss: 1.4290 - regression_loss: 1.1716 - classification_loss: 0.2574
 455/1000 [============>.................] - ETA: 2:36 - loss: 1.4307 - regression_loss: 1.1730 - classification_loss: 0.2577
 456/1000 [============>.................] - ETA: 2:36 - loss: 1.4306 - regression_loss: 1.1730 - classification_loss: 0.2575
 457/1000 [============>.................] - ETA: 2:36 - loss: 1.4295 - regression_loss: 1.1721 - classification_loss: 0.2574
 458/1000 [============>.................] - ETA: 2:35 - loss: 1.4285 - regression_loss: 1.1713 - classification_loss: 0.2571
 459/1000 [============>.................] - ETA: 2:35 - loss: 1.4269 - regression_loss: 1.1701 - classification_loss: 0.2568
 460/1000 [============>.................] - ETA: 2:35 - loss: 1.4254 - regression_loss: 1.1686 - classification_loss: 0.2568
 461/1000 [============>.................] - ETA: 2:35 - loss: 1.4273 - regression_loss: 1.1703 - classification_loss: 0.2570
 462/1000 [============>.................] - ETA: 2:34 - loss: 1.4279 - regression_loss: 1.1708 - classification_loss: 0.2571
 463/1000 [============>.................] - ETA: 2:34 - loss: 1.4274 - regression_loss: 1.1704 - classification_loss: 0.2570
 464/1000 [============>.................] - ETA: 2:34 - loss: 1.4304 - regression_loss: 1.1734 - classification_loss: 0.2570
 465/1000 [============>.................] - ETA: 2:33 - loss: 1.4300 - regression_loss: 1.1732 - classification_loss: 0.2568
 466/1000 [============>.................] - ETA: 2:33 - loss: 1.4299 - regression_loss: 1.1733 - classification_loss: 0.2566
 467/1000 [=============>................] - ETA: 2:33 - loss: 1.4302 - regression_loss: 1.1736 - classification_loss: 0.2566
 468/1000 [=============>................] - ETA: 2:33 - loss: 1.4291 - regression_loss: 1.1726 - classification_loss: 0.2565
 469/1000 [=============>................] - ETA: 2:32 - loss: 1.4289 - regression_loss: 1.1724 - classification_loss: 0.2564
 470/1000 [=============>................] - ETA: 2:32 - loss: 1.4292 - regression_loss: 1.1727 - classification_loss: 0.2565
 471/1000 [=============>................] - ETA: 2:32 - loss: 1.4295 - regression_loss: 1.1732 - classification_loss: 0.2563
 472/1000 [=============>................] - ETA: 2:31 - loss: 1.4290 - regression_loss: 1.1727 - classification_loss: 0.2563
 473/1000 [=============>................] - ETA: 2:31 - loss: 1.4291 - regression_loss: 1.1728 - classification_loss: 0.2563
 474/1000 [=============>................] - ETA: 2:31 - loss: 1.4300 - regression_loss: 1.1731 - classification_loss: 0.2569
 475/1000 [=============>................] - ETA: 2:31 - loss: 1.4288 - regression_loss: 1.1722 - classification_loss: 0.2566
 476/1000 [=============>................] - ETA: 2:30 - loss: 1.4318 - regression_loss: 1.1746 - classification_loss: 0.2572
 477/1000 [=============>................] - ETA: 2:30 - loss: 1.4323 - regression_loss: 1.1750 - classification_loss: 0.2573
 478/1000 [=============>................] - ETA: 2:30 - loss: 1.4317 - regression_loss: 1.1745 - classification_loss: 0.2572
 479/1000 [=============>................] - ETA: 2:29 - loss: 1.4319 - regression_loss: 1.1749 - classification_loss: 0.2570
 480/1000 [=============>................] - ETA: 2:29 - loss: 1.4310 - regression_loss: 1.1741 - classification_loss: 0.2569
 481/1000 [=============>................] - ETA: 2:29 - loss: 1.4307 - regression_loss: 1.1740 - classification_loss: 0.2567
 482/1000 [=============>................] - ETA: 2:29 - loss: 1.4318 - regression_loss: 1.1749 - classification_loss: 0.2568
 483/1000 [=============>................] - ETA: 2:28 - loss: 1.4319 - regression_loss: 1.1751 - classification_loss: 0.2568
 484/1000 [=============>................] - ETA: 2:28 - loss: 1.4312 - regression_loss: 1.1746 - classification_loss: 0.2566
 485/1000 [=============>................] - ETA: 2:28 - loss: 1.4314 - regression_loss: 1.1746 - classification_loss: 0.2567
 486/1000 [=============>................] - ETA: 2:27 - loss: 1.4329 - regression_loss: 1.1759 - classification_loss: 0.2570
 487/1000 [=============>................] - ETA: 2:27 - loss: 1.4312 - regression_loss: 1.1745 - classification_loss: 0.2567
 488/1000 [=============>................] - ETA: 2:27 - loss: 1.4300 - regression_loss: 1.1736 - classification_loss: 0.2564
 489/1000 [=============>................] - ETA: 2:26 - loss: 1.4285 - regression_loss: 1.1723 - classification_loss: 0.2563
 490/1000 [=============>................] - ETA: 2:26 - loss: 1.4275 - regression_loss: 1.1712 - classification_loss: 0.2563
 491/1000 [=============>................] - ETA: 2:26 - loss: 1.4266 - regression_loss: 1.1706 - classification_loss: 0.2561
 492/1000 [=============>................] - ETA: 2:26 - loss: 1.4256 - regression_loss: 1.1696 - classification_loss: 0.2560
 493/1000 [=============>................] - ETA: 2:25 - loss: 1.4240 - regression_loss: 1.1684 - classification_loss: 0.2556
 494/1000 [=============>................] - ETA: 2:25 - loss: 1.4246 - regression_loss: 1.1691 - classification_loss: 0.2555
 495/1000 [=============>................] - ETA: 2:25 - loss: 1.4256 - regression_loss: 1.1701 - classification_loss: 0.2555
 496/1000 [=============>................] - ETA: 2:24 - loss: 1.4241 - regression_loss: 1.1690 - classification_loss: 0.2552
 497/1000 [=============>................] - ETA: 2:24 - loss: 1.4237 - regression_loss: 1.1687 - classification_loss: 0.2550
 498/1000 [=============>................] - ETA: 2:24 - loss: 1.4218 - regression_loss: 1.1672 - classification_loss: 0.2546
 499/1000 [=============>................] - ETA: 2:24 - loss: 1.4235 - regression_loss: 1.1685 - classification_loss: 0.2550
 500/1000 [==============>...............] - ETA: 2:23 - loss: 1.4248 - regression_loss: 1.1697 - classification_loss: 0.2551
 501/1000 [==============>...............] - ETA: 2:23 - loss: 1.4264 - regression_loss: 1.1706 - classification_loss: 0.2559
 502/1000 [==============>...............] - ETA: 2:23 - loss: 1.4272 - regression_loss: 1.1713 - classification_loss: 0.2559
 503/1000 [==============>...............] - ETA: 2:22 - loss: 1.4273 - regression_loss: 1.1715 - classification_loss: 0.2558
 504/1000 [==============>...............] - ETA: 2:22 - loss: 1.4267 - regression_loss: 1.1710 - classification_loss: 0.2557
 505/1000 [==============>...............] - ETA: 2:22 - loss: 1.4251 - regression_loss: 1.1697 - classification_loss: 0.2554
 506/1000 [==============>...............] - ETA: 2:22 - loss: 1.4245 - regression_loss: 1.1689 - classification_loss: 0.2556
 507/1000 [==============>...............] - ETA: 2:21 - loss: 1.4251 - regression_loss: 1.1690 - classification_loss: 0.2561
 508/1000 [==============>...............] - ETA: 2:21 - loss: 1.4239 - regression_loss: 1.1680 - classification_loss: 0.2558
 509/1000 [==============>...............] - ETA: 2:21 - loss: 1.4222 - regression_loss: 1.1667 - classification_loss: 0.2555
 510/1000 [==============>...............] - ETA: 2:20 - loss: 1.4217 - regression_loss: 1.1664 - classification_loss: 0.2553
 511/1000 [==============>...............] - ETA: 2:20 - loss: 1.4233 - regression_loss: 1.1675 - classification_loss: 0.2557
 512/1000 [==============>...............] - ETA: 2:20 - loss: 1.4232 - regression_loss: 1.1677 - classification_loss: 0.2555
 513/1000 [==============>...............] - ETA: 2:20 - loss: 1.4219 - regression_loss: 1.1666 - classification_loss: 0.2553
 514/1000 [==============>...............] - ETA: 2:19 - loss: 1.4238 - regression_loss: 1.1683 - classification_loss: 0.2555
 515/1000 [==============>...............] - ETA: 2:19 - loss: 1.4244 - regression_loss: 1.1689 - classification_loss: 0.2555
 516/1000 [==============>...............] - ETA: 2:19 - loss: 1.4236 - regression_loss: 1.1683 - classification_loss: 0.2554
 517/1000 [==============>...............] - ETA: 2:18 - loss: 1.4231 - regression_loss: 1.1679 - classification_loss: 0.2552
 518/1000 [==============>...............] - ETA: 2:18 - loss: 1.4233 - regression_loss: 1.1678 - classification_loss: 0.2554
 519/1000 [==============>...............] - ETA: 2:18 - loss: 1.4235 - regression_loss: 1.1682 - classification_loss: 0.2553
 520/1000 [==============>...............] - ETA: 2:18 - loss: 1.4254 - regression_loss: 1.1698 - classification_loss: 0.2556
 521/1000 [==============>...............] - ETA: 2:17 - loss: 1.4245 - regression_loss: 1.1691 - classification_loss: 0.2554
 522/1000 [==============>...............] - ETA: 2:17 - loss: 1.4248 - regression_loss: 1.1694 - classification_loss: 0.2554
 523/1000 [==============>...............] - ETA: 2:17 - loss: 1.4261 - regression_loss: 1.1705 - classification_loss: 0.2555
 524/1000 [==============>...............] - ETA: 2:16 - loss: 1.4257 - regression_loss: 1.1702 - classification_loss: 0.2555
 525/1000 [==============>...............] - ETA: 2:16 - loss: 1.4275 - regression_loss: 1.1716 - classification_loss: 0.2560
 526/1000 [==============>...............] - ETA: 2:16 - loss: 1.4270 - regression_loss: 1.1712 - classification_loss: 0.2558
 527/1000 [==============>...............] - ETA: 2:16 - loss: 1.4263 - regression_loss: 1.1706 - classification_loss: 0.2557
 528/1000 [==============>...............] - ETA: 2:15 - loss: 1.4260 - regression_loss: 1.1703 - classification_loss: 0.2557
 529/1000 [==============>...............] - ETA: 2:15 - loss: 1.4253 - regression_loss: 1.1698 - classification_loss: 0.2555
 530/1000 [==============>...............] - ETA: 2:15 - loss: 1.4241 - regression_loss: 1.1688 - classification_loss: 0.2553
 531/1000 [==============>...............] - ETA: 2:14 - loss: 1.4238 - regression_loss: 1.1687 - classification_loss: 0.2551
 532/1000 [==============>...............] - ETA: 2:14 - loss: 1.4232 - regression_loss: 1.1682 - classification_loss: 0.2550
 533/1000 [==============>...............] - ETA: 2:14 - loss: 1.4251 - regression_loss: 1.1693 - classification_loss: 0.2558
 534/1000 [===============>..............] - ETA: 2:14 - loss: 1.4254 - regression_loss: 1.1695 - classification_loss: 0.2559
 535/1000 [===============>..............] - ETA: 2:13 - loss: 1.4261 - regression_loss: 1.1701 - classification_loss: 0.2560
 536/1000 [===============>..............] - ETA: 2:13 - loss: 1.4249 - regression_loss: 1.1691 - classification_loss: 0.2558
 537/1000 [===============>..............] - ETA: 2:13 - loss: 1.4242 - regression_loss: 1.1686 - classification_loss: 0.2556
 538/1000 [===============>..............] - ETA: 2:12 - loss: 1.4265 - regression_loss: 1.1702 - classification_loss: 0.2564
 539/1000 [===============>..............] - ETA: 2:12 - loss: 1.4254 - regression_loss: 1.1694 - classification_loss: 0.2560
 540/1000 [===============>..............] - ETA: 2:12 - loss: 1.4250 - regression_loss: 1.1691 - classification_loss: 0.2559
 541/1000 [===============>..............] - ETA: 2:11 - loss: 1.4255 - regression_loss: 1.1695 - classification_loss: 0.2559
 542/1000 [===============>..............] - ETA: 2:11 - loss: 1.4239 - regression_loss: 1.1682 - classification_loss: 0.2557
 543/1000 [===============>..............] - ETA: 2:11 - loss: 1.4240 - regression_loss: 1.1683 - classification_loss: 0.2557
 544/1000 [===============>..............] - ETA: 2:11 - loss: 1.4249 - regression_loss: 1.1693 - classification_loss: 0.2556
 545/1000 [===============>..............] - ETA: 2:10 - loss: 1.4265 - regression_loss: 1.1707 - classification_loss: 0.2558
 546/1000 [===============>..............] - ETA: 2:10 - loss: 1.4259 - regression_loss: 1.1703 - classification_loss: 0.2555
 547/1000 [===============>..............] - ETA: 2:10 - loss: 1.4265 - regression_loss: 1.1711 - classification_loss: 0.2555
 548/1000 [===============>..............] - ETA: 2:09 - loss: 1.4255 - regression_loss: 1.1702 - classification_loss: 0.2552
 549/1000 [===============>..............] - ETA: 2:09 - loss: 1.4255 - regression_loss: 1.1702 - classification_loss: 0.2553
 550/1000 [===============>..............] - ETA: 2:09 - loss: 1.4266 - regression_loss: 1.1714 - classification_loss: 0.2552
 551/1000 [===============>..............] - ETA: 2:09 - loss: 1.4271 - regression_loss: 1.1720 - classification_loss: 0.2551
 552/1000 [===============>..............] - ETA: 2:08 - loss: 1.4274 - regression_loss: 1.1724 - classification_loss: 0.2550
 553/1000 [===============>..............] - ETA: 2:08 - loss: 1.4274 - regression_loss: 1.1724 - classification_loss: 0.2550
 554/1000 [===============>..............] - ETA: 2:08 - loss: 1.4263 - regression_loss: 1.1716 - classification_loss: 0.2548
 555/1000 [===============>..............] - ETA: 2:07 - loss: 1.4266 - regression_loss: 1.1717 - classification_loss: 0.2549
 556/1000 [===============>..............] - ETA: 2:07 - loss: 1.4264 - regression_loss: 1.1716 - classification_loss: 0.2547
 557/1000 [===============>..............] - ETA: 2:07 - loss: 1.4260 - regression_loss: 1.1714 - classification_loss: 0.2546
 558/1000 [===============>..............] - ETA: 2:07 - loss: 1.4259 - regression_loss: 1.1715 - classification_loss: 0.2544
 559/1000 [===============>..............] - ETA: 2:06 - loss: 1.4263 - regression_loss: 1.1718 - classification_loss: 0.2545
 560/1000 [===============>..............] - ETA: 2:06 - loss: 1.4262 - regression_loss: 1.1718 - classification_loss: 0.2544
 561/1000 [===============>..............] - ETA: 2:06 - loss: 1.4260 - regression_loss: 1.1718 - classification_loss: 0.2542
 562/1000 [===============>..............] - ETA: 2:05 - loss: 1.4282 - regression_loss: 1.1738 - classification_loss: 0.2544
 563/1000 [===============>..............] - ETA: 2:05 - loss: 1.4271 - regression_loss: 1.1730 - classification_loss: 0.2541
 564/1000 [===============>..............] - ETA: 2:05 - loss: 1.4261 - regression_loss: 1.1723 - classification_loss: 0.2538
 565/1000 [===============>..............] - ETA: 2:05 - loss: 1.4251 - regression_loss: 1.1715 - classification_loss: 0.2536
 566/1000 [===============>..............] - ETA: 2:04 - loss: 1.4239 - regression_loss: 1.1706 - classification_loss: 0.2534
 567/1000 [================>.............] - ETA: 2:04 - loss: 1.4234 - regression_loss: 1.1703 - classification_loss: 0.2531
 568/1000 [================>.............] - ETA: 2:04 - loss: 1.4236 - regression_loss: 1.1705 - classification_loss: 0.2531
 569/1000 [================>.............] - ETA: 2:03 - loss: 1.4225 - regression_loss: 1.1696 - classification_loss: 0.2529
 570/1000 [================>.............] - ETA: 2:03 - loss: 1.4225 - regression_loss: 1.1696 - classification_loss: 0.2528
 571/1000 [================>.............] - ETA: 2:03 - loss: 1.4232 - regression_loss: 1.1701 - classification_loss: 0.2531
 572/1000 [================>.............] - ETA: 2:03 - loss: 1.4230 - regression_loss: 1.1699 - classification_loss: 0.2531
 573/1000 [================>.............] - ETA: 2:02 - loss: 1.4221 - regression_loss: 1.1693 - classification_loss: 0.2529
 574/1000 [================>.............] - ETA: 2:02 - loss: 1.4237 - regression_loss: 1.1706 - classification_loss: 0.2531
 575/1000 [================>.............] - ETA: 2:02 - loss: 1.4225 - regression_loss: 1.1696 - classification_loss: 0.2529
 576/1000 [================>.............] - ETA: 2:01 - loss: 1.4232 - regression_loss: 1.1702 - classification_loss: 0.2530
 577/1000 [================>.............] - ETA: 2:01 - loss: 1.4225 - regression_loss: 1.1698 - classification_loss: 0.2527
 578/1000 [================>.............] - ETA: 2:01 - loss: 1.4210 - regression_loss: 1.1686 - classification_loss: 0.2525
 579/1000 [================>.............] - ETA: 2:01 - loss: 1.4221 - regression_loss: 1.1697 - classification_loss: 0.2525
 580/1000 [================>.............] - ETA: 2:00 - loss: 1.4214 - regression_loss: 1.1691 - classification_loss: 0.2523
 581/1000 [================>.............] - ETA: 2:00 - loss: 1.4213 - regression_loss: 1.1691 - classification_loss: 0.2522
 582/1000 [================>.............] - ETA: 2:00 - loss: 1.4214 - regression_loss: 1.1693 - classification_loss: 0.2521
 583/1000 [================>.............] - ETA: 1:59 - loss: 1.4211 - regression_loss: 1.1690 - classification_loss: 0.2521
 584/1000 [================>.............] - ETA: 1:59 - loss: 1.4207 - regression_loss: 1.1685 - classification_loss: 0.2522
 585/1000 [================>.............] - ETA: 1:59 - loss: 1.4196 - regression_loss: 1.1676 - classification_loss: 0.2519
 586/1000 [================>.............] - ETA: 1:59 - loss: 1.4193 - regression_loss: 1.1674 - classification_loss: 0.2518
 587/1000 [================>.............] - ETA: 1:58 - loss: 1.4197 - regression_loss: 1.1679 - classification_loss: 0.2518
 588/1000 [================>.............] - ETA: 1:58 - loss: 1.4205 - regression_loss: 1.1684 - classification_loss: 0.2521
 589/1000 [================>.............] - ETA: 1:58 - loss: 1.4201 - regression_loss: 1.1681 - classification_loss: 0.2520
 590/1000 [================>.............] - ETA: 1:57 - loss: 1.4211 - regression_loss: 1.1692 - classification_loss: 0.2519
 591/1000 [================>.............] - ETA: 1:57 - loss: 1.4211 - regression_loss: 1.1693 - classification_loss: 0.2517
 592/1000 [================>.............] - ETA: 1:57 - loss: 1.4214 - regression_loss: 1.1697 - classification_loss: 0.2517
 593/1000 [================>.............] - ETA: 1:56 - loss: 1.4207 - regression_loss: 1.1692 - classification_loss: 0.2515
 594/1000 [================>.............] - ETA: 1:56 - loss: 1.4197 - regression_loss: 1.1683 - classification_loss: 0.2513
 595/1000 [================>.............] - ETA: 1:56 - loss: 1.4186 - regression_loss: 1.1675 - classification_loss: 0.2511
 596/1000 [================>.............] - ETA: 1:56 - loss: 1.4190 - regression_loss: 1.1680 - classification_loss: 0.2510
 597/1000 [================>.............] - ETA: 1:55 - loss: 1.4176 - regression_loss: 1.1669 - classification_loss: 0.2507
 598/1000 [================>.............] - ETA: 1:55 - loss: 1.4177 - regression_loss: 1.1670 - classification_loss: 0.2507
 599/1000 [================>.............] - ETA: 1:55 - loss: 1.4178 - regression_loss: 1.1671 - classification_loss: 0.2507
 600/1000 [=================>............] - ETA: 1:54 - loss: 1.4182 - regression_loss: 1.1675 - classification_loss: 0.2508
 601/1000 [=================>............] - ETA: 1:54 - loss: 1.4195 - regression_loss: 1.1684 - classification_loss: 0.2512
 602/1000 [=================>............] - ETA: 1:54 - loss: 1.4189 - regression_loss: 1.1677 - classification_loss: 0.2512
 603/1000 [=================>............] - ETA: 1:54 - loss: 1.4199 - regression_loss: 1.1685 - classification_loss: 0.2513
 604/1000 [=================>............] - ETA: 1:53 - loss: 1.4187 - regression_loss: 1.1676 - classification_loss: 0.2511
 605/1000 [=================>............] - ETA: 1:53 - loss: 1.4183 - regression_loss: 1.1674 - classification_loss: 0.2509
 606/1000 [=================>............] - ETA: 1:53 - loss: 1.4173 - regression_loss: 1.1666 - classification_loss: 0.2508
 607/1000 [=================>............] - ETA: 1:52 - loss: 1.4189 - regression_loss: 1.1677 - classification_loss: 0.2512
 608/1000 [=================>............] - ETA: 1:52 - loss: 1.4177 - regression_loss: 1.1667 - classification_loss: 0.2509
 609/1000 [=================>............] - ETA: 1:52 - loss: 1.4168 - regression_loss: 1.1661 - classification_loss: 0.2507
 610/1000 [=================>............] - ETA: 1:52 - loss: 1.4162 - regression_loss: 1.1655 - classification_loss: 0.2507
 611/1000 [=================>............] - ETA: 1:51 - loss: 1.4167 - regression_loss: 1.1661 - classification_loss: 0.2506
 612/1000 [=================>............] - ETA: 1:51 - loss: 1.4167 - regression_loss: 1.1660 - classification_loss: 0.2506
 613/1000 [=================>............] - ETA: 1:51 - loss: 1.4156 - regression_loss: 1.1651 - classification_loss: 0.2505
 614/1000 [=================>............] - ETA: 1:50 - loss: 1.4146 - regression_loss: 1.1643 - classification_loss: 0.2504
 615/1000 [=================>............] - ETA: 1:50 - loss: 1.4143 - regression_loss: 1.1641 - classification_loss: 0.2502
 616/1000 [=================>............] - ETA: 1:50 - loss: 1.4136 - regression_loss: 1.1637 - classification_loss: 0.2500
 617/1000 [=================>............] - ETA: 1:50 - loss: 1.4124 - regression_loss: 1.1627 - classification_loss: 0.2497
 618/1000 [=================>............] - ETA: 1:49 - loss: 1.4116 - regression_loss: 1.1620 - classification_loss: 0.2495
 619/1000 [=================>............] - ETA: 1:49 - loss: 1.4116 - regression_loss: 1.1622 - classification_loss: 0.2494
 620/1000 [=================>............] - ETA: 1:49 - loss: 1.4115 - regression_loss: 1.1622 - classification_loss: 0.2493
 621/1000 [=================>............] - ETA: 1:48 - loss: 1.4103 - regression_loss: 1.1613 - classification_loss: 0.2490
 622/1000 [=================>............] - ETA: 1:48 - loss: 1.4094 - regression_loss: 1.1607 - classification_loss: 0.2487
 623/1000 [=================>............] - ETA: 1:48 - loss: 1.4101 - regression_loss: 1.1614 - classification_loss: 0.2488
 624/1000 [=================>............] - ETA: 1:48 - loss: 1.4101 - regression_loss: 1.1614 - classification_loss: 0.2487
 625/1000 [=================>............] - ETA: 1:47 - loss: 1.4104 - regression_loss: 1.1617 - classification_loss: 0.2487
 626/1000 [=================>............] - ETA: 1:47 - loss: 1.4125 - regression_loss: 1.1633 - classification_loss: 0.2491
 627/1000 [=================>............] - ETA: 1:47 - loss: 1.4152 - regression_loss: 1.1655 - classification_loss: 0.2497
 628/1000 [=================>............] - ETA: 1:46 - loss: 1.4155 - regression_loss: 1.1656 - classification_loss: 0.2499
 629/1000 [=================>............] - ETA: 1:46 - loss: 1.4149 - regression_loss: 1.1652 - classification_loss: 0.2498
 630/1000 [=================>............] - ETA: 1:46 - loss: 1.4142 - regression_loss: 1.1647 - classification_loss: 0.2496
 631/1000 [=================>............] - ETA: 1:46 - loss: 1.4138 - regression_loss: 1.1640 - classification_loss: 0.2498
 632/1000 [=================>............] - ETA: 1:45 - loss: 1.4124 - regression_loss: 1.1629 - classification_loss: 0.2495
 633/1000 [=================>............] - ETA: 1:45 - loss: 1.4130 - regression_loss: 1.1635 - classification_loss: 0.2495
 634/1000 [==================>...........] - ETA: 1:45 - loss: 1.4126 - regression_loss: 1.1633 - classification_loss: 0.2494
 635/1000 [==================>...........] - ETA: 1:44 - loss: 1.4120 - regression_loss: 1.1628 - classification_loss: 0.2492
 636/1000 [==================>...........] - ETA: 1:44 - loss: 1.4118 - regression_loss: 1.1628 - classification_loss: 0.2490
 637/1000 [==================>...........] - ETA: 1:44 - loss: 1.4113 - regression_loss: 1.1625 - classification_loss: 0.2489
 638/1000 [==================>...........] - ETA: 1:44 - loss: 1.4125 - regression_loss: 1.1632 - classification_loss: 0.2494
 639/1000 [==================>...........] - ETA: 1:43 - loss: 1.4137 - regression_loss: 1.1644 - classification_loss: 0.2493
 640/1000 [==================>...........] - ETA: 1:43 - loss: 1.4163 - regression_loss: 1.1664 - classification_loss: 0.2499
 641/1000 [==================>...........] - ETA: 1:43 - loss: 1.4161 - regression_loss: 1.1663 - classification_loss: 0.2498
 642/1000 [==================>...........] - ETA: 1:42 - loss: 1.4160 - regression_loss: 1.1663 - classification_loss: 0.2497
 643/1000 [==================>...........] - ETA: 1:42 - loss: 1.4170 - regression_loss: 1.1665 - classification_loss: 0.2505
 644/1000 [==================>...........] - ETA: 1:42 - loss: 1.4164 - regression_loss: 1.1655 - classification_loss: 0.2508
 645/1000 [==================>...........] - ETA: 1:42 - loss: 1.4177 - regression_loss: 1.1665 - classification_loss: 0.2512
 646/1000 [==================>...........] - ETA: 1:41 - loss: 1.4172 - regression_loss: 1.1658 - classification_loss: 0.2513
 647/1000 [==================>...........] - ETA: 1:41 - loss: 1.4193 - regression_loss: 1.1674 - classification_loss: 0.2519
 648/1000 [==================>...........] - ETA: 1:41 - loss: 1.4200 - regression_loss: 1.1679 - classification_loss: 0.2521
 649/1000 [==================>...........] - ETA: 1:40 - loss: 1.4201 - regression_loss: 1.1679 - classification_loss: 0.2521
 650/1000 [==================>...........] - ETA: 1:40 - loss: 1.4191 - regression_loss: 1.1670 - classification_loss: 0.2521
 651/1000 [==================>...........] - ETA: 1:40 - loss: 1.4188 - regression_loss: 1.1667 - classification_loss: 0.2521
 652/1000 [==================>...........] - ETA: 1:40 - loss: 1.4183 - regression_loss: 1.1663 - classification_loss: 0.2520
 653/1000 [==================>...........] - ETA: 1:39 - loss: 1.4192 - regression_loss: 1.1670 - classification_loss: 0.2522
 654/1000 [==================>...........] - ETA: 1:39 - loss: 1.4195 - regression_loss: 1.1675 - classification_loss: 0.2521
 655/1000 [==================>...........] - ETA: 1:39 - loss: 1.4185 - regression_loss: 1.1666 - classification_loss: 0.2519
 656/1000 [==================>...........] - ETA: 1:38 - loss: 1.4184 - regression_loss: 1.1666 - classification_loss: 0.2518
 657/1000 [==================>...........] - ETA: 1:38 - loss: 1.4172 - regression_loss: 1.1657 - classification_loss: 0.2516
 658/1000 [==================>...........] - ETA: 1:38 - loss: 1.4170 - regression_loss: 1.1654 - classification_loss: 0.2516
 659/1000 [==================>...........] - ETA: 1:37 - loss: 1.4169 - regression_loss: 1.1653 - classification_loss: 0.2515
 660/1000 [==================>...........] - ETA: 1:37 - loss: 1.4166 - regression_loss: 1.1652 - classification_loss: 0.2514
 661/1000 [==================>...........] - ETA: 1:37 - loss: 1.4173 - regression_loss: 1.1655 - classification_loss: 0.2517
 662/1000 [==================>...........] - ETA: 1:37 - loss: 1.4175 - regression_loss: 1.1655 - classification_loss: 0.2519
 663/1000 [==================>...........] - ETA: 1:36 - loss: 1.4182 - regression_loss: 1.1658 - classification_loss: 0.2524
 664/1000 [==================>...........] - ETA: 1:36 - loss: 1.4180 - regression_loss: 1.1657 - classification_loss: 0.2522
 665/1000 [==================>...........] - ETA: 1:36 - loss: 1.4176 - regression_loss: 1.1654 - classification_loss: 0.2522
 666/1000 [==================>...........] - ETA: 1:35 - loss: 1.4174 - regression_loss: 1.1651 - classification_loss: 0.2523
 667/1000 [===================>..........] - ETA: 1:35 - loss: 1.4180 - regression_loss: 1.1657 - classification_loss: 0.2523
 668/1000 [===================>..........] - ETA: 1:35 - loss: 1.4171 - regression_loss: 1.1650 - classification_loss: 0.2521
 669/1000 [===================>..........] - ETA: 1:35 - loss: 1.4177 - regression_loss: 1.1656 - classification_loss: 0.2522
 670/1000 [===================>..........] - ETA: 1:34 - loss: 1.4179 - regression_loss: 1.1650 - classification_loss: 0.2530
 671/1000 [===================>..........] - ETA: 1:34 - loss: 1.4173 - regression_loss: 1.1645 - classification_loss: 0.2528
 672/1000 [===================>..........] - ETA: 1:34 - loss: 1.4162 - regression_loss: 1.1636 - classification_loss: 0.2526
 673/1000 [===================>..........] - ETA: 1:33 - loss: 1.4168 - regression_loss: 1.1642 - classification_loss: 0.2526
 674/1000 [===================>..........] - ETA: 1:33 - loss: 1.4164 - regression_loss: 1.1639 - classification_loss: 0.2525
 675/1000 [===================>..........] - ETA: 1:33 - loss: 1.4159 - regression_loss: 1.1634 - classification_loss: 0.2525
 676/1000 [===================>..........] - ETA: 1:33 - loss: 1.4150 - regression_loss: 1.1627 - classification_loss: 0.2522
 677/1000 [===================>..........] - ETA: 1:32 - loss: 1.4142 - regression_loss: 1.1622 - classification_loss: 0.2520
 678/1000 [===================>..........] - ETA: 1:32 - loss: 1.4141 - regression_loss: 1.1619 - classification_loss: 0.2522
 679/1000 [===================>..........] - ETA: 1:32 - loss: 1.4131 - regression_loss: 1.1609 - classification_loss: 0.2522
 680/1000 [===================>..........] - ETA: 1:31 - loss: 1.4127 - regression_loss: 1.1607 - classification_loss: 0.2520
 681/1000 [===================>..........] - ETA: 1:31 - loss: 1.4118 - regression_loss: 1.1599 - classification_loss: 0.2518
 682/1000 [===================>..........] - ETA: 1:31 - loss: 1.4133 - regression_loss: 1.1613 - classification_loss: 0.2520
 683/1000 [===================>..........] - ETA: 1:31 - loss: 1.4152 - regression_loss: 1.1627 - classification_loss: 0.2525
 684/1000 [===================>..........] - ETA: 1:30 - loss: 1.4145 - regression_loss: 1.1622 - classification_loss: 0.2523
 685/1000 [===================>..........] - ETA: 1:30 - loss: 1.4137 - regression_loss: 1.1616 - classification_loss: 0.2521
 686/1000 [===================>..........] - ETA: 1:30 - loss: 1.4129 - regression_loss: 1.1609 - classification_loss: 0.2520
 687/1000 [===================>..........] - ETA: 1:29 - loss: 1.4141 - regression_loss: 1.1622 - classification_loss: 0.2519
 688/1000 [===================>..........] - ETA: 1:29 - loss: 1.4129 - regression_loss: 1.1612 - classification_loss: 0.2517
 689/1000 [===================>..........] - ETA: 1:29 - loss: 1.4134 - regression_loss: 1.1616 - classification_loss: 0.2518
 690/1000 [===================>..........] - ETA: 1:29 - loss: 1.4123 - regression_loss: 1.1607 - classification_loss: 0.2516
 691/1000 [===================>..........] - ETA: 1:28 - loss: 1.4120 - regression_loss: 1.1604 - classification_loss: 0.2516
 692/1000 [===================>..........] - ETA: 1:28 - loss: 1.4114 - regression_loss: 1.1599 - classification_loss: 0.2515
 693/1000 [===================>..........] - ETA: 1:28 - loss: 1.4107 - regression_loss: 1.1594 - classification_loss: 0.2513
 694/1000 [===================>..........] - ETA: 1:27 - loss: 1.4103 - regression_loss: 1.1591 - classification_loss: 0.2512
 695/1000 [===================>..........] - ETA: 1:27 - loss: 1.4101 - regression_loss: 1.1591 - classification_loss: 0.2510
 696/1000 [===================>..........] - ETA: 1:27 - loss: 1.4099 - regression_loss: 1.1591 - classification_loss: 0.2508
 697/1000 [===================>..........] - ETA: 1:27 - loss: 1.4098 - regression_loss: 1.1589 - classification_loss: 0.2509
 698/1000 [===================>..........] - ETA: 1:26 - loss: 1.4090 - regression_loss: 1.1583 - classification_loss: 0.2507
 699/1000 [===================>..........] - ETA: 1:26 - loss: 1.4082 - regression_loss: 1.1576 - classification_loss: 0.2506
 700/1000 [====================>.........] - ETA: 1:26 - loss: 1.4080 - regression_loss: 1.1576 - classification_loss: 0.2504
 701/1000 [====================>.........] - ETA: 1:25 - loss: 1.4077 - regression_loss: 1.1573 - classification_loss: 0.2504
 702/1000 [====================>.........] - ETA: 1:25 - loss: 1.4071 - regression_loss: 1.1569 - classification_loss: 0.2502
 703/1000 [====================>.........] - ETA: 1:25 - loss: 1.4061 - regression_loss: 1.1561 - classification_loss: 0.2500
 704/1000 [====================>.........] - ETA: 1:25 - loss: 1.4072 - regression_loss: 1.1568 - classification_loss: 0.2504
 705/1000 [====================>.........] - ETA: 1:24 - loss: 1.4063 - regression_loss: 1.1563 - classification_loss: 0.2501
 706/1000 [====================>.........] - ETA: 1:24 - loss: 1.4056 - regression_loss: 1.1558 - classification_loss: 0.2499
 707/1000 [====================>.........] - ETA: 1:24 - loss: 1.4055 - regression_loss: 1.1558 - classification_loss: 0.2497
 708/1000 [====================>.........] - ETA: 1:23 - loss: 1.4057 - regression_loss: 1.1561 - classification_loss: 0.2496
 709/1000 [====================>.........] - ETA: 1:23 - loss: 1.4060 - regression_loss: 1.1564 - classification_loss: 0.2496
 710/1000 [====================>.........] - ETA: 1:23 - loss: 1.4057 - regression_loss: 1.1562 - classification_loss: 0.2495
 711/1000 [====================>.........] - ETA: 1:23 - loss: 1.4061 - regression_loss: 1.1564 - classification_loss: 0.2497
 712/1000 [====================>.........] - ETA: 1:22 - loss: 1.4061 - regression_loss: 1.1564 - classification_loss: 0.2497
 713/1000 [====================>.........] - ETA: 1:22 - loss: 1.4074 - regression_loss: 1.1575 - classification_loss: 0.2500
 714/1000 [====================>.........] - ETA: 1:22 - loss: 1.4069 - regression_loss: 1.1571 - classification_loss: 0.2498
 715/1000 [====================>.........] - ETA: 1:21 - loss: 1.4068 - regression_loss: 1.1572 - classification_loss: 0.2496
 716/1000 [====================>.........] - ETA: 1:21 - loss: 1.4060 - regression_loss: 1.1566 - classification_loss: 0.2495
 717/1000 [====================>.........] - ETA: 1:21 - loss: 1.4067 - regression_loss: 1.1572 - classification_loss: 0.2496
 718/1000 [====================>.........] - ETA: 1:21 - loss: 1.4072 - regression_loss: 1.1577 - classification_loss: 0.2495
 719/1000 [====================>.........] - ETA: 1:20 - loss: 1.4064 - regression_loss: 1.1571 - classification_loss: 0.2493
 720/1000 [====================>.........] - ETA: 1:20 - loss: 1.4081 - regression_loss: 1.1582 - classification_loss: 0.2499
 721/1000 [====================>.........] - ETA: 1:20 - loss: 1.4073 - regression_loss: 1.1575 - classification_loss: 0.2498
 722/1000 [====================>.........] - ETA: 1:19 - loss: 1.4073 - regression_loss: 1.1576 - classification_loss: 0.2497
 723/1000 [====================>.........] - ETA: 1:19 - loss: 1.4076 - regression_loss: 1.1580 - classification_loss: 0.2496
 724/1000 [====================>.........] - ETA: 1:19 - loss: 1.4069 - regression_loss: 1.1573 - classification_loss: 0.2496
 725/1000 [====================>.........] - ETA: 1:18 - loss: 1.4078 - regression_loss: 1.1580 - classification_loss: 0.2498
 726/1000 [====================>.........] - ETA: 1:18 - loss: 1.4077 - regression_loss: 1.1579 - classification_loss: 0.2498
 727/1000 [====================>.........] - ETA: 1:18 - loss: 1.4067 - regression_loss: 1.1571 - classification_loss: 0.2496
 728/1000 [====================>.........] - ETA: 1:18 - loss: 1.4071 - regression_loss: 1.1575 - classification_loss: 0.2497
 729/1000 [====================>.........] - ETA: 1:17 - loss: 1.4075 - regression_loss: 1.1577 - classification_loss: 0.2498
 730/1000 [====================>.........] - ETA: 1:17 - loss: 1.4070 - regression_loss: 1.1573 - classification_loss: 0.2497
 731/1000 [====================>.........] - ETA: 1:17 - loss: 1.4085 - regression_loss: 1.1583 - classification_loss: 0.2502
 732/1000 [====================>.........] - ETA: 1:16 - loss: 1.4079 - regression_loss: 1.1579 - classification_loss: 0.2500
 733/1000 [====================>.........] - ETA: 1:16 - loss: 1.4080 - regression_loss: 1.1579 - classification_loss: 0.2500
 734/1000 [=====================>........] - ETA: 1:16 - loss: 1.4077 - regression_loss: 1.1577 - classification_loss: 0.2500
 735/1000 [=====================>........] - ETA: 1:16 - loss: 1.4069 - regression_loss: 1.1571 - classification_loss: 0.2498
 736/1000 [=====================>........] - ETA: 1:15 - loss: 1.4064 - regression_loss: 1.1568 - classification_loss: 0.2497
 737/1000 [=====================>........] - ETA: 1:15 - loss: 1.4064 - regression_loss: 1.1565 - classification_loss: 0.2499
 738/1000 [=====================>........] - ETA: 1:15 - loss: 1.4065 - regression_loss: 1.1566 - classification_loss: 0.2499
 739/1000 [=====================>........] - ETA: 1:14 - loss: 1.4065 - regression_loss: 1.1565 - classification_loss: 0.2500
 740/1000 [=====================>........] - ETA: 1:14 - loss: 1.4064 - regression_loss: 1.1565 - classification_loss: 0.2499
 741/1000 [=====================>........] - ETA: 1:14 - loss: 1.4054 - regression_loss: 1.1557 - classification_loss: 0.2497
 742/1000 [=====================>........] - ETA: 1:14 - loss: 1.4052 - regression_loss: 1.1555 - classification_loss: 0.2497
 743/1000 [=====================>........] - ETA: 1:13 - loss: 1.4075 - regression_loss: 1.1576 - classification_loss: 0.2498
 744/1000 [=====================>........] - ETA: 1:13 - loss: 1.4074 - regression_loss: 1.1576 - classification_loss: 0.2498
 745/1000 [=====================>........] - ETA: 1:13 - loss: 1.4066 - regression_loss: 1.1570 - classification_loss: 0.2496
 746/1000 [=====================>........] - ETA: 1:12 - loss: 1.4059 - regression_loss: 1.1564 - classification_loss: 0.2495
 747/1000 [=====================>........] - ETA: 1:12 - loss: 1.4056 - regression_loss: 1.1561 - classification_loss: 0.2495
 748/1000 [=====================>........] - ETA: 1:12 - loss: 1.4065 - regression_loss: 1.1565 - classification_loss: 0.2500
 749/1000 [=====================>........] - ETA: 1:12 - loss: 1.4079 - regression_loss: 1.1575 - classification_loss: 0.2504
 750/1000 [=====================>........] - ETA: 1:11 - loss: 1.4072 - regression_loss: 1.1570 - classification_loss: 0.2502
 751/1000 [=====================>........] - ETA: 1:11 - loss: 1.4080 - regression_loss: 1.1575 - classification_loss: 0.2505
 752/1000 [=====================>........] - ETA: 1:11 - loss: 1.4081 - regression_loss: 1.1578 - classification_loss: 0.2504
 753/1000 [=====================>........] - ETA: 1:10 - loss: 1.4075 - regression_loss: 1.1572 - classification_loss: 0.2503
 754/1000 [=====================>........] - ETA: 1:10 - loss: 1.4073 - regression_loss: 1.1570 - classification_loss: 0.2502
 755/1000 [=====================>........] - ETA: 1:10 - loss: 1.4064 - regression_loss: 1.1563 - classification_loss: 0.2500
 756/1000 [=====================>........] - ETA: 1:10 - loss: 1.4063 - regression_loss: 1.1564 - classification_loss: 0.2499
 757/1000 [=====================>........] - ETA: 1:09 - loss: 1.4067 - regression_loss: 1.1565 - classification_loss: 0.2502
 758/1000 [=====================>........] - ETA: 1:09 - loss: 1.4074 - regression_loss: 1.1572 - classification_loss: 0.2502
 759/1000 [=====================>........] - ETA: 1:09 - loss: 1.4090 - regression_loss: 1.1581 - classification_loss: 0.2510
 760/1000 [=====================>........] - ETA: 1:08 - loss: 1.4088 - regression_loss: 1.1579 - classification_loss: 0.2509
 761/1000 [=====================>........] - ETA: 1:08 - loss: 1.4087 - regression_loss: 1.1579 - classification_loss: 0.2508
 762/1000 [=====================>........] - ETA: 1:08 - loss: 1.4090 - regression_loss: 1.1581 - classification_loss: 0.2509
 763/1000 [=====================>........] - ETA: 1:08 - loss: 1.4090 - regression_loss: 1.1583 - classification_loss: 0.2507
 764/1000 [=====================>........] - ETA: 1:07 - loss: 1.4084 - regression_loss: 1.1578 - classification_loss: 0.2506
 765/1000 [=====================>........] - ETA: 1:07 - loss: 1.4075 - regression_loss: 1.1570 - classification_loss: 0.2505
 766/1000 [=====================>........] - ETA: 1:07 - loss: 1.4072 - regression_loss: 1.1569 - classification_loss: 0.2504
 767/1000 [======================>.......] - ETA: 1:06 - loss: 1.4081 - regression_loss: 1.1576 - classification_loss: 0.2504
 768/1000 [======================>.......] - ETA: 1:06 - loss: 1.4088 - regression_loss: 1.1582 - classification_loss: 0.2506
 769/1000 [======================>.......] - ETA: 1:06 - loss: 1.4086 - regression_loss: 1.1582 - classification_loss: 0.2504
 770/1000 [======================>.......] - ETA: 1:06 - loss: 1.4089 - regression_loss: 1.1584 - classification_loss: 0.2505
 771/1000 [======================>.......] - ETA: 1:05 - loss: 1.4083 - regression_loss: 1.1579 - classification_loss: 0.2504
 772/1000 [======================>.......] - ETA: 1:05 - loss: 1.4076 - regression_loss: 1.1574 - classification_loss: 0.2502
 773/1000 [======================>.......] - ETA: 1:05 - loss: 1.4077 - regression_loss: 1.1574 - classification_loss: 0.2503
 774/1000 [======================>.......] - ETA: 1:04 - loss: 1.4074 - regression_loss: 1.1571 - classification_loss: 0.2503
 775/1000 [======================>.......] - ETA: 1:04 - loss: 1.4068 - regression_loss: 1.1566 - classification_loss: 0.2501
 776/1000 [======================>.......] - ETA: 1:04 - loss: 1.4069 - regression_loss: 1.1567 - classification_loss: 0.2502
 777/1000 [======================>.......] - ETA: 1:04 - loss: 1.4087 - regression_loss: 1.1584 - classification_loss: 0.2503
 778/1000 [======================>.......] - ETA: 1:03 - loss: 1.4084 - regression_loss: 1.1581 - classification_loss: 0.2503
 779/1000 [======================>.......] - ETA: 1:03 - loss: 1.4075 - regression_loss: 1.1574 - classification_loss: 0.2501
 780/1000 [======================>.......] - ETA: 1:03 - loss: 1.4072 - regression_loss: 1.1572 - classification_loss: 0.2500
 781/1000 [======================>.......] - ETA: 1:02 - loss: 1.4062 - regression_loss: 1.1565 - classification_loss: 0.2498
 782/1000 [======================>.......] - ETA: 1:02 - loss: 1.4056 - regression_loss: 1.1560 - classification_loss: 0.2496
 783/1000 [======================>.......] - ETA: 1:02 - loss: 1.4052 - regression_loss: 1.1556 - classification_loss: 0.2496
 784/1000 [======================>.......] - ETA: 1:02 - loss: 1.4057 - regression_loss: 1.1561 - classification_loss: 0.2496
 785/1000 [======================>.......] - ETA: 1:01 - loss: 1.4071 - regression_loss: 1.1568 - classification_loss: 0.2503
 786/1000 [======================>.......] - ETA: 1:01 - loss: 1.4066 - regression_loss: 1.1565 - classification_loss: 0.2501
 787/1000 [======================>.......] - ETA: 1:01 - loss: 1.4060 - regression_loss: 1.1559 - classification_loss: 0.2501
 788/1000 [======================>.......] - ETA: 1:00 - loss: 1.4063 - regression_loss: 1.1562 - classification_loss: 0.2501
 789/1000 [======================>.......] - ETA: 1:00 - loss: 1.4064 - regression_loss: 1.1564 - classification_loss: 0.2499
 790/1000 [======================>.......] - ETA: 1:00 - loss: 1.4060 - regression_loss: 1.1562 - classification_loss: 0.2498
 791/1000 [======================>.......] - ETA: 1:00 - loss: 1.4054 - regression_loss: 1.1558 - classification_loss: 0.2496
 792/1000 [======================>.......] - ETA: 59s - loss: 1.4058 - regression_loss: 1.1562 - classification_loss: 0.2496 
 793/1000 [======================>.......] - ETA: 59s - loss: 1.4061 - regression_loss: 1.1565 - classification_loss: 0.2496
 794/1000 [======================>.......] - ETA: 59s - loss: 1.4050 - regression_loss: 1.1556 - classification_loss: 0.2494
 795/1000 [======================>.......] - ETA: 58s - loss: 1.4049 - regression_loss: 1.1553 - classification_loss: 0.2496
 796/1000 [======================>.......] - ETA: 58s - loss: 1.4055 - regression_loss: 1.1557 - classification_loss: 0.2498
 797/1000 [======================>.......] - ETA: 58s - loss: 1.4057 - regression_loss: 1.1558 - classification_loss: 0.2499
 798/1000 [======================>.......] - ETA: 58s - loss: 1.4055 - regression_loss: 1.1557 - classification_loss: 0.2498
 799/1000 [======================>.......] - ETA: 57s - loss: 1.4048 - regression_loss: 1.1551 - classification_loss: 0.2497
 800/1000 [=======================>......] - ETA: 57s - loss: 1.4046 - regression_loss: 1.1551 - classification_loss: 0.2495
 801/1000 [=======================>......] - ETA: 57s - loss: 1.4045 - regression_loss: 1.1550 - classification_loss: 0.2495
 802/1000 [=======================>......] - ETA: 56s - loss: 1.4065 - regression_loss: 1.1565 - classification_loss: 0.2499
 803/1000 [=======================>......] - ETA: 56s - loss: 1.4072 - regression_loss: 1.1572 - classification_loss: 0.2500
 804/1000 [=======================>......] - ETA: 56s - loss: 1.4060 - regression_loss: 1.1562 - classification_loss: 0.2499
 805/1000 [=======================>......] - ETA: 56s - loss: 1.4059 - regression_loss: 1.1562 - classification_loss: 0.2497
 806/1000 [=======================>......] - ETA: 55s - loss: 1.4062 - regression_loss: 1.1564 - classification_loss: 0.2498
 807/1000 [=======================>......] - ETA: 55s - loss: 1.4063 - regression_loss: 1.1565 - classification_loss: 0.2498
 808/1000 [=======================>......] - ETA: 55s - loss: 1.4055 - regression_loss: 1.1556 - classification_loss: 0.2499
 809/1000 [=======================>......] - ETA: 54s - loss: 1.4062 - regression_loss: 1.1563 - classification_loss: 0.2499
 810/1000 [=======================>......] - ETA: 54s - loss: 1.4051 - regression_loss: 1.1554 - classification_loss: 0.2497
 811/1000 [=======================>......] - ETA: 54s - loss: 1.4048 - regression_loss: 1.1551 - classification_loss: 0.2496
 812/1000 [=======================>......] - ETA: 53s - loss: 1.4049 - regression_loss: 1.1553 - classification_loss: 0.2496
 813/1000 [=======================>......] - ETA: 53s - loss: 1.4056 - regression_loss: 1.1559 - classification_loss: 0.2497
 814/1000 [=======================>......] - ETA: 53s - loss: 1.4069 - regression_loss: 1.1569 - classification_loss: 0.2500
 815/1000 [=======================>......] - ETA: 53s - loss: 1.4065 - regression_loss: 1.1565 - classification_loss: 0.2501
 816/1000 [=======================>......] - ETA: 52s - loss: 1.4071 - regression_loss: 1.1569 - classification_loss: 0.2501
 817/1000 [=======================>......] - ETA: 52s - loss: 1.4072 - regression_loss: 1.1571 - classification_loss: 0.2501
 818/1000 [=======================>......] - ETA: 52s - loss: 1.4064 - regression_loss: 1.1565 - classification_loss: 0.2499
 819/1000 [=======================>......] - ETA: 51s - loss: 1.4062 - regression_loss: 1.1564 - classification_loss: 0.2497
 820/1000 [=======================>......] - ETA: 51s - loss: 1.4066 - regression_loss: 1.1561 - classification_loss: 0.2505
 821/1000 [=======================>......] - ETA: 51s - loss: 1.4066 - regression_loss: 1.1560 - classification_loss: 0.2505
 822/1000 [=======================>......] - ETA: 51s - loss: 1.4078 - regression_loss: 1.1568 - classification_loss: 0.2509
 823/1000 [=======================>......] - ETA: 50s - loss: 1.4074 - regression_loss: 1.1564 - classification_loss: 0.2510
 824/1000 [=======================>......] - ETA: 50s - loss: 1.4078 - regression_loss: 1.1565 - classification_loss: 0.2513
 825/1000 [=======================>......] - ETA: 50s - loss: 1.4093 - regression_loss: 1.1575 - classification_loss: 0.2519
 826/1000 [=======================>......] - ETA: 49s - loss: 1.4091 - regression_loss: 1.1573 - classification_loss: 0.2518
 827/1000 [=======================>......] - ETA: 49s - loss: 1.4085 - regression_loss: 1.1568 - classification_loss: 0.2517
 828/1000 [=======================>......] - ETA: 49s - loss: 1.4091 - regression_loss: 1.1574 - classification_loss: 0.2517
 829/1000 [=======================>......] - ETA: 49s - loss: 1.4089 - regression_loss: 1.1573 - classification_loss: 0.2516
 830/1000 [=======================>......] - ETA: 48s - loss: 1.4091 - regression_loss: 1.1575 - classification_loss: 0.2515
 831/1000 [=======================>......] - ETA: 48s - loss: 1.4094 - regression_loss: 1.1580 - classification_loss: 0.2514
 832/1000 [=======================>......] - ETA: 48s - loss: 1.4098 - regression_loss: 1.1582 - classification_loss: 0.2516
 833/1000 [=======================>......] - ETA: 47s - loss: 1.4096 - regression_loss: 1.1581 - classification_loss: 0.2516
 834/1000 [========================>.....] - ETA: 47s - loss: 1.4093 - regression_loss: 1.1578 - classification_loss: 0.2516
 835/1000 [========================>.....] - ETA: 47s - loss: 1.4088 - regression_loss: 1.1574 - classification_loss: 0.2514
 836/1000 [========================>.....] - ETA: 47s - loss: 1.4082 - regression_loss: 1.1570 - classification_loss: 0.2513
 837/1000 [========================>.....] - ETA: 46s - loss: 1.4086 - regression_loss: 1.1573 - classification_loss: 0.2513
 838/1000 [========================>.....] - ETA: 46s - loss: 1.4087 - regression_loss: 1.1572 - classification_loss: 0.2514
 839/1000 [========================>.....] - ETA: 46s - loss: 1.4081 - regression_loss: 1.1569 - classification_loss: 0.2512
 840/1000 [========================>.....] - ETA: 45s - loss: 1.4071 - regression_loss: 1.1560 - classification_loss: 0.2511
 841/1000 [========================>.....] - ETA: 45s - loss: 1.4066 - regression_loss: 1.1557 - classification_loss: 0.2510
 842/1000 [========================>.....] - ETA: 45s - loss: 1.4064 - regression_loss: 1.1555 - classification_loss: 0.2510
 843/1000 [========================>.....] - ETA: 45s - loss: 1.4071 - regression_loss: 1.1560 - classification_loss: 0.2511
 844/1000 [========================>.....] - ETA: 44s - loss: 1.4070 - regression_loss: 1.1559 - classification_loss: 0.2512
 845/1000 [========================>.....] - ETA: 44s - loss: 1.4084 - regression_loss: 1.1567 - classification_loss: 0.2516
 846/1000 [========================>.....] - ETA: 44s - loss: 1.4082 - regression_loss: 1.1565 - classification_loss: 0.2517
 847/1000 [========================>.....] - ETA: 43s - loss: 1.4080 - regression_loss: 1.1564 - classification_loss: 0.2516
 848/1000 [========================>.....] - ETA: 43s - loss: 1.4075 - regression_loss: 1.1561 - classification_loss: 0.2515
 849/1000 [========================>.....] - ETA: 43s - loss: 1.4074 - regression_loss: 1.1560 - classification_loss: 0.2514
 850/1000 [========================>.....] - ETA: 43s - loss: 1.4069 - regression_loss: 1.1556 - classification_loss: 0.2513
 851/1000 [========================>.....] - ETA: 42s - loss: 1.4065 - regression_loss: 1.1552 - classification_loss: 0.2512
 852/1000 [========================>.....] - ETA: 42s - loss: 1.4067 - regression_loss: 1.1554 - classification_loss: 0.2513
 853/1000 [========================>.....] - ETA: 42s - loss: 1.4069 - regression_loss: 1.1554 - classification_loss: 0.2515
 854/1000 [========================>.....] - ETA: 41s - loss: 1.4076 - regression_loss: 1.1560 - classification_loss: 0.2516
 855/1000 [========================>.....] - ETA: 41s - loss: 1.4081 - regression_loss: 1.1565 - classification_loss: 0.2516
 856/1000 [========================>.....] - ETA: 41s - loss: 1.4072 - regression_loss: 1.1558 - classification_loss: 0.2514
 857/1000 [========================>.....] - ETA: 41s - loss: 1.4066 - regression_loss: 1.1554 - classification_loss: 0.2512
 858/1000 [========================>.....] - ETA: 40s - loss: 1.4060 - regression_loss: 1.1548 - classification_loss: 0.2511
 859/1000 [========================>.....] - ETA: 40s - loss: 1.4071 - regression_loss: 1.1560 - classification_loss: 0.2511
 860/1000 [========================>.....] - ETA: 40s - loss: 1.4072 - regression_loss: 1.1563 - classification_loss: 0.2509
 861/1000 [========================>.....] - ETA: 39s - loss: 1.4062 - regression_loss: 1.1555 - classification_loss: 0.2507
 862/1000 [========================>.....] - ETA: 39s - loss: 1.4062 - regression_loss: 1.1555 - classification_loss: 0.2507
 863/1000 [========================>.....] - ETA: 39s - loss: 1.4057 - regression_loss: 1.1552 - classification_loss: 0.2505
 864/1000 [========================>.....] - ETA: 39s - loss: 1.4064 - regression_loss: 1.1557 - classification_loss: 0.2506
 865/1000 [========================>.....] - ETA: 38s - loss: 1.4063 - regression_loss: 1.1557 - classification_loss: 0.2506
 866/1000 [========================>.....] - ETA: 38s - loss: 1.4055 - regression_loss: 1.1551 - classification_loss: 0.2504
 867/1000 [=========================>....] - ETA: 38s - loss: 1.4050 - regression_loss: 1.1546 - classification_loss: 0.2504
 868/1000 [=========================>....] - ETA: 37s - loss: 1.4048 - regression_loss: 1.1545 - classification_loss: 0.2503
 869/1000 [=========================>....] - ETA: 37s - loss: 1.4041 - regression_loss: 1.1540 - classification_loss: 0.2501
 870/1000 [=========================>....] - ETA: 37s - loss: 1.4044 - regression_loss: 1.1543 - classification_loss: 0.2502
 871/1000 [=========================>....] - ETA: 37s - loss: 1.4055 - regression_loss: 1.1551 - classification_loss: 0.2504
 872/1000 [=========================>....] - ETA: 36s - loss: 1.4052 - regression_loss: 1.1548 - classification_loss: 0.2504
 873/1000 [=========================>....] - ETA: 36s - loss: 1.4048 - regression_loss: 1.1545 - classification_loss: 0.2503
 874/1000 [=========================>....] - ETA: 36s - loss: 1.4041 - regression_loss: 1.1540 - classification_loss: 0.2502
 875/1000 [=========================>....] - ETA: 35s - loss: 1.4037 - regression_loss: 1.1536 - classification_loss: 0.2501
 876/1000 [=========================>....] - ETA: 35s - loss: 1.4033 - regression_loss: 1.1533 - classification_loss: 0.2500
 877/1000 [=========================>....] - ETA: 35s - loss: 1.4031 - regression_loss: 1.1531 - classification_loss: 0.2500
 878/1000 [=========================>....] - ETA: 35s - loss: 1.4034 - regression_loss: 1.1534 - classification_loss: 0.2500
 879/1000 [=========================>....] - ETA: 34s - loss: 1.4038 - regression_loss: 1.1538 - classification_loss: 0.2500
 880/1000 [=========================>....] - ETA: 34s - loss: 1.4033 - regression_loss: 1.1535 - classification_loss: 0.2498
 881/1000 [=========================>....] - ETA: 34s - loss: 1.4045 - regression_loss: 1.1542 - classification_loss: 0.2503
 882/1000 [=========================>....] - ETA: 33s - loss: 1.4044 - regression_loss: 1.1542 - classification_loss: 0.2502
 883/1000 [=========================>....] - ETA: 33s - loss: 1.4041 - regression_loss: 1.1540 - classification_loss: 0.2502
 884/1000 [=========================>....] - ETA: 33s - loss: 1.4037 - regression_loss: 1.1535 - classification_loss: 0.2502
 885/1000 [=========================>....] - ETA: 33s - loss: 1.4031 - regression_loss: 1.1529 - classification_loss: 0.2502
 886/1000 [=========================>....] - ETA: 32s - loss: 1.4030 - regression_loss: 1.1529 - classification_loss: 0.2501
 887/1000 [=========================>....] - ETA: 32s - loss: 1.4019 - regression_loss: 1.1520 - classification_loss: 0.2499
 888/1000 [=========================>....] - ETA: 32s - loss: 1.4020 - regression_loss: 1.1521 - classification_loss: 0.2499
 889/1000 [=========================>....] - ETA: 31s - loss: 1.4020 - regression_loss: 1.1523 - classification_loss: 0.2498
 890/1000 [=========================>....] - ETA: 31s - loss: 1.4013 - regression_loss: 1.1517 - classification_loss: 0.2496
 891/1000 [=========================>....] - ETA: 31s - loss: 1.4008 - regression_loss: 1.1513 - classification_loss: 0.2496
 892/1000 [=========================>....] - ETA: 31s - loss: 1.4006 - regression_loss: 1.1512 - classification_loss: 0.2494
 893/1000 [=========================>....] - ETA: 30s - loss: 1.4005 - regression_loss: 1.1511 - classification_loss: 0.2494
 894/1000 [=========================>....] - ETA: 30s - loss: 1.4006 - regression_loss: 1.1512 - classification_loss: 0.2494
 895/1000 [=========================>....] - ETA: 30s - loss: 1.4004 - regression_loss: 1.1510 - classification_loss: 0.2494
 896/1000 [=========================>....] - ETA: 29s - loss: 1.3995 - regression_loss: 1.1503 - classification_loss: 0.2492
 897/1000 [=========================>....] - ETA: 29s - loss: 1.3985 - regression_loss: 1.1495 - classification_loss: 0.2490
 898/1000 [=========================>....] - ETA: 29s - loss: 1.3979 - regression_loss: 1.1491 - classification_loss: 0.2489
 899/1000 [=========================>....] - ETA: 29s - loss: 1.3975 - regression_loss: 1.1487 - classification_loss: 0.2487
 900/1000 [==========================>...] - ETA: 28s - loss: 1.3980 - regression_loss: 1.1492 - classification_loss: 0.2489
 901/1000 [==========================>...] - ETA: 28s - loss: 1.3984 - regression_loss: 1.1491 - classification_loss: 0.2493
 902/1000 [==========================>...] - ETA: 28s - loss: 1.3976 - regression_loss: 1.1485 - classification_loss: 0.2491
 903/1000 [==========================>...] - ETA: 27s - loss: 1.3975 - regression_loss: 1.1485 - classification_loss: 0.2490
 904/1000 [==========================>...] - ETA: 27s - loss: 1.3987 - regression_loss: 1.1495 - classification_loss: 0.2492
 905/1000 [==========================>...] - ETA: 27s - loss: 1.3982 - regression_loss: 1.1491 - classification_loss: 0.2491
 906/1000 [==========================>...] - ETA: 26s - loss: 1.3982 - regression_loss: 1.1491 - classification_loss: 0.2491
 907/1000 [==========================>...] - ETA: 26s - loss: 1.3983 - regression_loss: 1.1493 - classification_loss: 0.2490
 908/1000 [==========================>...] - ETA: 26s - loss: 1.3988 - regression_loss: 1.1498 - classification_loss: 0.2491
 909/1000 [==========================>...] - ETA: 26s - loss: 1.3989 - regression_loss: 1.1499 - classification_loss: 0.2490
 910/1000 [==========================>...] - ETA: 25s - loss: 1.3987 - regression_loss: 1.1498 - classification_loss: 0.2489
 911/1000 [==========================>...] - ETA: 25s - loss: 1.3990 - regression_loss: 1.1501 - classification_loss: 0.2490
 912/1000 [==========================>...] - ETA: 25s - loss: 1.3986 - regression_loss: 1.1496 - classification_loss: 0.2490
 913/1000 [==========================>...] - ETA: 24s - loss: 1.3981 - regression_loss: 1.1493 - classification_loss: 0.2488
 914/1000 [==========================>...] - ETA: 24s - loss: 1.3984 - regression_loss: 1.1495 - classification_loss: 0.2489
 915/1000 [==========================>...] - ETA: 24s - loss: 1.3987 - regression_loss: 1.1498 - classification_loss: 0.2489
 916/1000 [==========================>...] - ETA: 24s - loss: 1.3997 - regression_loss: 1.1506 - classification_loss: 0.2491
 917/1000 [==========================>...] - ETA: 23s - loss: 1.4009 - regression_loss: 1.1515 - classification_loss: 0.2494
 918/1000 [==========================>...] - ETA: 23s - loss: 1.4008 - regression_loss: 1.1514 - classification_loss: 0.2493
 919/1000 [==========================>...] - ETA: 23s - loss: 1.4003 - regression_loss: 1.1511 - classification_loss: 0.2493
 920/1000 [==========================>...] - ETA: 22s - loss: 1.3997 - regression_loss: 1.1507 - classification_loss: 0.2491
 921/1000 [==========================>...] - ETA: 22s - loss: 1.3993 - regression_loss: 1.1504 - classification_loss: 0.2489
 922/1000 [==========================>...] - ETA: 22s - loss: 1.3986 - regression_loss: 1.1498 - classification_loss: 0.2488
 923/1000 [==========================>...] - ETA: 22s - loss: 1.3979 - regression_loss: 1.1492 - classification_loss: 0.2487
 924/1000 [==========================>...] - ETA: 21s - loss: 1.3980 - regression_loss: 1.1493 - classification_loss: 0.2486
 925/1000 [==========================>...] - ETA: 21s - loss: 1.3974 - regression_loss: 1.1488 - classification_loss: 0.2486
 926/1000 [==========================>...] - ETA: 21s - loss: 1.3970 - regression_loss: 1.1486 - classification_loss: 0.2485
 927/1000 [==========================>...] - ETA: 20s - loss: 1.3968 - regression_loss: 1.1484 - classification_loss: 0.2484
 928/1000 [==========================>...] - ETA: 20s - loss: 1.3986 - regression_loss: 1.1499 - classification_loss: 0.2487
 929/1000 [==========================>...] - ETA: 20s - loss: 1.3978 - regression_loss: 1.1492 - classification_loss: 0.2486
 930/1000 [==========================>...] - ETA: 20s - loss: 1.3971 - regression_loss: 1.1486 - classification_loss: 0.2484
 931/1000 [==========================>...] - ETA: 19s - loss: 1.3968 - regression_loss: 1.1485 - classification_loss: 0.2483
 932/1000 [==========================>...] - ETA: 19s - loss: 1.3965 - regression_loss: 1.1483 - classification_loss: 0.2482
 933/1000 [==========================>...] - ETA: 19s - loss: 1.3965 - regression_loss: 1.1484 - classification_loss: 0.2481
 934/1000 [===========================>..] - ETA: 18s - loss: 1.3960 - regression_loss: 1.1480 - classification_loss: 0.2480
 935/1000 [===========================>..] - ETA: 18s - loss: 1.3970 - regression_loss: 1.1488 - classification_loss: 0.2482
 936/1000 [===========================>..] - ETA: 18s - loss: 1.3966 - regression_loss: 1.1484 - classification_loss: 0.2482
 937/1000 [===========================>..] - ETA: 18s - loss: 1.3966 - regression_loss: 1.1486 - classification_loss: 0.2480
 938/1000 [===========================>..] - ETA: 17s - loss: 1.3959 - regression_loss: 1.1478 - classification_loss: 0.2480
 939/1000 [===========================>..] - ETA: 17s - loss: 1.3965 - regression_loss: 1.1482 - classification_loss: 0.2482
 940/1000 [===========================>..] - ETA: 17s - loss: 1.3961 - regression_loss: 1.1480 - classification_loss: 0.2482
 941/1000 [===========================>..] - ETA: 16s - loss: 1.3961 - regression_loss: 1.1480 - classification_loss: 0.2481
 942/1000 [===========================>..] - ETA: 16s - loss: 1.3957 - regression_loss: 1.1477 - classification_loss: 0.2480
 943/1000 [===========================>..] - ETA: 16s - loss: 1.3948 - regression_loss: 1.1469 - classification_loss: 0.2478
 944/1000 [===========================>..] - ETA: 16s - loss: 1.3946 - regression_loss: 1.1469 - classification_loss: 0.2477
 945/1000 [===========================>..] - ETA: 15s - loss: 1.3940 - regression_loss: 1.1463 - classification_loss: 0.2477
 946/1000 [===========================>..] - ETA: 15s - loss: 1.3946 - regression_loss: 1.1468 - classification_loss: 0.2477
 947/1000 [===========================>..] - ETA: 15s - loss: 1.3944 - regression_loss: 1.1466 - classification_loss: 0.2478
 948/1000 [===========================>..] - ETA: 14s - loss: 1.3946 - regression_loss: 1.1467 - classification_loss: 0.2478
 949/1000 [===========================>..] - ETA: 14s - loss: 1.3942 - regression_loss: 1.1465 - classification_loss: 0.2477
 950/1000 [===========================>..] - ETA: 14s - loss: 1.3953 - regression_loss: 1.1473 - classification_loss: 0.2480
 951/1000 [===========================>..] - ETA: 14s - loss: 1.3950 - regression_loss: 1.1472 - classification_loss: 0.2478
 952/1000 [===========================>..] - ETA: 13s - loss: 1.3947 - regression_loss: 1.1468 - classification_loss: 0.2479
 953/1000 [===========================>..] - ETA: 13s - loss: 1.3938 - regression_loss: 1.1461 - classification_loss: 0.2477
 954/1000 [===========================>..] - ETA: 13s - loss: 1.3933 - regression_loss: 1.1456 - classification_loss: 0.2477
 955/1000 [===========================>..] - ETA: 12s - loss: 1.3932 - regression_loss: 1.1456 - classification_loss: 0.2476
 956/1000 [===========================>..] - ETA: 12s - loss: 1.3929 - regression_loss: 1.1454 - classification_loss: 0.2475
 957/1000 [===========================>..] - ETA: 12s - loss: 1.3925 - regression_loss: 1.1451 - classification_loss: 0.2474
 958/1000 [===========================>..] - ETA: 12s - loss: 1.3920 - regression_loss: 1.1448 - classification_loss: 0.2472
 959/1000 [===========================>..] - ETA: 11s - loss: 1.3911 - regression_loss: 1.1440 - classification_loss: 0.2471
 960/1000 [===========================>..] - ETA: 11s - loss: 1.3910 - regression_loss: 1.1439 - classification_loss: 0.2471
 961/1000 [===========================>..] - ETA: 11s - loss: 1.3906 - regression_loss: 1.1436 - classification_loss: 0.2469
 962/1000 [===========================>..] - ETA: 10s - loss: 1.3905 - regression_loss: 1.1436 - classification_loss: 0.2469
 963/1000 [===========================>..] - ETA: 10s - loss: 1.3908 - regression_loss: 1.1439 - classification_loss: 0.2470
 964/1000 [===========================>..] - ETA: 10s - loss: 1.3904 - regression_loss: 1.1436 - classification_loss: 0.2468
 965/1000 [===========================>..] - ETA: 10s - loss: 1.3902 - regression_loss: 1.1435 - classification_loss: 0.2467
 966/1000 [===========================>..] - ETA: 9s - loss: 1.3909 - regression_loss: 1.1442 - classification_loss: 0.2467 
 967/1000 [============================>.] - ETA: 9s - loss: 1.3904 - regression_loss: 1.1437 - classification_loss: 0.2466
 968/1000 [============================>.] - ETA: 9s - loss: 1.3900 - regression_loss: 1.1434 - classification_loss: 0.2466
 969/1000 [============================>.] - ETA: 8s - loss: 1.3899 - regression_loss: 1.1433 - classification_loss: 0.2465
 970/1000 [============================>.] - ETA: 8s - loss: 1.3900 - regression_loss: 1.1435 - classification_loss: 0.2465
 971/1000 [============================>.] - ETA: 8s - loss: 1.3904 - regression_loss: 1.1438 - classification_loss: 0.2466
 972/1000 [============================>.] - ETA: 8s - loss: 1.3896 - regression_loss: 1.1431 - classification_loss: 0.2464
 973/1000 [============================>.] - ETA: 7s - loss: 1.3893 - regression_loss: 1.1429 - classification_loss: 0.2464
 974/1000 [============================>.] - ETA: 7s - loss: 1.3887 - regression_loss: 1.1423 - classification_loss: 0.2464
 975/1000 [============================>.] - ETA: 7s - loss: 1.3879 - regression_loss: 1.1417 - classification_loss: 0.2462
 976/1000 [============================>.] - ETA: 6s - loss: 1.3874 - regression_loss: 1.1413 - classification_loss: 0.2461
 977/1000 [============================>.] - ETA: 6s - loss: 1.3876 - regression_loss: 1.1414 - classification_loss: 0.2463
 978/1000 [============================>.] - ETA: 6s - loss: 1.3870 - regression_loss: 1.1409 - classification_loss: 0.2461
 979/1000 [============================>.] - ETA: 6s - loss: 1.3875 - regression_loss: 1.1413 - classification_loss: 0.2463
 980/1000 [============================>.] - ETA: 5s - loss: 1.3871 - regression_loss: 1.1408 - classification_loss: 0.2463
 981/1000 [============================>.] - ETA: 5s - loss: 1.3871 - regression_loss: 1.1408 - classification_loss: 0.2463
 982/1000 [============================>.] - ETA: 5s - loss: 1.3872 - regression_loss: 1.1409 - classification_loss: 0.2463
 983/1000 [============================>.] - ETA: 4s - loss: 1.3872 - regression_loss: 1.1410 - classification_loss: 0.2462
 984/1000 [============================>.] - ETA: 4s - loss: 1.3878 - regression_loss: 1.1416 - classification_loss: 0.2462
 985/1000 [============================>.] - ETA: 4s - loss: 1.3900 - regression_loss: 1.1431 - classification_loss: 0.2469
 986/1000 [============================>.] - ETA: 4s - loss: 1.3893 - regression_loss: 1.1426 - classification_loss: 0.2468
 987/1000 [============================>.] - ETA: 3s - loss: 1.3889 - regression_loss: 1.1421 - classification_loss: 0.2468
 988/1000 [============================>.] - ETA: 3s - loss: 1.3889 - regression_loss: 1.1418 - classification_loss: 0.2470
 989/1000 [============================>.] - ETA: 3s - loss: 1.3884 - regression_loss: 1.1415 - classification_loss: 0.2469
 990/1000 [============================>.] - ETA: 2s - loss: 1.3879 - regression_loss: 1.1410 - classification_loss: 0.2469
 991/1000 [============================>.] - ETA: 2s - loss: 1.3875 - regression_loss: 1.1407 - classification_loss: 0.2468
 992/1000 [============================>.] - ETA: 2s - loss: 1.3882 - regression_loss: 1.1413 - classification_loss: 0.2469
 993/1000 [============================>.] - ETA: 2s - loss: 1.3881 - regression_loss: 1.1413 - classification_loss: 0.2468
 994/1000 [============================>.] - ETA: 1s - loss: 1.3876 - regression_loss: 1.1409 - classification_loss: 0.2467
 995/1000 [============================>.] - ETA: 1s - loss: 1.3882 - regression_loss: 1.1414 - classification_loss: 0.2468
 996/1000 [============================>.] - ETA: 1s - loss: 1.3881 - regression_loss: 1.1414 - classification_loss: 0.2467
 997/1000 [============================>.] - ETA: 0s - loss: 1.3877 - regression_loss: 1.1410 - classification_loss: 0.2467
 998/1000 [============================>.] - ETA: 0s - loss: 1.3877 - regression_loss: 1.1410 - classification_loss: 0.2467
 999/1000 [============================>.] - ETA: 0s - loss: 1.3877 - regression_loss: 1.1410 - classification_loss: 0.2467
1000/1000 [==============================] - 287s 287ms/step - loss: 1.3871 - regression_loss: 1.1405 - classification_loss: 0.2466

Epoch 00006: saving model to ./snapshots/resnet50_csv_06.h5
Epoch 7/10

   1/1000 [..............................] - ETA: 4:43 - loss: 1.7092 - regression_loss: 1.3769 - classification_loss: 0.3323
   2/1000 [..............................] - ETA: 4:50 - loss: 1.3058 - regression_loss: 1.0856 - classification_loss: 0.2202
   3/1000 [..............................] - ETA: 4:49 - loss: 1.2926 - regression_loss: 1.0347 - classification_loss: 0.2579
   4/1000 [..............................] - ETA: 4:48 - loss: 1.2402 - regression_loss: 1.0119 - classification_loss: 0.2283
   5/1000 [..............................] - ETA: 4:47 - loss: 1.2118 - regression_loss: 0.9997 - classification_loss: 0.2121
   6/1000 [..............................] - ETA: 4:47 - loss: 1.1856 - regression_loss: 0.9796 - classification_loss: 0.2061
   7/1000 [..............................] - ETA: 4:46 - loss: 1.0915 - regression_loss: 0.9052 - classification_loss: 0.1864
   8/1000 [..............................] - ETA: 4:46 - loss: 1.1236 - regression_loss: 0.9260 - classification_loss: 0.1976
   9/1000 [..............................] - ETA: 4:46 - loss: 1.0565 - regression_loss: 0.8716 - classification_loss: 0.1850
  10/1000 [..............................] - ETA: 4:44 - loss: 1.0103 - regression_loss: 0.8345 - classification_loss: 0.1758
  11/1000 [..............................] - ETA: 4:44 - loss: 1.0502 - regression_loss: 0.8729 - classification_loss: 0.1774
  12/1000 [..............................] - ETA: 4:43 - loss: 1.1023 - regression_loss: 0.9154 - classification_loss: 0.1869
  13/1000 [..............................] - ETA: 4:43 - loss: 1.0892 - regression_loss: 0.9095 - classification_loss: 0.1797
  14/1000 [..............................] - ETA: 4:44 - loss: 1.0770 - regression_loss: 0.8968 - classification_loss: 0.1802
  15/1000 [..............................] - ETA: 4:43 - loss: 1.1593 - regression_loss: 0.9638 - classification_loss: 0.1954
  16/1000 [..............................] - ETA: 4:43 - loss: 1.1672 - regression_loss: 0.9687 - classification_loss: 0.1985
  17/1000 [..............................] - ETA: 4:42 - loss: 1.1970 - regression_loss: 0.9959 - classification_loss: 0.2012
  18/1000 [..............................] - ETA: 4:41 - loss: 1.2130 - regression_loss: 1.0002 - classification_loss: 0.2128
  19/1000 [..............................] - ETA: 4:41 - loss: 1.1830 - regression_loss: 0.9772 - classification_loss: 0.2059
  20/1000 [..............................] - ETA: 4:41 - loss: 1.1626 - regression_loss: 0.9590 - classification_loss: 0.2036
  21/1000 [..............................] - ETA: 4:41 - loss: 1.1507 - regression_loss: 0.9517 - classification_loss: 0.1990
  22/1000 [..............................] - ETA: 4:40 - loss: 1.1397 - regression_loss: 0.9447 - classification_loss: 0.1951
  23/1000 [..............................] - ETA: 4:40 - loss: 1.1093 - regression_loss: 0.9204 - classification_loss: 0.1889
  24/1000 [..............................] - ETA: 4:39 - loss: 1.0908 - regression_loss: 0.9057 - classification_loss: 0.1852
  25/1000 [..............................] - ETA: 4:39 - loss: 1.0667 - regression_loss: 0.8851 - classification_loss: 0.1816
  26/1000 [..............................] - ETA: 4:40 - loss: 1.0783 - regression_loss: 0.8933 - classification_loss: 0.1850
  27/1000 [..............................] - ETA: 4:40 - loss: 1.0896 - regression_loss: 0.9035 - classification_loss: 0.1861
  28/1000 [..............................] - ETA: 4:39 - loss: 1.0882 - regression_loss: 0.9006 - classification_loss: 0.1876
  29/1000 [..............................] - ETA: 4:39 - loss: 1.0671 - regression_loss: 0.8833 - classification_loss: 0.1838
  30/1000 [..............................] - ETA: 4:39 - loss: 1.0653 - regression_loss: 0.8833 - classification_loss: 0.1821
  31/1000 [..............................] - ETA: 4:39 - loss: 1.0730 - regression_loss: 0.8904 - classification_loss: 0.1826
  32/1000 [..............................] - ETA: 4:39 - loss: 1.0831 - regression_loss: 0.8989 - classification_loss: 0.1842
  33/1000 [..............................] - ETA: 4:38 - loss: 1.0977 - regression_loss: 0.9112 - classification_loss: 0.1865
  34/1000 [>.............................] - ETA: 4:38 - loss: 1.0932 - regression_loss: 0.9079 - classification_loss: 0.1853
  35/1000 [>.............................] - ETA: 4:37 - loss: 1.0953 - regression_loss: 0.9112 - classification_loss: 0.1840
  36/1000 [>.............................] - ETA: 4:37 - loss: 1.1127 - regression_loss: 0.9269 - classification_loss: 0.1857
  37/1000 [>.............................] - ETA: 4:37 - loss: 1.1037 - regression_loss: 0.9182 - classification_loss: 0.1855
  38/1000 [>.............................] - ETA: 4:37 - loss: 1.1012 - regression_loss: 0.9169 - classification_loss: 0.1844
  39/1000 [>.............................] - ETA: 4:36 - loss: 1.1136 - regression_loss: 0.9295 - classification_loss: 0.1842
  40/1000 [>.............................] - ETA: 4:36 - loss: 1.1034 - regression_loss: 0.9196 - classification_loss: 0.1838
  41/1000 [>.............................] - ETA: 4:35 - loss: 1.1009 - regression_loss: 0.9186 - classification_loss: 0.1823
  42/1000 [>.............................] - ETA: 4:35 - loss: 1.0872 - regression_loss: 0.9072 - classification_loss: 0.1800
  43/1000 [>.............................] - ETA: 4:35 - loss: 1.0843 - regression_loss: 0.9025 - classification_loss: 0.1819
  44/1000 [>.............................] - ETA: 4:34 - loss: 1.1264 - regression_loss: 0.9336 - classification_loss: 0.1928
  45/1000 [>.............................] - ETA: 4:34 - loss: 1.1298 - regression_loss: 0.9374 - classification_loss: 0.1924
  46/1000 [>.............................] - ETA: 4:34 - loss: 1.1244 - regression_loss: 0.9336 - classification_loss: 0.1908
  47/1000 [>.............................] - ETA: 4:34 - loss: 1.1738 - regression_loss: 0.9668 - classification_loss: 0.2070
  48/1000 [>.............................] - ETA: 4:34 - loss: 1.1843 - regression_loss: 0.9771 - classification_loss: 0.2072
  49/1000 [>.............................] - ETA: 4:33 - loss: 1.1747 - regression_loss: 0.9684 - classification_loss: 0.2063
  50/1000 [>.............................] - ETA: 4:33 - loss: 1.1937 - regression_loss: 0.9836 - classification_loss: 0.2101
  51/1000 [>.............................] - ETA: 4:33 - loss: 1.1835 - regression_loss: 0.9748 - classification_loss: 0.2087
  52/1000 [>.............................] - ETA: 4:33 - loss: 1.2095 - regression_loss: 0.9934 - classification_loss: 0.2161
  53/1000 [>.............................] - ETA: 4:32 - loss: 1.2187 - regression_loss: 1.0012 - classification_loss: 0.2176
  54/1000 [>.............................] - ETA: 4:32 - loss: 1.2250 - regression_loss: 1.0079 - classification_loss: 0.2171
  55/1000 [>.............................] - ETA: 4:31 - loss: 1.2272 - regression_loss: 1.0076 - classification_loss: 0.2196
  56/1000 [>.............................] - ETA: 4:31 - loss: 1.2409 - regression_loss: 1.0188 - classification_loss: 0.2222
  57/1000 [>.............................] - ETA: 4:31 - loss: 1.2444 - regression_loss: 1.0218 - classification_loss: 0.2226
  58/1000 [>.............................] - ETA: 4:31 - loss: 1.2426 - regression_loss: 1.0206 - classification_loss: 0.2221
  59/1000 [>.............................] - ETA: 4:30 - loss: 1.2494 - regression_loss: 1.0268 - classification_loss: 0.2225
  60/1000 [>.............................] - ETA: 4:30 - loss: 1.2443 - regression_loss: 1.0231 - classification_loss: 0.2211
  61/1000 [>.............................] - ETA: 4:30 - loss: 1.2578 - regression_loss: 1.0355 - classification_loss: 0.2223
  62/1000 [>.............................] - ETA: 4:30 - loss: 1.2496 - regression_loss: 1.0283 - classification_loss: 0.2213
  63/1000 [>.............................] - ETA: 4:29 - loss: 1.2562 - regression_loss: 1.0332 - classification_loss: 0.2230
  64/1000 [>.............................] - ETA: 4:29 - loss: 1.2514 - regression_loss: 1.0298 - classification_loss: 0.2216
  65/1000 [>.............................] - ETA: 4:29 - loss: 1.2558 - regression_loss: 1.0313 - classification_loss: 0.2245
  66/1000 [>.............................] - ETA: 4:28 - loss: 1.2628 - regression_loss: 1.0385 - classification_loss: 0.2243
  67/1000 [=>............................] - ETA: 4:28 - loss: 1.2628 - regression_loss: 1.0393 - classification_loss: 0.2234
  68/1000 [=>............................] - ETA: 4:28 - loss: 1.2702 - regression_loss: 1.0468 - classification_loss: 0.2234
  69/1000 [=>............................] - ETA: 4:28 - loss: 1.2661 - regression_loss: 1.0435 - classification_loss: 0.2226
  70/1000 [=>............................] - ETA: 4:27 - loss: 1.2791 - regression_loss: 1.0534 - classification_loss: 0.2257
  71/1000 [=>............................] - ETA: 4:27 - loss: 1.2781 - regression_loss: 1.0510 - classification_loss: 0.2272
  72/1000 [=>............................] - ETA: 4:27 - loss: 1.2816 - regression_loss: 1.0539 - classification_loss: 0.2277
  73/1000 [=>............................] - ETA: 4:26 - loss: 1.2861 - regression_loss: 1.0587 - classification_loss: 0.2274
  74/1000 [=>............................] - ETA: 4:26 - loss: 1.2798 - regression_loss: 1.0540 - classification_loss: 0.2258
  75/1000 [=>............................] - ETA: 4:26 - loss: 1.2953 - regression_loss: 1.0669 - classification_loss: 0.2284
  76/1000 [=>............................] - ETA: 4:26 - loss: 1.2932 - regression_loss: 1.0665 - classification_loss: 0.2267
  77/1000 [=>............................] - ETA: 4:25 - loss: 1.2937 - regression_loss: 1.0678 - classification_loss: 0.2259
  78/1000 [=>............................] - ETA: 4:25 - loss: 1.2890 - regression_loss: 1.0650 - classification_loss: 0.2240
  79/1000 [=>............................] - ETA: 4:25 - loss: 1.2936 - regression_loss: 1.0698 - classification_loss: 0.2239
  80/1000 [=>............................] - ETA: 4:24 - loss: 1.2961 - regression_loss: 1.0713 - classification_loss: 0.2248
  81/1000 [=>............................] - ETA: 4:24 - loss: 1.2939 - regression_loss: 1.0702 - classification_loss: 0.2237
  82/1000 [=>............................] - ETA: 4:24 - loss: 1.2909 - regression_loss: 1.0682 - classification_loss: 0.2227
  83/1000 [=>............................] - ETA: 4:24 - loss: 1.2863 - regression_loss: 1.0645 - classification_loss: 0.2218
  84/1000 [=>............................] - ETA: 4:23 - loss: 1.2813 - regression_loss: 1.0599 - classification_loss: 0.2214
  85/1000 [=>............................] - ETA: 4:23 - loss: 1.2860 - regression_loss: 1.0636 - classification_loss: 0.2224
  86/1000 [=>............................] - ETA: 4:23 - loss: 1.2784 - regression_loss: 1.0575 - classification_loss: 0.2209
  87/1000 [=>............................] - ETA: 4:22 - loss: 1.2726 - regression_loss: 1.0535 - classification_loss: 0.2192
  88/1000 [=>............................] - ETA: 4:22 - loss: 1.2674 - regression_loss: 1.0501 - classification_loss: 0.2174
  89/1000 [=>............................] - ETA: 4:22 - loss: 1.2631 - regression_loss: 1.0466 - classification_loss: 0.2165
  90/1000 [=>............................] - ETA: 4:21 - loss: 1.2643 - regression_loss: 1.0485 - classification_loss: 0.2159
  91/1000 [=>............................] - ETA: 4:21 - loss: 1.2663 - regression_loss: 1.0510 - classification_loss: 0.2153
  92/1000 [=>............................] - ETA: 4:21 - loss: 1.2644 - regression_loss: 1.0495 - classification_loss: 0.2149
  93/1000 [=>............................] - ETA: 4:21 - loss: 1.2708 - regression_loss: 1.0522 - classification_loss: 0.2186
  94/1000 [=>............................] - ETA: 4:20 - loss: 1.2720 - regression_loss: 1.0531 - classification_loss: 0.2189
  95/1000 [=>............................] - ETA: 4:20 - loss: 1.2769 - regression_loss: 1.0574 - classification_loss: 0.2196
  96/1000 [=>............................] - ETA: 4:20 - loss: 1.2711 - regression_loss: 1.0525 - classification_loss: 0.2186
  97/1000 [=>............................] - ETA: 4:19 - loss: 1.2694 - regression_loss: 1.0514 - classification_loss: 0.2179
  98/1000 [=>............................] - ETA: 4:19 - loss: 1.2705 - regression_loss: 1.0528 - classification_loss: 0.2177
  99/1000 [=>............................] - ETA: 4:19 - loss: 1.2715 - regression_loss: 1.0537 - classification_loss: 0.2177
 100/1000 [==>...........................] - ETA: 4:18 - loss: 1.2683 - regression_loss: 1.0505 - classification_loss: 0.2178
 101/1000 [==>...........................] - ETA: 4:18 - loss: 1.2687 - regression_loss: 1.0513 - classification_loss: 0.2174
 102/1000 [==>...........................] - ETA: 4:18 - loss: 1.2744 - regression_loss: 1.0559 - classification_loss: 0.2185
 103/1000 [==>...........................] - ETA: 4:18 - loss: 1.2747 - regression_loss: 1.0552 - classification_loss: 0.2195
 104/1000 [==>...........................] - ETA: 4:17 - loss: 1.2712 - regression_loss: 1.0527 - classification_loss: 0.2185
 105/1000 [==>...........................] - ETA: 4:17 - loss: 1.2697 - regression_loss: 1.0520 - classification_loss: 0.2177
 106/1000 [==>...........................] - ETA: 4:17 - loss: 1.2735 - regression_loss: 1.0555 - classification_loss: 0.2180
 107/1000 [==>...........................] - ETA: 4:17 - loss: 1.2723 - regression_loss: 1.0549 - classification_loss: 0.2175
 108/1000 [==>...........................] - ETA: 4:16 - loss: 1.2753 - regression_loss: 1.0576 - classification_loss: 0.2176
 109/1000 [==>...........................] - ETA: 4:16 - loss: 1.2859 - regression_loss: 1.0648 - classification_loss: 0.2211
 110/1000 [==>...........................] - ETA: 4:16 - loss: 1.2848 - regression_loss: 1.0645 - classification_loss: 0.2203
 111/1000 [==>...........................] - ETA: 4:15 - loss: 1.2861 - regression_loss: 1.0653 - classification_loss: 0.2208
 112/1000 [==>...........................] - ETA: 4:15 - loss: 1.2855 - regression_loss: 1.0653 - classification_loss: 0.2202
 113/1000 [==>...........................] - ETA: 4:15 - loss: 1.2823 - regression_loss: 1.0630 - classification_loss: 0.2193
 114/1000 [==>...........................] - ETA: 4:14 - loss: 1.2826 - regression_loss: 1.0628 - classification_loss: 0.2198
 115/1000 [==>...........................] - ETA: 4:14 - loss: 1.2855 - regression_loss: 1.0658 - classification_loss: 0.2197
 116/1000 [==>...........................] - ETA: 4:14 - loss: 1.2863 - regression_loss: 1.0660 - classification_loss: 0.2203
 117/1000 [==>...........................] - ETA: 4:14 - loss: 1.2829 - regression_loss: 1.0632 - classification_loss: 0.2197
 118/1000 [==>...........................] - ETA: 4:13 - loss: 1.2775 - regression_loss: 1.0589 - classification_loss: 0.2186
 119/1000 [==>...........................] - ETA: 4:13 - loss: 1.2790 - regression_loss: 1.0580 - classification_loss: 0.2210
 120/1000 [==>...........................] - ETA: 4:13 - loss: 1.2859 - regression_loss: 1.0648 - classification_loss: 0.2211
 121/1000 [==>...........................] - ETA: 4:12 - loss: 1.2897 - regression_loss: 1.0683 - classification_loss: 0.2214
 122/1000 [==>...........................] - ETA: 4:12 - loss: 1.2974 - regression_loss: 1.0727 - classification_loss: 0.2247
 123/1000 [==>...........................] - ETA: 4:12 - loss: 1.2966 - regression_loss: 1.0723 - classification_loss: 0.2243
 124/1000 [==>...........................] - ETA: 4:11 - loss: 1.2961 - regression_loss: 1.0714 - classification_loss: 0.2247
 125/1000 [==>...........................] - ETA: 4:11 - loss: 1.2978 - regression_loss: 1.0732 - classification_loss: 0.2245
 126/1000 [==>...........................] - ETA: 4:11 - loss: 1.2954 - regression_loss: 1.0709 - classification_loss: 0.2245
 127/1000 [==>...........................] - ETA: 4:11 - loss: 1.2944 - regression_loss: 1.0693 - classification_loss: 0.2251
 128/1000 [==>...........................] - ETA: 4:10 - loss: 1.2925 - regression_loss: 1.0670 - classification_loss: 0.2255
 129/1000 [==>...........................] - ETA: 4:10 - loss: 1.2919 - regression_loss: 1.0663 - classification_loss: 0.2256
 130/1000 [==>...........................] - ETA: 4:10 - loss: 1.2950 - regression_loss: 1.0684 - classification_loss: 0.2266
 131/1000 [==>...........................] - ETA: 4:09 - loss: 1.2947 - regression_loss: 1.0678 - classification_loss: 0.2269
 132/1000 [==>...........................] - ETA: 4:09 - loss: 1.3000 - regression_loss: 1.0721 - classification_loss: 0.2278
 133/1000 [==>...........................] - ETA: 4:09 - loss: 1.3034 - regression_loss: 1.0756 - classification_loss: 0.2279
 134/1000 [===>..........................] - ETA: 4:09 - loss: 1.3036 - regression_loss: 1.0758 - classification_loss: 0.2278
 135/1000 [===>..........................] - ETA: 4:08 - loss: 1.3132 - regression_loss: 1.0836 - classification_loss: 0.2296
 136/1000 [===>..........................] - ETA: 4:08 - loss: 1.3076 - regression_loss: 1.0793 - classification_loss: 0.2284
 137/1000 [===>..........................] - ETA: 4:08 - loss: 1.3075 - regression_loss: 1.0794 - classification_loss: 0.2281
 138/1000 [===>..........................] - ETA: 4:07 - loss: 1.3024 - regression_loss: 1.0753 - classification_loss: 0.2271
 139/1000 [===>..........................] - ETA: 4:07 - loss: 1.3013 - regression_loss: 1.0745 - classification_loss: 0.2268
 140/1000 [===>..........................] - ETA: 4:07 - loss: 1.2958 - regression_loss: 1.0700 - classification_loss: 0.2258
 141/1000 [===>..........................] - ETA: 4:07 - loss: 1.2946 - regression_loss: 1.0685 - classification_loss: 0.2262
 142/1000 [===>..........................] - ETA: 4:06 - loss: 1.2977 - regression_loss: 1.0693 - classification_loss: 0.2284
 143/1000 [===>..........................] - ETA: 4:06 - loss: 1.2960 - regression_loss: 1.0684 - classification_loss: 0.2276
 144/1000 [===>..........................] - ETA: 4:06 - loss: 1.3010 - regression_loss: 1.0724 - classification_loss: 0.2287
 145/1000 [===>..........................] - ETA: 4:05 - loss: 1.3043 - regression_loss: 1.0748 - classification_loss: 0.2295
 146/1000 [===>..........................] - ETA: 4:05 - loss: 1.3087 - regression_loss: 1.0775 - classification_loss: 0.2312
 147/1000 [===>..........................] - ETA: 4:05 - loss: 1.3066 - regression_loss: 1.0762 - classification_loss: 0.2304
 148/1000 [===>..........................] - ETA: 4:04 - loss: 1.3087 - regression_loss: 1.0776 - classification_loss: 0.2311
 149/1000 [===>..........................] - ETA: 4:04 - loss: 1.3085 - regression_loss: 1.0774 - classification_loss: 0.2311
 150/1000 [===>..........................] - ETA: 4:04 - loss: 1.3064 - regression_loss: 1.0758 - classification_loss: 0.2305
 151/1000 [===>..........................] - ETA: 4:04 - loss: 1.3103 - regression_loss: 1.0803 - classification_loss: 0.2300
 152/1000 [===>..........................] - ETA: 4:03 - loss: 1.3155 - regression_loss: 1.0853 - classification_loss: 0.2302
 153/1000 [===>..........................] - ETA: 4:03 - loss: 1.3183 - regression_loss: 1.0876 - classification_loss: 0.2307
 154/1000 [===>..........................] - ETA: 4:03 - loss: 1.3147 - regression_loss: 1.0845 - classification_loss: 0.2302
 155/1000 [===>..........................] - ETA: 4:02 - loss: 1.3120 - regression_loss: 1.0825 - classification_loss: 0.2295
 156/1000 [===>..........................] - ETA: 4:02 - loss: 1.3154 - regression_loss: 1.0853 - classification_loss: 0.2301
 157/1000 [===>..........................] - ETA: 4:02 - loss: 1.3128 - regression_loss: 1.0828 - classification_loss: 0.2300
 158/1000 [===>..........................] - ETA: 4:02 - loss: 1.3160 - regression_loss: 1.0854 - classification_loss: 0.2306
 159/1000 [===>..........................] - ETA: 4:01 - loss: 1.3132 - regression_loss: 1.0832 - classification_loss: 0.2299
 160/1000 [===>..........................] - ETA: 4:01 - loss: 1.3168 - regression_loss: 1.0872 - classification_loss: 0.2297
 161/1000 [===>..........................] - ETA: 4:01 - loss: 1.3137 - regression_loss: 1.0849 - classification_loss: 0.2287
 162/1000 [===>..........................] - ETA: 4:00 - loss: 1.3101 - regression_loss: 1.0817 - classification_loss: 0.2283
 163/1000 [===>..........................] - ETA: 4:00 - loss: 1.3059 - regression_loss: 1.0783 - classification_loss: 0.2276
 164/1000 [===>..........................] - ETA: 4:00 - loss: 1.3072 - regression_loss: 1.0792 - classification_loss: 0.2279
 165/1000 [===>..........................] - ETA: 4:00 - loss: 1.3056 - regression_loss: 1.0779 - classification_loss: 0.2277
 166/1000 [===>..........................] - ETA: 3:59 - loss: 1.3007 - regression_loss: 1.0738 - classification_loss: 0.2269
 167/1000 [====>.........................] - ETA: 3:59 - loss: 1.2979 - regression_loss: 1.0716 - classification_loss: 0.2263
 168/1000 [====>.........................] - ETA: 3:59 - loss: 1.2979 - regression_loss: 1.0715 - classification_loss: 0.2264
 169/1000 [====>.........................] - ETA: 3:58 - loss: 1.3010 - regression_loss: 1.0741 - classification_loss: 0.2269
 170/1000 [====>.........................] - ETA: 3:58 - loss: 1.2990 - regression_loss: 1.0726 - classification_loss: 0.2264
 171/1000 [====>.........................] - ETA: 3:58 - loss: 1.2987 - regression_loss: 1.0730 - classification_loss: 0.2257
 172/1000 [====>.........................] - ETA: 3:57 - loss: 1.2970 - regression_loss: 1.0716 - classification_loss: 0.2255
 173/1000 [====>.........................] - ETA: 3:57 - loss: 1.2928 - regression_loss: 1.0680 - classification_loss: 0.2248
 174/1000 [====>.........................] - ETA: 3:57 - loss: 1.2921 - regression_loss: 1.0666 - classification_loss: 0.2255
 175/1000 [====>.........................] - ETA: 3:57 - loss: 1.2917 - regression_loss: 1.0666 - classification_loss: 0.2251
 176/1000 [====>.........................] - ETA: 3:56 - loss: 1.2903 - regression_loss: 1.0655 - classification_loss: 0.2247
 177/1000 [====>.........................] - ETA: 3:56 - loss: 1.2879 - regression_loss: 1.0636 - classification_loss: 0.2242
 178/1000 [====>.........................] - ETA: 3:56 - loss: 1.2877 - regression_loss: 1.0637 - classification_loss: 0.2240
 179/1000 [====>.........................] - ETA: 3:55 - loss: 1.2854 - regression_loss: 1.0618 - classification_loss: 0.2237
 180/1000 [====>.........................] - ETA: 3:55 - loss: 1.2849 - regression_loss: 1.0611 - classification_loss: 0.2238
 181/1000 [====>.........................] - ETA: 3:55 - loss: 1.2868 - regression_loss: 1.0627 - classification_loss: 0.2241
 182/1000 [====>.........................] - ETA: 3:55 - loss: 1.2865 - regression_loss: 1.0627 - classification_loss: 0.2238
 183/1000 [====>.........................] - ETA: 3:54 - loss: 1.2846 - regression_loss: 1.0614 - classification_loss: 0.2232
 184/1000 [====>.........................] - ETA: 3:54 - loss: 1.2858 - regression_loss: 1.0629 - classification_loss: 0.2229
 185/1000 [====>.........................] - ETA: 3:54 - loss: 1.2899 - regression_loss: 1.0648 - classification_loss: 0.2251
 186/1000 [====>.........................] - ETA: 3:53 - loss: 1.2902 - regression_loss: 1.0653 - classification_loss: 0.2249
 187/1000 [====>.........................] - ETA: 3:53 - loss: 1.2948 - regression_loss: 1.0686 - classification_loss: 0.2262
 188/1000 [====>.........................] - ETA: 3:53 - loss: 1.2933 - regression_loss: 1.0676 - classification_loss: 0.2257
 189/1000 [====>.........................] - ETA: 3:52 - loss: 1.2995 - regression_loss: 1.0726 - classification_loss: 0.2270
 190/1000 [====>.........................] - ETA: 3:52 - loss: 1.2995 - regression_loss: 1.0723 - classification_loss: 0.2271
 191/1000 [====>.........................] - ETA: 3:52 - loss: 1.2966 - regression_loss: 1.0703 - classification_loss: 0.2264
 192/1000 [====>.........................] - ETA: 3:52 - loss: 1.2947 - regression_loss: 1.0690 - classification_loss: 0.2257
 193/1000 [====>.........................] - ETA: 3:51 - loss: 1.2947 - regression_loss: 1.0686 - classification_loss: 0.2261
 194/1000 [====>.........................] - ETA: 3:51 - loss: 1.2974 - regression_loss: 1.0704 - classification_loss: 0.2270
 195/1000 [====>.........................] - ETA: 3:51 - loss: 1.2970 - regression_loss: 1.0649 - classification_loss: 0.2321
 196/1000 [====>.........................] - ETA: 3:51 - loss: 1.2985 - regression_loss: 1.0662 - classification_loss: 0.2323
 197/1000 [====>.........................] - ETA: 3:50 - loss: 1.2960 - regression_loss: 1.0642 - classification_loss: 0.2317
 198/1000 [====>.........................] - ETA: 3:50 - loss: 1.2929 - regression_loss: 1.0618 - classification_loss: 0.2311
 199/1000 [====>.........................] - ETA: 3:50 - loss: 1.2981 - regression_loss: 1.0665 - classification_loss: 0.2316
 200/1000 [=====>........................] - ETA: 3:49 - loss: 1.2967 - regression_loss: 1.0653 - classification_loss: 0.2314
 201/1000 [=====>........................] - ETA: 3:49 - loss: 1.2976 - regression_loss: 1.0656 - classification_loss: 0.2320
 202/1000 [=====>........................] - ETA: 3:49 - loss: 1.3017 - regression_loss: 1.0681 - classification_loss: 0.2336
 203/1000 [=====>........................] - ETA: 3:49 - loss: 1.2991 - regression_loss: 1.0661 - classification_loss: 0.2330
 204/1000 [=====>........................] - ETA: 3:48 - loss: 1.2964 - regression_loss: 1.0639 - classification_loss: 0.2325
 205/1000 [=====>........................] - ETA: 3:48 - loss: 1.2959 - regression_loss: 1.0635 - classification_loss: 0.2324
 206/1000 [=====>........................] - ETA: 3:48 - loss: 1.2927 - regression_loss: 1.0607 - classification_loss: 0.2320
 207/1000 [=====>........................] - ETA: 3:47 - loss: 1.2902 - regression_loss: 1.0588 - classification_loss: 0.2314
 208/1000 [=====>........................] - ETA: 3:47 - loss: 1.2901 - regression_loss: 1.0586 - classification_loss: 0.2315
 209/1000 [=====>........................] - ETA: 3:47 - loss: 1.2876 - regression_loss: 1.0568 - classification_loss: 0.2308
 210/1000 [=====>........................] - ETA: 3:47 - loss: 1.2886 - regression_loss: 1.0575 - classification_loss: 0.2311
 211/1000 [=====>........................] - ETA: 3:46 - loss: 1.2890 - regression_loss: 1.0581 - classification_loss: 0.2309
 212/1000 [=====>........................] - ETA: 3:46 - loss: 1.2912 - regression_loss: 1.0600 - classification_loss: 0.2313
 213/1000 [=====>........................] - ETA: 3:46 - loss: 1.2886 - regression_loss: 1.0576 - classification_loss: 0.2310
 214/1000 [=====>........................] - ETA: 3:45 - loss: 1.2889 - regression_loss: 1.0585 - classification_loss: 0.2304
 215/1000 [=====>........................] - ETA: 3:45 - loss: 1.2870 - regression_loss: 1.0568 - classification_loss: 0.2302
 216/1000 [=====>........................] - ETA: 3:45 - loss: 1.2917 - regression_loss: 1.0611 - classification_loss: 0.2306
 217/1000 [=====>........................] - ETA: 3:45 - loss: 1.2931 - regression_loss: 1.0624 - classification_loss: 0.2307
 218/1000 [=====>........................] - ETA: 3:44 - loss: 1.2924 - regression_loss: 1.0620 - classification_loss: 0.2304
 219/1000 [=====>........................] - ETA: 3:44 - loss: 1.2896 - regression_loss: 1.0599 - classification_loss: 0.2297
 220/1000 [=====>........................] - ETA: 3:44 - loss: 1.2879 - regression_loss: 1.0589 - classification_loss: 0.2290
 221/1000 [=====>........................] - ETA: 3:43 - loss: 1.2877 - regression_loss: 1.0592 - classification_loss: 0.2285
 222/1000 [=====>........................] - ETA: 3:43 - loss: 1.2886 - regression_loss: 1.0599 - classification_loss: 0.2287
 223/1000 [=====>........................] - ETA: 3:43 - loss: 1.2877 - regression_loss: 1.0594 - classification_loss: 0.2283
 224/1000 [=====>........................] - ETA: 3:43 - loss: 1.2870 - regression_loss: 1.0590 - classification_loss: 0.2279
 225/1000 [=====>........................] - ETA: 3:42 - loss: 1.2872 - regression_loss: 1.0576 - classification_loss: 0.2296
 226/1000 [=====>........................] - ETA: 3:42 - loss: 1.2910 - regression_loss: 1.0606 - classification_loss: 0.2303
 227/1000 [=====>........................] - ETA: 3:42 - loss: 1.2933 - regression_loss: 1.0627 - classification_loss: 0.2306
 228/1000 [=====>........................] - ETA: 3:41 - loss: 1.2971 - regression_loss: 1.0656 - classification_loss: 0.2315
 229/1000 [=====>........................] - ETA: 3:41 - loss: 1.3012 - regression_loss: 1.0687 - classification_loss: 0.2325
 230/1000 [=====>........................] - ETA: 3:41 - loss: 1.3023 - regression_loss: 1.0697 - classification_loss: 0.2326
 231/1000 [=====>........................] - ETA: 3:40 - loss: 1.3017 - regression_loss: 1.0692 - classification_loss: 0.2326
 232/1000 [=====>........................] - ETA: 3:40 - loss: 1.3038 - regression_loss: 1.0706 - classification_loss: 0.2333
 233/1000 [=====>........................] - ETA: 3:40 - loss: 1.3012 - regression_loss: 1.0683 - classification_loss: 0.2329
 234/1000 [======>.......................] - ETA: 3:40 - loss: 1.3035 - regression_loss: 1.0701 - classification_loss: 0.2334
 235/1000 [======>.......................] - ETA: 3:39 - loss: 1.3051 - regression_loss: 1.0721 - classification_loss: 0.2330
 236/1000 [======>.......................] - ETA: 3:39 - loss: 1.3081 - regression_loss: 1.0749 - classification_loss: 0.2332
 237/1000 [======>.......................] - ETA: 3:39 - loss: 1.3079 - regression_loss: 1.0753 - classification_loss: 0.2325
 238/1000 [======>.......................] - ETA: 3:38 - loss: 1.3095 - regression_loss: 1.0761 - classification_loss: 0.2334
 239/1000 [======>.......................] - ETA: 3:38 - loss: 1.3098 - regression_loss: 1.0767 - classification_loss: 0.2331
 240/1000 [======>.......................] - ETA: 3:38 - loss: 1.3083 - regression_loss: 1.0757 - classification_loss: 0.2326
 241/1000 [======>.......................] - ETA: 3:38 - loss: 1.3100 - regression_loss: 1.0771 - classification_loss: 0.2329
 242/1000 [======>.......................] - ETA: 3:37 - loss: 1.3062 - regression_loss: 1.0740 - classification_loss: 0.2322
 243/1000 [======>.......................] - ETA: 3:37 - loss: 1.3044 - regression_loss: 1.0725 - classification_loss: 0.2319
 244/1000 [======>.......................] - ETA: 3:37 - loss: 1.3071 - regression_loss: 1.0745 - classification_loss: 0.2326
 245/1000 [======>.......................] - ETA: 3:36 - loss: 1.3052 - regression_loss: 1.0729 - classification_loss: 0.2322
 246/1000 [======>.......................] - ETA: 3:36 - loss: 1.3064 - regression_loss: 1.0740 - classification_loss: 0.2324
 247/1000 [======>.......................] - ETA: 3:36 - loss: 1.3046 - regression_loss: 1.0723 - classification_loss: 0.2322
 248/1000 [======>.......................] - ETA: 3:36 - loss: 1.3072 - regression_loss: 1.0744 - classification_loss: 0.2328
 249/1000 [======>.......................] - ETA: 3:35 - loss: 1.3060 - regression_loss: 1.0732 - classification_loss: 0.2328
 250/1000 [======>.......................] - ETA: 3:35 - loss: 1.3077 - regression_loss: 1.0740 - classification_loss: 0.2337
 251/1000 [======>.......................] - ETA: 3:35 - loss: 1.3054 - regression_loss: 1.0721 - classification_loss: 0.2332
 252/1000 [======>.......................] - ETA: 3:34 - loss: 1.3133 - regression_loss: 1.0781 - classification_loss: 0.2353
 253/1000 [======>.......................] - ETA: 3:34 - loss: 1.3108 - regression_loss: 1.0761 - classification_loss: 0.2347
 254/1000 [======>.......................] - ETA: 3:34 - loss: 1.3115 - regression_loss: 1.0767 - classification_loss: 0.2348
 255/1000 [======>.......................] - ETA: 3:34 - loss: 1.3088 - regression_loss: 1.0746 - classification_loss: 0.2342
 256/1000 [======>.......................] - ETA: 3:33 - loss: 1.3109 - regression_loss: 1.0762 - classification_loss: 0.2347
 257/1000 [======>.......................] - ETA: 3:33 - loss: 1.3112 - regression_loss: 1.0767 - classification_loss: 0.2345
 258/1000 [======>.......................] - ETA: 3:33 - loss: 1.3160 - regression_loss: 1.0798 - classification_loss: 0.2362
 259/1000 [======>.......................] - ETA: 3:32 - loss: 1.3139 - regression_loss: 1.0781 - classification_loss: 0.2358
 260/1000 [======>.......................] - ETA: 3:32 - loss: 1.3138 - regression_loss: 1.0783 - classification_loss: 0.2355
 261/1000 [======>.......................] - ETA: 3:32 - loss: 1.3143 - regression_loss: 1.0791 - classification_loss: 0.2353
 262/1000 [======>.......................] - ETA: 3:32 - loss: 1.3114 - regression_loss: 1.0767 - classification_loss: 0.2347
 263/1000 [======>.......................] - ETA: 3:31 - loss: 1.3136 - regression_loss: 1.0781 - classification_loss: 0.2355
 264/1000 [======>.......................] - ETA: 3:31 - loss: 1.3142 - regression_loss: 1.0786 - classification_loss: 0.2356
 265/1000 [======>.......................] - ETA: 3:31 - loss: 1.3120 - regression_loss: 1.0769 - classification_loss: 0.2351
 266/1000 [======>.......................] - ETA: 3:30 - loss: 1.3095 - regression_loss: 1.0750 - classification_loss: 0.2346
 267/1000 [=======>......................] - ETA: 3:30 - loss: 1.3093 - regression_loss: 1.0746 - classification_loss: 0.2347
 268/1000 [=======>......................] - ETA: 3:30 - loss: 1.3065 - regression_loss: 1.0722 - classification_loss: 0.2343
 269/1000 [=======>......................] - ETA: 3:30 - loss: 1.3063 - regression_loss: 1.0720 - classification_loss: 0.2343
 270/1000 [=======>......................] - ETA: 3:29 - loss: 1.3092 - regression_loss: 1.0744 - classification_loss: 0.2348
 271/1000 [=======>......................] - ETA: 3:29 - loss: 1.3081 - regression_loss: 1.0732 - classification_loss: 0.2349
 272/1000 [=======>......................] - ETA: 3:29 - loss: 1.3124 - regression_loss: 1.0757 - classification_loss: 0.2367
 273/1000 [=======>......................] - ETA: 3:28 - loss: 1.3168 - regression_loss: 1.0791 - classification_loss: 0.2377
 274/1000 [=======>......................] - ETA: 3:28 - loss: 1.3141 - regression_loss: 1.0770 - classification_loss: 0.2371
 275/1000 [=======>......................] - ETA: 3:28 - loss: 1.3129 - regression_loss: 1.0758 - classification_loss: 0.2371
 276/1000 [=======>......................] - ETA: 3:28 - loss: 1.3147 - regression_loss: 1.0719 - classification_loss: 0.2428
 277/1000 [=======>......................] - ETA: 3:27 - loss: 1.3148 - regression_loss: 1.0718 - classification_loss: 0.2430
 278/1000 [=======>......................] - ETA: 3:27 - loss: 1.3141 - regression_loss: 1.0712 - classification_loss: 0.2428
 279/1000 [=======>......................] - ETA: 3:27 - loss: 1.3133 - regression_loss: 1.0707 - classification_loss: 0.2426
 280/1000 [=======>......................] - ETA: 3:26 - loss: 1.3127 - regression_loss: 1.0702 - classification_loss: 0.2425
 281/1000 [=======>......................] - ETA: 3:26 - loss: 1.3133 - regression_loss: 1.0706 - classification_loss: 0.2427
 282/1000 [=======>......................] - ETA: 3:26 - loss: 1.3115 - regression_loss: 1.0688 - classification_loss: 0.2427
 283/1000 [=======>......................] - ETA: 3:26 - loss: 1.3118 - regression_loss: 1.0689 - classification_loss: 0.2429
 284/1000 [=======>......................] - ETA: 3:25 - loss: 1.3115 - regression_loss: 1.0685 - classification_loss: 0.2430
 285/1000 [=======>......................] - ETA: 3:25 - loss: 1.3133 - regression_loss: 1.0701 - classification_loss: 0.2432
 286/1000 [=======>......................] - ETA: 3:25 - loss: 1.3138 - regression_loss: 1.0707 - classification_loss: 0.2431
 287/1000 [=======>......................] - ETA: 3:24 - loss: 1.3171 - regression_loss: 1.0735 - classification_loss: 0.2436
 288/1000 [=======>......................] - ETA: 3:24 - loss: 1.3173 - regression_loss: 1.0737 - classification_loss: 0.2436
 289/1000 [=======>......................] - ETA: 3:24 - loss: 1.3176 - regression_loss: 1.0740 - classification_loss: 0.2436
 290/1000 [=======>......................] - ETA: 3:24 - loss: 1.3210 - regression_loss: 1.0775 - classification_loss: 0.2434
 291/1000 [=======>......................] - ETA: 3:23 - loss: 1.3198 - regression_loss: 1.0766 - classification_loss: 0.2433
 292/1000 [=======>......................] - ETA: 3:23 - loss: 1.3180 - regression_loss: 1.0753 - classification_loss: 0.2427
 293/1000 [=======>......................] - ETA: 3:23 - loss: 1.3201 - regression_loss: 1.0771 - classification_loss: 0.2430
 294/1000 [=======>......................] - ETA: 3:22 - loss: 1.3198 - regression_loss: 1.0772 - classification_loss: 0.2426
 295/1000 [=======>......................] - ETA: 3:22 - loss: 1.3200 - regression_loss: 1.0772 - classification_loss: 0.2427
 296/1000 [=======>......................] - ETA: 3:22 - loss: 1.3199 - regression_loss: 1.0773 - classification_loss: 0.2425
 297/1000 [=======>......................] - ETA: 3:22 - loss: 1.3201 - regression_loss: 1.0776 - classification_loss: 0.2425
 298/1000 [=======>......................] - ETA: 3:21 - loss: 1.3183 - regression_loss: 1.0761 - classification_loss: 0.2422
 299/1000 [=======>......................] - ETA: 3:21 - loss: 1.3175 - regression_loss: 1.0756 - classification_loss: 0.2419
 300/1000 [========>.....................] - ETA: 3:21 - loss: 1.3168 - regression_loss: 1.0749 - classification_loss: 0.2419
 301/1000 [========>.....................] - ETA: 3:20 - loss: 1.3147 - regression_loss: 1.0731 - classification_loss: 0.2416
 302/1000 [========>.....................] - ETA: 3:20 - loss: 1.3155 - regression_loss: 1.0735 - classification_loss: 0.2419
 303/1000 [========>.....................] - ETA: 3:20 - loss: 1.3153 - regression_loss: 1.0737 - classification_loss: 0.2416
 304/1000 [========>.....................] - ETA: 3:20 - loss: 1.3159 - regression_loss: 1.0743 - classification_loss: 0.2416
 305/1000 [========>.....................] - ETA: 3:19 - loss: 1.3152 - regression_loss: 1.0738 - classification_loss: 0.2414
 306/1000 [========>.....................] - ETA: 3:19 - loss: 1.3172 - regression_loss: 1.0754 - classification_loss: 0.2417
 307/1000 [========>.....................] - ETA: 3:19 - loss: 1.3150 - regression_loss: 1.0737 - classification_loss: 0.2413
 308/1000 [========>.....................] - ETA: 3:18 - loss: 1.3149 - regression_loss: 1.0736 - classification_loss: 0.2413
 309/1000 [========>.....................] - ETA: 3:18 - loss: 1.3132 - regression_loss: 1.0722 - classification_loss: 0.2410
 310/1000 [========>.....................] - ETA: 3:18 - loss: 1.3135 - regression_loss: 1.0726 - classification_loss: 0.2409
 311/1000 [========>.....................] - ETA: 3:18 - loss: 1.3129 - regression_loss: 1.0719 - classification_loss: 0.2410
 312/1000 [========>.....................] - ETA: 3:17 - loss: 1.3123 - regression_loss: 1.0716 - classification_loss: 0.2407
 313/1000 [========>.....................] - ETA: 3:17 - loss: 1.3144 - regression_loss: 1.0731 - classification_loss: 0.2413
 314/1000 [========>.....................] - ETA: 3:17 - loss: 1.3136 - regression_loss: 1.0728 - classification_loss: 0.2409
 315/1000 [========>.....................] - ETA: 3:16 - loss: 1.3114 - regression_loss: 1.0710 - classification_loss: 0.2404
 316/1000 [========>.....................] - ETA: 3:16 - loss: 1.3128 - regression_loss: 1.0724 - classification_loss: 0.2403
 317/1000 [========>.....................] - ETA: 3:16 - loss: 1.3133 - regression_loss: 1.0731 - classification_loss: 0.2403
 318/1000 [========>.....................] - ETA: 3:16 - loss: 1.3115 - regression_loss: 1.0714 - classification_loss: 0.2401
 319/1000 [========>.....................] - ETA: 3:15 - loss: 1.3097 - regression_loss: 1.0700 - classification_loss: 0.2396
 320/1000 [========>.....................] - ETA: 3:15 - loss: 1.3108 - regression_loss: 1.0712 - classification_loss: 0.2396
 321/1000 [========>.....................] - ETA: 3:15 - loss: 1.3095 - regression_loss: 1.0703 - classification_loss: 0.2392
 322/1000 [========>.....................] - ETA: 3:14 - loss: 1.3082 - regression_loss: 1.0693 - classification_loss: 0.2389
 323/1000 [========>.....................] - ETA: 3:14 - loss: 1.3085 - regression_loss: 1.0692 - classification_loss: 0.2393
 324/1000 [========>.....................] - ETA: 3:14 - loss: 1.3105 - regression_loss: 1.0709 - classification_loss: 0.2396
 325/1000 [========>.....................] - ETA: 3:14 - loss: 1.3088 - regression_loss: 1.0696 - classification_loss: 0.2393
 326/1000 [========>.....................] - ETA: 3:13 - loss: 1.3067 - regression_loss: 1.0677 - classification_loss: 0.2390
 327/1000 [========>.....................] - ETA: 3:13 - loss: 1.3063 - regression_loss: 1.0673 - classification_loss: 0.2390
 328/1000 [========>.....................] - ETA: 3:13 - loss: 1.3063 - regression_loss: 1.0672 - classification_loss: 0.2391
 329/1000 [========>.....................] - ETA: 3:12 - loss: 1.3057 - regression_loss: 1.0665 - classification_loss: 0.2391
 330/1000 [========>.....................] - ETA: 3:12 - loss: 1.3052 - regression_loss: 1.0664 - classification_loss: 0.2388
 331/1000 [========>.....................] - ETA: 3:12 - loss: 1.3048 - regression_loss: 1.0659 - classification_loss: 0.2389
 332/1000 [========>.....................] - ETA: 3:12 - loss: 1.3037 - regression_loss: 1.0650 - classification_loss: 0.2387
 333/1000 [========>.....................] - ETA: 3:11 - loss: 1.3026 - regression_loss: 1.0644 - classification_loss: 0.2383
 334/1000 [=========>....................] - ETA: 3:11 - loss: 1.3032 - regression_loss: 1.0645 - classification_loss: 0.2386
 335/1000 [=========>....................] - ETA: 3:11 - loss: 1.3028 - regression_loss: 1.0644 - classification_loss: 0.2384
 336/1000 [=========>....................] - ETA: 3:10 - loss: 1.3040 - regression_loss: 1.0655 - classification_loss: 0.2385
 337/1000 [=========>....................] - ETA: 3:10 - loss: 1.3055 - regression_loss: 1.0668 - classification_loss: 0.2387
 338/1000 [=========>....................] - ETA: 3:10 - loss: 1.3072 - regression_loss: 1.0682 - classification_loss: 0.2389
 339/1000 [=========>....................] - ETA: 3:10 - loss: 1.3075 - regression_loss: 1.0683 - classification_loss: 0.2392
 340/1000 [=========>....................] - ETA: 3:09 - loss: 1.3055 - regression_loss: 1.0667 - classification_loss: 0.2388
 341/1000 [=========>....................] - ETA: 3:09 - loss: 1.3047 - regression_loss: 1.0661 - classification_loss: 0.2386
 342/1000 [=========>....................] - ETA: 3:09 - loss: 1.3063 - regression_loss: 1.0672 - classification_loss: 0.2391
 343/1000 [=========>....................] - ETA: 3:08 - loss: 1.3054 - regression_loss: 1.0666 - classification_loss: 0.2388
 344/1000 [=========>....................] - ETA: 3:08 - loss: 1.3042 - regression_loss: 1.0657 - classification_loss: 0.2385
 345/1000 [=========>....................] - ETA: 3:08 - loss: 1.3031 - regression_loss: 1.0649 - classification_loss: 0.2381
 346/1000 [=========>....................] - ETA: 3:08 - loss: 1.3024 - regression_loss: 1.0643 - classification_loss: 0.2381
 347/1000 [=========>....................] - ETA: 3:07 - loss: 1.3055 - regression_loss: 1.0667 - classification_loss: 0.2388
 348/1000 [=========>....................] - ETA: 3:07 - loss: 1.3068 - regression_loss: 1.0679 - classification_loss: 0.2388
 349/1000 [=========>....................] - ETA: 3:07 - loss: 1.3045 - regression_loss: 1.0661 - classification_loss: 0.2384
 350/1000 [=========>....................] - ETA: 3:06 - loss: 1.3033 - regression_loss: 1.0650 - classification_loss: 0.2383
 351/1000 [=========>....................] - ETA: 3:06 - loss: 1.3041 - regression_loss: 1.0659 - classification_loss: 0.2382
 352/1000 [=========>....................] - ETA: 3:06 - loss: 1.3031 - regression_loss: 1.0651 - classification_loss: 0.2380
 353/1000 [=========>....................] - ETA: 3:05 - loss: 1.3013 - regression_loss: 1.0636 - classification_loss: 0.2378
 354/1000 [=========>....................] - ETA: 3:05 - loss: 1.2991 - regression_loss: 1.0618 - classification_loss: 0.2373
 355/1000 [=========>....................] - ETA: 3:05 - loss: 1.2977 - regression_loss: 1.0607 - classification_loss: 0.2369
 356/1000 [=========>....................] - ETA: 3:05 - loss: 1.2967 - regression_loss: 1.0600 - classification_loss: 0.2367
 357/1000 [=========>....................] - ETA: 3:04 - loss: 1.2948 - regression_loss: 1.0583 - classification_loss: 0.2365
 358/1000 [=========>....................] - ETA: 3:04 - loss: 1.2936 - regression_loss: 1.0567 - classification_loss: 0.2369
 359/1000 [=========>....................] - ETA: 3:04 - loss: 1.2928 - regression_loss: 1.0562 - classification_loss: 0.2366
 360/1000 [=========>....................] - ETA: 3:03 - loss: 1.2921 - regression_loss: 1.0557 - classification_loss: 0.2364
 361/1000 [=========>....................] - ETA: 3:03 - loss: 1.2900 - regression_loss: 1.0540 - classification_loss: 0.2360
 362/1000 [=========>....................] - ETA: 3:03 - loss: 1.2885 - regression_loss: 1.0529 - classification_loss: 0.2356
 363/1000 [=========>....................] - ETA: 3:03 - loss: 1.2883 - regression_loss: 1.0527 - classification_loss: 0.2356
 364/1000 [=========>....................] - ETA: 3:02 - loss: 1.2873 - regression_loss: 1.0519 - classification_loss: 0.2354
 365/1000 [=========>....................] - ETA: 3:02 - loss: 1.2875 - regression_loss: 1.0520 - classification_loss: 0.2356
 366/1000 [=========>....................] - ETA: 3:02 - loss: 1.2862 - regression_loss: 1.0509 - classification_loss: 0.2353
 367/1000 [==========>...................] - ETA: 3:01 - loss: 1.2865 - regression_loss: 1.0508 - classification_loss: 0.2357
 368/1000 [==========>...................] - ETA: 3:01 - loss: 1.2847 - regression_loss: 1.0494 - classification_loss: 0.2353
 369/1000 [==========>...................] - ETA: 3:01 - loss: 1.2856 - regression_loss: 1.0503 - classification_loss: 0.2353
 370/1000 [==========>...................] - ETA: 3:01 - loss: 1.2851 - regression_loss: 1.0498 - classification_loss: 0.2352
 371/1000 [==========>...................] - ETA: 3:00 - loss: 1.2841 - regression_loss: 1.0491 - classification_loss: 0.2350
 372/1000 [==========>...................] - ETA: 3:00 - loss: 1.2870 - regression_loss: 1.0514 - classification_loss: 0.2356
 373/1000 [==========>...................] - ETA: 3:00 - loss: 1.2865 - regression_loss: 1.0512 - classification_loss: 0.2353
 374/1000 [==========>...................] - ETA: 2:59 - loss: 1.2857 - regression_loss: 1.0507 - classification_loss: 0.2350
 375/1000 [==========>...................] - ETA: 2:59 - loss: 1.2883 - regression_loss: 1.0526 - classification_loss: 0.2357
 376/1000 [==========>...................] - ETA: 2:59 - loss: 1.2885 - regression_loss: 1.0527 - classification_loss: 0.2358
 377/1000 [==========>...................] - ETA: 2:59 - loss: 1.2877 - regression_loss: 1.0522 - classification_loss: 0.2355
 378/1000 [==========>...................] - ETA: 2:58 - loss: 1.2890 - regression_loss: 1.0535 - classification_loss: 0.2355
 379/1000 [==========>...................] - ETA: 2:58 - loss: 1.2874 - regression_loss: 1.0521 - classification_loss: 0.2352
 380/1000 [==========>...................] - ETA: 2:58 - loss: 1.2910 - regression_loss: 1.0553 - classification_loss: 0.2356
 381/1000 [==========>...................] - ETA: 2:57 - loss: 1.2905 - regression_loss: 1.0552 - classification_loss: 0.2353
 382/1000 [==========>...................] - ETA: 2:57 - loss: 1.2927 - regression_loss: 1.0568 - classification_loss: 0.2360
 383/1000 [==========>...................] - ETA: 2:57 - loss: 1.2938 - regression_loss: 1.0579 - classification_loss: 0.2360
 384/1000 [==========>...................] - ETA: 2:56 - loss: 1.2925 - regression_loss: 1.0568 - classification_loss: 0.2357
 385/1000 [==========>...................] - ETA: 2:56 - loss: 1.2918 - regression_loss: 1.0564 - classification_loss: 0.2354
 386/1000 [==========>...................] - ETA: 2:56 - loss: 1.2920 - regression_loss: 1.0566 - classification_loss: 0.2354
 387/1000 [==========>...................] - ETA: 2:56 - loss: 1.2966 - regression_loss: 1.0603 - classification_loss: 0.2364
 388/1000 [==========>...................] - ETA: 2:55 - loss: 1.2957 - regression_loss: 1.0596 - classification_loss: 0.2361
 389/1000 [==========>...................] - ETA: 2:55 - loss: 1.2959 - regression_loss: 1.0600 - classification_loss: 0.2359
 390/1000 [==========>...................] - ETA: 2:55 - loss: 1.2955 - regression_loss: 1.0599 - classification_loss: 0.2357
 391/1000 [==========>...................] - ETA: 2:54 - loss: 1.2939 - regression_loss: 1.0585 - classification_loss: 0.2354
 392/1000 [==========>...................] - ETA: 2:54 - loss: 1.2957 - regression_loss: 1.0602 - classification_loss: 0.2356
 393/1000 [==========>...................] - ETA: 2:54 - loss: 1.2938 - regression_loss: 1.0587 - classification_loss: 0.2351
 394/1000 [==========>...................] - ETA: 2:54 - loss: 1.2943 - regression_loss: 1.0591 - classification_loss: 0.2352
 395/1000 [==========>...................] - ETA: 2:53 - loss: 1.2928 - regression_loss: 1.0579 - classification_loss: 0.2349
 396/1000 [==========>...................] - ETA: 2:53 - loss: 1.2919 - regression_loss: 1.0571 - classification_loss: 0.2348
 397/1000 [==========>...................] - ETA: 2:53 - loss: 1.2922 - regression_loss: 1.0575 - classification_loss: 0.2346
 398/1000 [==========>...................] - ETA: 2:52 - loss: 1.2923 - regression_loss: 1.0577 - classification_loss: 0.2345
 399/1000 [==========>...................] - ETA: 2:52 - loss: 1.2921 - regression_loss: 1.0577 - classification_loss: 0.2344
 400/1000 [===========>..................] - ETA: 2:52 - loss: 1.2917 - regression_loss: 1.0576 - classification_loss: 0.2341
 401/1000 [===========>..................] - ETA: 2:52 - loss: 1.2907 - regression_loss: 1.0566 - classification_loss: 0.2341
 402/1000 [===========>..................] - ETA: 2:51 - loss: 1.2914 - regression_loss: 1.0574 - classification_loss: 0.2340
 403/1000 [===========>..................] - ETA: 2:51 - loss: 1.2900 - regression_loss: 1.0563 - classification_loss: 0.2336
 404/1000 [===========>..................] - ETA: 2:51 - loss: 1.2901 - regression_loss: 1.0568 - classification_loss: 0.2334
 405/1000 [===========>..................] - ETA: 2:50 - loss: 1.2894 - regression_loss: 1.0563 - classification_loss: 0.2331
 406/1000 [===========>..................] - ETA: 2:50 - loss: 1.2877 - regression_loss: 1.0551 - classification_loss: 0.2327
 407/1000 [===========>..................] - ETA: 2:50 - loss: 1.2868 - regression_loss: 1.0545 - classification_loss: 0.2324
 408/1000 [===========>..................] - ETA: 2:50 - loss: 1.2868 - regression_loss: 1.0547 - classification_loss: 0.2321
 409/1000 [===========>..................] - ETA: 2:49 - loss: 1.2870 - regression_loss: 1.0550 - classification_loss: 0.2320
 410/1000 [===========>..................] - ETA: 2:49 - loss: 1.2876 - regression_loss: 1.0556 - classification_loss: 0.2321
 411/1000 [===========>..................] - ETA: 2:49 - loss: 1.2895 - regression_loss: 1.0573 - classification_loss: 0.2322
 412/1000 [===========>..................] - ETA: 2:48 - loss: 1.2901 - regression_loss: 1.0581 - classification_loss: 0.2320
 413/1000 [===========>..................] - ETA: 2:48 - loss: 1.2901 - regression_loss: 1.0581 - classification_loss: 0.2320
 414/1000 [===========>..................] - ETA: 2:48 - loss: 1.2921 - regression_loss: 1.0594 - classification_loss: 0.2327
 415/1000 [===========>..................] - ETA: 2:48 - loss: 1.2908 - regression_loss: 1.0585 - classification_loss: 0.2323
 416/1000 [===========>..................] - ETA: 2:47 - loss: 1.2907 - regression_loss: 1.0584 - classification_loss: 0.2323
 417/1000 [===========>..................] - ETA: 2:47 - loss: 1.2944 - regression_loss: 1.0609 - classification_loss: 0.2335
 418/1000 [===========>..................] - ETA: 2:47 - loss: 1.2946 - regression_loss: 1.0608 - classification_loss: 0.2338
 419/1000 [===========>..................] - ETA: 2:46 - loss: 1.2952 - regression_loss: 1.0615 - classification_loss: 0.2337
 420/1000 [===========>..................] - ETA: 2:46 - loss: 1.2968 - regression_loss: 1.0632 - classification_loss: 0.2336
 421/1000 [===========>..................] - ETA: 2:46 - loss: 1.2954 - regression_loss: 1.0619 - classification_loss: 0.2335
 422/1000 [===========>..................] - ETA: 2:46 - loss: 1.2953 - regression_loss: 1.0618 - classification_loss: 0.2335
 423/1000 [===========>..................] - ETA: 2:45 - loss: 1.2954 - regression_loss: 1.0619 - classification_loss: 0.2335
 424/1000 [===========>..................] - ETA: 2:45 - loss: 1.2963 - regression_loss: 1.0629 - classification_loss: 0.2334
 425/1000 [===========>..................] - ETA: 2:45 - loss: 1.2957 - regression_loss: 1.0625 - classification_loss: 0.2332
 426/1000 [===========>..................] - ETA: 2:44 - loss: 1.2939 - regression_loss: 1.0610 - classification_loss: 0.2329
 427/1000 [===========>..................] - ETA: 2:44 - loss: 1.2919 - regression_loss: 1.0593 - classification_loss: 0.2325
 428/1000 [===========>..................] - ETA: 2:44 - loss: 1.2962 - regression_loss: 1.0633 - classification_loss: 0.2329
 429/1000 [===========>..................] - ETA: 2:44 - loss: 1.2975 - regression_loss: 1.0643 - classification_loss: 0.2332
 430/1000 [===========>..................] - ETA: 2:43 - loss: 1.2965 - regression_loss: 1.0632 - classification_loss: 0.2332
 431/1000 [===========>..................] - ETA: 2:43 - loss: 1.2958 - regression_loss: 1.0626 - classification_loss: 0.2333
 432/1000 [===========>..................] - ETA: 2:43 - loss: 1.2942 - regression_loss: 1.0613 - classification_loss: 0.2329
 433/1000 [===========>..................] - ETA: 2:42 - loss: 1.2935 - regression_loss: 1.0605 - classification_loss: 0.2329
 434/1000 [============>.................] - ETA: 2:42 - loss: 1.2950 - regression_loss: 1.0620 - classification_loss: 0.2330
 435/1000 [============>.................] - ETA: 2:42 - loss: 1.2980 - regression_loss: 1.0646 - classification_loss: 0.2334
 436/1000 [============>.................] - ETA: 2:41 - loss: 1.2987 - regression_loss: 1.0652 - classification_loss: 0.2336
 437/1000 [============>.................] - ETA: 2:41 - loss: 1.2985 - regression_loss: 1.0651 - classification_loss: 0.2334
 438/1000 [============>.................] - ETA: 2:41 - loss: 1.2978 - regression_loss: 1.0645 - classification_loss: 0.2333
 439/1000 [============>.................] - ETA: 2:41 - loss: 1.2976 - regression_loss: 1.0645 - classification_loss: 0.2331
 440/1000 [============>.................] - ETA: 2:40 - loss: 1.2960 - regression_loss: 1.0630 - classification_loss: 0.2330
 441/1000 [============>.................] - ETA: 2:40 - loss: 1.2949 - regression_loss: 1.0622 - classification_loss: 0.2327
 442/1000 [============>.................] - ETA: 2:40 - loss: 1.2981 - regression_loss: 1.0647 - classification_loss: 0.2334
 443/1000 [============>.................] - ETA: 2:39 - loss: 1.2979 - regression_loss: 1.0646 - classification_loss: 0.2333
 444/1000 [============>.................] - ETA: 2:39 - loss: 1.3008 - regression_loss: 1.0665 - classification_loss: 0.2343
 445/1000 [============>.................] - ETA: 2:39 - loss: 1.3009 - regression_loss: 1.0669 - classification_loss: 0.2340
 446/1000 [============>.................] - ETA: 2:39 - loss: 1.2993 - regression_loss: 1.0655 - classification_loss: 0.2338
 447/1000 [============>.................] - ETA: 2:38 - loss: 1.2998 - regression_loss: 1.0661 - classification_loss: 0.2337
 448/1000 [============>.................] - ETA: 2:38 - loss: 1.3002 - regression_loss: 1.0664 - classification_loss: 0.2338
 449/1000 [============>.................] - ETA: 2:38 - loss: 1.2997 - regression_loss: 1.0662 - classification_loss: 0.2336
 450/1000 [============>.................] - ETA: 2:37 - loss: 1.3013 - regression_loss: 1.0677 - classification_loss: 0.2335
 451/1000 [============>.................] - ETA: 2:37 - loss: 1.3015 - regression_loss: 1.0680 - classification_loss: 0.2335
 452/1000 [============>.................] - ETA: 2:37 - loss: 1.3015 - regression_loss: 1.0679 - classification_loss: 0.2336
 453/1000 [============>.................] - ETA: 2:37 - loss: 1.3008 - regression_loss: 1.0675 - classification_loss: 0.2334
 454/1000 [============>.................] - ETA: 2:36 - loss: 1.3006 - regression_loss: 1.0672 - classification_loss: 0.2333
 455/1000 [============>.................] - ETA: 2:36 - loss: 1.3009 - regression_loss: 1.0677 - classification_loss: 0.2332
 456/1000 [============>.................] - ETA: 2:36 - loss: 1.3013 - regression_loss: 1.0680 - classification_loss: 0.2334
 457/1000 [============>.................] - ETA: 2:35 - loss: 1.3019 - regression_loss: 1.0684 - classification_loss: 0.2335
 458/1000 [============>.................] - ETA: 2:35 - loss: 1.3009 - regression_loss: 1.0677 - classification_loss: 0.2332
 459/1000 [============>.................] - ETA: 2:35 - loss: 1.2987 - regression_loss: 1.0654 - classification_loss: 0.2334
 460/1000 [============>.................] - ETA: 2:35 - loss: 1.3005 - regression_loss: 1.0668 - classification_loss: 0.2338
 461/1000 [============>.................] - ETA: 2:34 - loss: 1.3002 - regression_loss: 1.0663 - classification_loss: 0.2340
 462/1000 [============>.................] - ETA: 2:34 - loss: 1.2998 - regression_loss: 1.0655 - classification_loss: 0.2343
 463/1000 [============>.................] - ETA: 2:34 - loss: 1.2985 - regression_loss: 1.0645 - classification_loss: 0.2340
 464/1000 [============>.................] - ETA: 2:33 - loss: 1.2978 - regression_loss: 1.0637 - classification_loss: 0.2340
 465/1000 [============>.................] - ETA: 2:33 - loss: 1.2965 - regression_loss: 1.0628 - classification_loss: 0.2338
 466/1000 [============>.................] - ETA: 2:33 - loss: 1.2954 - regression_loss: 1.0619 - classification_loss: 0.2335
 467/1000 [=============>................] - ETA: 2:33 - loss: 1.2949 - regression_loss: 1.0615 - classification_loss: 0.2334
 468/1000 [=============>................] - ETA: 2:32 - loss: 1.2943 - regression_loss: 1.0609 - classification_loss: 0.2334
 469/1000 [=============>................] - ETA: 2:32 - loss: 1.2936 - regression_loss: 1.0605 - classification_loss: 0.2332
 470/1000 [=============>................] - ETA: 2:32 - loss: 1.2944 - regression_loss: 1.0610 - classification_loss: 0.2334
 471/1000 [=============>................] - ETA: 2:31 - loss: 1.2943 - regression_loss: 1.0611 - classification_loss: 0.2332
 472/1000 [=============>................] - ETA: 2:31 - loss: 1.2974 - regression_loss: 1.0636 - classification_loss: 0.2339
 473/1000 [=============>................] - ETA: 2:31 - loss: 1.2981 - regression_loss: 1.0639 - classification_loss: 0.2342
 474/1000 [=============>................] - ETA: 2:31 - loss: 1.2978 - regression_loss: 1.0637 - classification_loss: 0.2342
 475/1000 [=============>................] - ETA: 2:30 - loss: 1.2979 - regression_loss: 1.0636 - classification_loss: 0.2343
 476/1000 [=============>................] - ETA: 2:30 - loss: 1.2964 - regression_loss: 1.0625 - classification_loss: 0.2340
 477/1000 [=============>................] - ETA: 2:30 - loss: 1.2959 - regression_loss: 1.0621 - classification_loss: 0.2339
 478/1000 [=============>................] - ETA: 2:29 - loss: 1.2945 - regression_loss: 1.0608 - classification_loss: 0.2337
 479/1000 [=============>................] - ETA: 2:29 - loss: 1.2945 - regression_loss: 1.0607 - classification_loss: 0.2338
 480/1000 [=============>................] - ETA: 2:29 - loss: 1.2939 - regression_loss: 1.0601 - classification_loss: 0.2338
 481/1000 [=============>................] - ETA: 2:29 - loss: 1.2934 - regression_loss: 1.0596 - classification_loss: 0.2338
 482/1000 [=============>................] - ETA: 2:28 - loss: 1.2924 - regression_loss: 1.0588 - classification_loss: 0.2336
 483/1000 [=============>................] - ETA: 2:28 - loss: 1.2914 - regression_loss: 1.0579 - classification_loss: 0.2335
 484/1000 [=============>................] - ETA: 2:28 - loss: 1.2917 - regression_loss: 1.0582 - classification_loss: 0.2336
 485/1000 [=============>................] - ETA: 2:27 - loss: 1.2912 - regression_loss: 1.0578 - classification_loss: 0.2334
 486/1000 [=============>................] - ETA: 2:27 - loss: 1.2894 - regression_loss: 1.0563 - classification_loss: 0.2331
 487/1000 [=============>................] - ETA: 2:27 - loss: 1.2906 - regression_loss: 1.0577 - classification_loss: 0.2330
 488/1000 [=============>................] - ETA: 2:27 - loss: 1.2905 - regression_loss: 1.0575 - classification_loss: 0.2330
 489/1000 [=============>................] - ETA: 2:26 - loss: 1.2904 - regression_loss: 1.0574 - classification_loss: 0.2330
 490/1000 [=============>................] - ETA: 2:26 - loss: 1.2893 - regression_loss: 1.0566 - classification_loss: 0.2327
 491/1000 [=============>................] - ETA: 2:26 - loss: 1.2889 - regression_loss: 1.0564 - classification_loss: 0.2325
 492/1000 [=============>................] - ETA: 2:25 - loss: 1.2895 - regression_loss: 1.0571 - classification_loss: 0.2324
 493/1000 [=============>................] - ETA: 2:25 - loss: 1.2907 - regression_loss: 1.0583 - classification_loss: 0.2324
 494/1000 [=============>................] - ETA: 2:25 - loss: 1.2901 - regression_loss: 1.0579 - classification_loss: 0.2322
 495/1000 [=============>................] - ETA: 2:24 - loss: 1.2905 - regression_loss: 1.0585 - classification_loss: 0.2320
 496/1000 [=============>................] - ETA: 2:24 - loss: 1.2932 - regression_loss: 1.0606 - classification_loss: 0.2326
 497/1000 [=============>................] - ETA: 2:24 - loss: 1.2934 - regression_loss: 1.0610 - classification_loss: 0.2324
 498/1000 [=============>................] - ETA: 2:24 - loss: 1.2934 - regression_loss: 1.0612 - classification_loss: 0.2322
 499/1000 [=============>................] - ETA: 2:23 - loss: 1.2942 - regression_loss: 1.0619 - classification_loss: 0.2323
 500/1000 [==============>...............] - ETA: 2:23 - loss: 1.2935 - regression_loss: 1.0614 - classification_loss: 0.2321
 501/1000 [==============>...............] - ETA: 2:23 - loss: 1.2930 - regression_loss: 1.0610 - classification_loss: 0.2319
 502/1000 [==============>...............] - ETA: 2:22 - loss: 1.2931 - regression_loss: 1.0609 - classification_loss: 0.2322
 503/1000 [==============>...............] - ETA: 2:22 - loss: 1.2934 - regression_loss: 1.0612 - classification_loss: 0.2322
 504/1000 [==============>...............] - ETA: 2:22 - loss: 1.2922 - regression_loss: 1.0603 - classification_loss: 0.2319
 505/1000 [==============>...............] - ETA: 2:22 - loss: 1.2915 - regression_loss: 1.0599 - classification_loss: 0.2317
 506/1000 [==============>...............] - ETA: 2:21 - loss: 1.2923 - regression_loss: 1.0602 - classification_loss: 0.2321
 507/1000 [==============>...............] - ETA: 2:21 - loss: 1.2919 - regression_loss: 1.0600 - classification_loss: 0.2319
 508/1000 [==============>...............] - ETA: 2:21 - loss: 1.2918 - regression_loss: 1.0601 - classification_loss: 0.2317
 509/1000 [==============>...............] - ETA: 2:20 - loss: 1.2923 - regression_loss: 1.0606 - classification_loss: 0.2317
 510/1000 [==============>...............] - ETA: 2:20 - loss: 1.2930 - regression_loss: 1.0612 - classification_loss: 0.2319
 511/1000 [==============>...............] - ETA: 2:20 - loss: 1.2932 - regression_loss: 1.0614 - classification_loss: 0.2318
 512/1000 [==============>...............] - ETA: 2:20 - loss: 1.2929 - regression_loss: 1.0613 - classification_loss: 0.2316
 513/1000 [==============>...............] - ETA: 2:19 - loss: 1.2939 - regression_loss: 1.0621 - classification_loss: 0.2318
 514/1000 [==============>...............] - ETA: 2:19 - loss: 1.2931 - regression_loss: 1.0614 - classification_loss: 0.2317
 515/1000 [==============>...............] - ETA: 2:19 - loss: 1.2928 - regression_loss: 1.0612 - classification_loss: 0.2316
 516/1000 [==============>...............] - ETA: 2:18 - loss: 1.2922 - regression_loss: 1.0607 - classification_loss: 0.2315
 517/1000 [==============>...............] - ETA: 2:18 - loss: 1.2940 - regression_loss: 1.0618 - classification_loss: 0.2321
 518/1000 [==============>...............] - ETA: 2:18 - loss: 1.2940 - regression_loss: 1.0617 - classification_loss: 0.2322
 519/1000 [==============>...............] - ETA: 2:18 - loss: 1.2928 - regression_loss: 1.0608 - classification_loss: 0.2320
 520/1000 [==============>...............] - ETA: 2:17 - loss: 1.2921 - regression_loss: 1.0602 - classification_loss: 0.2319
 521/1000 [==============>...............] - ETA: 2:17 - loss: 1.2915 - regression_loss: 1.0597 - classification_loss: 0.2318
 522/1000 [==============>...............] - ETA: 2:17 - loss: 1.2902 - regression_loss: 1.0588 - classification_loss: 0.2314
 523/1000 [==============>...............] - ETA: 2:16 - loss: 1.2896 - regression_loss: 1.0582 - classification_loss: 0.2315
 524/1000 [==============>...............] - ETA: 2:16 - loss: 1.2900 - regression_loss: 1.0585 - classification_loss: 0.2315
 525/1000 [==============>...............] - ETA: 2:16 - loss: 1.2888 - regression_loss: 1.0577 - classification_loss: 0.2312
 526/1000 [==============>...............] - ETA: 2:16 - loss: 1.2880 - regression_loss: 1.0568 - classification_loss: 0.2313
 527/1000 [==============>...............] - ETA: 2:15 - loss: 1.2897 - regression_loss: 1.0584 - classification_loss: 0.2313
 528/1000 [==============>...............] - ETA: 2:15 - loss: 1.2904 - regression_loss: 1.0587 - classification_loss: 0.2316
 529/1000 [==============>...............] - ETA: 2:15 - loss: 1.2917 - regression_loss: 1.0600 - classification_loss: 0.2316
 530/1000 [==============>...............] - ETA: 2:14 - loss: 1.2919 - regression_loss: 1.0601 - classification_loss: 0.2318
 531/1000 [==============>...............] - ETA: 2:14 - loss: 1.2924 - regression_loss: 1.0605 - classification_loss: 0.2319
 532/1000 [==============>...............] - ETA: 2:14 - loss: 1.2966 - regression_loss: 1.0635 - classification_loss: 0.2331
 533/1000 [==============>...............] - ETA: 2:14 - loss: 1.2993 - regression_loss: 1.0654 - classification_loss: 0.2339
 534/1000 [===============>..............] - ETA: 2:13 - loss: 1.2977 - regression_loss: 1.0642 - classification_loss: 0.2336
 535/1000 [===============>..............] - ETA: 2:13 - loss: 1.2983 - regression_loss: 1.0648 - classification_loss: 0.2336
 536/1000 [===============>..............] - ETA: 2:13 - loss: 1.2998 - regression_loss: 1.0661 - classification_loss: 0.2337
 537/1000 [===============>..............] - ETA: 2:12 - loss: 1.2996 - regression_loss: 1.0659 - classification_loss: 0.2336
 538/1000 [===============>..............] - ETA: 2:12 - loss: 1.3009 - regression_loss: 1.0669 - classification_loss: 0.2340
 539/1000 [===============>..............] - ETA: 2:12 - loss: 1.3007 - regression_loss: 1.0667 - classification_loss: 0.2340
 540/1000 [===============>..............] - ETA: 2:12 - loss: 1.3018 - regression_loss: 1.0679 - classification_loss: 0.2340
 541/1000 [===============>..............] - ETA: 2:11 - loss: 1.3005 - regression_loss: 1.0669 - classification_loss: 0.2337
 542/1000 [===============>..............] - ETA: 2:11 - loss: 1.2995 - regression_loss: 1.0661 - classification_loss: 0.2334
 543/1000 [===============>..............] - ETA: 2:11 - loss: 1.2990 - regression_loss: 1.0657 - classification_loss: 0.2333
 544/1000 [===============>..............] - ETA: 2:10 - loss: 1.2986 - regression_loss: 1.0653 - classification_loss: 0.2333
 545/1000 [===============>..............] - ETA: 2:10 - loss: 1.2986 - regression_loss: 1.0655 - classification_loss: 0.2331
 546/1000 [===============>..............] - ETA: 2:10 - loss: 1.2989 - regression_loss: 1.0658 - classification_loss: 0.2330
 547/1000 [===============>..............] - ETA: 2:10 - loss: 1.2987 - regression_loss: 1.0653 - classification_loss: 0.2335
 548/1000 [===============>..............] - ETA: 2:09 - loss: 1.2988 - regression_loss: 1.0654 - classification_loss: 0.2334
 549/1000 [===============>..............] - ETA: 2:09 - loss: 1.2970 - regression_loss: 1.0639 - classification_loss: 0.2331
 550/1000 [===============>..............] - ETA: 2:09 - loss: 1.2968 - regression_loss: 1.0638 - classification_loss: 0.2330
 551/1000 [===============>..............] - ETA: 2:08 - loss: 1.2966 - regression_loss: 1.0637 - classification_loss: 0.2329
 552/1000 [===============>..............] - ETA: 2:08 - loss: 1.2957 - regression_loss: 1.0630 - classification_loss: 0.2327
 553/1000 [===============>..............] - ETA: 2:08 - loss: 1.2950 - regression_loss: 1.0624 - classification_loss: 0.2326
 554/1000 [===============>..............] - ETA: 2:08 - loss: 1.2954 - regression_loss: 1.0625 - classification_loss: 0.2329
 555/1000 [===============>..............] - ETA: 2:07 - loss: 1.2964 - regression_loss: 1.0634 - classification_loss: 0.2330
 556/1000 [===============>..............] - ETA: 2:07 - loss: 1.2962 - regression_loss: 1.0633 - classification_loss: 0.2329
 557/1000 [===============>..............] - ETA: 2:07 - loss: 1.2970 - regression_loss: 1.0640 - classification_loss: 0.2330
 558/1000 [===============>..............] - ETA: 2:06 - loss: 1.2971 - regression_loss: 1.0643 - classification_loss: 0.2328
 559/1000 [===============>..............] - ETA: 2:06 - loss: 1.2966 - regression_loss: 1.0637 - classification_loss: 0.2329
 560/1000 [===============>..............] - ETA: 2:06 - loss: 1.2973 - regression_loss: 1.0643 - classification_loss: 0.2329
 561/1000 [===============>..............] - ETA: 2:06 - loss: 1.2984 - regression_loss: 1.0653 - classification_loss: 0.2331
 562/1000 [===============>..............] - ETA: 2:05 - loss: 1.2985 - regression_loss: 1.0655 - classification_loss: 0.2330
 563/1000 [===============>..............] - ETA: 2:05 - loss: 1.2979 - regression_loss: 1.0651 - classification_loss: 0.2327
 564/1000 [===============>..............] - ETA: 2:05 - loss: 1.2976 - regression_loss: 1.0649 - classification_loss: 0.2326
 565/1000 [===============>..............] - ETA: 2:04 - loss: 1.2978 - regression_loss: 1.0653 - classification_loss: 0.2325
 566/1000 [===============>..............] - ETA: 2:04 - loss: 1.2986 - regression_loss: 1.0661 - classification_loss: 0.2325
 567/1000 [================>.............] - ETA: 2:04 - loss: 1.3013 - regression_loss: 1.0680 - classification_loss: 0.2333
 568/1000 [================>.............] - ETA: 2:04 - loss: 1.3003 - regression_loss: 1.0672 - classification_loss: 0.2330
 569/1000 [================>.............] - ETA: 2:03 - loss: 1.3010 - regression_loss: 1.0680 - classification_loss: 0.2331
 570/1000 [================>.............] - ETA: 2:03 - loss: 1.3036 - regression_loss: 1.0696 - classification_loss: 0.2340
 571/1000 [================>.............] - ETA: 2:03 - loss: 1.3052 - regression_loss: 1.0709 - classification_loss: 0.2343
 572/1000 [================>.............] - ETA: 2:02 - loss: 1.3058 - regression_loss: 1.0714 - classification_loss: 0.2344
 573/1000 [================>.............] - ETA: 2:02 - loss: 1.3059 - regression_loss: 1.0716 - classification_loss: 0.2343
 574/1000 [================>.............] - ETA: 2:02 - loss: 1.3058 - regression_loss: 1.0715 - classification_loss: 0.2342
 575/1000 [================>.............] - ETA: 2:02 - loss: 1.3051 - regression_loss: 1.0711 - classification_loss: 0.2340
 576/1000 [================>.............] - ETA: 2:01 - loss: 1.3057 - regression_loss: 1.0718 - classification_loss: 0.2339
 577/1000 [================>.............] - ETA: 2:01 - loss: 1.3052 - regression_loss: 1.0716 - classification_loss: 0.2337
 578/1000 [================>.............] - ETA: 2:01 - loss: 1.3048 - regression_loss: 1.0712 - classification_loss: 0.2336
 579/1000 [================>.............] - ETA: 2:00 - loss: 1.3036 - regression_loss: 1.0702 - classification_loss: 0.2334
 580/1000 [================>.............] - ETA: 2:00 - loss: 1.3026 - regression_loss: 1.0694 - classification_loss: 0.2332
 581/1000 [================>.............] - ETA: 2:00 - loss: 1.3016 - regression_loss: 1.0686 - classification_loss: 0.2330
 582/1000 [================>.............] - ETA: 1:59 - loss: 1.3016 - regression_loss: 1.0688 - classification_loss: 0.2329
 583/1000 [================>.............] - ETA: 1:59 - loss: 1.3008 - regression_loss: 1.0682 - classification_loss: 0.2326
 584/1000 [================>.............] - ETA: 1:59 - loss: 1.3012 - regression_loss: 1.0687 - classification_loss: 0.2326
 585/1000 [================>.............] - ETA: 1:59 - loss: 1.3005 - regression_loss: 1.0682 - classification_loss: 0.2323
 586/1000 [================>.............] - ETA: 1:58 - loss: 1.3003 - regression_loss: 1.0681 - classification_loss: 0.2322
 587/1000 [================>.............] - ETA: 1:58 - loss: 1.3018 - regression_loss: 1.0693 - classification_loss: 0.2325
 588/1000 [================>.............] - ETA: 1:58 - loss: 1.3010 - regression_loss: 1.0685 - classification_loss: 0.2325
 589/1000 [================>.............] - ETA: 1:57 - loss: 1.3004 - regression_loss: 1.0681 - classification_loss: 0.2323
 590/1000 [================>.............] - ETA: 1:57 - loss: 1.3000 - regression_loss: 1.0679 - classification_loss: 0.2321
 591/1000 [================>.............] - ETA: 1:57 - loss: 1.2991 - regression_loss: 1.0672 - classification_loss: 0.2319
 592/1000 [================>.............] - ETA: 1:57 - loss: 1.2985 - regression_loss: 1.0669 - classification_loss: 0.2316
 593/1000 [================>.............] - ETA: 1:56 - loss: 1.2979 - regression_loss: 1.0664 - classification_loss: 0.2315
 594/1000 [================>.............] - ETA: 1:56 - loss: 1.2973 - regression_loss: 1.0658 - classification_loss: 0.2315
 595/1000 [================>.............] - ETA: 1:56 - loss: 1.2966 - regression_loss: 1.0652 - classification_loss: 0.2314
 596/1000 [================>.............] - ETA: 1:55 - loss: 1.2967 - regression_loss: 1.0655 - classification_loss: 0.2312
 597/1000 [================>.............] - ETA: 1:55 - loss: 1.2958 - regression_loss: 1.0648 - classification_loss: 0.2310
 598/1000 [================>.............] - ETA: 1:55 - loss: 1.2988 - regression_loss: 1.0673 - classification_loss: 0.2315
 599/1000 [================>.............] - ETA: 1:55 - loss: 1.2983 - regression_loss: 1.0669 - classification_loss: 0.2314
 600/1000 [=================>............] - ETA: 1:54 - loss: 1.2985 - regression_loss: 1.0673 - classification_loss: 0.2313
 601/1000 [=================>............] - ETA: 1:54 - loss: 1.3011 - regression_loss: 1.0689 - classification_loss: 0.2322
 602/1000 [=================>............] - ETA: 1:54 - loss: 1.2999 - regression_loss: 1.0680 - classification_loss: 0.2320
 603/1000 [=================>............] - ETA: 1:53 - loss: 1.3019 - regression_loss: 1.0696 - classification_loss: 0.2323
 604/1000 [=================>............] - ETA: 1:53 - loss: 1.3028 - regression_loss: 1.0702 - classification_loss: 0.2326
 605/1000 [=================>............] - ETA: 1:53 - loss: 1.3031 - regression_loss: 1.0706 - classification_loss: 0.2325
 606/1000 [=================>............] - ETA: 1:53 - loss: 1.3024 - regression_loss: 1.0701 - classification_loss: 0.2323
 607/1000 [=================>............] - ETA: 1:52 - loss: 1.3011 - regression_loss: 1.0690 - classification_loss: 0.2321
 608/1000 [=================>............] - ETA: 1:52 - loss: 1.3018 - regression_loss: 1.0697 - classification_loss: 0.2321
 609/1000 [=================>............] - ETA: 1:52 - loss: 1.3019 - regression_loss: 1.0697 - classification_loss: 0.2322
 610/1000 [=================>............] - ETA: 1:51 - loss: 1.3022 - regression_loss: 1.0699 - classification_loss: 0.2323
 611/1000 [=================>............] - ETA: 1:51 - loss: 1.3012 - regression_loss: 1.0692 - classification_loss: 0.2321
 612/1000 [=================>............] - ETA: 1:51 - loss: 1.3021 - regression_loss: 1.0698 - classification_loss: 0.2323
 613/1000 [=================>............] - ETA: 1:51 - loss: 1.3022 - regression_loss: 1.0699 - classification_loss: 0.2323
 614/1000 [=================>............] - ETA: 1:50 - loss: 1.3010 - regression_loss: 1.0689 - classification_loss: 0.2321
 615/1000 [=================>............] - ETA: 1:50 - loss: 1.3024 - regression_loss: 1.0700 - classification_loss: 0.2324
 616/1000 [=================>............] - ETA: 1:50 - loss: 1.3021 - regression_loss: 1.0697 - classification_loss: 0.2324
 617/1000 [=================>............] - ETA: 1:49 - loss: 1.3015 - regression_loss: 1.0691 - classification_loss: 0.2324
 618/1000 [=================>............] - ETA: 1:49 - loss: 1.3002 - regression_loss: 1.0680 - classification_loss: 0.2321
 619/1000 [=================>............] - ETA: 1:49 - loss: 1.2995 - regression_loss: 1.0675 - classification_loss: 0.2320
 620/1000 [=================>............] - ETA: 1:49 - loss: 1.2997 - regression_loss: 1.0678 - classification_loss: 0.2319
 621/1000 [=================>............] - ETA: 1:48 - loss: 1.2989 - regression_loss: 1.0670 - classification_loss: 0.2319
 622/1000 [=================>............] - ETA: 1:48 - loss: 1.2987 - regression_loss: 1.0668 - classification_loss: 0.2319
 623/1000 [=================>............] - ETA: 1:48 - loss: 1.2980 - regression_loss: 1.0663 - classification_loss: 0.2317
 624/1000 [=================>............] - ETA: 1:47 - loss: 1.2996 - regression_loss: 1.0676 - classification_loss: 0.2320
 625/1000 [=================>............] - ETA: 1:47 - loss: 1.2996 - regression_loss: 1.0677 - classification_loss: 0.2319
 626/1000 [=================>............] - ETA: 1:47 - loss: 1.3003 - regression_loss: 1.0681 - classification_loss: 0.2322
 627/1000 [=================>............] - ETA: 1:47 - loss: 1.2992 - regression_loss: 1.0672 - classification_loss: 0.2320
 628/1000 [=================>............] - ETA: 1:46 - loss: 1.3001 - regression_loss: 1.0679 - classification_loss: 0.2323
 629/1000 [=================>............] - ETA: 1:46 - loss: 1.3006 - regression_loss: 1.0682 - classification_loss: 0.2323
 630/1000 [=================>............] - ETA: 1:46 - loss: 1.2992 - regression_loss: 1.0670 - classification_loss: 0.2321
 631/1000 [=================>............] - ETA: 1:45 - loss: 1.2994 - regression_loss: 1.0672 - classification_loss: 0.2322
 632/1000 [=================>............] - ETA: 1:45 - loss: 1.2994 - regression_loss: 1.0672 - classification_loss: 0.2322
 633/1000 [=================>............] - ETA: 1:45 - loss: 1.3007 - regression_loss: 1.0684 - classification_loss: 0.2322
 634/1000 [==================>...........] - ETA: 1:45 - loss: 1.2999 - regression_loss: 1.0678 - classification_loss: 0.2320
 635/1000 [==================>...........] - ETA: 1:44 - loss: 1.3004 - regression_loss: 1.0684 - classification_loss: 0.2320
 636/1000 [==================>...........] - ETA: 1:44 - loss: 1.3012 - regression_loss: 1.0693 - classification_loss: 0.2320
 637/1000 [==================>...........] - ETA: 1:44 - loss: 1.3015 - regression_loss: 1.0694 - classification_loss: 0.2321
 638/1000 [==================>...........] - ETA: 1:43 - loss: 1.3013 - regression_loss: 1.0692 - classification_loss: 0.2321
 639/1000 [==================>...........] - ETA: 1:43 - loss: 1.3021 - regression_loss: 1.0695 - classification_loss: 0.2326
 640/1000 [==================>...........] - ETA: 1:43 - loss: 1.3011 - regression_loss: 1.0685 - classification_loss: 0.2326
 641/1000 [==================>...........] - ETA: 1:43 - loss: 1.3012 - regression_loss: 1.0688 - classification_loss: 0.2324
 642/1000 [==================>...........] - ETA: 1:42 - loss: 1.3028 - regression_loss: 1.0700 - classification_loss: 0.2328
 643/1000 [==================>...........] - ETA: 1:42 - loss: 1.3038 - regression_loss: 1.0711 - classification_loss: 0.2327
 644/1000 [==================>...........] - ETA: 1:42 - loss: 1.3038 - regression_loss: 1.0711 - classification_loss: 0.2327
 645/1000 [==================>...........] - ETA: 1:41 - loss: 1.3040 - regression_loss: 1.0713 - classification_loss: 0.2327
 646/1000 [==================>...........] - ETA: 1:41 - loss: 1.3036 - regression_loss: 1.0711 - classification_loss: 0.2325
 647/1000 [==================>...........] - ETA: 1:41 - loss: 1.3054 - regression_loss: 1.0724 - classification_loss: 0.2330
 648/1000 [==================>...........] - ETA: 1:41 - loss: 1.3064 - regression_loss: 1.0731 - classification_loss: 0.2333
 649/1000 [==================>...........] - ETA: 1:40 - loss: 1.3068 - regression_loss: 1.0735 - classification_loss: 0.2333
 650/1000 [==================>...........] - ETA: 1:40 - loss: 1.3066 - regression_loss: 1.0733 - classification_loss: 0.2333
 651/1000 [==================>...........] - ETA: 1:40 - loss: 1.3066 - regression_loss: 1.0734 - classification_loss: 0.2332
 652/1000 [==================>...........] - ETA: 1:39 - loss: 1.3058 - regression_loss: 1.0728 - classification_loss: 0.2330
 653/1000 [==================>...........] - ETA: 1:39 - loss: 1.3061 - regression_loss: 1.0732 - classification_loss: 0.2329
 654/1000 [==================>...........] - ETA: 1:39 - loss: 1.3072 - regression_loss: 1.0741 - classification_loss: 0.2331
 655/1000 [==================>...........] - ETA: 1:39 - loss: 1.3090 - regression_loss: 1.0754 - classification_loss: 0.2336
 656/1000 [==================>...........] - ETA: 1:38 - loss: 1.3079 - regression_loss: 1.0745 - classification_loss: 0.2334
 657/1000 [==================>...........] - ETA: 1:38 - loss: 1.3075 - regression_loss: 1.0741 - classification_loss: 0.2335
 658/1000 [==================>...........] - ETA: 1:38 - loss: 1.3073 - regression_loss: 1.0739 - classification_loss: 0.2334
 659/1000 [==================>...........] - ETA: 1:37 - loss: 1.3069 - regression_loss: 1.0736 - classification_loss: 0.2332
 660/1000 [==================>...........] - ETA: 1:37 - loss: 1.3068 - regression_loss: 1.0737 - classification_loss: 0.2331
 661/1000 [==================>...........] - ETA: 1:37 - loss: 1.3063 - regression_loss: 1.0733 - classification_loss: 0.2329
 662/1000 [==================>...........] - ETA: 1:37 - loss: 1.3066 - regression_loss: 1.0734 - classification_loss: 0.2331
 663/1000 [==================>...........] - ETA: 1:36 - loss: 1.3067 - regression_loss: 1.0736 - classification_loss: 0.2332
 664/1000 [==================>...........] - ETA: 1:36 - loss: 1.3068 - regression_loss: 1.0736 - classification_loss: 0.2332
 665/1000 [==================>...........] - ETA: 1:36 - loss: 1.3067 - regression_loss: 1.0735 - classification_loss: 0.2332
 666/1000 [==================>...........] - ETA: 1:35 - loss: 1.3057 - regression_loss: 1.0726 - classification_loss: 0.2330
 667/1000 [===================>..........] - ETA: 1:35 - loss: 1.3059 - regression_loss: 1.0728 - classification_loss: 0.2330
 668/1000 [===================>..........] - ETA: 1:35 - loss: 1.3053 - regression_loss: 1.0724 - classification_loss: 0.2329
 669/1000 [===================>..........] - ETA: 1:35 - loss: 1.3059 - regression_loss: 1.0729 - classification_loss: 0.2330
 670/1000 [===================>..........] - ETA: 1:34 - loss: 1.3059 - regression_loss: 1.0729 - classification_loss: 0.2330
 671/1000 [===================>..........] - ETA: 1:34 - loss: 1.3057 - regression_loss: 1.0728 - classification_loss: 0.2330
 672/1000 [===================>..........] - ETA: 1:34 - loss: 1.3057 - regression_loss: 1.0727 - classification_loss: 0.2330
 673/1000 [===================>..........] - ETA: 1:33 - loss: 1.3056 - regression_loss: 1.0727 - classification_loss: 0.2329
 674/1000 [===================>..........] - ETA: 1:33 - loss: 1.3050 - regression_loss: 1.0723 - classification_loss: 0.2327
 675/1000 [===================>..........] - ETA: 1:33 - loss: 1.3051 - regression_loss: 1.0722 - classification_loss: 0.2329
 676/1000 [===================>..........] - ETA: 1:32 - loss: 1.3039 - regression_loss: 1.0712 - classification_loss: 0.2327
 677/1000 [===================>..........] - ETA: 1:32 - loss: 1.3044 - regression_loss: 1.0716 - classification_loss: 0.2328
 678/1000 [===================>..........] - ETA: 1:32 - loss: 1.3046 - regression_loss: 1.0719 - classification_loss: 0.2327
 679/1000 [===================>..........] - ETA: 1:32 - loss: 1.3051 - regression_loss: 1.0725 - classification_loss: 0.2326
 680/1000 [===================>..........] - ETA: 1:31 - loss: 1.3056 - regression_loss: 1.0730 - classification_loss: 0.2326
 681/1000 [===================>..........] - ETA: 1:31 - loss: 1.3057 - regression_loss: 1.0733 - classification_loss: 0.2325
 682/1000 [===================>..........] - ETA: 1:31 - loss: 1.3069 - regression_loss: 1.0741 - classification_loss: 0.2327
 683/1000 [===================>..........] - ETA: 1:30 - loss: 1.3090 - regression_loss: 1.0757 - classification_loss: 0.2333
 684/1000 [===================>..........] - ETA: 1:30 - loss: 1.3088 - regression_loss: 1.0755 - classification_loss: 0.2332
 685/1000 [===================>..........] - ETA: 1:30 - loss: 1.3079 - regression_loss: 1.0748 - classification_loss: 0.2331
 686/1000 [===================>..........] - ETA: 1:30 - loss: 1.3068 - regression_loss: 1.0739 - classification_loss: 0.2328
 687/1000 [===================>..........] - ETA: 1:29 - loss: 1.3069 - regression_loss: 1.0741 - classification_loss: 0.2328
 688/1000 [===================>..........] - ETA: 1:29 - loss: 1.3065 - regression_loss: 1.0737 - classification_loss: 0.2328
 689/1000 [===================>..........] - ETA: 1:29 - loss: 1.3065 - regression_loss: 1.0736 - classification_loss: 0.2329
 690/1000 [===================>..........] - ETA: 1:28 - loss: 1.3068 - regression_loss: 1.0737 - classification_loss: 0.2331
 691/1000 [===================>..........] - ETA: 1:28 - loss: 1.3070 - regression_loss: 1.0739 - classification_loss: 0.2331
 692/1000 [===================>..........] - ETA: 1:28 - loss: 1.3066 - regression_loss: 1.0737 - classification_loss: 0.2329
 693/1000 [===================>..........] - ETA: 1:28 - loss: 1.3065 - regression_loss: 1.0736 - classification_loss: 0.2329
 694/1000 [===================>..........] - ETA: 1:27 - loss: 1.3072 - regression_loss: 1.0742 - classification_loss: 0.2330
 695/1000 [===================>..........] - ETA: 1:27 - loss: 1.3071 - regression_loss: 1.0742 - classification_loss: 0.2329
 696/1000 [===================>..........] - ETA: 1:27 - loss: 1.3083 - regression_loss: 1.0753 - classification_loss: 0.2330
 697/1000 [===================>..........] - ETA: 1:26 - loss: 1.3073 - regression_loss: 1.0745 - classification_loss: 0.2328
 698/1000 [===================>..........] - ETA: 1:26 - loss: 1.3072 - regression_loss: 1.0745 - classification_loss: 0.2327
 699/1000 [===================>..........] - ETA: 1:26 - loss: 1.3070 - regression_loss: 1.0743 - classification_loss: 0.2328
 700/1000 [====================>.........] - ETA: 1:26 - loss: 1.3070 - regression_loss: 1.0743 - classification_loss: 0.2326
 701/1000 [====================>.........] - ETA: 1:25 - loss: 1.3077 - regression_loss: 1.0749 - classification_loss: 0.2329
 702/1000 [====================>.........] - ETA: 1:25 - loss: 1.3077 - regression_loss: 1.0748 - classification_loss: 0.2330
 703/1000 [====================>.........] - ETA: 1:25 - loss: 1.3091 - regression_loss: 1.0759 - classification_loss: 0.2332
 704/1000 [====================>.........] - ETA: 1:24 - loss: 1.3095 - regression_loss: 1.0762 - classification_loss: 0.2333
 705/1000 [====================>.........] - ETA: 1:24 - loss: 1.3095 - regression_loss: 1.0763 - classification_loss: 0.2333
 706/1000 [====================>.........] - ETA: 1:24 - loss: 1.3086 - regression_loss: 1.0756 - classification_loss: 0.2330
 707/1000 [====================>.........] - ETA: 1:24 - loss: 1.3083 - regression_loss: 1.0755 - classification_loss: 0.2329
 708/1000 [====================>.........] - ETA: 1:23 - loss: 1.3075 - regression_loss: 1.0745 - classification_loss: 0.2331
 709/1000 [====================>.........] - ETA: 1:23 - loss: 1.3065 - regression_loss: 1.0736 - classification_loss: 0.2329
 710/1000 [====================>.........] - ETA: 1:23 - loss: 1.3062 - regression_loss: 1.0735 - classification_loss: 0.2327
 711/1000 [====================>.........] - ETA: 1:22 - loss: 1.3053 - regression_loss: 1.0727 - classification_loss: 0.2325
 712/1000 [====================>.........] - ETA: 1:22 - loss: 1.3046 - regression_loss: 1.0722 - classification_loss: 0.2323
 713/1000 [====================>.........] - ETA: 1:22 - loss: 1.3049 - regression_loss: 1.0725 - classification_loss: 0.2324
 714/1000 [====================>.........] - ETA: 1:22 - loss: 1.3046 - regression_loss: 1.0721 - classification_loss: 0.2325
 715/1000 [====================>.........] - ETA: 1:21 - loss: 1.3042 - regression_loss: 1.0717 - classification_loss: 0.2325
 716/1000 [====================>.........] - ETA: 1:21 - loss: 1.3042 - regression_loss: 1.0717 - classification_loss: 0.2325
 717/1000 [====================>.........] - ETA: 1:21 - loss: 1.3042 - regression_loss: 1.0718 - classification_loss: 0.2324
 718/1000 [====================>.........] - ETA: 1:20 - loss: 1.3031 - regression_loss: 1.0709 - classification_loss: 0.2322
 719/1000 [====================>.........] - ETA: 1:20 - loss: 1.3022 - regression_loss: 1.0702 - classification_loss: 0.2321
 720/1000 [====================>.........] - ETA: 1:20 - loss: 1.3020 - regression_loss: 1.0701 - classification_loss: 0.2319
 721/1000 [====================>.........] - ETA: 1:20 - loss: 1.3031 - regression_loss: 1.0713 - classification_loss: 0.2318
 722/1000 [====================>.........] - ETA: 1:19 - loss: 1.3027 - regression_loss: 1.0707 - classification_loss: 0.2320
 723/1000 [====================>.........] - ETA: 1:19 - loss: 1.3018 - regression_loss: 1.0699 - classification_loss: 0.2319
 724/1000 [====================>.........] - ETA: 1:19 - loss: 1.3015 - regression_loss: 1.0697 - classification_loss: 0.2318
 725/1000 [====================>.........] - ETA: 1:18 - loss: 1.3007 - regression_loss: 1.0692 - classification_loss: 0.2316
 726/1000 [====================>.........] - ETA: 1:18 - loss: 1.3000 - regression_loss: 1.0685 - classification_loss: 0.2315
 727/1000 [====================>.........] - ETA: 1:18 - loss: 1.3006 - regression_loss: 1.0691 - classification_loss: 0.2314
 728/1000 [====================>.........] - ETA: 1:18 - loss: 1.3013 - regression_loss: 1.0697 - classification_loss: 0.2316
 729/1000 [====================>.........] - ETA: 1:17 - loss: 1.3013 - regression_loss: 1.0697 - classification_loss: 0.2316
 730/1000 [====================>.........] - ETA: 1:17 - loss: 1.3013 - regression_loss: 1.0697 - classification_loss: 0.2316
 731/1000 [====================>.........] - ETA: 1:17 - loss: 1.3009 - regression_loss: 1.0693 - classification_loss: 0.2316
 732/1000 [====================>.........] - ETA: 1:16 - loss: 1.3003 - regression_loss: 1.0688 - classification_loss: 0.2315
 733/1000 [====================>.........] - ETA: 1:16 - loss: 1.3005 - regression_loss: 1.0690 - classification_loss: 0.2315
 734/1000 [=====================>........] - ETA: 1:16 - loss: 1.3003 - regression_loss: 1.0689 - classification_loss: 0.2315
 735/1000 [=====================>........] - ETA: 1:16 - loss: 1.2996 - regression_loss: 1.0683 - classification_loss: 0.2313
 736/1000 [=====================>........] - ETA: 1:15 - loss: 1.2990 - regression_loss: 1.0678 - classification_loss: 0.2312
 737/1000 [=====================>........] - ETA: 1:15 - loss: 1.2989 - regression_loss: 1.0678 - classification_loss: 0.2311
 738/1000 [=====================>........] - ETA: 1:15 - loss: 1.2999 - regression_loss: 1.0686 - classification_loss: 0.2313
 739/1000 [=====================>........] - ETA: 1:14 - loss: 1.2992 - regression_loss: 1.0681 - classification_loss: 0.2312
 740/1000 [=====================>........] - ETA: 1:14 - loss: 1.2993 - regression_loss: 1.0680 - classification_loss: 0.2313
 741/1000 [=====================>........] - ETA: 1:14 - loss: 1.2993 - regression_loss: 1.0681 - classification_loss: 0.2312
 742/1000 [=====================>........] - ETA: 1:14 - loss: 1.3014 - regression_loss: 1.0693 - classification_loss: 0.2321
 743/1000 [=====================>........] - ETA: 1:13 - loss: 1.3010 - regression_loss: 1.0690 - classification_loss: 0.2320
 744/1000 [=====================>........] - ETA: 1:13 - loss: 1.3007 - regression_loss: 1.0688 - classification_loss: 0.2319
 745/1000 [=====================>........] - ETA: 1:13 - loss: 1.3006 - regression_loss: 1.0688 - classification_loss: 0.2318
 746/1000 [=====================>........] - ETA: 1:12 - loss: 1.3013 - regression_loss: 1.0694 - classification_loss: 0.2319
 747/1000 [=====================>........] - ETA: 1:12 - loss: 1.3009 - regression_loss: 1.0692 - classification_loss: 0.2317
 748/1000 [=====================>........] - ETA: 1:12 - loss: 1.3002 - regression_loss: 1.0685 - classification_loss: 0.2317
 749/1000 [=====================>........] - ETA: 1:12 - loss: 1.2991 - regression_loss: 1.0676 - classification_loss: 0.2315
 750/1000 [=====================>........] - ETA: 1:11 - loss: 1.2986 - regression_loss: 1.0672 - classification_loss: 0.2314
 751/1000 [=====================>........] - ETA: 1:11 - loss: 1.2985 - regression_loss: 1.0671 - classification_loss: 0.2314
 752/1000 [=====================>........] - ETA: 1:11 - loss: 1.2992 - regression_loss: 1.0678 - classification_loss: 0.2315
 753/1000 [=====================>........] - ETA: 1:10 - loss: 1.3005 - regression_loss: 1.0687 - classification_loss: 0.2317
 754/1000 [=====================>........] - ETA: 1:10 - loss: 1.3004 - regression_loss: 1.0688 - classification_loss: 0.2317
 755/1000 [=====================>........] - ETA: 1:10 - loss: 1.2998 - regression_loss: 1.0683 - classification_loss: 0.2315
 756/1000 [=====================>........] - ETA: 1:09 - loss: 1.2989 - regression_loss: 1.0675 - classification_loss: 0.2314
 757/1000 [=====================>........] - ETA: 1:09 - loss: 1.2982 - regression_loss: 1.0669 - classification_loss: 0.2313
 758/1000 [=====================>........] - ETA: 1:09 - loss: 1.2974 - regression_loss: 1.0662 - classification_loss: 0.2312
 759/1000 [=====================>........] - ETA: 1:09 - loss: 1.2978 - regression_loss: 1.0666 - classification_loss: 0.2312
 760/1000 [=====================>........] - ETA: 1:08 - loss: 1.2971 - regression_loss: 1.0660 - classification_loss: 0.2311
 761/1000 [=====================>........] - ETA: 1:08 - loss: 1.2976 - regression_loss: 1.0663 - classification_loss: 0.2313
 762/1000 [=====================>........] - ETA: 1:08 - loss: 1.2979 - regression_loss: 1.0665 - classification_loss: 0.2314
 763/1000 [=====================>........] - ETA: 1:07 - loss: 1.2981 - regression_loss: 1.0664 - classification_loss: 0.2318
 764/1000 [=====================>........] - ETA: 1:07 - loss: 1.2986 - regression_loss: 1.0667 - classification_loss: 0.2319
 765/1000 [=====================>........] - ETA: 1:07 - loss: 1.2990 - regression_loss: 1.0669 - classification_loss: 0.2321
 766/1000 [=====================>........] - ETA: 1:07 - loss: 1.2996 - regression_loss: 1.0676 - classification_loss: 0.2320
 767/1000 [======================>.......] - ETA: 1:06 - loss: 1.2990 - regression_loss: 1.0672 - classification_loss: 0.2318
 768/1000 [======================>.......] - ETA: 1:06 - loss: 1.2997 - regression_loss: 1.0677 - classification_loss: 0.2320
 769/1000 [======================>.......] - ETA: 1:06 - loss: 1.2997 - regression_loss: 1.0676 - classification_loss: 0.2321
 770/1000 [======================>.......] - ETA: 1:05 - loss: 1.3004 - regression_loss: 1.0682 - classification_loss: 0.2322
 771/1000 [======================>.......] - ETA: 1:05 - loss: 1.2998 - regression_loss: 1.0677 - classification_loss: 0.2321
 772/1000 [======================>.......] - ETA: 1:05 - loss: 1.2995 - regression_loss: 1.0676 - classification_loss: 0.2319
 773/1000 [======================>.......] - ETA: 1:05 - loss: 1.3000 - regression_loss: 1.0682 - classification_loss: 0.2319
 774/1000 [======================>.......] - ETA: 1:04 - loss: 1.2994 - regression_loss: 1.0677 - classification_loss: 0.2317
 775/1000 [======================>.......] - ETA: 1:04 - loss: 1.2991 - regression_loss: 1.0675 - classification_loss: 0.2317
 776/1000 [======================>.......] - ETA: 1:04 - loss: 1.2987 - regression_loss: 1.0671 - classification_loss: 0.2315
 777/1000 [======================>.......] - ETA: 1:03 - loss: 1.2986 - regression_loss: 1.0668 - classification_loss: 0.2318
 778/1000 [======================>.......] - ETA: 1:03 - loss: 1.2980 - regression_loss: 1.0664 - classification_loss: 0.2316
 779/1000 [======================>.......] - ETA: 1:03 - loss: 1.2980 - regression_loss: 1.0664 - classification_loss: 0.2316
 780/1000 [======================>.......] - ETA: 1:03 - loss: 1.2978 - regression_loss: 1.0662 - classification_loss: 0.2316
 781/1000 [======================>.......] - ETA: 1:02 - loss: 1.2994 - regression_loss: 1.0672 - classification_loss: 0.2321
 782/1000 [======================>.......] - ETA: 1:02 - loss: 1.2998 - regression_loss: 1.0677 - classification_loss: 0.2322
 783/1000 [======================>.......] - ETA: 1:02 - loss: 1.2995 - regression_loss: 1.0674 - classification_loss: 0.2322
 784/1000 [======================>.......] - ETA: 1:01 - loss: 1.3000 - regression_loss: 1.0678 - classification_loss: 0.2322
 785/1000 [======================>.......] - ETA: 1:01 - loss: 1.3001 - regression_loss: 1.0679 - classification_loss: 0.2322
 786/1000 [======================>.......] - ETA: 1:01 - loss: 1.2994 - regression_loss: 1.0673 - classification_loss: 0.2321
 787/1000 [======================>.......] - ETA: 1:01 - loss: 1.3010 - regression_loss: 1.0683 - classification_loss: 0.2327
 788/1000 [======================>.......] - ETA: 1:00 - loss: 1.3016 - regression_loss: 1.0686 - classification_loss: 0.2330
 789/1000 [======================>.......] - ETA: 1:00 - loss: 1.3006 - regression_loss: 1.0677 - classification_loss: 0.2329
 790/1000 [======================>.......] - ETA: 1:00 - loss: 1.3017 - regression_loss: 1.0688 - classification_loss: 0.2329
 791/1000 [======================>.......] - ETA: 59s - loss: 1.3008 - regression_loss: 1.0681 - classification_loss: 0.2327 
 792/1000 [======================>.......] - ETA: 59s - loss: 1.3004 - regression_loss: 1.0677 - classification_loss: 0.2327
 793/1000 [======================>.......] - ETA: 59s - loss: 1.3000 - regression_loss: 1.0675 - classification_loss: 0.2325
 794/1000 [======================>.......] - ETA: 59s - loss: 1.3009 - regression_loss: 1.0684 - classification_loss: 0.2325
 795/1000 [======================>.......] - ETA: 58s - loss: 1.3009 - regression_loss: 1.0684 - classification_loss: 0.2324
 796/1000 [======================>.......] - ETA: 58s - loss: 1.3001 - regression_loss: 1.0678 - classification_loss: 0.2323
 797/1000 [======================>.......] - ETA: 58s - loss: 1.2994 - regression_loss: 1.0672 - classification_loss: 0.2322
 798/1000 [======================>.......] - ETA: 57s - loss: 1.2986 - regression_loss: 1.0666 - classification_loss: 0.2320
 799/1000 [======================>.......] - ETA: 57s - loss: 1.2979 - regression_loss: 1.0661 - classification_loss: 0.2318
 800/1000 [=======================>......] - ETA: 57s - loss: 1.2973 - regression_loss: 1.0657 - classification_loss: 0.2316
 801/1000 [=======================>......] - ETA: 57s - loss: 1.2976 - regression_loss: 1.0660 - classification_loss: 0.2316
 802/1000 [=======================>......] - ETA: 56s - loss: 1.2969 - regression_loss: 1.0655 - classification_loss: 0.2314
 803/1000 [=======================>......] - ETA: 56s - loss: 1.2962 - regression_loss: 1.0649 - classification_loss: 0.2313
 804/1000 [=======================>......] - ETA: 56s - loss: 1.2955 - regression_loss: 1.0645 - classification_loss: 0.2311
 805/1000 [=======================>......] - ETA: 55s - loss: 1.2947 - regression_loss: 1.0638 - classification_loss: 0.2309
 806/1000 [=======================>......] - ETA: 55s - loss: 1.2949 - regression_loss: 1.0640 - classification_loss: 0.2310
 807/1000 [=======================>......] - ETA: 55s - loss: 1.2945 - regression_loss: 1.0637 - classification_loss: 0.2308
 808/1000 [=======================>......] - ETA: 55s - loss: 1.2935 - regression_loss: 1.0629 - classification_loss: 0.2306
 809/1000 [=======================>......] - ETA: 54s - loss: 1.2939 - regression_loss: 1.0633 - classification_loss: 0.2306
 810/1000 [=======================>......] - ETA: 54s - loss: 1.2941 - regression_loss: 1.0635 - classification_loss: 0.2305
 811/1000 [=======================>......] - ETA: 54s - loss: 1.2932 - regression_loss: 1.0629 - classification_loss: 0.2303
 812/1000 [=======================>......] - ETA: 53s - loss: 1.2928 - regression_loss: 1.0623 - classification_loss: 0.2305
 813/1000 [=======================>......] - ETA: 53s - loss: 1.2919 - regression_loss: 1.0615 - classification_loss: 0.2304
 814/1000 [=======================>......] - ETA: 53s - loss: 1.2916 - regression_loss: 1.0613 - classification_loss: 0.2303
 815/1000 [=======================>......] - ETA: 53s - loss: 1.2918 - regression_loss: 1.0615 - classification_loss: 0.2303
 816/1000 [=======================>......] - ETA: 52s - loss: 1.2911 - regression_loss: 1.0610 - classification_loss: 0.2302
 817/1000 [=======================>......] - ETA: 52s - loss: 1.2909 - regression_loss: 1.0608 - classification_loss: 0.2301
 818/1000 [=======================>......] - ETA: 52s - loss: 1.2915 - regression_loss: 1.0613 - classification_loss: 0.2302
 819/1000 [=======================>......] - ETA: 51s - loss: 1.2918 - regression_loss: 1.0615 - classification_loss: 0.2303
 820/1000 [=======================>......] - ETA: 51s - loss: 1.2921 - regression_loss: 1.0618 - classification_loss: 0.2303
 821/1000 [=======================>......] - ETA: 51s - loss: 1.2935 - regression_loss: 1.0631 - classification_loss: 0.2304
 822/1000 [=======================>......] - ETA: 51s - loss: 1.2930 - regression_loss: 1.0627 - classification_loss: 0.2303
 823/1000 [=======================>......] - ETA: 50s - loss: 1.2936 - regression_loss: 1.0633 - classification_loss: 0.2303
 824/1000 [=======================>......] - ETA: 50s - loss: 1.2934 - regression_loss: 1.0632 - classification_loss: 0.2302
 825/1000 [=======================>......] - ETA: 50s - loss: 1.2928 - regression_loss: 1.0627 - classification_loss: 0.2302
 826/1000 [=======================>......] - ETA: 49s - loss: 1.2923 - regression_loss: 1.0623 - classification_loss: 0.2300
 827/1000 [=======================>......] - ETA: 49s - loss: 1.2916 - regression_loss: 1.0617 - classification_loss: 0.2299
 828/1000 [=======================>......] - ETA: 49s - loss: 1.2926 - regression_loss: 1.0625 - classification_loss: 0.2301
 829/1000 [=======================>......] - ETA: 49s - loss: 1.2920 - regression_loss: 1.0621 - classification_loss: 0.2299
 830/1000 [=======================>......] - ETA: 48s - loss: 1.2913 - regression_loss: 1.0615 - classification_loss: 0.2298
 831/1000 [=======================>......] - ETA: 48s - loss: 1.2905 - regression_loss: 1.0608 - classification_loss: 0.2297
 832/1000 [=======================>......] - ETA: 48s - loss: 1.2909 - regression_loss: 1.0612 - classification_loss: 0.2298
 833/1000 [=======================>......] - ETA: 47s - loss: 1.2916 - regression_loss: 1.0617 - classification_loss: 0.2299
 834/1000 [========================>.....] - ETA: 47s - loss: 1.2927 - regression_loss: 1.0625 - classification_loss: 0.2302
 835/1000 [========================>.....] - ETA: 47s - loss: 1.2935 - regression_loss: 1.0632 - classification_loss: 0.2303
 836/1000 [========================>.....] - ETA: 47s - loss: 1.2935 - regression_loss: 1.0633 - classification_loss: 0.2302
 837/1000 [========================>.....] - ETA: 46s - loss: 1.2927 - regression_loss: 1.0626 - classification_loss: 0.2301
 838/1000 [========================>.....] - ETA: 46s - loss: 1.2918 - regression_loss: 1.0620 - classification_loss: 0.2299
 839/1000 [========================>.....] - ETA: 46s - loss: 1.2911 - regression_loss: 1.0614 - classification_loss: 0.2297
 840/1000 [========================>.....] - ETA: 45s - loss: 1.2930 - regression_loss: 1.0632 - classification_loss: 0.2298
 841/1000 [========================>.....] - ETA: 45s - loss: 1.2929 - regression_loss: 1.0630 - classification_loss: 0.2299
 842/1000 [========================>.....] - ETA: 45s - loss: 1.2924 - regression_loss: 1.0627 - classification_loss: 0.2298
 843/1000 [========================>.....] - ETA: 45s - loss: 1.2925 - regression_loss: 1.0628 - classification_loss: 0.2297
 844/1000 [========================>.....] - ETA: 44s - loss: 1.2920 - regression_loss: 1.0625 - classification_loss: 0.2296
 845/1000 [========================>.....] - ETA: 44s - loss: 1.2910 - regression_loss: 1.0617 - classification_loss: 0.2294
 846/1000 [========================>.....] - ETA: 44s - loss: 1.2909 - regression_loss: 1.0615 - classification_loss: 0.2294
 847/1000 [========================>.....] - ETA: 43s - loss: 1.2903 - regression_loss: 1.0610 - classification_loss: 0.2292
 848/1000 [========================>.....] - ETA: 43s - loss: 1.2911 - regression_loss: 1.0617 - classification_loss: 0.2294
 849/1000 [========================>.....] - ETA: 43s - loss: 1.2903 - regression_loss: 1.0611 - classification_loss: 0.2292
 850/1000 [========================>.....] - ETA: 43s - loss: 1.2896 - regression_loss: 1.0604 - classification_loss: 0.2292
 851/1000 [========================>.....] - ETA: 42s - loss: 1.2897 - regression_loss: 1.0604 - classification_loss: 0.2293
 852/1000 [========================>.....] - ETA: 42s - loss: 1.2894 - regression_loss: 1.0602 - classification_loss: 0.2292
 853/1000 [========================>.....] - ETA: 42s - loss: 1.2898 - regression_loss: 1.0605 - classification_loss: 0.2292
 854/1000 [========================>.....] - ETA: 41s - loss: 1.2898 - regression_loss: 1.0606 - classification_loss: 0.2292
 855/1000 [========================>.....] - ETA: 41s - loss: 1.2900 - regression_loss: 1.0607 - classification_loss: 0.2293
 856/1000 [========================>.....] - ETA: 41s - loss: 1.2912 - regression_loss: 1.0615 - classification_loss: 0.2297
 857/1000 [========================>.....] - ETA: 41s - loss: 1.2927 - regression_loss: 1.0625 - classification_loss: 0.2303
 858/1000 [========================>.....] - ETA: 40s - loss: 1.2920 - regression_loss: 1.0618 - classification_loss: 0.2302
 859/1000 [========================>.....] - ETA: 40s - loss: 1.2914 - regression_loss: 1.0614 - classification_loss: 0.2300
 860/1000 [========================>.....] - ETA: 40s - loss: 1.2908 - regression_loss: 1.0607 - classification_loss: 0.2301
 861/1000 [========================>.....] - ETA: 39s - loss: 1.2912 - regression_loss: 1.0610 - classification_loss: 0.2302
 862/1000 [========================>.....] - ETA: 39s - loss: 1.2916 - regression_loss: 1.0615 - classification_loss: 0.2301
 863/1000 [========================>.....] - ETA: 39s - loss: 1.2915 - regression_loss: 1.0615 - classification_loss: 0.2300
 864/1000 [========================>.....] - ETA: 39s - loss: 1.2909 - regression_loss: 1.0609 - classification_loss: 0.2300
 865/1000 [========================>.....] - ETA: 38s - loss: 1.2904 - regression_loss: 1.0606 - classification_loss: 0.2299
 866/1000 [========================>.....] - ETA: 38s - loss: 1.2977 - regression_loss: 1.0607 - classification_loss: 0.2370
 867/1000 [=========================>....] - ETA: 38s - loss: 1.2967 - regression_loss: 1.0599 - classification_loss: 0.2369
 868/1000 [=========================>....] - ETA: 37s - loss: 1.2970 - regression_loss: 1.0601 - classification_loss: 0.2369
 869/1000 [=========================>....] - ETA: 37s - loss: 1.2964 - regression_loss: 1.0596 - classification_loss: 0.2368
 870/1000 [=========================>....] - ETA: 37s - loss: 1.2958 - regression_loss: 1.0591 - classification_loss: 0.2366
 871/1000 [=========================>....] - ETA: 36s - loss: 1.2969 - regression_loss: 1.0599 - classification_loss: 0.2369
 872/1000 [=========================>....] - ETA: 36s - loss: 1.2971 - regression_loss: 1.0602 - classification_loss: 0.2368
 873/1000 [=========================>....] - ETA: 36s - loss: 1.2979 - regression_loss: 1.0609 - classification_loss: 0.2370
 874/1000 [=========================>....] - ETA: 36s - loss: 1.2979 - regression_loss: 1.0610 - classification_loss: 0.2369
 875/1000 [=========================>....] - ETA: 35s - loss: 1.2977 - regression_loss: 1.0609 - classification_loss: 0.2368
 876/1000 [=========================>....] - ETA: 35s - loss: 1.2967 - regression_loss: 1.0601 - classification_loss: 0.2366
 877/1000 [=========================>....] - ETA: 35s - loss: 1.2966 - regression_loss: 1.0600 - classification_loss: 0.2365
 878/1000 [=========================>....] - ETA: 34s - loss: 1.2958 - regression_loss: 1.0594 - classification_loss: 0.2364
 879/1000 [=========================>....] - ETA: 34s - loss: 1.2961 - regression_loss: 1.0597 - classification_loss: 0.2364
 880/1000 [=========================>....] - ETA: 34s - loss: 1.2954 - regression_loss: 1.0591 - classification_loss: 0.2363
 881/1000 [=========================>....] - ETA: 34s - loss: 1.2966 - regression_loss: 1.0599 - classification_loss: 0.2367
 882/1000 [=========================>....] - ETA: 33s - loss: 1.2964 - regression_loss: 1.0599 - classification_loss: 0.2365
 883/1000 [=========================>....] - ETA: 33s - loss: 1.2955 - regression_loss: 1.0592 - classification_loss: 0.2364
 884/1000 [=========================>....] - ETA: 33s - loss: 1.2952 - regression_loss: 1.0589 - classification_loss: 0.2362
 885/1000 [=========================>....] - ETA: 32s - loss: 1.2960 - regression_loss: 1.0595 - classification_loss: 0.2365
 886/1000 [=========================>....] - ETA: 32s - loss: 1.2952 - regression_loss: 1.0589 - classification_loss: 0.2364
 887/1000 [=========================>....] - ETA: 32s - loss: 1.2964 - regression_loss: 1.0593 - classification_loss: 0.2371
 888/1000 [=========================>....] - ETA: 32s - loss: 1.2973 - regression_loss: 1.0601 - classification_loss: 0.2372
 889/1000 [=========================>....] - ETA: 31s - loss: 1.2969 - regression_loss: 1.0599 - classification_loss: 0.2370
 890/1000 [=========================>....] - ETA: 31s - loss: 1.2964 - regression_loss: 1.0595 - classification_loss: 0.2369
 891/1000 [=========================>....] - ETA: 31s - loss: 1.2967 - regression_loss: 1.0597 - classification_loss: 0.2370
 892/1000 [=========================>....] - ETA: 30s - loss: 1.2978 - regression_loss: 1.0606 - classification_loss: 0.2372
 893/1000 [=========================>....] - ETA: 30s - loss: 1.2982 - regression_loss: 1.0609 - classification_loss: 0.2373
 894/1000 [=========================>....] - ETA: 30s - loss: 1.2978 - regression_loss: 1.0605 - classification_loss: 0.2373
 895/1000 [=========================>....] - ETA: 30s - loss: 1.2976 - regression_loss: 1.0604 - classification_loss: 0.2372
 896/1000 [=========================>....] - ETA: 29s - loss: 1.2972 - regression_loss: 1.0601 - classification_loss: 0.2371
 897/1000 [=========================>....] - ETA: 29s - loss: 1.2971 - regression_loss: 1.0601 - classification_loss: 0.2370
 898/1000 [=========================>....] - ETA: 29s - loss: 1.2967 - regression_loss: 1.0598 - classification_loss: 0.2370
 899/1000 [=========================>....] - ETA: 28s - loss: 1.2971 - regression_loss: 1.0602 - classification_loss: 0.2369
 900/1000 [==========================>...] - ETA: 28s - loss: 1.2969 - regression_loss: 1.0601 - classification_loss: 0.2368
 901/1000 [==========================>...] - ETA: 28s - loss: 1.2985 - regression_loss: 1.0612 - classification_loss: 0.2372
 902/1000 [==========================>...] - ETA: 28s - loss: 1.2987 - regression_loss: 1.0615 - classification_loss: 0.2372
 903/1000 [==========================>...] - ETA: 27s - loss: 1.2979 - regression_loss: 1.0610 - classification_loss: 0.2370
 904/1000 [==========================>...] - ETA: 27s - loss: 1.2981 - regression_loss: 1.0608 - classification_loss: 0.2373
 905/1000 [==========================>...] - ETA: 27s - loss: 1.2977 - regression_loss: 1.0605 - classification_loss: 0.2372
 906/1000 [==========================>...] - ETA: 26s - loss: 1.2976 - regression_loss: 1.0604 - classification_loss: 0.2372
 907/1000 [==========================>...] - ETA: 26s - loss: 1.2967 - regression_loss: 1.0597 - classification_loss: 0.2370
 908/1000 [==========================>...] - ETA: 26s - loss: 1.2963 - regression_loss: 1.0594 - classification_loss: 0.2369
 909/1000 [==========================>...] - ETA: 26s - loss: 1.2971 - regression_loss: 1.0603 - classification_loss: 0.2369
 910/1000 [==========================>...] - ETA: 25s - loss: 1.2977 - regression_loss: 1.0607 - classification_loss: 0.2370
 911/1000 [==========================>...] - ETA: 25s - loss: 1.2972 - regression_loss: 1.0603 - classification_loss: 0.2369
 912/1000 [==========================>...] - ETA: 25s - loss: 1.2981 - regression_loss: 1.0611 - classification_loss: 0.2370
 913/1000 [==========================>...] - ETA: 24s - loss: 1.2976 - regression_loss: 1.0607 - classification_loss: 0.2369
 914/1000 [==========================>...] - ETA: 24s - loss: 1.2980 - regression_loss: 1.0611 - classification_loss: 0.2369
 915/1000 [==========================>...] - ETA: 24s - loss: 1.2977 - regression_loss: 1.0604 - classification_loss: 0.2374
 916/1000 [==========================>...] - ETA: 24s - loss: 1.2974 - regression_loss: 1.0602 - classification_loss: 0.2372
 917/1000 [==========================>...] - ETA: 23s - loss: 1.2971 - regression_loss: 1.0599 - classification_loss: 0.2372
 918/1000 [==========================>...] - ETA: 23s - loss: 1.2972 - regression_loss: 1.0600 - classification_loss: 0.2372
 919/1000 [==========================>...] - ETA: 23s - loss: 1.2968 - regression_loss: 1.0596 - classification_loss: 0.2371
 920/1000 [==========================>...] - ETA: 22s - loss: 1.2964 - regression_loss: 1.0593 - classification_loss: 0.2371
 921/1000 [==========================>...] - ETA: 22s - loss: 1.2958 - regression_loss: 1.0588 - classification_loss: 0.2370
 922/1000 [==========================>...] - ETA: 22s - loss: 1.2966 - regression_loss: 1.0593 - classification_loss: 0.2373
 923/1000 [==========================>...] - ETA: 22s - loss: 1.2961 - regression_loss: 1.0589 - classification_loss: 0.2372
 924/1000 [==========================>...] - ETA: 21s - loss: 1.2971 - regression_loss: 1.0595 - classification_loss: 0.2375
 925/1000 [==========================>...] - ETA: 21s - loss: 1.2970 - regression_loss: 1.0595 - classification_loss: 0.2375
 926/1000 [==========================>...] - ETA: 21s - loss: 1.2974 - regression_loss: 1.0598 - classification_loss: 0.2377
 927/1000 [==========================>...] - ETA: 20s - loss: 1.2974 - regression_loss: 1.0597 - classification_loss: 0.2377
 928/1000 [==========================>...] - ETA: 20s - loss: 1.2967 - regression_loss: 1.0592 - classification_loss: 0.2375
 929/1000 [==========================>...] - ETA: 20s - loss: 1.2971 - regression_loss: 1.0596 - classification_loss: 0.2375
 930/1000 [==========================>...] - ETA: 20s - loss: 1.2962 - regression_loss: 1.0588 - classification_loss: 0.2374
 931/1000 [==========================>...] - ETA: 19s - loss: 1.2955 - regression_loss: 1.0583 - classification_loss: 0.2373
 932/1000 [==========================>...] - ETA: 19s - loss: 1.2954 - regression_loss: 1.0581 - classification_loss: 0.2373
 933/1000 [==========================>...] - ETA: 19s - loss: 1.2951 - regression_loss: 1.0577 - classification_loss: 0.2374
 934/1000 [===========================>..] - ETA: 18s - loss: 1.2947 - regression_loss: 1.0574 - classification_loss: 0.2373
 935/1000 [===========================>..] - ETA: 18s - loss: 1.2944 - regression_loss: 1.0573 - classification_loss: 0.2371
 936/1000 [===========================>..] - ETA: 18s - loss: 1.2938 - regression_loss: 1.0568 - classification_loss: 0.2370
 937/1000 [===========================>..] - ETA: 18s - loss: 1.2941 - regression_loss: 1.0570 - classification_loss: 0.2370
 938/1000 [===========================>..] - ETA: 17s - loss: 1.2941 - regression_loss: 1.0570 - classification_loss: 0.2371
 939/1000 [===========================>..] - ETA: 17s - loss: 1.2936 - regression_loss: 1.0566 - classification_loss: 0.2370
 940/1000 [===========================>..] - ETA: 17s - loss: 1.2927 - regression_loss: 1.0559 - classification_loss: 0.2368
 941/1000 [===========================>..] - ETA: 16s - loss: 1.2926 - regression_loss: 1.0559 - classification_loss: 0.2367
 942/1000 [===========================>..] - ETA: 16s - loss: 1.2933 - regression_loss: 1.0563 - classification_loss: 0.2370
 943/1000 [===========================>..] - ETA: 16s - loss: 1.2932 - regression_loss: 1.0562 - classification_loss: 0.2370
 944/1000 [===========================>..] - ETA: 16s - loss: 1.2934 - regression_loss: 1.0565 - classification_loss: 0.2369
 945/1000 [===========================>..] - ETA: 15s - loss: 1.2925 - regression_loss: 1.0558 - classification_loss: 0.2367
 946/1000 [===========================>..] - ETA: 15s - loss: 1.2919 - regression_loss: 1.0552 - classification_loss: 0.2366
 947/1000 [===========================>..] - ETA: 15s - loss: 1.2915 - regression_loss: 1.0550 - classification_loss: 0.2365
 948/1000 [===========================>..] - ETA: 14s - loss: 1.2921 - regression_loss: 1.0555 - classification_loss: 0.2366
 949/1000 [===========================>..] - ETA: 14s - loss: 1.2935 - regression_loss: 1.0569 - classification_loss: 0.2366
 950/1000 [===========================>..] - ETA: 14s - loss: 1.2931 - regression_loss: 1.0565 - classification_loss: 0.2366
 951/1000 [===========================>..] - ETA: 14s - loss: 1.2932 - regression_loss: 1.0565 - classification_loss: 0.2366
 952/1000 [===========================>..] - ETA: 13s - loss: 1.2933 - regression_loss: 1.0567 - classification_loss: 0.2366
 953/1000 [===========================>..] - ETA: 13s - loss: 1.2934 - regression_loss: 1.0569 - classification_loss: 0.2365
 954/1000 [===========================>..] - ETA: 13s - loss: 1.2929 - regression_loss: 1.0565 - classification_loss: 0.2365
 955/1000 [===========================>..] - ETA: 12s - loss: 1.2929 - regression_loss: 1.0565 - classification_loss: 0.2365
 956/1000 [===========================>..] - ETA: 12s - loss: 1.2920 - regression_loss: 1.0556 - classification_loss: 0.2363
 957/1000 [===========================>..] - ETA: 12s - loss: 1.2916 - regression_loss: 1.0554 - classification_loss: 0.2361
 958/1000 [===========================>..] - ETA: 12s - loss: 1.2907 - regression_loss: 1.0548 - classification_loss: 0.2359
 959/1000 [===========================>..] - ETA: 11s - loss: 1.2915 - regression_loss: 1.0556 - classification_loss: 0.2359
 960/1000 [===========================>..] - ETA: 11s - loss: 1.2927 - regression_loss: 1.0562 - classification_loss: 0.2365
 961/1000 [===========================>..] - ETA: 11s - loss: 1.2925 - regression_loss: 1.0560 - classification_loss: 0.2365
 962/1000 [===========================>..] - ETA: 10s - loss: 1.2924 - regression_loss: 1.0560 - classification_loss: 0.2364
 963/1000 [===========================>..] - ETA: 10s - loss: 1.2922 - regression_loss: 1.0559 - classification_loss: 0.2362
 964/1000 [===========================>..] - ETA: 10s - loss: 1.2917 - regression_loss: 1.0556 - classification_loss: 0.2361
 965/1000 [===========================>..] - ETA: 10s - loss: 1.2918 - regression_loss: 1.0558 - classification_loss: 0.2361
 966/1000 [===========================>..] - ETA: 9s - loss: 1.2913 - regression_loss: 1.0554 - classification_loss: 0.2359 
 967/1000 [============================>.] - ETA: 9s - loss: 1.2910 - regression_loss: 1.0550 - classification_loss: 0.2359
 968/1000 [============================>.] - ETA: 9s - loss: 1.2905 - regression_loss: 1.0546 - classification_loss: 0.2359
 969/1000 [============================>.] - ETA: 8s - loss: 1.2900 - regression_loss: 1.0542 - classification_loss: 0.2358
 970/1000 [============================>.] - ETA: 8s - loss: 1.2895 - regression_loss: 1.0539 - classification_loss: 0.2357
 971/1000 [============================>.] - ETA: 8s - loss: 1.2890 - regression_loss: 1.0534 - classification_loss: 0.2355
 972/1000 [============================>.] - ETA: 8s - loss: 1.2890 - regression_loss: 1.0535 - classification_loss: 0.2354
 973/1000 [============================>.] - ETA: 7s - loss: 1.2888 - regression_loss: 1.0534 - classification_loss: 0.2354
 974/1000 [============================>.] - ETA: 7s - loss: 1.2881 - regression_loss: 1.0528 - classification_loss: 0.2353
 975/1000 [============================>.] - ETA: 7s - loss: 1.2878 - regression_loss: 1.0526 - classification_loss: 0.2352
 976/1000 [============================>.] - ETA: 6s - loss: 1.2876 - regression_loss: 1.0525 - classification_loss: 0.2352
 977/1000 [============================>.] - ETA: 6s - loss: 1.2881 - regression_loss: 1.0529 - classification_loss: 0.2353
 978/1000 [============================>.] - ETA: 6s - loss: 1.2873 - regression_loss: 1.0521 - classification_loss: 0.2352
 979/1000 [============================>.] - ETA: 6s - loss: 1.2870 - regression_loss: 1.0519 - classification_loss: 0.2351
 980/1000 [============================>.] - ETA: 5s - loss: 1.2882 - regression_loss: 1.0528 - classification_loss: 0.2354
 981/1000 [============================>.] - ETA: 5s - loss: 1.2879 - regression_loss: 1.0527 - classification_loss: 0.2353
 982/1000 [============================>.] - ETA: 5s - loss: 1.2886 - regression_loss: 1.0533 - classification_loss: 0.2352
 983/1000 [============================>.] - ETA: 4s - loss: 1.2882 - regression_loss: 1.0530 - classification_loss: 0.2352
 984/1000 [============================>.] - ETA: 4s - loss: 1.2874 - regression_loss: 1.0524 - classification_loss: 0.2351
 985/1000 [============================>.] - ETA: 4s - loss: 1.2871 - regression_loss: 1.0522 - classification_loss: 0.2350
 986/1000 [============================>.] - ETA: 4s - loss: 1.2876 - regression_loss: 1.0526 - classification_loss: 0.2350
 987/1000 [============================>.] - ETA: 3s - loss: 1.2876 - regression_loss: 1.0527 - classification_loss: 0.2349
 988/1000 [============================>.] - ETA: 3s - loss: 1.2870 - regression_loss: 1.0522 - classification_loss: 0.2348
 989/1000 [============================>.] - ETA: 3s - loss: 1.2871 - regression_loss: 1.0523 - classification_loss: 0.2348
 990/1000 [============================>.] - ETA: 2s - loss: 1.2868 - regression_loss: 1.0519 - classification_loss: 0.2349
 991/1000 [============================>.] - ETA: 2s - loss: 1.2871 - regression_loss: 1.0523 - classification_loss: 0.2348
 992/1000 [============================>.] - ETA: 2s - loss: 1.2867 - regression_loss: 1.0520 - classification_loss: 0.2347
 993/1000 [============================>.] - ETA: 2s - loss: 1.2865 - regression_loss: 1.0518 - classification_loss: 0.2347
 994/1000 [============================>.] - ETA: 1s - loss: 1.2878 - regression_loss: 1.0528 - classification_loss: 0.2350
 995/1000 [============================>.] - ETA: 1s - loss: 1.2874 - regression_loss: 1.0525 - classification_loss: 0.2349
 996/1000 [============================>.] - ETA: 1s - loss: 1.2878 - regression_loss: 1.0529 - classification_loss: 0.2349
 997/1000 [============================>.] - ETA: 0s - loss: 1.2874 - regression_loss: 1.0526 - classification_loss: 0.2348
 998/1000 [============================>.] - ETA: 0s - loss: 1.2880 - regression_loss: 1.0532 - classification_loss: 0.2349
 999/1000 [============================>.] - ETA: 0s - loss: 1.2875 - regression_loss: 1.0527 - classification_loss: 0.2348
1000/1000 [==============================] - 287s 287ms/step - loss: 1.2868 - regression_loss: 1.0521 - classification_loss: 0.2346

Epoch 00007: saving model to ./snapshots/resnet50_csv_07.h5
Epoch 8/10

   1/1000 [..............................] - ETA: 4:43 - loss: 1.0994 - regression_loss: 0.8829 - classification_loss: 0.2165
   2/1000 [..............................] - ETA: 4:42 - loss: 1.1102 - regression_loss: 0.9434 - classification_loss: 0.1668
   3/1000 [..............................] - ETA: 4:44 - loss: 1.0006 - regression_loss: 0.8667 - classification_loss: 0.1339
   4/1000 [..............................] - ETA: 4:45 - loss: 1.3498 - regression_loss: 1.0993 - classification_loss: 0.2505
   5/1000 [..............................] - ETA: 4:45 - loss: 1.4275 - regression_loss: 1.1666 - classification_loss: 0.2609
   6/1000 [..............................] - ETA: 4:44 - loss: 1.3971 - regression_loss: 1.1276 - classification_loss: 0.2695
   7/1000 [..............................] - ETA: 4:43 - loss: 1.4001 - regression_loss: 1.1418 - classification_loss: 0.2583
   8/1000 [..............................] - ETA: 4:43 - loss: 1.3687 - regression_loss: 1.1050 - classification_loss: 0.2637
   9/1000 [..............................] - ETA: 4:42 - loss: 1.3230 - regression_loss: 1.0775 - classification_loss: 0.2455
  10/1000 [..............................] - ETA: 4:41 - loss: 1.2974 - regression_loss: 1.0622 - classification_loss: 0.2352
  11/1000 [..............................] - ETA: 4:41 - loss: 1.2346 - regression_loss: 1.0120 - classification_loss: 0.2226
  12/1000 [..............................] - ETA: 4:41 - loss: 1.2853 - regression_loss: 1.0361 - classification_loss: 0.2492
  13/1000 [..............................] - ETA: 4:41 - loss: 1.3009 - regression_loss: 1.0419 - classification_loss: 0.2590
  14/1000 [..............................] - ETA: 4:41 - loss: 1.2642 - regression_loss: 1.0159 - classification_loss: 0.2483
  15/1000 [..............................] - ETA: 4:40 - loss: 1.2619 - regression_loss: 1.0193 - classification_loss: 0.2426
  16/1000 [..............................] - ETA: 4:40 - loss: 1.2142 - regression_loss: 0.9822 - classification_loss: 0.2320
  17/1000 [..............................] - ETA: 4:40 - loss: 1.1892 - regression_loss: 0.9634 - classification_loss: 0.2259
  18/1000 [..............................] - ETA: 4:40 - loss: 1.1586 - regression_loss: 0.9339 - classification_loss: 0.2247
  19/1000 [..............................] - ETA: 4:40 - loss: 1.1381 - regression_loss: 0.9190 - classification_loss: 0.2191
  20/1000 [..............................] - ETA: 4:39 - loss: 1.1340 - regression_loss: 0.9167 - classification_loss: 0.2173
  21/1000 [..............................] - ETA: 4:38 - loss: 1.1495 - regression_loss: 0.9303 - classification_loss: 0.2192
  22/1000 [..............................] - ETA: 4:39 - loss: 1.1469 - regression_loss: 0.9300 - classification_loss: 0.2168
  23/1000 [..............................] - ETA: 4:38 - loss: 1.1420 - regression_loss: 0.9219 - classification_loss: 0.2201
  24/1000 [..............................] - ETA: 4:38 - loss: 1.1768 - regression_loss: 0.9570 - classification_loss: 0.2198
  25/1000 [..............................] - ETA: 4:37 - loss: 1.1719 - regression_loss: 0.9468 - classification_loss: 0.2251
  26/1000 [..............................] - ETA: 4:37 - loss: 1.1556 - regression_loss: 0.9281 - classification_loss: 0.2275
  27/1000 [..............................] - ETA: 4:37 - loss: 1.1688 - regression_loss: 0.9419 - classification_loss: 0.2269
  28/1000 [..............................] - ETA: 4:37 - loss: 1.1785 - regression_loss: 0.9502 - classification_loss: 0.2282
  29/1000 [..............................] - ETA: 4:37 - loss: 1.1777 - regression_loss: 0.9505 - classification_loss: 0.2272
  30/1000 [..............................] - ETA: 4:36 - loss: 1.1858 - regression_loss: 0.9586 - classification_loss: 0.2272
  31/1000 [..............................] - ETA: 4:36 - loss: 1.1870 - regression_loss: 0.9601 - classification_loss: 0.2269
  32/1000 [..............................] - ETA: 4:36 - loss: 1.2136 - regression_loss: 0.9816 - classification_loss: 0.2320
  33/1000 [..............................] - ETA: 4:36 - loss: 1.2160 - regression_loss: 0.9838 - classification_loss: 0.2322
  34/1000 [>.............................] - ETA: 4:35 - loss: 1.2017 - regression_loss: 0.9725 - classification_loss: 0.2291
  35/1000 [>.............................] - ETA: 4:35 - loss: 1.2014 - regression_loss: 0.9649 - classification_loss: 0.2366
  36/1000 [>.............................] - ETA: 4:35 - loss: 1.2190 - regression_loss: 0.9776 - classification_loss: 0.2414
  37/1000 [>.............................] - ETA: 4:34 - loss: 1.2051 - regression_loss: 0.9673 - classification_loss: 0.2378
  38/1000 [>.............................] - ETA: 4:34 - loss: 1.2127 - regression_loss: 0.9767 - classification_loss: 0.2360
  39/1000 [>.............................] - ETA: 4:34 - loss: 1.2250 - regression_loss: 0.9833 - classification_loss: 0.2417
  40/1000 [>.............................] - ETA: 4:34 - loss: 1.2191 - regression_loss: 0.9756 - classification_loss: 0.2435
  41/1000 [>.............................] - ETA: 4:33 - loss: 1.2663 - regression_loss: 1.0126 - classification_loss: 0.2537
  42/1000 [>.............................] - ETA: 4:33 - loss: 1.2681 - regression_loss: 1.0149 - classification_loss: 0.2532
  43/1000 [>.............................] - ETA: 4:33 - loss: 1.2587 - regression_loss: 1.0091 - classification_loss: 0.2496
  44/1000 [>.............................] - ETA: 4:32 - loss: 1.2426 - regression_loss: 0.9968 - classification_loss: 0.2458
  45/1000 [>.............................] - ETA: 4:32 - loss: 1.2724 - regression_loss: 1.0201 - classification_loss: 0.2522
  46/1000 [>.............................] - ETA: 4:32 - loss: 1.2666 - regression_loss: 1.0162 - classification_loss: 0.2504
  47/1000 [>.............................] - ETA: 4:31 - loss: 1.2671 - regression_loss: 1.0164 - classification_loss: 0.2507
  48/1000 [>.............................] - ETA: 4:31 - loss: 1.2630 - regression_loss: 1.0150 - classification_loss: 0.2480
  49/1000 [>.............................] - ETA: 4:31 - loss: 1.2536 - regression_loss: 1.0061 - classification_loss: 0.2475
  50/1000 [>.............................] - ETA: 4:31 - loss: 1.2480 - regression_loss: 1.0024 - classification_loss: 0.2456
  51/1000 [>.............................] - ETA: 4:30 - loss: 1.2392 - regression_loss: 0.9961 - classification_loss: 0.2432
  52/1000 [>.............................] - ETA: 4:30 - loss: 1.2321 - regression_loss: 0.9912 - classification_loss: 0.2409
  53/1000 [>.............................] - ETA: 4:30 - loss: 1.2227 - regression_loss: 0.9844 - classification_loss: 0.2383
  54/1000 [>.............................] - ETA: 4:30 - loss: 1.2355 - regression_loss: 0.9949 - classification_loss: 0.2406
  55/1000 [>.............................] - ETA: 4:29 - loss: 1.2390 - regression_loss: 0.9992 - classification_loss: 0.2399
  56/1000 [>.............................] - ETA: 4:29 - loss: 1.2353 - regression_loss: 0.9961 - classification_loss: 0.2392
  57/1000 [>.............................] - ETA: 4:29 - loss: 1.2316 - regression_loss: 0.9948 - classification_loss: 0.2369
  58/1000 [>.............................] - ETA: 4:29 - loss: 1.2486 - regression_loss: 1.0094 - classification_loss: 0.2393
  59/1000 [>.............................] - ETA: 4:28 - loss: 1.2422 - regression_loss: 1.0052 - classification_loss: 0.2369
  60/1000 [>.............................] - ETA: 4:28 - loss: 1.2325 - regression_loss: 0.9978 - classification_loss: 0.2348
  61/1000 [>.............................] - ETA: 4:28 - loss: 1.2353 - regression_loss: 1.0006 - classification_loss: 0.2347
  62/1000 [>.............................] - ETA: 4:28 - loss: 1.2251 - regression_loss: 0.9930 - classification_loss: 0.2321
  63/1000 [>.............................] - ETA: 4:28 - loss: 1.2207 - regression_loss: 0.9906 - classification_loss: 0.2301
  64/1000 [>.............................] - ETA: 4:27 - loss: 1.2289 - regression_loss: 0.9987 - classification_loss: 0.2302
  65/1000 [>.............................] - ETA: 4:27 - loss: 1.2312 - regression_loss: 0.9998 - classification_loss: 0.2314
  66/1000 [>.............................] - ETA: 4:27 - loss: 1.2354 - regression_loss: 1.0038 - classification_loss: 0.2316
  67/1000 [=>............................] - ETA: 4:26 - loss: 1.2265 - regression_loss: 0.9973 - classification_loss: 0.2292
  68/1000 [=>............................] - ETA: 4:26 - loss: 1.2268 - regression_loss: 0.9980 - classification_loss: 0.2288
  69/1000 [=>............................] - ETA: 4:26 - loss: 1.2179 - regression_loss: 0.9899 - classification_loss: 0.2281
  70/1000 [=>............................] - ETA: 4:26 - loss: 1.2269 - regression_loss: 0.9990 - classification_loss: 0.2279
  71/1000 [=>............................] - ETA: 4:26 - loss: 1.2241 - regression_loss: 0.9970 - classification_loss: 0.2270
  72/1000 [=>............................] - ETA: 4:25 - loss: 1.2187 - regression_loss: 0.9920 - classification_loss: 0.2267
  73/1000 [=>............................] - ETA: 4:25 - loss: 1.2141 - regression_loss: 0.9889 - classification_loss: 0.2252
  74/1000 [=>............................] - ETA: 4:25 - loss: 1.2067 - regression_loss: 0.9831 - classification_loss: 0.2236
  75/1000 [=>............................] - ETA: 4:24 - loss: 1.2092 - regression_loss: 0.9860 - classification_loss: 0.2232
  76/1000 [=>............................] - ETA: 4:24 - loss: 1.2336 - regression_loss: 1.0020 - classification_loss: 0.2316
  77/1000 [=>............................] - ETA: 4:24 - loss: 1.2321 - regression_loss: 1.0003 - classification_loss: 0.2318
  78/1000 [=>............................] - ETA: 4:24 - loss: 1.2346 - regression_loss: 1.0013 - classification_loss: 0.2333
  79/1000 [=>............................] - ETA: 4:24 - loss: 1.2411 - regression_loss: 1.0067 - classification_loss: 0.2344
  80/1000 [=>............................] - ETA: 4:23 - loss: 1.2387 - regression_loss: 1.0058 - classification_loss: 0.2329
  81/1000 [=>............................] - ETA: 4:23 - loss: 1.2477 - regression_loss: 1.0131 - classification_loss: 0.2345
  82/1000 [=>............................] - ETA: 4:23 - loss: 1.2507 - regression_loss: 1.0164 - classification_loss: 0.2343
  83/1000 [=>............................] - ETA: 4:22 - loss: 1.2423 - regression_loss: 1.0093 - classification_loss: 0.2330
  84/1000 [=>............................] - ETA: 4:22 - loss: 1.2419 - regression_loss: 1.0087 - classification_loss: 0.2332
  85/1000 [=>............................] - ETA: 4:22 - loss: 1.2431 - regression_loss: 1.0100 - classification_loss: 0.2331
  86/1000 [=>............................] - ETA: 4:22 - loss: 1.2491 - regression_loss: 1.0154 - classification_loss: 0.2337
  87/1000 [=>............................] - ETA: 4:21 - loss: 1.2404 - regression_loss: 1.0087 - classification_loss: 0.2317
  88/1000 [=>............................] - ETA: 4:21 - loss: 1.2374 - regression_loss: 1.0063 - classification_loss: 0.2311
  89/1000 [=>............................] - ETA: 4:21 - loss: 1.2475 - regression_loss: 1.0126 - classification_loss: 0.2349
  90/1000 [=>............................] - ETA: 4:21 - loss: 1.2451 - regression_loss: 1.0100 - classification_loss: 0.2350
  91/1000 [=>............................] - ETA: 4:20 - loss: 1.2519 - regression_loss: 1.0160 - classification_loss: 0.2359
  92/1000 [=>............................] - ETA: 4:20 - loss: 1.2514 - regression_loss: 1.0171 - classification_loss: 0.2343
  93/1000 [=>............................] - ETA: 4:20 - loss: 1.2489 - regression_loss: 1.0157 - classification_loss: 0.2333
  94/1000 [=>............................] - ETA: 4:20 - loss: 1.2476 - regression_loss: 1.0149 - classification_loss: 0.2327
  95/1000 [=>............................] - ETA: 4:19 - loss: 1.2550 - regression_loss: 1.0196 - classification_loss: 0.2354
  96/1000 [=>............................] - ETA: 4:19 - loss: 1.2592 - regression_loss: 1.0236 - classification_loss: 0.2356
  97/1000 [=>............................] - ETA: 4:19 - loss: 1.2527 - regression_loss: 1.0184 - classification_loss: 0.2342
  98/1000 [=>............................] - ETA: 4:18 - loss: 1.2531 - regression_loss: 1.0187 - classification_loss: 0.2344
  99/1000 [=>............................] - ETA: 4:18 - loss: 1.2505 - regression_loss: 1.0174 - classification_loss: 0.2331
 100/1000 [==>...........................] - ETA: 4:18 - loss: 1.2556 - regression_loss: 1.0214 - classification_loss: 0.2341
 101/1000 [==>...........................] - ETA: 4:18 - loss: 1.2504 - regression_loss: 1.0178 - classification_loss: 0.2326
 102/1000 [==>...........................] - ETA: 4:17 - loss: 1.2475 - regression_loss: 1.0159 - classification_loss: 0.2316
 103/1000 [==>...........................] - ETA: 4:17 - loss: 1.2514 - regression_loss: 1.0189 - classification_loss: 0.2324
 104/1000 [==>...........................] - ETA: 4:17 - loss: 1.2462 - regression_loss: 1.0152 - classification_loss: 0.2310
 105/1000 [==>...........................] - ETA: 4:17 - loss: 1.2548 - regression_loss: 1.0232 - classification_loss: 0.2317
 106/1000 [==>...........................] - ETA: 4:16 - loss: 1.2589 - regression_loss: 1.0266 - classification_loss: 0.2323
 107/1000 [==>...........................] - ETA: 4:16 - loss: 1.2573 - regression_loss: 1.0259 - classification_loss: 0.2315
 108/1000 [==>...........................] - ETA: 4:16 - loss: 1.2584 - regression_loss: 1.0269 - classification_loss: 0.2315
 109/1000 [==>...........................] - ETA: 4:15 - loss: 1.2517 - regression_loss: 1.0211 - classification_loss: 0.2307
 110/1000 [==>...........................] - ETA: 4:15 - loss: 1.2503 - regression_loss: 1.0204 - classification_loss: 0.2299
 111/1000 [==>...........................] - ETA: 4:15 - loss: 1.2519 - regression_loss: 1.0220 - classification_loss: 0.2299
 112/1000 [==>...........................] - ETA: 4:15 - loss: 1.2461 - regression_loss: 1.0169 - classification_loss: 0.2292
 113/1000 [==>...........................] - ETA: 4:14 - loss: 1.2508 - regression_loss: 1.0211 - classification_loss: 0.2297
 114/1000 [==>...........................] - ETA: 4:14 - loss: 1.2517 - regression_loss: 1.0220 - classification_loss: 0.2297
 115/1000 [==>...........................] - ETA: 4:14 - loss: 1.2510 - regression_loss: 1.0218 - classification_loss: 0.2292
 116/1000 [==>...........................] - ETA: 4:13 - loss: 1.2548 - regression_loss: 1.0260 - classification_loss: 0.2288
 117/1000 [==>...........................] - ETA: 4:13 - loss: 1.2513 - regression_loss: 1.0234 - classification_loss: 0.2278
 118/1000 [==>...........................] - ETA: 4:13 - loss: 1.2487 - regression_loss: 1.0215 - classification_loss: 0.2272
 119/1000 [==>...........................] - ETA: 4:12 - loss: 1.2530 - regression_loss: 1.0246 - classification_loss: 0.2284
 120/1000 [==>...........................] - ETA: 4:12 - loss: 1.2525 - regression_loss: 1.0250 - classification_loss: 0.2274
 121/1000 [==>...........................] - ETA: 4:12 - loss: 1.2535 - regression_loss: 1.0249 - classification_loss: 0.2286
 122/1000 [==>...........................] - ETA: 4:11 - loss: 1.2482 - regression_loss: 1.0209 - classification_loss: 0.2274
 123/1000 [==>...........................] - ETA: 4:11 - loss: 1.2452 - regression_loss: 1.0188 - classification_loss: 0.2264
 124/1000 [==>...........................] - ETA: 4:11 - loss: 1.2436 - regression_loss: 1.0181 - classification_loss: 0.2255
 125/1000 [==>...........................] - ETA: 4:11 - loss: 1.2424 - regression_loss: 1.0163 - classification_loss: 0.2261
 126/1000 [==>...........................] - ETA: 4:10 - loss: 1.2445 - regression_loss: 1.0189 - classification_loss: 0.2256
 127/1000 [==>...........................] - ETA: 4:10 - loss: 1.2423 - regression_loss: 1.0159 - classification_loss: 0.2264
 128/1000 [==>...........................] - ETA: 4:10 - loss: 1.2370 - regression_loss: 1.0115 - classification_loss: 0.2255
 129/1000 [==>...........................] - ETA: 4:09 - loss: 1.2422 - regression_loss: 1.0154 - classification_loss: 0.2268
 130/1000 [==>...........................] - ETA: 4:09 - loss: 1.2359 - regression_loss: 1.0103 - classification_loss: 0.2256
 131/1000 [==>...........................] - ETA: 4:09 - loss: 1.2306 - regression_loss: 1.0061 - classification_loss: 0.2246
 132/1000 [==>...........................] - ETA: 4:09 - loss: 1.2287 - regression_loss: 1.0046 - classification_loss: 0.2241
 133/1000 [==>...........................] - ETA: 4:08 - loss: 1.2254 - regression_loss: 1.0020 - classification_loss: 0.2234
 134/1000 [===>..........................] - ETA: 4:08 - loss: 1.2251 - regression_loss: 1.0027 - classification_loss: 0.2224
 135/1000 [===>..........................] - ETA: 4:08 - loss: 1.2233 - regression_loss: 1.0007 - classification_loss: 0.2226
 136/1000 [===>..........................] - ETA: 4:08 - loss: 1.2245 - regression_loss: 1.0015 - classification_loss: 0.2230
 137/1000 [===>..........................] - ETA: 4:07 - loss: 1.2214 - regression_loss: 0.9986 - classification_loss: 0.2227
 138/1000 [===>..........................] - ETA: 4:07 - loss: 1.2174 - regression_loss: 0.9954 - classification_loss: 0.2220
 139/1000 [===>..........................] - ETA: 4:07 - loss: 1.2171 - regression_loss: 0.9950 - classification_loss: 0.2221
 140/1000 [===>..........................] - ETA: 4:06 - loss: 1.2256 - regression_loss: 1.0009 - classification_loss: 0.2247
 141/1000 [===>..........................] - ETA: 4:06 - loss: 1.2281 - regression_loss: 1.0036 - classification_loss: 0.2244
 142/1000 [===>..........................] - ETA: 4:06 - loss: 1.2316 - regression_loss: 1.0051 - classification_loss: 0.2265
 143/1000 [===>..........................] - ETA: 4:06 - loss: 1.2328 - regression_loss: 1.0064 - classification_loss: 0.2264
 144/1000 [===>..........................] - ETA: 4:05 - loss: 1.2334 - regression_loss: 1.0074 - classification_loss: 0.2260
 145/1000 [===>..........................] - ETA: 4:05 - loss: 1.2333 - regression_loss: 1.0074 - classification_loss: 0.2260
 146/1000 [===>..........................] - ETA: 4:05 - loss: 1.2312 - regression_loss: 1.0062 - classification_loss: 0.2251
 147/1000 [===>..........................] - ETA: 4:05 - loss: 1.2334 - regression_loss: 1.0083 - classification_loss: 0.2251
 148/1000 [===>..........................] - ETA: 4:04 - loss: 1.2291 - regression_loss: 1.0051 - classification_loss: 0.2240
 149/1000 [===>..........................] - ETA: 4:04 - loss: 1.2343 - regression_loss: 1.0085 - classification_loss: 0.2258
 150/1000 [===>..........................] - ETA: 4:04 - loss: 1.2332 - regression_loss: 1.0071 - classification_loss: 0.2262
 151/1000 [===>..........................] - ETA: 4:03 - loss: 1.2314 - regression_loss: 1.0052 - classification_loss: 0.2262
 152/1000 [===>..........................] - ETA: 4:03 - loss: 1.2292 - regression_loss: 1.0037 - classification_loss: 0.2255
 153/1000 [===>..........................] - ETA: 4:03 - loss: 1.2283 - regression_loss: 1.0024 - classification_loss: 0.2259
 154/1000 [===>..........................] - ETA: 4:02 - loss: 1.2249 - regression_loss: 0.9999 - classification_loss: 0.2250
 155/1000 [===>..........................] - ETA: 4:02 - loss: 1.2271 - regression_loss: 1.0022 - classification_loss: 0.2249
 156/1000 [===>..........................] - ETA: 4:02 - loss: 1.2282 - regression_loss: 1.0034 - classification_loss: 0.2248
 157/1000 [===>..........................] - ETA: 4:02 - loss: 1.2299 - regression_loss: 1.0049 - classification_loss: 0.2250
 158/1000 [===>..........................] - ETA: 4:01 - loss: 1.2314 - regression_loss: 1.0061 - classification_loss: 0.2253
 159/1000 [===>..........................] - ETA: 4:01 - loss: 1.2300 - regression_loss: 1.0038 - classification_loss: 0.2262
 160/1000 [===>..........................] - ETA: 4:01 - loss: 1.2354 - regression_loss: 1.0058 - classification_loss: 0.2296
 161/1000 [===>..........................] - ETA: 4:00 - loss: 1.2303 - regression_loss: 1.0014 - classification_loss: 0.2290
 162/1000 [===>..........................] - ETA: 4:00 - loss: 1.2281 - regression_loss: 0.9997 - classification_loss: 0.2285
 163/1000 [===>..........................] - ETA: 4:00 - loss: 1.2245 - regression_loss: 0.9969 - classification_loss: 0.2275
 164/1000 [===>..........................] - ETA: 4:00 - loss: 1.2195 - regression_loss: 0.9929 - classification_loss: 0.2266
 165/1000 [===>..........................] - ETA: 3:59 - loss: 1.2154 - regression_loss: 0.9892 - classification_loss: 0.2262
 166/1000 [===>..........................] - ETA: 3:59 - loss: 1.2121 - regression_loss: 0.9866 - classification_loss: 0.2256
 167/1000 [====>.........................] - ETA: 3:59 - loss: 1.2150 - regression_loss: 0.9885 - classification_loss: 0.2265
 168/1000 [====>.........................] - ETA: 3:58 - loss: 1.2149 - regression_loss: 0.9880 - classification_loss: 0.2269
 169/1000 [====>.........................] - ETA: 3:58 - loss: 1.2181 - regression_loss: 0.9911 - classification_loss: 0.2270
 170/1000 [====>.........................] - ETA: 3:58 - loss: 1.2236 - regression_loss: 0.9949 - classification_loss: 0.2288
 171/1000 [====>.........................] - ETA: 3:57 - loss: 1.2369 - regression_loss: 1.0062 - classification_loss: 0.2307
 172/1000 [====>.........................] - ETA: 3:57 - loss: 1.2334 - regression_loss: 1.0037 - classification_loss: 0.2297
 173/1000 [====>.........................] - ETA: 3:57 - loss: 1.2349 - regression_loss: 1.0046 - classification_loss: 0.2304
 174/1000 [====>.........................] - ETA: 3:57 - loss: 1.2332 - regression_loss: 1.0034 - classification_loss: 0.2298
 175/1000 [====>.........................] - ETA: 3:56 - loss: 1.2334 - regression_loss: 1.0035 - classification_loss: 0.2299
 176/1000 [====>.........................] - ETA: 3:56 - loss: 1.2425 - regression_loss: 1.0117 - classification_loss: 0.2308
 177/1000 [====>.........................] - ETA: 3:56 - loss: 1.2418 - regression_loss: 1.0115 - classification_loss: 0.2303
 178/1000 [====>.........................] - ETA: 3:56 - loss: 1.2483 - regression_loss: 1.0168 - classification_loss: 0.2316
 179/1000 [====>.........................] - ETA: 3:55 - loss: 1.2454 - regression_loss: 1.0147 - classification_loss: 0.2307
 180/1000 [====>.........................] - ETA: 3:55 - loss: 1.2437 - regression_loss: 1.0136 - classification_loss: 0.2300
 181/1000 [====>.........................] - ETA: 3:55 - loss: 1.2467 - regression_loss: 1.0164 - classification_loss: 0.2304
 182/1000 [====>.........................] - ETA: 3:54 - loss: 1.2510 - regression_loss: 1.0201 - classification_loss: 0.2309
 183/1000 [====>.........................] - ETA: 3:54 - loss: 1.2577 - regression_loss: 1.0252 - classification_loss: 0.2325
 184/1000 [====>.........................] - ETA: 3:54 - loss: 1.2624 - regression_loss: 1.0298 - classification_loss: 0.2326
 185/1000 [====>.........................] - ETA: 3:53 - loss: 1.2652 - regression_loss: 1.0326 - classification_loss: 0.2326
 186/1000 [====>.........................] - ETA: 3:53 - loss: 1.2627 - regression_loss: 1.0308 - classification_loss: 0.2319
 187/1000 [====>.........................] - ETA: 3:53 - loss: 1.2646 - regression_loss: 1.0325 - classification_loss: 0.2321
 188/1000 [====>.........................] - ETA: 3:53 - loss: 1.2658 - regression_loss: 1.0333 - classification_loss: 0.2325
 189/1000 [====>.........................] - ETA: 3:52 - loss: 1.2691 - regression_loss: 1.0344 - classification_loss: 0.2348
 190/1000 [====>.........................] - ETA: 3:52 - loss: 1.2663 - regression_loss: 1.0320 - classification_loss: 0.2344
 191/1000 [====>.........................] - ETA: 3:52 - loss: 1.2661 - regression_loss: 1.0320 - classification_loss: 0.2340
 192/1000 [====>.........................] - ETA: 3:51 - loss: 1.2698 - regression_loss: 1.0357 - classification_loss: 0.2342
 193/1000 [====>.........................] - ETA: 3:51 - loss: 1.2710 - regression_loss: 1.0365 - classification_loss: 0.2345
 194/1000 [====>.........................] - ETA: 3:51 - loss: 1.2712 - regression_loss: 1.0367 - classification_loss: 0.2345
 195/1000 [====>.........................] - ETA: 3:50 - loss: 1.2676 - regression_loss: 1.0331 - classification_loss: 0.2345
 196/1000 [====>.........................] - ETA: 3:50 - loss: 1.2702 - regression_loss: 1.0360 - classification_loss: 0.2343
 197/1000 [====>.........................] - ETA: 3:50 - loss: 1.2681 - regression_loss: 1.0345 - classification_loss: 0.2336
 198/1000 [====>.........................] - ETA: 3:50 - loss: 1.2699 - regression_loss: 1.0363 - classification_loss: 0.2335
 199/1000 [====>.........................] - ETA: 3:49 - loss: 1.2697 - regression_loss: 1.0366 - classification_loss: 0.2331
 200/1000 [=====>........................] - ETA: 3:49 - loss: 1.2707 - regression_loss: 1.0378 - classification_loss: 0.2329
 201/1000 [=====>........................] - ETA: 3:49 - loss: 1.2686 - regression_loss: 1.0364 - classification_loss: 0.2323
 202/1000 [=====>........................] - ETA: 3:49 - loss: 1.2701 - regression_loss: 1.0374 - classification_loss: 0.2327
 203/1000 [=====>........................] - ETA: 3:48 - loss: 1.2686 - regression_loss: 1.0364 - classification_loss: 0.2322
 204/1000 [=====>........................] - ETA: 3:48 - loss: 1.2704 - regression_loss: 1.0381 - classification_loss: 0.2323
 205/1000 [=====>........................] - ETA: 3:48 - loss: 1.2697 - regression_loss: 1.0376 - classification_loss: 0.2321
 206/1000 [=====>........................] - ETA: 3:47 - loss: 1.2708 - regression_loss: 1.0384 - classification_loss: 0.2324
 207/1000 [=====>........................] - ETA: 3:47 - loss: 1.2702 - regression_loss: 1.0381 - classification_loss: 0.2321
 208/1000 [=====>........................] - ETA: 3:47 - loss: 1.2674 - regression_loss: 1.0361 - classification_loss: 0.2313
 209/1000 [=====>........................] - ETA: 3:47 - loss: 1.2629 - regression_loss: 1.0324 - classification_loss: 0.2305
 210/1000 [=====>........................] - ETA: 3:46 - loss: 1.2611 - regression_loss: 1.0309 - classification_loss: 0.2302
 211/1000 [=====>........................] - ETA: 3:46 - loss: 1.2622 - regression_loss: 1.0320 - classification_loss: 0.2302
 212/1000 [=====>........................] - ETA: 3:46 - loss: 1.2673 - regression_loss: 1.0358 - classification_loss: 0.2315
 213/1000 [=====>........................] - ETA: 3:45 - loss: 1.2677 - regression_loss: 1.0366 - classification_loss: 0.2311
 214/1000 [=====>........................] - ETA: 3:45 - loss: 1.2721 - regression_loss: 1.0386 - classification_loss: 0.2335
 215/1000 [=====>........................] - ETA: 3:45 - loss: 1.2700 - regression_loss: 1.0366 - classification_loss: 0.2334
 216/1000 [=====>........................] - ETA: 3:45 - loss: 1.2682 - regression_loss: 1.0353 - classification_loss: 0.2329
 217/1000 [=====>........................] - ETA: 3:44 - loss: 1.2657 - regression_loss: 1.0333 - classification_loss: 0.2324
 218/1000 [=====>........................] - ETA: 3:44 - loss: 1.2660 - regression_loss: 1.0329 - classification_loss: 0.2331
 219/1000 [=====>........................] - ETA: 3:44 - loss: 1.2628 - regression_loss: 1.0303 - classification_loss: 0.2325
 220/1000 [=====>........................] - ETA: 3:43 - loss: 1.2644 - regression_loss: 1.0322 - classification_loss: 0.2322
 221/1000 [=====>........................] - ETA: 3:43 - loss: 1.2666 - regression_loss: 1.0338 - classification_loss: 0.2327
 222/1000 [=====>........................] - ETA: 3:43 - loss: 1.2657 - regression_loss: 1.0334 - classification_loss: 0.2323
 223/1000 [=====>........................] - ETA: 3:42 - loss: 1.2643 - regression_loss: 1.0321 - classification_loss: 0.2322
 224/1000 [=====>........................] - ETA: 3:42 - loss: 1.2627 - regression_loss: 1.0308 - classification_loss: 0.2319
 225/1000 [=====>........................] - ETA: 3:42 - loss: 1.2636 - regression_loss: 1.0315 - classification_loss: 0.2321
 226/1000 [=====>........................] - ETA: 3:42 - loss: 1.2616 - regression_loss: 1.0299 - classification_loss: 0.2317
 227/1000 [=====>........................] - ETA: 3:41 - loss: 1.2613 - regression_loss: 1.0296 - classification_loss: 0.2317
 228/1000 [=====>........................] - ETA: 3:41 - loss: 1.2618 - regression_loss: 1.0303 - classification_loss: 0.2316
 229/1000 [=====>........................] - ETA: 3:41 - loss: 1.2676 - regression_loss: 1.0348 - classification_loss: 0.2329
 230/1000 [=====>........................] - ETA: 3:40 - loss: 1.2685 - regression_loss: 1.0358 - classification_loss: 0.2327
 231/1000 [=====>........................] - ETA: 3:40 - loss: 1.2690 - regression_loss: 1.0368 - classification_loss: 0.2322
 232/1000 [=====>........................] - ETA: 3:40 - loss: 1.2669 - regression_loss: 1.0351 - classification_loss: 0.2318
 233/1000 [=====>........................] - ETA: 3:40 - loss: 1.2654 - regression_loss: 1.0340 - classification_loss: 0.2314
 234/1000 [======>.......................] - ETA: 3:39 - loss: 1.2703 - regression_loss: 1.0386 - classification_loss: 0.2317
 235/1000 [======>.......................] - ETA: 3:39 - loss: 1.2700 - regression_loss: 1.0378 - classification_loss: 0.2322
 236/1000 [======>.......................] - ETA: 3:39 - loss: 1.2777 - regression_loss: 1.0388 - classification_loss: 0.2389
 237/1000 [======>.......................] - ETA: 3:39 - loss: 1.2802 - regression_loss: 1.0394 - classification_loss: 0.2408
 238/1000 [======>.......................] - ETA: 3:38 - loss: 1.2825 - regression_loss: 1.0415 - classification_loss: 0.2411
 239/1000 [======>.......................] - ETA: 3:38 - loss: 1.2844 - regression_loss: 1.0427 - classification_loss: 0.2417
 240/1000 [======>.......................] - ETA: 3:38 - loss: 1.2842 - regression_loss: 1.0427 - classification_loss: 0.2415
 241/1000 [======>.......................] - ETA: 3:37 - loss: 1.2879 - regression_loss: 1.0460 - classification_loss: 0.2419
 242/1000 [======>.......................] - ETA: 3:37 - loss: 1.2930 - regression_loss: 1.0493 - classification_loss: 0.2437
 243/1000 [======>.......................] - ETA: 3:37 - loss: 1.2929 - regression_loss: 1.0494 - classification_loss: 0.2435
 244/1000 [======>.......................] - ETA: 3:37 - loss: 1.2895 - regression_loss: 1.0466 - classification_loss: 0.2429
 245/1000 [======>.......................] - ETA: 3:36 - loss: 1.2902 - regression_loss: 1.0472 - classification_loss: 0.2430
 246/1000 [======>.......................] - ETA: 3:36 - loss: 1.2887 - regression_loss: 1.0460 - classification_loss: 0.2427
 247/1000 [======>.......................] - ETA: 3:36 - loss: 1.2865 - regression_loss: 1.0443 - classification_loss: 0.2422
 248/1000 [======>.......................] - ETA: 3:35 - loss: 1.2840 - regression_loss: 1.0424 - classification_loss: 0.2416
 249/1000 [======>.......................] - ETA: 3:35 - loss: 1.2847 - regression_loss: 1.0430 - classification_loss: 0.2417
 250/1000 [======>.......................] - ETA: 3:35 - loss: 1.2866 - regression_loss: 1.0445 - classification_loss: 0.2421
 251/1000 [======>.......................] - ETA: 3:35 - loss: 1.2891 - regression_loss: 1.0468 - classification_loss: 0.2424
 252/1000 [======>.......................] - ETA: 3:34 - loss: 1.2911 - regression_loss: 1.0471 - classification_loss: 0.2440
 253/1000 [======>.......................] - ETA: 3:34 - loss: 1.2883 - regression_loss: 1.0451 - classification_loss: 0.2432
 254/1000 [======>.......................] - ETA: 3:34 - loss: 1.2878 - regression_loss: 1.0444 - classification_loss: 0.2434
 255/1000 [======>.......................] - ETA: 3:33 - loss: 1.2864 - regression_loss: 1.0435 - classification_loss: 0.2428
 256/1000 [======>.......................] - ETA: 3:33 - loss: 1.2877 - regression_loss: 1.0450 - classification_loss: 0.2427
 257/1000 [======>.......................] - ETA: 3:33 - loss: 1.2900 - regression_loss: 1.0471 - classification_loss: 0.2428
 258/1000 [======>.......................] - ETA: 3:33 - loss: 1.2909 - regression_loss: 1.0482 - classification_loss: 0.2427
 259/1000 [======>.......................] - ETA: 3:32 - loss: 1.2941 - regression_loss: 1.0501 - classification_loss: 0.2441
 260/1000 [======>.......................] - ETA: 3:32 - loss: 1.2940 - regression_loss: 1.0503 - classification_loss: 0.2437
 261/1000 [======>.......................] - ETA: 3:32 - loss: 1.2928 - regression_loss: 1.0496 - classification_loss: 0.2432
 262/1000 [======>.......................] - ETA: 3:31 - loss: 1.2926 - regression_loss: 1.0492 - classification_loss: 0.2433
 263/1000 [======>.......................] - ETA: 3:31 - loss: 1.2907 - regression_loss: 1.0474 - classification_loss: 0.2433
 264/1000 [======>.......................] - ETA: 3:31 - loss: 1.2875 - regression_loss: 1.0450 - classification_loss: 0.2426
 265/1000 [======>.......................] - ETA: 3:31 - loss: 1.2897 - regression_loss: 1.0467 - classification_loss: 0.2430
 266/1000 [======>.......................] - ETA: 3:30 - loss: 1.2876 - regression_loss: 1.0449 - classification_loss: 0.2427
 267/1000 [=======>......................] - ETA: 3:30 - loss: 1.2865 - regression_loss: 1.0443 - classification_loss: 0.2422
 268/1000 [=======>......................] - ETA: 3:30 - loss: 1.2847 - regression_loss: 1.0430 - classification_loss: 0.2416
 269/1000 [=======>......................] - ETA: 3:29 - loss: 1.2869 - regression_loss: 1.0449 - classification_loss: 0.2419
 270/1000 [=======>......................] - ETA: 3:29 - loss: 1.2853 - regression_loss: 1.0436 - classification_loss: 0.2417
 271/1000 [=======>......................] - ETA: 3:29 - loss: 1.2848 - regression_loss: 1.0434 - classification_loss: 0.2413
 272/1000 [=======>......................] - ETA: 3:29 - loss: 1.2827 - regression_loss: 1.0416 - classification_loss: 0.2411
 273/1000 [=======>......................] - ETA: 3:28 - loss: 1.2821 - regression_loss: 1.0411 - classification_loss: 0.2410
 274/1000 [=======>......................] - ETA: 3:28 - loss: 1.2796 - regression_loss: 1.0386 - classification_loss: 0.2409
 275/1000 [=======>......................] - ETA: 3:28 - loss: 1.2793 - regression_loss: 1.0387 - classification_loss: 0.2406
 276/1000 [=======>......................] - ETA: 3:27 - loss: 1.2770 - regression_loss: 1.0370 - classification_loss: 0.2400
 277/1000 [=======>......................] - ETA: 3:27 - loss: 1.2755 - regression_loss: 1.0359 - classification_loss: 0.2396
 278/1000 [=======>......................] - ETA: 3:27 - loss: 1.2732 - regression_loss: 1.0341 - classification_loss: 0.2391
 279/1000 [=======>......................] - ETA: 3:27 - loss: 1.2728 - regression_loss: 1.0339 - classification_loss: 0.2389
 280/1000 [=======>......................] - ETA: 3:26 - loss: 1.2719 - regression_loss: 1.0334 - classification_loss: 0.2385
 281/1000 [=======>......................] - ETA: 3:26 - loss: 1.2711 - regression_loss: 1.0321 - classification_loss: 0.2390
 282/1000 [=======>......................] - ETA: 3:26 - loss: 1.2703 - regression_loss: 1.0314 - classification_loss: 0.2390
 283/1000 [=======>......................] - ETA: 3:25 - loss: 1.2679 - regression_loss: 1.0295 - classification_loss: 0.2384
 284/1000 [=======>......................] - ETA: 3:25 - loss: 1.2676 - regression_loss: 1.0294 - classification_loss: 0.2382
 285/1000 [=======>......................] - ETA: 3:25 - loss: 1.2671 - regression_loss: 1.0292 - classification_loss: 0.2378
 286/1000 [=======>......................] - ETA: 3:25 - loss: 1.2661 - regression_loss: 1.0287 - classification_loss: 0.2374
 287/1000 [=======>......................] - ETA: 3:24 - loss: 1.2640 - regression_loss: 1.0267 - classification_loss: 0.2373
 288/1000 [=======>......................] - ETA: 3:24 - loss: 1.2616 - regression_loss: 1.0248 - classification_loss: 0.2368
 289/1000 [=======>......................] - ETA: 3:24 - loss: 1.2604 - regression_loss: 1.0241 - classification_loss: 0.2363
 290/1000 [=======>......................] - ETA: 3:23 - loss: 1.2576 - regression_loss: 1.0219 - classification_loss: 0.2357
 291/1000 [=======>......................] - ETA: 3:23 - loss: 1.2568 - regression_loss: 1.0215 - classification_loss: 0.2353
 292/1000 [=======>......................] - ETA: 3:23 - loss: 1.2560 - regression_loss: 1.0208 - classification_loss: 0.2352
 293/1000 [=======>......................] - ETA: 3:23 - loss: 1.2543 - regression_loss: 1.0195 - classification_loss: 0.2348
 294/1000 [=======>......................] - ETA: 3:22 - loss: 1.2527 - regression_loss: 1.0181 - classification_loss: 0.2345
 295/1000 [=======>......................] - ETA: 3:22 - loss: 1.2528 - regression_loss: 1.0184 - classification_loss: 0.2343
 296/1000 [=======>......................] - ETA: 3:22 - loss: 1.2518 - regression_loss: 1.0179 - classification_loss: 0.2339
 297/1000 [=======>......................] - ETA: 3:21 - loss: 1.2509 - regression_loss: 1.0172 - classification_loss: 0.2337
 298/1000 [=======>......................] - ETA: 3:21 - loss: 1.2491 - regression_loss: 1.0154 - classification_loss: 0.2337
 299/1000 [=======>......................] - ETA: 3:21 - loss: 1.2523 - regression_loss: 1.0182 - classification_loss: 0.2341
 300/1000 [========>.....................] - ETA: 3:21 - loss: 1.2520 - regression_loss: 1.0183 - classification_loss: 0.2338
 301/1000 [========>.....................] - ETA: 3:20 - loss: 1.2499 - regression_loss: 1.0166 - classification_loss: 0.2333
 302/1000 [========>.....................] - ETA: 3:20 - loss: 1.2485 - regression_loss: 1.0157 - classification_loss: 0.2328
 303/1000 [========>.....................] - ETA: 3:20 - loss: 1.2473 - regression_loss: 1.0149 - classification_loss: 0.2324
 304/1000 [========>.....................] - ETA: 3:19 - loss: 1.2460 - regression_loss: 1.0138 - classification_loss: 0.2322
 305/1000 [========>.....................] - ETA: 3:19 - loss: 1.2444 - regression_loss: 1.0126 - classification_loss: 0.2318
 306/1000 [========>.....................] - ETA: 3:19 - loss: 1.2445 - regression_loss: 1.0130 - classification_loss: 0.2315
 307/1000 [========>.....................] - ETA: 3:19 - loss: 1.2426 - regression_loss: 1.0116 - classification_loss: 0.2310
 308/1000 [========>.....................] - ETA: 3:18 - loss: 1.2428 - regression_loss: 1.0118 - classification_loss: 0.2310
 309/1000 [========>.....................] - ETA: 3:18 - loss: 1.2428 - regression_loss: 1.0122 - classification_loss: 0.2307
 310/1000 [========>.....................] - ETA: 3:18 - loss: 1.2410 - regression_loss: 1.0105 - classification_loss: 0.2305
 311/1000 [========>.....................] - ETA: 3:17 - loss: 1.2415 - regression_loss: 1.0109 - classification_loss: 0.2305
 312/1000 [========>.....................] - ETA: 3:17 - loss: 1.2431 - regression_loss: 1.0123 - classification_loss: 0.2308
 313/1000 [========>.....................] - ETA: 3:17 - loss: 1.2443 - regression_loss: 1.0138 - classification_loss: 0.2305
 314/1000 [========>.....................] - ETA: 3:17 - loss: 1.2423 - regression_loss: 1.0121 - classification_loss: 0.2303
 315/1000 [========>.....................] - ETA: 3:16 - loss: 1.2412 - regression_loss: 1.0107 - classification_loss: 0.2305
 316/1000 [========>.....................] - ETA: 3:16 - loss: 1.2396 - regression_loss: 1.0094 - classification_loss: 0.2301
 317/1000 [========>.....................] - ETA: 3:16 - loss: 1.2382 - regression_loss: 1.0084 - classification_loss: 0.2299
 318/1000 [========>.....................] - ETA: 3:15 - loss: 1.2369 - regression_loss: 1.0075 - classification_loss: 0.2294
 319/1000 [========>.....................] - ETA: 3:15 - loss: 1.2366 - regression_loss: 1.0073 - classification_loss: 0.2293
 320/1000 [========>.....................] - ETA: 3:15 - loss: 1.2352 - regression_loss: 1.0062 - classification_loss: 0.2290
 321/1000 [========>.....................] - ETA: 3:15 - loss: 1.2335 - regression_loss: 1.0048 - classification_loss: 0.2288
 322/1000 [========>.....................] - ETA: 3:14 - loss: 1.2316 - regression_loss: 1.0032 - classification_loss: 0.2283
 323/1000 [========>.....................] - ETA: 3:14 - loss: 1.2302 - regression_loss: 1.0022 - classification_loss: 0.2280
 324/1000 [========>.....................] - ETA: 3:14 - loss: 1.2291 - regression_loss: 1.0014 - classification_loss: 0.2277
 325/1000 [========>.....................] - ETA: 3:13 - loss: 1.2330 - regression_loss: 1.0045 - classification_loss: 0.2285
 326/1000 [========>.....................] - ETA: 3:13 - loss: 1.2322 - regression_loss: 1.0038 - classification_loss: 0.2284
 327/1000 [========>.....................] - ETA: 3:13 - loss: 1.2301 - regression_loss: 1.0022 - classification_loss: 0.2279
 328/1000 [========>.....................] - ETA: 3:13 - loss: 1.2295 - regression_loss: 1.0019 - classification_loss: 0.2276
 329/1000 [========>.....................] - ETA: 3:12 - loss: 1.2292 - regression_loss: 1.0016 - classification_loss: 0.2276
 330/1000 [========>.....................] - ETA: 3:12 - loss: 1.2297 - regression_loss: 1.0023 - classification_loss: 0.2274
 331/1000 [========>.....................] - ETA: 3:12 - loss: 1.2329 - regression_loss: 1.0055 - classification_loss: 0.2274
 332/1000 [========>.....................] - ETA: 3:11 - loss: 1.2307 - regression_loss: 1.0038 - classification_loss: 0.2269
 333/1000 [========>.....................] - ETA: 3:11 - loss: 1.2304 - regression_loss: 1.0034 - classification_loss: 0.2270
 334/1000 [=========>....................] - ETA: 3:11 - loss: 1.2317 - regression_loss: 1.0044 - classification_loss: 0.2273
 335/1000 [=========>....................] - ETA: 3:11 - loss: 1.2337 - regression_loss: 1.0064 - classification_loss: 0.2273
 336/1000 [=========>....................] - ETA: 3:10 - loss: 1.2328 - regression_loss: 1.0059 - classification_loss: 0.2270
 337/1000 [=========>....................] - ETA: 3:10 - loss: 1.2315 - regression_loss: 1.0047 - classification_loss: 0.2268
 338/1000 [=========>....................] - ETA: 3:10 - loss: 1.2336 - regression_loss: 1.0063 - classification_loss: 0.2273
 339/1000 [=========>....................] - ETA: 3:09 - loss: 1.2348 - regression_loss: 1.0069 - classification_loss: 0.2279
 340/1000 [=========>....................] - ETA: 3:09 - loss: 1.2332 - regression_loss: 1.0057 - classification_loss: 0.2274
 341/1000 [=========>....................] - ETA: 3:09 - loss: 1.2338 - regression_loss: 1.0065 - classification_loss: 0.2273
 342/1000 [=========>....................] - ETA: 3:09 - loss: 1.2348 - regression_loss: 1.0071 - classification_loss: 0.2277
 343/1000 [=========>....................] - ETA: 3:08 - loss: 1.2349 - regression_loss: 1.0072 - classification_loss: 0.2277
 344/1000 [=========>....................] - ETA: 3:08 - loss: 1.2364 - regression_loss: 1.0084 - classification_loss: 0.2279
 345/1000 [=========>....................] - ETA: 3:08 - loss: 1.2356 - regression_loss: 1.0080 - classification_loss: 0.2277
 346/1000 [=========>....................] - ETA: 3:07 - loss: 1.2417 - regression_loss: 1.0124 - classification_loss: 0.2293
 347/1000 [=========>....................] - ETA: 3:07 - loss: 1.2400 - regression_loss: 1.0111 - classification_loss: 0.2288
 348/1000 [=========>....................] - ETA: 3:07 - loss: 1.2390 - regression_loss: 1.0102 - classification_loss: 0.2287
 349/1000 [=========>....................] - ETA: 3:07 - loss: 1.2372 - regression_loss: 1.0089 - classification_loss: 0.2284
 350/1000 [=========>....................] - ETA: 3:06 - loss: 1.2386 - regression_loss: 1.0089 - classification_loss: 0.2297
 351/1000 [=========>....................] - ETA: 3:06 - loss: 1.2376 - regression_loss: 1.0080 - classification_loss: 0.2296
 352/1000 [=========>....................] - ETA: 3:06 - loss: 1.2369 - regression_loss: 1.0075 - classification_loss: 0.2294
 353/1000 [=========>....................] - ETA: 3:05 - loss: 1.2361 - regression_loss: 1.0068 - classification_loss: 0.2292
 354/1000 [=========>....................] - ETA: 3:05 - loss: 1.2352 - regression_loss: 1.0062 - classification_loss: 0.2290
 355/1000 [=========>....................] - ETA: 3:05 - loss: 1.2354 - regression_loss: 1.0066 - classification_loss: 0.2288
 356/1000 [=========>....................] - ETA: 3:05 - loss: 1.2360 - regression_loss: 1.0073 - classification_loss: 0.2287
 357/1000 [=========>....................] - ETA: 3:04 - loss: 1.2358 - regression_loss: 1.0070 - classification_loss: 0.2288
 358/1000 [=========>....................] - ETA: 3:04 - loss: 1.2340 - regression_loss: 1.0056 - classification_loss: 0.2285
 359/1000 [=========>....................] - ETA: 3:04 - loss: 1.2358 - regression_loss: 1.0071 - classification_loss: 0.2287
 360/1000 [=========>....................] - ETA: 3:03 - loss: 1.2348 - regression_loss: 1.0060 - classification_loss: 0.2288
 361/1000 [=========>....................] - ETA: 3:03 - loss: 1.2346 - regression_loss: 1.0060 - classification_loss: 0.2286
 362/1000 [=========>....................] - ETA: 3:03 - loss: 1.2331 - regression_loss: 1.0049 - classification_loss: 0.2283
 363/1000 [=========>....................] - ETA: 3:02 - loss: 1.2331 - regression_loss: 1.0048 - classification_loss: 0.2283
 364/1000 [=========>....................] - ETA: 3:02 - loss: 1.2353 - regression_loss: 1.0065 - classification_loss: 0.2288
 365/1000 [=========>....................] - ETA: 3:02 - loss: 1.2356 - regression_loss: 1.0067 - classification_loss: 0.2289
 366/1000 [=========>....................] - ETA: 3:02 - loss: 1.2351 - regression_loss: 1.0064 - classification_loss: 0.2287
 367/1000 [==========>...................] - ETA: 3:01 - loss: 1.2346 - regression_loss: 1.0059 - classification_loss: 0.2286
 368/1000 [==========>...................] - ETA: 3:01 - loss: 1.2326 - regression_loss: 1.0044 - classification_loss: 0.2282
 369/1000 [==========>...................] - ETA: 3:01 - loss: 1.2320 - regression_loss: 1.0041 - classification_loss: 0.2278
 370/1000 [==========>...................] - ETA: 3:00 - loss: 1.2305 - regression_loss: 1.0028 - classification_loss: 0.2277
 371/1000 [==========>...................] - ETA: 3:00 - loss: 1.2306 - regression_loss: 1.0032 - classification_loss: 0.2274
 372/1000 [==========>...................] - ETA: 3:00 - loss: 1.2321 - regression_loss: 1.0048 - classification_loss: 0.2274
 373/1000 [==========>...................] - ETA: 3:00 - loss: 1.2313 - regression_loss: 1.0042 - classification_loss: 0.2271
 374/1000 [==========>...................] - ETA: 2:59 - loss: 1.2301 - regression_loss: 1.0034 - classification_loss: 0.2267
 375/1000 [==========>...................] - ETA: 2:59 - loss: 1.2292 - regression_loss: 1.0027 - classification_loss: 0.2264
 376/1000 [==========>...................] - ETA: 2:59 - loss: 1.2279 - regression_loss: 1.0018 - classification_loss: 0.2261
 377/1000 [==========>...................] - ETA: 2:58 - loss: 1.2285 - regression_loss: 1.0025 - classification_loss: 0.2261
 378/1000 [==========>...................] - ETA: 2:58 - loss: 1.2262 - regression_loss: 1.0005 - classification_loss: 0.2257
 379/1000 [==========>...................] - ETA: 2:58 - loss: 1.2251 - regression_loss: 0.9995 - classification_loss: 0.2256
 380/1000 [==========>...................] - ETA: 2:58 - loss: 1.2248 - regression_loss: 0.9993 - classification_loss: 0.2254
 381/1000 [==========>...................] - ETA: 2:57 - loss: 1.2265 - regression_loss: 1.0009 - classification_loss: 0.2256
 382/1000 [==========>...................] - ETA: 2:57 - loss: 1.2253 - regression_loss: 1.0001 - classification_loss: 0.2252
 383/1000 [==========>...................] - ETA: 2:57 - loss: 1.2487 - regression_loss: 0.9975 - classification_loss: 0.2512
 384/1000 [==========>...................] - ETA: 2:56 - loss: 1.2487 - regression_loss: 0.9978 - classification_loss: 0.2509
 385/1000 [==========>...................] - ETA: 2:56 - loss: 1.2481 - regression_loss: 0.9973 - classification_loss: 0.2507
 386/1000 [==========>...................] - ETA: 2:56 - loss: 1.2473 - regression_loss: 0.9964 - classification_loss: 0.2509
 387/1000 [==========>...................] - ETA: 2:56 - loss: 1.2470 - regression_loss: 0.9960 - classification_loss: 0.2510
 388/1000 [==========>...................] - ETA: 2:55 - loss: 1.2479 - regression_loss: 0.9965 - classification_loss: 0.2514
 389/1000 [==========>...................] - ETA: 2:55 - loss: 1.2481 - regression_loss: 0.9969 - classification_loss: 0.2512
 390/1000 [==========>...................] - ETA: 2:55 - loss: 1.2479 - regression_loss: 0.9968 - classification_loss: 0.2511
 391/1000 [==========>...................] - ETA: 2:54 - loss: 1.2475 - regression_loss: 0.9965 - classification_loss: 0.2510
 392/1000 [==========>...................] - ETA: 2:54 - loss: 1.2468 - regression_loss: 0.9958 - classification_loss: 0.2511
 393/1000 [==========>...................] - ETA: 2:54 - loss: 1.2455 - regression_loss: 0.9947 - classification_loss: 0.2508
 394/1000 [==========>...................] - ETA: 2:54 - loss: 1.2451 - regression_loss: 0.9945 - classification_loss: 0.2506
 395/1000 [==========>...................] - ETA: 2:53 - loss: 1.2442 - regression_loss: 0.9938 - classification_loss: 0.2505
 396/1000 [==========>...................] - ETA: 2:53 - loss: 1.2443 - regression_loss: 0.9936 - classification_loss: 0.2506
 397/1000 [==========>...................] - ETA: 2:53 - loss: 1.2423 - regression_loss: 0.9921 - classification_loss: 0.2502
 398/1000 [==========>...................] - ETA: 2:52 - loss: 1.2406 - regression_loss: 0.9906 - classification_loss: 0.2499
 399/1000 [==========>...................] - ETA: 2:52 - loss: 1.2405 - regression_loss: 0.9908 - classification_loss: 0.2497
 400/1000 [===========>..................] - ETA: 2:52 - loss: 1.2420 - regression_loss: 0.9918 - classification_loss: 0.2502
 401/1000 [===========>..................] - ETA: 2:52 - loss: 1.2443 - regression_loss: 0.9936 - classification_loss: 0.2506
 402/1000 [===========>..................] - ETA: 2:51 - loss: 1.2434 - regression_loss: 0.9929 - classification_loss: 0.2505
 403/1000 [===========>..................] - ETA: 2:51 - loss: 1.2439 - regression_loss: 0.9931 - classification_loss: 0.2508
 404/1000 [===========>..................] - ETA: 2:51 - loss: 1.2422 - regression_loss: 0.9917 - classification_loss: 0.2505
 405/1000 [===========>..................] - ETA: 2:50 - loss: 1.2434 - regression_loss: 0.9930 - classification_loss: 0.2504
 406/1000 [===========>..................] - ETA: 2:50 - loss: 1.2459 - regression_loss: 0.9948 - classification_loss: 0.2512
 407/1000 [===========>..................] - ETA: 2:50 - loss: 1.2446 - regression_loss: 0.9939 - classification_loss: 0.2507
 408/1000 [===========>..................] - ETA: 2:50 - loss: 1.2444 - regression_loss: 0.9938 - classification_loss: 0.2506
 409/1000 [===========>..................] - ETA: 2:49 - loss: 1.2445 - regression_loss: 0.9939 - classification_loss: 0.2507
 410/1000 [===========>..................] - ETA: 2:49 - loss: 1.2437 - regression_loss: 0.9934 - classification_loss: 0.2503
 411/1000 [===========>..................] - ETA: 2:49 - loss: 1.2443 - regression_loss: 0.9941 - classification_loss: 0.2502
 412/1000 [===========>..................] - ETA: 2:48 - loss: 1.2449 - regression_loss: 0.9946 - classification_loss: 0.2503
 413/1000 [===========>..................] - ETA: 2:48 - loss: 1.2437 - regression_loss: 0.9938 - classification_loss: 0.2500
 414/1000 [===========>..................] - ETA: 2:48 - loss: 1.2447 - regression_loss: 0.9946 - classification_loss: 0.2501
 415/1000 [===========>..................] - ETA: 2:48 - loss: 1.2447 - regression_loss: 0.9948 - classification_loss: 0.2499
 416/1000 [===========>..................] - ETA: 2:47 - loss: 1.2431 - regression_loss: 0.9936 - classification_loss: 0.2495
 417/1000 [===========>..................] - ETA: 2:47 - loss: 1.2419 - regression_loss: 0.9927 - classification_loss: 0.2491
 418/1000 [===========>..................] - ETA: 2:47 - loss: 1.2449 - regression_loss: 0.9950 - classification_loss: 0.2499
 419/1000 [===========>..................] - ETA: 2:46 - loss: 1.2479 - regression_loss: 0.9967 - classification_loss: 0.2511
 420/1000 [===========>..................] - ETA: 2:46 - loss: 1.2476 - regression_loss: 0.9963 - classification_loss: 0.2513
 421/1000 [===========>..................] - ETA: 2:46 - loss: 1.2472 - regression_loss: 0.9961 - classification_loss: 0.2511
 422/1000 [===========>..................] - ETA: 2:46 - loss: 1.2487 - regression_loss: 0.9975 - classification_loss: 0.2512
 423/1000 [===========>..................] - ETA: 2:45 - loss: 1.2510 - regression_loss: 0.9999 - classification_loss: 0.2511
 424/1000 [===========>..................] - ETA: 2:45 - loss: 1.2504 - regression_loss: 0.9995 - classification_loss: 0.2509
 425/1000 [===========>..................] - ETA: 2:45 - loss: 1.2498 - regression_loss: 0.9991 - classification_loss: 0.2506
 426/1000 [===========>..................] - ETA: 2:44 - loss: 1.2508 - regression_loss: 1.0000 - classification_loss: 0.2508
 427/1000 [===========>..................] - ETA: 2:44 - loss: 1.2516 - regression_loss: 1.0008 - classification_loss: 0.2507
 428/1000 [===========>..................] - ETA: 2:44 - loss: 1.2508 - regression_loss: 1.0004 - classification_loss: 0.2504
 429/1000 [===========>..................] - ETA: 2:44 - loss: 1.2502 - regression_loss: 0.9999 - classification_loss: 0.2503
 430/1000 [===========>..................] - ETA: 2:43 - loss: 1.2502 - regression_loss: 0.9999 - classification_loss: 0.2502
 431/1000 [===========>..................] - ETA: 2:43 - loss: 1.2517 - regression_loss: 1.0008 - classification_loss: 0.2509
 432/1000 [===========>..................] - ETA: 2:43 - loss: 1.2501 - regression_loss: 0.9996 - classification_loss: 0.2505
 433/1000 [===========>..................] - ETA: 2:42 - loss: 1.2554 - regression_loss: 1.0036 - classification_loss: 0.2518
 434/1000 [============>.................] - ETA: 2:42 - loss: 1.2546 - regression_loss: 1.0029 - classification_loss: 0.2518
 435/1000 [============>.................] - ETA: 2:42 - loss: 1.2560 - regression_loss: 1.0040 - classification_loss: 0.2520
 436/1000 [============>.................] - ETA: 2:42 - loss: 1.2548 - regression_loss: 1.0031 - classification_loss: 0.2517
 437/1000 [============>.................] - ETA: 2:41 - loss: 1.2557 - regression_loss: 1.0039 - classification_loss: 0.2519
 438/1000 [============>.................] - ETA: 2:41 - loss: 1.2555 - regression_loss: 1.0038 - classification_loss: 0.2517
 439/1000 [============>.................] - ETA: 2:41 - loss: 1.2539 - regression_loss: 1.0023 - classification_loss: 0.2516
 440/1000 [============>.................] - ETA: 2:40 - loss: 1.2546 - regression_loss: 1.0032 - classification_loss: 0.2514
 441/1000 [============>.................] - ETA: 2:40 - loss: 1.2541 - regression_loss: 1.0029 - classification_loss: 0.2512
 442/1000 [============>.................] - ETA: 2:40 - loss: 1.2524 - regression_loss: 1.0017 - classification_loss: 0.2507
 443/1000 [============>.................] - ETA: 2:39 - loss: 1.2526 - regression_loss: 1.0020 - classification_loss: 0.2506
 444/1000 [============>.................] - ETA: 2:39 - loss: 1.2519 - regression_loss: 1.0012 - classification_loss: 0.2507
 445/1000 [============>.................] - ETA: 2:39 - loss: 1.2511 - regression_loss: 1.0007 - classification_loss: 0.2505
 446/1000 [============>.................] - ETA: 2:39 - loss: 1.2513 - regression_loss: 1.0006 - classification_loss: 0.2507
 447/1000 [============>.................] - ETA: 2:38 - loss: 1.2512 - regression_loss: 1.0004 - classification_loss: 0.2508
 448/1000 [============>.................] - ETA: 2:38 - loss: 1.2497 - regression_loss: 0.9993 - classification_loss: 0.2504
 449/1000 [============>.................] - ETA: 2:38 - loss: 1.2516 - regression_loss: 1.0011 - classification_loss: 0.2505
 450/1000 [============>.................] - ETA: 2:37 - loss: 1.2504 - regression_loss: 1.0002 - classification_loss: 0.2502
 451/1000 [============>.................] - ETA: 2:37 - loss: 1.2492 - regression_loss: 0.9992 - classification_loss: 0.2499
 452/1000 [============>.................] - ETA: 2:37 - loss: 1.2480 - regression_loss: 0.9983 - classification_loss: 0.2496
 453/1000 [============>.................] - ETA: 2:37 - loss: 1.2482 - regression_loss: 0.9979 - classification_loss: 0.2503
 454/1000 [============>.................] - ETA: 2:36 - loss: 1.2483 - regression_loss: 0.9978 - classification_loss: 0.2504
 455/1000 [============>.................] - ETA: 2:36 - loss: 1.2477 - regression_loss: 0.9973 - classification_loss: 0.2503
 456/1000 [============>.................] - ETA: 2:36 - loss: 1.2471 - regression_loss: 0.9970 - classification_loss: 0.2500
 457/1000 [============>.................] - ETA: 2:35 - loss: 1.2458 - regression_loss: 0.9960 - classification_loss: 0.2498
 458/1000 [============>.................] - ETA: 2:35 - loss: 1.2465 - regression_loss: 0.9965 - classification_loss: 0.2501
 459/1000 [============>.................] - ETA: 2:35 - loss: 1.2474 - regression_loss: 0.9969 - classification_loss: 0.2505
 460/1000 [============>.................] - ETA: 2:35 - loss: 1.2459 - regression_loss: 0.9955 - classification_loss: 0.2504
 461/1000 [============>.................] - ETA: 2:34 - loss: 1.2450 - regression_loss: 0.9947 - classification_loss: 0.2503
 462/1000 [============>.................] - ETA: 2:34 - loss: 1.2441 - regression_loss: 0.9942 - classification_loss: 0.2499
 463/1000 [============>.................] - ETA: 2:34 - loss: 1.2445 - regression_loss: 0.9945 - classification_loss: 0.2500
 464/1000 [============>.................] - ETA: 2:33 - loss: 1.2470 - regression_loss: 0.9963 - classification_loss: 0.2507
 465/1000 [============>.................] - ETA: 2:33 - loss: 1.2462 - regression_loss: 0.9955 - classification_loss: 0.2507
 466/1000 [============>.................] - ETA: 2:33 - loss: 1.2469 - regression_loss: 0.9960 - classification_loss: 0.2508
 467/1000 [=============>................] - ETA: 2:33 - loss: 1.2476 - regression_loss: 0.9966 - classification_loss: 0.2509
 468/1000 [=============>................] - ETA: 2:32 - loss: 1.2459 - regression_loss: 0.9952 - classification_loss: 0.2507
 469/1000 [=============>................] - ETA: 2:32 - loss: 1.2447 - regression_loss: 0.9944 - classification_loss: 0.2503
 470/1000 [=============>................] - ETA: 2:32 - loss: 1.2468 - regression_loss: 0.9965 - classification_loss: 0.2502
 471/1000 [=============>................] - ETA: 2:31 - loss: 1.2489 - regression_loss: 0.9987 - classification_loss: 0.2503
 472/1000 [=============>................] - ETA: 2:31 - loss: 1.2476 - regression_loss: 0.9976 - classification_loss: 0.2499
 473/1000 [=============>................] - ETA: 2:31 - loss: 1.2473 - regression_loss: 0.9976 - classification_loss: 0.2497
 474/1000 [=============>................] - ETA: 2:31 - loss: 1.2483 - regression_loss: 0.9985 - classification_loss: 0.2499
 475/1000 [=============>................] - ETA: 2:30 - loss: 1.2471 - regression_loss: 0.9975 - classification_loss: 0.2496
 476/1000 [=============>................] - ETA: 2:30 - loss: 1.2483 - regression_loss: 0.9985 - classification_loss: 0.2498
 477/1000 [=============>................] - ETA: 2:30 - loss: 1.2465 - regression_loss: 0.9971 - classification_loss: 0.2494
 478/1000 [=============>................] - ETA: 2:29 - loss: 1.2457 - regression_loss: 0.9966 - classification_loss: 0.2491
 479/1000 [=============>................] - ETA: 2:29 - loss: 1.2443 - regression_loss: 0.9955 - classification_loss: 0.2488
 480/1000 [=============>................] - ETA: 2:29 - loss: 1.2446 - regression_loss: 0.9957 - classification_loss: 0.2489
 481/1000 [=============>................] - ETA: 2:29 - loss: 1.2429 - regression_loss: 0.9945 - classification_loss: 0.2484
 482/1000 [=============>................] - ETA: 2:28 - loss: 1.2427 - regression_loss: 0.9945 - classification_loss: 0.2482
 483/1000 [=============>................] - ETA: 2:28 - loss: 1.2437 - regression_loss: 0.9955 - classification_loss: 0.2481
 484/1000 [=============>................] - ETA: 2:28 - loss: 1.2428 - regression_loss: 0.9950 - classification_loss: 0.2478
 485/1000 [=============>................] - ETA: 2:27 - loss: 1.2421 - regression_loss: 0.9944 - classification_loss: 0.2476
 486/1000 [=============>................] - ETA: 2:27 - loss: 1.2421 - regression_loss: 0.9945 - classification_loss: 0.2475
 487/1000 [=============>................] - ETA: 2:27 - loss: 1.2418 - regression_loss: 0.9944 - classification_loss: 0.2474
 488/1000 [=============>................] - ETA: 2:27 - loss: 1.2412 - regression_loss: 0.9939 - classification_loss: 0.2472
 489/1000 [=============>................] - ETA: 2:26 - loss: 1.2406 - regression_loss: 0.9935 - classification_loss: 0.2471
 490/1000 [=============>................] - ETA: 2:26 - loss: 1.2411 - regression_loss: 0.9942 - classification_loss: 0.2469
 491/1000 [=============>................] - ETA: 2:26 - loss: 1.2427 - regression_loss: 0.9956 - classification_loss: 0.2471
 492/1000 [=============>................] - ETA: 2:25 - loss: 1.2421 - regression_loss: 0.9952 - classification_loss: 0.2469
 493/1000 [=============>................] - ETA: 2:25 - loss: 1.2420 - regression_loss: 0.9951 - classification_loss: 0.2469
 494/1000 [=============>................] - ETA: 2:25 - loss: 1.2408 - regression_loss: 0.9941 - classification_loss: 0.2466
 495/1000 [=============>................] - ETA: 2:25 - loss: 1.2432 - regression_loss: 0.9962 - classification_loss: 0.2470
 496/1000 [=============>................] - ETA: 2:24 - loss: 1.2431 - regression_loss: 0.9963 - classification_loss: 0.2468
 497/1000 [=============>................] - ETA: 2:24 - loss: 1.2441 - regression_loss: 0.9970 - classification_loss: 0.2472
 498/1000 [=============>................] - ETA: 2:24 - loss: 1.2443 - regression_loss: 0.9972 - classification_loss: 0.2471
 499/1000 [=============>................] - ETA: 2:23 - loss: 1.2439 - regression_loss: 0.9969 - classification_loss: 0.2469
 500/1000 [==============>...............] - ETA: 2:23 - loss: 1.2465 - regression_loss: 0.9989 - classification_loss: 0.2475
 501/1000 [==============>...............] - ETA: 2:23 - loss: 1.2461 - regression_loss: 0.9988 - classification_loss: 0.2473
 502/1000 [==============>...............] - ETA: 2:23 - loss: 1.2452 - regression_loss: 0.9979 - classification_loss: 0.2472
 503/1000 [==============>...............] - ETA: 2:22 - loss: 1.2448 - regression_loss: 0.9978 - classification_loss: 0.2470
 504/1000 [==============>...............] - ETA: 2:22 - loss: 1.2449 - regression_loss: 0.9980 - classification_loss: 0.2469
 505/1000 [==============>...............] - ETA: 2:22 - loss: 1.2459 - regression_loss: 0.9989 - classification_loss: 0.2470
 506/1000 [==============>...............] - ETA: 2:21 - loss: 1.2460 - regression_loss: 0.9992 - classification_loss: 0.2468
 507/1000 [==============>...............] - ETA: 2:21 - loss: 1.2476 - regression_loss: 0.9996 - classification_loss: 0.2479
 508/1000 [==============>...............] - ETA: 2:21 - loss: 1.2477 - regression_loss: 0.9997 - classification_loss: 0.2480
 509/1000 [==============>...............] - ETA: 2:21 - loss: 1.2496 - regression_loss: 1.0015 - classification_loss: 0.2482
 510/1000 [==============>...............] - ETA: 2:20 - loss: 1.2508 - regression_loss: 1.0026 - classification_loss: 0.2482
 511/1000 [==============>...............] - ETA: 2:20 - loss: 1.2516 - regression_loss: 1.0032 - classification_loss: 0.2483
 512/1000 [==============>...............] - ETA: 2:20 - loss: 1.2517 - regression_loss: 1.0035 - classification_loss: 0.2483
 513/1000 [==============>...............] - ETA: 2:19 - loss: 1.2533 - regression_loss: 1.0049 - classification_loss: 0.2484
 514/1000 [==============>...............] - ETA: 2:19 - loss: 1.2519 - regression_loss: 1.0038 - classification_loss: 0.2481
 515/1000 [==============>...............] - ETA: 2:19 - loss: 1.2516 - regression_loss: 1.0037 - classification_loss: 0.2479
 516/1000 [==============>...............] - ETA: 2:18 - loss: 1.2509 - regression_loss: 1.0030 - classification_loss: 0.2479
 517/1000 [==============>...............] - ETA: 2:18 - loss: 1.2508 - regression_loss: 1.0030 - classification_loss: 0.2478
 518/1000 [==============>...............] - ETA: 2:18 - loss: 1.2512 - regression_loss: 1.0035 - classification_loss: 0.2477
 519/1000 [==============>...............] - ETA: 2:18 - loss: 1.2515 - regression_loss: 1.0036 - classification_loss: 0.2479
 520/1000 [==============>...............] - ETA: 2:17 - loss: 1.2510 - regression_loss: 1.0033 - classification_loss: 0.2477
 521/1000 [==============>...............] - ETA: 2:17 - loss: 1.2519 - regression_loss: 1.0041 - classification_loss: 0.2478
 522/1000 [==============>...............] - ETA: 2:17 - loss: 1.2530 - regression_loss: 1.0049 - classification_loss: 0.2481
 523/1000 [==============>...............] - ETA: 2:16 - loss: 1.2515 - regression_loss: 1.0037 - classification_loss: 0.2478
 524/1000 [==============>...............] - ETA: 2:16 - loss: 1.2507 - regression_loss: 1.0032 - classification_loss: 0.2475
 525/1000 [==============>...............] - ETA: 2:16 - loss: 1.2495 - regression_loss: 1.0023 - classification_loss: 0.2473
 526/1000 [==============>...............] - ETA: 2:16 - loss: 1.2489 - regression_loss: 1.0016 - classification_loss: 0.2473
 527/1000 [==============>...............] - ETA: 2:15 - loss: 1.2473 - regression_loss: 1.0004 - classification_loss: 0.2470
 528/1000 [==============>...............] - ETA: 2:15 - loss: 1.2458 - regression_loss: 0.9990 - classification_loss: 0.2468
 529/1000 [==============>...............] - ETA: 2:15 - loss: 1.2451 - regression_loss: 0.9983 - classification_loss: 0.2467
 530/1000 [==============>...............] - ETA: 2:14 - loss: 1.2436 - regression_loss: 0.9972 - classification_loss: 0.2464
 531/1000 [==============>...............] - ETA: 2:14 - loss: 1.2435 - regression_loss: 0.9972 - classification_loss: 0.2463
 532/1000 [==============>...............] - ETA: 2:14 - loss: 1.2428 - regression_loss: 0.9968 - classification_loss: 0.2460
 533/1000 [==============>...............] - ETA: 2:14 - loss: 1.2428 - regression_loss: 0.9969 - classification_loss: 0.2458
 534/1000 [===============>..............] - ETA: 2:13 - loss: 1.2435 - regression_loss: 0.9974 - classification_loss: 0.2460
 535/1000 [===============>..............] - ETA: 2:13 - loss: 1.2438 - regression_loss: 0.9978 - classification_loss: 0.2461
 536/1000 [===============>..............] - ETA: 2:13 - loss: 1.2432 - regression_loss: 0.9973 - classification_loss: 0.2459
 537/1000 [===============>..............] - ETA: 2:12 - loss: 1.2443 - regression_loss: 0.9984 - classification_loss: 0.2459
 538/1000 [===============>..............] - ETA: 2:12 - loss: 1.2442 - regression_loss: 0.9983 - classification_loss: 0.2459
 539/1000 [===============>..............] - ETA: 2:12 - loss: 1.2433 - regression_loss: 0.9978 - classification_loss: 0.2456
 540/1000 [===============>..............] - ETA: 2:12 - loss: 1.2431 - regression_loss: 0.9977 - classification_loss: 0.2454
 541/1000 [===============>..............] - ETA: 2:11 - loss: 1.2425 - regression_loss: 0.9972 - classification_loss: 0.2453
 542/1000 [===============>..............] - ETA: 2:11 - loss: 1.2450 - regression_loss: 0.9991 - classification_loss: 0.2459
 543/1000 [===============>..............] - ETA: 2:11 - loss: 1.2439 - regression_loss: 0.9983 - classification_loss: 0.2456
 544/1000 [===============>..............] - ETA: 2:10 - loss: 1.2428 - regression_loss: 0.9975 - classification_loss: 0.2453
 545/1000 [===============>..............] - ETA: 2:10 - loss: 1.2420 - regression_loss: 0.9970 - classification_loss: 0.2451
 546/1000 [===============>..............] - ETA: 2:10 - loss: 1.2406 - regression_loss: 0.9959 - classification_loss: 0.2447
 547/1000 [===============>..............] - ETA: 2:10 - loss: 1.2396 - regression_loss: 0.9951 - classification_loss: 0.2445
 548/1000 [===============>..............] - ETA: 2:09 - loss: 1.2395 - regression_loss: 0.9951 - classification_loss: 0.2445
 549/1000 [===============>..............] - ETA: 2:09 - loss: 1.2392 - regression_loss: 0.9949 - classification_loss: 0.2443
 550/1000 [===============>..............] - ETA: 2:09 - loss: 1.2381 - regression_loss: 0.9941 - classification_loss: 0.2440
 551/1000 [===============>..............] - ETA: 2:08 - loss: 1.2385 - regression_loss: 0.9945 - classification_loss: 0.2440
 552/1000 [===============>..............] - ETA: 2:08 - loss: 1.2401 - regression_loss: 0.9960 - classification_loss: 0.2441
 553/1000 [===============>..............] - ETA: 2:08 - loss: 1.2396 - regression_loss: 0.9955 - classification_loss: 0.2442
 554/1000 [===============>..............] - ETA: 2:08 - loss: 1.2383 - regression_loss: 0.9944 - classification_loss: 0.2439
 555/1000 [===============>..............] - ETA: 2:07 - loss: 1.2381 - regression_loss: 0.9944 - classification_loss: 0.2437
 556/1000 [===============>..............] - ETA: 2:07 - loss: 1.2394 - regression_loss: 0.9955 - classification_loss: 0.2439
 557/1000 [===============>..............] - ETA: 2:07 - loss: 1.2385 - regression_loss: 0.9949 - classification_loss: 0.2436
 558/1000 [===============>..............] - ETA: 2:06 - loss: 1.2374 - regression_loss: 0.9941 - classification_loss: 0.2433
 559/1000 [===============>..............] - ETA: 2:06 - loss: 1.2369 - regression_loss: 0.9937 - classification_loss: 0.2432
 560/1000 [===============>..............] - ETA: 2:06 - loss: 1.2386 - regression_loss: 0.9952 - classification_loss: 0.2434
 561/1000 [===============>..............] - ETA: 2:06 - loss: 1.2377 - regression_loss: 0.9946 - classification_loss: 0.2431
 562/1000 [===============>..............] - ETA: 2:05 - loss: 1.2388 - regression_loss: 0.9954 - classification_loss: 0.2435
 563/1000 [===============>..............] - ETA: 2:05 - loss: 1.2400 - regression_loss: 0.9965 - classification_loss: 0.2435
 564/1000 [===============>..............] - ETA: 2:05 - loss: 1.2390 - regression_loss: 0.9957 - classification_loss: 0.2432
 565/1000 [===============>..............] - ETA: 2:04 - loss: 1.2388 - regression_loss: 0.9957 - classification_loss: 0.2431
 566/1000 [===============>..............] - ETA: 2:04 - loss: 1.2382 - regression_loss: 0.9953 - classification_loss: 0.2429
 567/1000 [================>.............] - ETA: 2:04 - loss: 1.2371 - regression_loss: 0.9945 - classification_loss: 0.2426
 568/1000 [================>.............] - ETA: 2:04 - loss: 1.2393 - regression_loss: 0.9965 - classification_loss: 0.2429
 569/1000 [================>.............] - ETA: 2:03 - loss: 1.2384 - regression_loss: 0.9959 - classification_loss: 0.2426
 570/1000 [================>.............] - ETA: 2:03 - loss: 1.2377 - regression_loss: 0.9953 - classification_loss: 0.2424
 571/1000 [================>.............] - ETA: 2:03 - loss: 1.2373 - regression_loss: 0.9948 - classification_loss: 0.2425
 572/1000 [================>.............] - ETA: 2:02 - loss: 1.2364 - regression_loss: 0.9940 - classification_loss: 0.2425
 573/1000 [================>.............] - ETA: 2:02 - loss: 1.2371 - regression_loss: 0.9947 - classification_loss: 0.2424
 574/1000 [================>.............] - ETA: 2:02 - loss: 1.2384 - regression_loss: 0.9956 - classification_loss: 0.2428
 575/1000 [================>.............] - ETA: 2:02 - loss: 1.2379 - regression_loss: 0.9950 - classification_loss: 0.2429
 576/1000 [================>.............] - ETA: 2:01 - loss: 1.2381 - regression_loss: 0.9951 - classification_loss: 0.2429
 577/1000 [================>.............] - ETA: 2:01 - loss: 1.2374 - regression_loss: 0.9946 - classification_loss: 0.2428
 578/1000 [================>.............] - ETA: 2:01 - loss: 1.2368 - regression_loss: 0.9939 - classification_loss: 0.2429
 579/1000 [================>.............] - ETA: 2:00 - loss: 1.2361 - regression_loss: 0.9934 - classification_loss: 0.2427
 580/1000 [================>.............] - ETA: 2:00 - loss: 1.2367 - regression_loss: 0.9937 - classification_loss: 0.2430
 581/1000 [================>.............] - ETA: 2:00 - loss: 1.2364 - regression_loss: 0.9934 - classification_loss: 0.2430
 582/1000 [================>.............] - ETA: 2:00 - loss: 1.2373 - regression_loss: 0.9938 - classification_loss: 0.2436
 583/1000 [================>.............] - ETA: 1:59 - loss: 1.2361 - regression_loss: 0.9929 - classification_loss: 0.2432
 584/1000 [================>.............] - ETA: 1:59 - loss: 1.2357 - regression_loss: 0.9926 - classification_loss: 0.2431
 585/1000 [================>.............] - ETA: 1:59 - loss: 1.2349 - regression_loss: 0.9919 - classification_loss: 0.2430
 586/1000 [================>.............] - ETA: 1:58 - loss: 1.2353 - regression_loss: 0.9925 - classification_loss: 0.2428
 587/1000 [================>.............] - ETA: 1:58 - loss: 1.2348 - regression_loss: 0.9923 - classification_loss: 0.2426
 588/1000 [================>.............] - ETA: 1:58 - loss: 1.2343 - regression_loss: 0.9918 - classification_loss: 0.2425
 589/1000 [================>.............] - ETA: 1:58 - loss: 1.2343 - regression_loss: 0.9918 - classification_loss: 0.2424
 590/1000 [================>.............] - ETA: 1:57 - loss: 1.2335 - regression_loss: 0.9912 - classification_loss: 0.2422
 591/1000 [================>.............] - ETA: 1:57 - loss: 1.2323 - regression_loss: 0.9903 - classification_loss: 0.2420
 592/1000 [================>.............] - ETA: 1:57 - loss: 1.2317 - regression_loss: 0.9898 - classification_loss: 0.2419
 593/1000 [================>.............] - ETA: 1:56 - loss: 1.2349 - regression_loss: 0.9923 - classification_loss: 0.2425
 594/1000 [================>.............] - ETA: 1:56 - loss: 1.2353 - regression_loss: 0.9927 - classification_loss: 0.2426
 595/1000 [================>.............] - ETA: 1:56 - loss: 1.2355 - regression_loss: 0.9928 - classification_loss: 0.2427
 596/1000 [================>.............] - ETA: 1:56 - loss: 1.2358 - regression_loss: 0.9932 - classification_loss: 0.2426
 597/1000 [================>.............] - ETA: 1:55 - loss: 1.2355 - regression_loss: 0.9932 - classification_loss: 0.2423
 598/1000 [================>.............] - ETA: 1:55 - loss: 1.2354 - regression_loss: 0.9933 - classification_loss: 0.2421
 599/1000 [================>.............] - ETA: 1:55 - loss: 1.2355 - regression_loss: 0.9935 - classification_loss: 0.2421
 600/1000 [=================>............] - ETA: 1:54 - loss: 1.2349 - regression_loss: 0.9931 - classification_loss: 0.2419
 601/1000 [=================>............] - ETA: 1:54 - loss: 1.2341 - regression_loss: 0.9924 - classification_loss: 0.2417
 602/1000 [=================>............] - ETA: 1:54 - loss: 1.2335 - regression_loss: 0.9916 - classification_loss: 0.2418
 603/1000 [=================>............] - ETA: 1:54 - loss: 1.2334 - regression_loss: 0.9916 - classification_loss: 0.2418
 604/1000 [=================>............] - ETA: 1:53 - loss: 1.2341 - regression_loss: 0.9923 - classification_loss: 0.2418
 605/1000 [=================>............] - ETA: 1:53 - loss: 1.2345 - regression_loss: 0.9929 - classification_loss: 0.2417
 606/1000 [=================>............] - ETA: 1:53 - loss: 1.2342 - regression_loss: 0.9926 - classification_loss: 0.2416
 607/1000 [=================>............] - ETA: 1:52 - loss: 1.2337 - regression_loss: 0.9920 - classification_loss: 0.2417
 608/1000 [=================>............] - ETA: 1:52 - loss: 1.2329 - regression_loss: 0.9914 - classification_loss: 0.2415
 609/1000 [=================>............] - ETA: 1:52 - loss: 1.2351 - regression_loss: 0.9936 - classification_loss: 0.2415
 610/1000 [=================>............] - ETA: 1:52 - loss: 1.2341 - regression_loss: 0.9927 - classification_loss: 0.2414
 611/1000 [=================>............] - ETA: 1:51 - loss: 1.2341 - regression_loss: 0.9928 - classification_loss: 0.2413
 612/1000 [=================>............] - ETA: 1:51 - loss: 1.2341 - regression_loss: 0.9930 - classification_loss: 0.2411
 613/1000 [=================>............] - ETA: 1:51 - loss: 1.2342 - regression_loss: 0.9931 - classification_loss: 0.2411
 614/1000 [=================>............] - ETA: 1:50 - loss: 1.2341 - regression_loss: 0.9932 - classification_loss: 0.2409
 615/1000 [=================>............] - ETA: 1:50 - loss: 1.2348 - regression_loss: 0.9940 - classification_loss: 0.2408
 616/1000 [=================>............] - ETA: 1:50 - loss: 1.2344 - regression_loss: 0.9939 - classification_loss: 0.2406
 617/1000 [=================>............] - ETA: 1:50 - loss: 1.2339 - regression_loss: 0.9935 - classification_loss: 0.2403
 618/1000 [=================>............] - ETA: 1:49 - loss: 1.2338 - regression_loss: 0.9936 - classification_loss: 0.2402
 619/1000 [=================>............] - ETA: 1:49 - loss: 1.2339 - regression_loss: 0.9934 - classification_loss: 0.2406
 620/1000 [=================>............] - ETA: 1:49 - loss: 1.2352 - regression_loss: 0.9943 - classification_loss: 0.2408
 621/1000 [=================>............] - ETA: 1:48 - loss: 1.2362 - regression_loss: 0.9952 - classification_loss: 0.2411
 622/1000 [=================>............] - ETA: 1:48 - loss: 1.2359 - regression_loss: 0.9950 - classification_loss: 0.2409
 623/1000 [=================>............] - ETA: 1:48 - loss: 1.2351 - regression_loss: 0.9945 - classification_loss: 0.2406
 624/1000 [=================>............] - ETA: 1:47 - loss: 1.2351 - regression_loss: 0.9945 - classification_loss: 0.2406
 625/1000 [=================>............] - ETA: 1:47 - loss: 1.2341 - regression_loss: 0.9937 - classification_loss: 0.2404
 626/1000 [=================>............] - ETA: 1:47 - loss: 1.2343 - regression_loss: 0.9939 - classification_loss: 0.2404
 627/1000 [=================>............] - ETA: 1:47 - loss: 1.2345 - regression_loss: 0.9941 - classification_loss: 0.2404
 628/1000 [=================>............] - ETA: 1:46 - loss: 1.2340 - regression_loss: 0.9937 - classification_loss: 0.2402
 629/1000 [=================>............] - ETA: 1:46 - loss: 1.2337 - regression_loss: 0.9936 - classification_loss: 0.2401
 630/1000 [=================>............] - ETA: 1:46 - loss: 1.2330 - regression_loss: 0.9930 - classification_loss: 0.2400
 631/1000 [=================>............] - ETA: 1:45 - loss: 1.2324 - regression_loss: 0.9927 - classification_loss: 0.2398
 632/1000 [=================>............] - ETA: 1:45 - loss: 1.2335 - regression_loss: 0.9935 - classification_loss: 0.2399
 633/1000 [=================>............] - ETA: 1:45 - loss: 1.2327 - regression_loss: 0.9929 - classification_loss: 0.2398
 634/1000 [==================>...........] - ETA: 1:45 - loss: 1.2326 - regression_loss: 0.9922 - classification_loss: 0.2403
 635/1000 [==================>...........] - ETA: 1:44 - loss: 1.2320 - regression_loss: 0.9918 - classification_loss: 0.2402
 636/1000 [==================>...........] - ETA: 1:44 - loss: 1.2309 - regression_loss: 0.9910 - classification_loss: 0.2399
 637/1000 [==================>...........] - ETA: 1:44 - loss: 1.2328 - regression_loss: 0.9922 - classification_loss: 0.2405
 638/1000 [==================>...........] - ETA: 1:43 - loss: 1.2328 - regression_loss: 0.9923 - classification_loss: 0.2405
 639/1000 [==================>...........] - ETA: 1:43 - loss: 1.2317 - regression_loss: 0.9914 - classification_loss: 0.2402
 640/1000 [==================>...........] - ETA: 1:43 - loss: 1.2311 - regression_loss: 0.9911 - classification_loss: 0.2400
 641/1000 [==================>...........] - ETA: 1:43 - loss: 1.2309 - regression_loss: 0.9909 - classification_loss: 0.2400
 642/1000 [==================>...........] - ETA: 1:42 - loss: 1.2310 - regression_loss: 0.9910 - classification_loss: 0.2399
 643/1000 [==================>...........] - ETA: 1:42 - loss: 1.2318 - regression_loss: 0.9916 - classification_loss: 0.2402
 644/1000 [==================>...........] - ETA: 1:42 - loss: 1.2318 - regression_loss: 0.9916 - classification_loss: 0.2402
 645/1000 [==================>...........] - ETA: 1:41 - loss: 1.2307 - regression_loss: 0.9908 - classification_loss: 0.2399
 646/1000 [==================>...........] - ETA: 1:41 - loss: 1.2321 - regression_loss: 0.9919 - classification_loss: 0.2402
 647/1000 [==================>...........] - ETA: 1:41 - loss: 1.2311 - regression_loss: 0.9910 - classification_loss: 0.2401
 648/1000 [==================>...........] - ETA: 1:41 - loss: 1.2320 - regression_loss: 0.9918 - classification_loss: 0.2402
 649/1000 [==================>...........] - ETA: 1:40 - loss: 1.2313 - regression_loss: 0.9913 - classification_loss: 0.2400
 650/1000 [==================>...........] - ETA: 1:40 - loss: 1.2313 - regression_loss: 0.9913 - classification_loss: 0.2400
 651/1000 [==================>...........] - ETA: 1:40 - loss: 1.2329 - regression_loss: 0.9925 - classification_loss: 0.2404
 652/1000 [==================>...........] - ETA: 1:39 - loss: 1.2324 - regression_loss: 0.9920 - classification_loss: 0.2404
 653/1000 [==================>...........] - ETA: 1:39 - loss: 1.2325 - regression_loss: 0.9922 - classification_loss: 0.2403
 654/1000 [==================>...........] - ETA: 1:39 - loss: 1.2321 - regression_loss: 0.9920 - classification_loss: 0.2401
 655/1000 [==================>...........] - ETA: 1:39 - loss: 1.2318 - regression_loss: 0.9918 - classification_loss: 0.2399
 656/1000 [==================>...........] - ETA: 1:38 - loss: 1.2313 - regression_loss: 0.9916 - classification_loss: 0.2397
 657/1000 [==================>...........] - ETA: 1:38 - loss: 1.2312 - regression_loss: 0.9916 - classification_loss: 0.2396
 658/1000 [==================>...........] - ETA: 1:38 - loss: 1.2313 - regression_loss: 0.9917 - classification_loss: 0.2396
 659/1000 [==================>...........] - ETA: 1:37 - loss: 1.2306 - regression_loss: 0.9909 - classification_loss: 0.2397
 660/1000 [==================>...........] - ETA: 1:37 - loss: 1.2300 - regression_loss: 0.9903 - classification_loss: 0.2397
 661/1000 [==================>...........] - ETA: 1:37 - loss: 1.2290 - regression_loss: 0.9894 - classification_loss: 0.2395
 662/1000 [==================>...........] - ETA: 1:37 - loss: 1.2297 - regression_loss: 0.9900 - classification_loss: 0.2397
 663/1000 [==================>...........] - ETA: 1:36 - loss: 1.2301 - regression_loss: 0.9903 - classification_loss: 0.2398
 664/1000 [==================>...........] - ETA: 1:36 - loss: 1.2292 - regression_loss: 0.9896 - classification_loss: 0.2396
 665/1000 [==================>...........] - ETA: 1:36 - loss: 1.2295 - regression_loss: 0.9900 - classification_loss: 0.2395
 666/1000 [==================>...........] - ETA: 1:35 - loss: 1.2294 - regression_loss: 0.9900 - classification_loss: 0.2394
 667/1000 [===================>..........] - ETA: 1:35 - loss: 1.2288 - regression_loss: 0.9895 - classification_loss: 0.2393
 668/1000 [===================>..........] - ETA: 1:35 - loss: 1.2282 - regression_loss: 0.9891 - classification_loss: 0.2391
 669/1000 [===================>..........] - ETA: 1:35 - loss: 1.2289 - regression_loss: 0.9897 - classification_loss: 0.2392
 670/1000 [===================>..........] - ETA: 1:34 - loss: 1.2287 - regression_loss: 0.9896 - classification_loss: 0.2391
 671/1000 [===================>..........] - ETA: 1:34 - loss: 1.2290 - regression_loss: 0.9899 - classification_loss: 0.2391
 672/1000 [===================>..........] - ETA: 1:34 - loss: 1.2289 - regression_loss: 0.9898 - classification_loss: 0.2390
 673/1000 [===================>..........] - ETA: 1:33 - loss: 1.2279 - regression_loss: 0.9891 - classification_loss: 0.2388
 674/1000 [===================>..........] - ETA: 1:33 - loss: 1.2283 - regression_loss: 0.9895 - classification_loss: 0.2388
 675/1000 [===================>..........] - ETA: 1:33 - loss: 1.2278 - regression_loss: 0.9891 - classification_loss: 0.2387
 676/1000 [===================>..........] - ETA: 1:33 - loss: 1.2275 - regression_loss: 0.9889 - classification_loss: 0.2385
 677/1000 [===================>..........] - ETA: 1:32 - loss: 1.2273 - regression_loss: 0.9888 - classification_loss: 0.2384
 678/1000 [===================>..........] - ETA: 1:32 - loss: 1.2272 - regression_loss: 0.9889 - classification_loss: 0.2383
 679/1000 [===================>..........] - ETA: 1:32 - loss: 1.2262 - regression_loss: 0.9880 - classification_loss: 0.2382
 680/1000 [===================>..........] - ETA: 1:31 - loss: 1.2266 - regression_loss: 0.9883 - classification_loss: 0.2383
 681/1000 [===================>..........] - ETA: 1:31 - loss: 1.2283 - regression_loss: 0.9898 - classification_loss: 0.2385
 682/1000 [===================>..........] - ETA: 1:31 - loss: 1.2288 - regression_loss: 0.9900 - classification_loss: 0.2388
 683/1000 [===================>..........] - ETA: 1:31 - loss: 1.2293 - regression_loss: 0.9905 - classification_loss: 0.2388
 684/1000 [===================>..........] - ETA: 1:30 - loss: 1.2301 - regression_loss: 0.9911 - classification_loss: 0.2389
 685/1000 [===================>..........] - ETA: 1:30 - loss: 1.2295 - regression_loss: 0.9908 - classification_loss: 0.2388
 686/1000 [===================>..........] - ETA: 1:30 - loss: 1.2297 - regression_loss: 0.9907 - classification_loss: 0.2389
 687/1000 [===================>..........] - ETA: 1:29 - loss: 1.2290 - regression_loss: 0.9902 - classification_loss: 0.2388
 688/1000 [===================>..........] - ETA: 1:29 - loss: 1.2291 - regression_loss: 0.9902 - classification_loss: 0.2388
 689/1000 [===================>..........] - ETA: 1:29 - loss: 1.2311 - regression_loss: 0.9915 - classification_loss: 0.2395
 690/1000 [===================>..........] - ETA: 1:29 - loss: 1.2310 - regression_loss: 0.9914 - classification_loss: 0.2396
 691/1000 [===================>..........] - ETA: 1:28 - loss: 1.2298 - regression_loss: 0.9904 - classification_loss: 0.2393
 692/1000 [===================>..........] - ETA: 1:28 - loss: 1.2298 - regression_loss: 0.9906 - classification_loss: 0.2391
 693/1000 [===================>..........] - ETA: 1:28 - loss: 1.2296 - regression_loss: 0.9905 - classification_loss: 0.2391
 694/1000 [===================>..........] - ETA: 1:27 - loss: 1.2289 - regression_loss: 0.9900 - classification_loss: 0.2389
 695/1000 [===================>..........] - ETA: 1:27 - loss: 1.2288 - regression_loss: 0.9901 - classification_loss: 0.2387
 696/1000 [===================>..........] - ETA: 1:27 - loss: 1.2285 - regression_loss: 0.9899 - classification_loss: 0.2386
 697/1000 [===================>..........] - ETA: 1:27 - loss: 1.2278 - regression_loss: 0.9894 - classification_loss: 0.2384
 698/1000 [===================>..........] - ETA: 1:26 - loss: 1.2269 - regression_loss: 0.9888 - classification_loss: 0.2381
 699/1000 [===================>..........] - ETA: 1:26 - loss: 1.2265 - regression_loss: 0.9884 - classification_loss: 0.2380
 700/1000 [====================>.........] - ETA: 1:26 - loss: 1.2263 - regression_loss: 0.9884 - classification_loss: 0.2379
 701/1000 [====================>.........] - ETA: 1:25 - loss: 1.2256 - regression_loss: 0.9877 - classification_loss: 0.2379
 702/1000 [====================>.........] - ETA: 1:25 - loss: 1.2258 - regression_loss: 0.9874 - classification_loss: 0.2384
 703/1000 [====================>.........] - ETA: 1:25 - loss: 1.2267 - regression_loss: 0.9882 - classification_loss: 0.2385
 704/1000 [====================>.........] - ETA: 1:25 - loss: 1.2264 - regression_loss: 0.9881 - classification_loss: 0.2383
 705/1000 [====================>.........] - ETA: 1:24 - loss: 1.2271 - regression_loss: 0.9886 - classification_loss: 0.2385
 706/1000 [====================>.........] - ETA: 1:24 - loss: 1.2284 - regression_loss: 0.9897 - classification_loss: 0.2387
 707/1000 [====================>.........] - ETA: 1:24 - loss: 1.2282 - regression_loss: 0.9897 - classification_loss: 0.2385
 708/1000 [====================>.........] - ETA: 1:23 - loss: 1.2297 - regression_loss: 0.9910 - classification_loss: 0.2387
 709/1000 [====================>.........] - ETA: 1:23 - loss: 1.2298 - regression_loss: 0.9912 - classification_loss: 0.2386
 710/1000 [====================>.........] - ETA: 1:23 - loss: 1.2296 - regression_loss: 0.9911 - classification_loss: 0.2385
 711/1000 [====================>.........] - ETA: 1:23 - loss: 1.2302 - regression_loss: 0.9915 - classification_loss: 0.2386
 712/1000 [====================>.........] - ETA: 1:22 - loss: 1.2323 - regression_loss: 0.9936 - classification_loss: 0.2387
 713/1000 [====================>.........] - ETA: 1:22 - loss: 1.2324 - regression_loss: 0.9938 - classification_loss: 0.2386
 714/1000 [====================>.........] - ETA: 1:22 - loss: 1.2316 - regression_loss: 0.9932 - classification_loss: 0.2384
 715/1000 [====================>.........] - ETA: 1:21 - loss: 1.2316 - regression_loss: 0.9933 - classification_loss: 0.2383
 716/1000 [====================>.........] - ETA: 1:21 - loss: 1.2304 - regression_loss: 0.9923 - classification_loss: 0.2381
 717/1000 [====================>.........] - ETA: 1:21 - loss: 1.2305 - regression_loss: 0.9925 - classification_loss: 0.2380
 718/1000 [====================>.........] - ETA: 1:20 - loss: 1.2301 - regression_loss: 0.9923 - classification_loss: 0.2379
 719/1000 [====================>.........] - ETA: 1:20 - loss: 1.2300 - regression_loss: 0.9922 - classification_loss: 0.2378
 720/1000 [====================>.........] - ETA: 1:20 - loss: 1.2309 - regression_loss: 0.9930 - classification_loss: 0.2379
 721/1000 [====================>.........] - ETA: 1:20 - loss: 1.2316 - regression_loss: 0.9934 - classification_loss: 0.2382
 722/1000 [====================>.........] - ETA: 1:19 - loss: 1.2320 - regression_loss: 0.9920 - classification_loss: 0.2400
 723/1000 [====================>.........] - ETA: 1:19 - loss: 1.2320 - regression_loss: 0.9920 - classification_loss: 0.2400
 724/1000 [====================>.........] - ETA: 1:19 - loss: 1.2322 - regression_loss: 0.9923 - classification_loss: 0.2399
 725/1000 [====================>.........] - ETA: 1:18 - loss: 1.2333 - regression_loss: 0.9932 - classification_loss: 0.2401
 726/1000 [====================>.........] - ETA: 1:18 - loss: 1.2330 - regression_loss: 0.9930 - classification_loss: 0.2400
 727/1000 [====================>.........] - ETA: 1:18 - loss: 1.2325 - regression_loss: 0.9927 - classification_loss: 0.2398
 728/1000 [====================>.........] - ETA: 1:18 - loss: 1.2316 - regression_loss: 0.9921 - classification_loss: 0.2396
 729/1000 [====================>.........] - ETA: 1:17 - loss: 1.2326 - regression_loss: 0.9927 - classification_loss: 0.2399
 730/1000 [====================>.........] - ETA: 1:17 - loss: 1.2322 - regression_loss: 0.9922 - classification_loss: 0.2399
 731/1000 [====================>.........] - ETA: 1:17 - loss: 1.2321 - regression_loss: 0.9923 - classification_loss: 0.2399
 732/1000 [====================>.........] - ETA: 1:16 - loss: 1.2323 - regression_loss: 0.9926 - classification_loss: 0.2397
 733/1000 [====================>.........] - ETA: 1:16 - loss: 1.2321 - regression_loss: 0.9925 - classification_loss: 0.2396
 734/1000 [=====================>........] - ETA: 1:16 - loss: 1.2313 - regression_loss: 0.9919 - classification_loss: 0.2395
 735/1000 [=====================>........] - ETA: 1:16 - loss: 1.2303 - regression_loss: 0.9910 - classification_loss: 0.2393
 736/1000 [=====================>........] - ETA: 1:15 - loss: 1.2297 - regression_loss: 0.9906 - classification_loss: 0.2391
 737/1000 [=====================>........] - ETA: 1:15 - loss: 1.2298 - regression_loss: 0.9905 - classification_loss: 0.2392
 738/1000 [=====================>........] - ETA: 1:15 - loss: 1.2300 - regression_loss: 0.9907 - classification_loss: 0.2392
 739/1000 [=====================>........] - ETA: 1:14 - loss: 1.2290 - regression_loss: 0.9900 - classification_loss: 0.2390
 740/1000 [=====================>........] - ETA: 1:14 - loss: 1.2281 - regression_loss: 0.9893 - classification_loss: 0.2388
 741/1000 [=====================>........] - ETA: 1:14 - loss: 1.2288 - regression_loss: 0.9899 - classification_loss: 0.2389
 742/1000 [=====================>........] - ETA: 1:14 - loss: 1.2279 - regression_loss: 0.9890 - classification_loss: 0.2389
 743/1000 [=====================>........] - ETA: 1:13 - loss: 1.2288 - regression_loss: 0.9896 - classification_loss: 0.2392
 744/1000 [=====================>........] - ETA: 1:13 - loss: 1.2286 - regression_loss: 0.9896 - classification_loss: 0.2390
 745/1000 [=====================>........] - ETA: 1:13 - loss: 1.2285 - regression_loss: 0.9895 - classification_loss: 0.2390
 746/1000 [=====================>........] - ETA: 1:12 - loss: 1.2277 - regression_loss: 0.9890 - classification_loss: 0.2387
 747/1000 [=====================>........] - ETA: 1:12 - loss: 1.2269 - regression_loss: 0.9883 - classification_loss: 0.2386
 748/1000 [=====================>........] - ETA: 1:12 - loss: 1.2269 - regression_loss: 0.9884 - classification_loss: 0.2385
 749/1000 [=====================>........] - ETA: 1:12 - loss: 1.2271 - regression_loss: 0.9883 - classification_loss: 0.2388
 750/1000 [=====================>........] - ETA: 1:11 - loss: 1.2268 - regression_loss: 0.9881 - classification_loss: 0.2387
 751/1000 [=====================>........] - ETA: 1:11 - loss: 1.2286 - regression_loss: 0.9897 - classification_loss: 0.2389
 752/1000 [=====================>........] - ETA: 1:11 - loss: 1.2292 - regression_loss: 0.9903 - classification_loss: 0.2390
 753/1000 [=====================>........] - ETA: 1:10 - loss: 1.2297 - regression_loss: 0.9907 - classification_loss: 0.2390
 754/1000 [=====================>........] - ETA: 1:10 - loss: 1.2293 - regression_loss: 0.9905 - classification_loss: 0.2388
 755/1000 [=====================>........] - ETA: 1:10 - loss: 1.2295 - regression_loss: 0.9907 - classification_loss: 0.2389
 756/1000 [=====================>........] - ETA: 1:10 - loss: 1.2288 - regression_loss: 0.9901 - classification_loss: 0.2387
 757/1000 [=====================>........] - ETA: 1:09 - loss: 1.2286 - regression_loss: 0.9900 - classification_loss: 0.2386
 758/1000 [=====================>........] - ETA: 1:09 - loss: 1.2284 - regression_loss: 0.9899 - classification_loss: 0.2385
 759/1000 [=====================>........] - ETA: 1:09 - loss: 1.2281 - regression_loss: 0.9898 - classification_loss: 0.2383
 760/1000 [=====================>........] - ETA: 1:08 - loss: 1.2287 - regression_loss: 0.9903 - classification_loss: 0.2384
 761/1000 [=====================>........] - ETA: 1:08 - loss: 1.2276 - regression_loss: 0.9894 - classification_loss: 0.2382
 762/1000 [=====================>........] - ETA: 1:08 - loss: 1.2267 - regression_loss: 0.9888 - classification_loss: 0.2379
 763/1000 [=====================>........] - ETA: 1:08 - loss: 1.2274 - regression_loss: 0.9894 - classification_loss: 0.2380
 764/1000 [=====================>........] - ETA: 1:07 - loss: 1.2287 - regression_loss: 0.9904 - classification_loss: 0.2383
 765/1000 [=====================>........] - ETA: 1:07 - loss: 1.2281 - regression_loss: 0.9900 - classification_loss: 0.2381
 766/1000 [=====================>........] - ETA: 1:07 - loss: 1.2276 - regression_loss: 0.9895 - classification_loss: 0.2380
 767/1000 [======================>.......] - ETA: 1:06 - loss: 1.2273 - regression_loss: 0.9892 - classification_loss: 0.2381
 768/1000 [======================>.......] - ETA: 1:06 - loss: 1.2279 - regression_loss: 0.9896 - classification_loss: 0.2384
 769/1000 [======================>.......] - ETA: 1:06 - loss: 1.2277 - regression_loss: 0.9894 - classification_loss: 0.2382
 770/1000 [======================>.......] - ETA: 1:06 - loss: 1.2277 - regression_loss: 0.9895 - classification_loss: 0.2382
 771/1000 [======================>.......] - ETA: 1:05 - loss: 1.2274 - regression_loss: 0.9893 - classification_loss: 0.2381
 772/1000 [======================>.......] - ETA: 1:05 - loss: 1.2280 - regression_loss: 0.9898 - classification_loss: 0.2382
 773/1000 [======================>.......] - ETA: 1:05 - loss: 1.2290 - regression_loss: 0.9907 - classification_loss: 0.2383
 774/1000 [======================>.......] - ETA: 1:04 - loss: 1.2298 - regression_loss: 0.9914 - classification_loss: 0.2384
 775/1000 [======================>.......] - ETA: 1:04 - loss: 1.2305 - regression_loss: 0.9920 - classification_loss: 0.2385
 776/1000 [======================>.......] - ETA: 1:04 - loss: 1.2301 - regression_loss: 0.9916 - classification_loss: 0.2385
 777/1000 [======================>.......] - ETA: 1:04 - loss: 1.2297 - regression_loss: 0.9913 - classification_loss: 0.2383
 778/1000 [======================>.......] - ETA: 1:03 - loss: 1.2300 - regression_loss: 0.9916 - classification_loss: 0.2385
 779/1000 [======================>.......] - ETA: 1:03 - loss: 1.2291 - regression_loss: 0.9909 - classification_loss: 0.2382
 780/1000 [======================>.......] - ETA: 1:03 - loss: 1.2287 - regression_loss: 0.9904 - classification_loss: 0.2382
 781/1000 [======================>.......] - ETA: 1:02 - loss: 1.2283 - regression_loss: 0.9903 - classification_loss: 0.2380
 782/1000 [======================>.......] - ETA: 1:02 - loss: 1.2287 - regression_loss: 0.9905 - classification_loss: 0.2381
 783/1000 [======================>.......] - ETA: 1:02 - loss: 1.2283 - regression_loss: 0.9903 - classification_loss: 0.2380
 784/1000 [======================>.......] - ETA: 1:02 - loss: 1.2291 - regression_loss: 0.9911 - classification_loss: 0.2380
 785/1000 [======================>.......] - ETA: 1:01 - loss: 1.2289 - regression_loss: 0.9910 - classification_loss: 0.2379
 786/1000 [======================>.......] - ETA: 1:01 - loss: 1.2291 - regression_loss: 0.9912 - classification_loss: 0.2379
 787/1000 [======================>.......] - ETA: 1:01 - loss: 1.2287 - regression_loss: 0.9908 - classification_loss: 0.2379
 788/1000 [======================>.......] - ETA: 1:00 - loss: 1.2288 - regression_loss: 0.9910 - classification_loss: 0.2378
 789/1000 [======================>.......] - ETA: 1:00 - loss: 1.2287 - regression_loss: 0.9910 - classification_loss: 0.2377
 790/1000 [======================>.......] - ETA: 1:00 - loss: 1.2292 - regression_loss: 0.9915 - classification_loss: 0.2377
 791/1000 [======================>.......] - ETA: 1:00 - loss: 1.2310 - regression_loss: 0.9927 - classification_loss: 0.2383
 792/1000 [======================>.......] - ETA: 59s - loss: 1.2313 - regression_loss: 0.9930 - classification_loss: 0.2383 
 793/1000 [======================>.......] - ETA: 59s - loss: 1.2307 - regression_loss: 0.9926 - classification_loss: 0.2381
 794/1000 [======================>.......] - ETA: 59s - loss: 1.2302 - regression_loss: 0.9922 - classification_loss: 0.2381
 795/1000 [======================>.......] - ETA: 58s - loss: 1.2300 - regression_loss: 0.9920 - classification_loss: 0.2379
 796/1000 [======================>.......] - ETA: 58s - loss: 1.2291 - regression_loss: 0.9914 - classification_loss: 0.2377
 797/1000 [======================>.......] - ETA: 58s - loss: 1.2285 - regression_loss: 0.9909 - classification_loss: 0.2375
 798/1000 [======================>.......] - ETA: 58s - loss: 1.2288 - regression_loss: 0.9911 - classification_loss: 0.2378
 799/1000 [======================>.......] - ETA: 57s - loss: 1.2287 - regression_loss: 0.9910 - classification_loss: 0.2377
 800/1000 [=======================>......] - ETA: 57s - loss: 1.2283 - regression_loss: 0.9908 - classification_loss: 0.2376
 801/1000 [=======================>......] - ETA: 57s - loss: 1.2285 - regression_loss: 0.9909 - classification_loss: 0.2375
 802/1000 [=======================>......] - ETA: 56s - loss: 1.2299 - regression_loss: 0.9920 - classification_loss: 0.2379
 803/1000 [=======================>......] - ETA: 56s - loss: 1.2304 - regression_loss: 0.9923 - classification_loss: 0.2382
 804/1000 [=======================>......] - ETA: 56s - loss: 1.2317 - regression_loss: 0.9933 - classification_loss: 0.2384
 805/1000 [=======================>......] - ETA: 55s - loss: 1.2313 - regression_loss: 0.9930 - classification_loss: 0.2382
 806/1000 [=======================>......] - ETA: 55s - loss: 1.2307 - regression_loss: 0.9926 - classification_loss: 0.2381
 807/1000 [=======================>......] - ETA: 55s - loss: 1.2303 - regression_loss: 0.9923 - classification_loss: 0.2380
 808/1000 [=======================>......] - ETA: 55s - loss: 1.2303 - regression_loss: 0.9924 - classification_loss: 0.2379
 809/1000 [=======================>......] - ETA: 54s - loss: 1.2300 - regression_loss: 0.9921 - classification_loss: 0.2379
 810/1000 [=======================>......] - ETA: 54s - loss: 1.2293 - regression_loss: 0.9916 - classification_loss: 0.2377
 811/1000 [=======================>......] - ETA: 54s - loss: 1.2289 - regression_loss: 0.9913 - classification_loss: 0.2376
 812/1000 [=======================>......] - ETA: 53s - loss: 1.2281 - regression_loss: 0.9907 - classification_loss: 0.2374
 813/1000 [=======================>......] - ETA: 53s - loss: 1.2278 - regression_loss: 0.9905 - classification_loss: 0.2373
 814/1000 [=======================>......] - ETA: 53s - loss: 1.2270 - regression_loss: 0.9899 - classification_loss: 0.2371
 815/1000 [=======================>......] - ETA: 53s - loss: 1.2268 - regression_loss: 0.9897 - classification_loss: 0.2371
 816/1000 [=======================>......] - ETA: 52s - loss: 1.2270 - regression_loss: 0.9898 - classification_loss: 0.2371
 817/1000 [=======================>......] - ETA: 52s - loss: 1.2270 - regression_loss: 0.9899 - classification_loss: 0.2370
 818/1000 [=======================>......] - ETA: 52s - loss: 1.2264 - regression_loss: 0.9895 - classification_loss: 0.2370
 819/1000 [=======================>......] - ETA: 51s - loss: 1.2269 - regression_loss: 0.9898 - classification_loss: 0.2371
 820/1000 [=======================>......] - ETA: 51s - loss: 1.2273 - regression_loss: 0.9901 - classification_loss: 0.2372
 821/1000 [=======================>......] - ETA: 51s - loss: 1.2267 - regression_loss: 0.9896 - classification_loss: 0.2370
 822/1000 [=======================>......] - ETA: 51s - loss: 1.2267 - regression_loss: 0.9895 - classification_loss: 0.2372
 823/1000 [=======================>......] - ETA: 50s - loss: 1.2264 - regression_loss: 0.9894 - classification_loss: 0.2370
 824/1000 [=======================>......] - ETA: 50s - loss: 1.2264 - regression_loss: 0.9895 - classification_loss: 0.2369
 825/1000 [=======================>......] - ETA: 50s - loss: 1.2266 - regression_loss: 0.9897 - classification_loss: 0.2369
 826/1000 [=======================>......] - ETA: 49s - loss: 1.2257 - regression_loss: 0.9890 - classification_loss: 0.2367
 827/1000 [=======================>......] - ETA: 49s - loss: 1.2250 - regression_loss: 0.9884 - classification_loss: 0.2366
 828/1000 [=======================>......] - ETA: 49s - loss: 1.2255 - regression_loss: 0.9888 - classification_loss: 0.2367
 829/1000 [=======================>......] - ETA: 49s - loss: 1.2253 - regression_loss: 0.9886 - classification_loss: 0.2367
 830/1000 [=======================>......] - ETA: 48s - loss: 1.2255 - regression_loss: 0.9886 - classification_loss: 0.2369
 831/1000 [=======================>......] - ETA: 48s - loss: 1.2258 - regression_loss: 0.9889 - classification_loss: 0.2369
 832/1000 [=======================>......] - ETA: 48s - loss: 1.2258 - regression_loss: 0.9890 - classification_loss: 0.2369
 833/1000 [=======================>......] - ETA: 47s - loss: 1.2260 - regression_loss: 0.9891 - classification_loss: 0.2369
 834/1000 [========================>.....] - ETA: 47s - loss: 1.2259 - regression_loss: 0.9891 - classification_loss: 0.2368
 835/1000 [========================>.....] - ETA: 47s - loss: 1.2263 - regression_loss: 0.9895 - classification_loss: 0.2368
 836/1000 [========================>.....] - ETA: 47s - loss: 1.2259 - regression_loss: 0.9892 - classification_loss: 0.2367
 837/1000 [========================>.....] - ETA: 46s - loss: 1.2261 - regression_loss: 0.9894 - classification_loss: 0.2367
 838/1000 [========================>.....] - ETA: 46s - loss: 1.2260 - regression_loss: 0.9894 - classification_loss: 0.2366
 839/1000 [========================>.....] - ETA: 46s - loss: 1.2259 - regression_loss: 0.9893 - classification_loss: 0.2366
 840/1000 [========================>.....] - ETA: 45s - loss: 1.2254 - regression_loss: 0.9891 - classification_loss: 0.2364
 841/1000 [========================>.....] - ETA: 45s - loss: 1.2249 - regression_loss: 0.9885 - classification_loss: 0.2363
 842/1000 [========================>.....] - ETA: 45s - loss: 1.2241 - regression_loss: 0.9880 - classification_loss: 0.2361
 843/1000 [========================>.....] - ETA: 45s - loss: 1.2243 - regression_loss: 0.9882 - classification_loss: 0.2360
 844/1000 [========================>.....] - ETA: 44s - loss: 1.2246 - regression_loss: 0.9886 - classification_loss: 0.2360
 845/1000 [========================>.....] - ETA: 44s - loss: 1.2253 - regression_loss: 0.9893 - classification_loss: 0.2359
 846/1000 [========================>.....] - ETA: 44s - loss: 1.2254 - regression_loss: 0.9895 - classification_loss: 0.2359
 847/1000 [========================>.....] - ETA: 43s - loss: 1.2262 - regression_loss: 0.9899 - classification_loss: 0.2363
 848/1000 [========================>.....] - ETA: 43s - loss: 1.2267 - regression_loss: 0.9905 - classification_loss: 0.2362
 849/1000 [========================>.....] - ETA: 43s - loss: 1.2265 - regression_loss: 0.9903 - classification_loss: 0.2362
 850/1000 [========================>.....] - ETA: 43s - loss: 1.2259 - regression_loss: 0.9899 - classification_loss: 0.2360
 851/1000 [========================>.....] - ETA: 42s - loss: 1.2261 - regression_loss: 0.9902 - classification_loss: 0.2359
 852/1000 [========================>.....] - ETA: 42s - loss: 1.2257 - regression_loss: 0.9898 - classification_loss: 0.2358
 853/1000 [========================>.....] - ETA: 42s - loss: 1.2267 - regression_loss: 0.9906 - classification_loss: 0.2361
 854/1000 [========================>.....] - ETA: 41s - loss: 1.2269 - regression_loss: 0.9908 - classification_loss: 0.2361
 855/1000 [========================>.....] - ETA: 41s - loss: 1.2272 - regression_loss: 0.9911 - classification_loss: 0.2362
 856/1000 [========================>.....] - ETA: 41s - loss: 1.2268 - regression_loss: 0.9908 - classification_loss: 0.2360
 857/1000 [========================>.....] - ETA: 41s - loss: 1.2275 - regression_loss: 0.9914 - classification_loss: 0.2361
 858/1000 [========================>.....] - ETA: 40s - loss: 1.2293 - regression_loss: 0.9924 - classification_loss: 0.2369
 859/1000 [========================>.....] - ETA: 40s - loss: 1.2298 - regression_loss: 0.9929 - classification_loss: 0.2369
 860/1000 [========================>.....] - ETA: 40s - loss: 1.2289 - regression_loss: 0.9921 - classification_loss: 0.2367
 861/1000 [========================>.....] - ETA: 39s - loss: 1.2292 - regression_loss: 0.9925 - classification_loss: 0.2367
 862/1000 [========================>.....] - ETA: 39s - loss: 1.2293 - regression_loss: 0.9927 - classification_loss: 0.2366
 863/1000 [========================>.....] - ETA: 39s - loss: 1.2292 - regression_loss: 0.9927 - classification_loss: 0.2365
 864/1000 [========================>.....] - ETA: 39s - loss: 1.2304 - regression_loss: 0.9936 - classification_loss: 0.2368
 865/1000 [========================>.....] - ETA: 38s - loss: 1.2304 - regression_loss: 0.9936 - classification_loss: 0.2367
 866/1000 [========================>.....] - ETA: 38s - loss: 1.2296 - regression_loss: 0.9931 - classification_loss: 0.2365
 867/1000 [=========================>....] - ETA: 38s - loss: 1.2296 - regression_loss: 0.9931 - classification_loss: 0.2365
 868/1000 [=========================>....] - ETA: 37s - loss: 1.2293 - regression_loss: 0.9929 - classification_loss: 0.2364
 869/1000 [=========================>....] - ETA: 37s - loss: 1.2294 - regression_loss: 0.9928 - classification_loss: 0.2365
 870/1000 [=========================>....] - ETA: 37s - loss: 1.2287 - regression_loss: 0.9923 - classification_loss: 0.2364
 871/1000 [=========================>....] - ETA: 37s - loss: 1.2279 - regression_loss: 0.9917 - classification_loss: 0.2362
 872/1000 [=========================>....] - ETA: 36s - loss: 1.2274 - regression_loss: 0.9912 - classification_loss: 0.2361
 873/1000 [=========================>....] - ETA: 36s - loss: 1.2267 - regression_loss: 0.9907 - classification_loss: 0.2360
 874/1000 [=========================>....] - ETA: 36s - loss: 1.2276 - regression_loss: 0.9914 - classification_loss: 0.2362
 875/1000 [=========================>....] - ETA: 35s - loss: 1.2273 - regression_loss: 0.9911 - classification_loss: 0.2362
 876/1000 [=========================>....] - ETA: 35s - loss: 1.2270 - regression_loss: 0.9909 - classification_loss: 0.2361
 877/1000 [=========================>....] - ETA: 35s - loss: 1.2278 - regression_loss: 0.9915 - classification_loss: 0.2363
 878/1000 [=========================>....] - ETA: 35s - loss: 1.2276 - regression_loss: 0.9913 - classification_loss: 0.2363
 879/1000 [=========================>....] - ETA: 34s - loss: 1.2271 - regression_loss: 0.9909 - classification_loss: 0.2363
 880/1000 [=========================>....] - ETA: 34s - loss: 1.2273 - regression_loss: 0.9910 - classification_loss: 0.2362
 881/1000 [=========================>....] - ETA: 34s - loss: 1.2277 - regression_loss: 0.9915 - classification_loss: 0.2362
 882/1000 [=========================>....] - ETA: 33s - loss: 1.2272 - regression_loss: 0.9912 - classification_loss: 0.2360
 883/1000 [=========================>....] - ETA: 33s - loss: 1.2284 - regression_loss: 0.9921 - classification_loss: 0.2363
 884/1000 [=========================>....] - ETA: 33s - loss: 1.2289 - regression_loss: 0.9925 - classification_loss: 0.2364
 885/1000 [=========================>....] - ETA: 33s - loss: 1.2293 - regression_loss: 0.9929 - classification_loss: 0.2364
 886/1000 [=========================>....] - ETA: 32s - loss: 1.2292 - regression_loss: 0.9929 - classification_loss: 0.2363
 887/1000 [=========================>....] - ETA: 32s - loss: 1.2287 - regression_loss: 0.9923 - classification_loss: 0.2364
 888/1000 [=========================>....] - ETA: 32s - loss: 1.2283 - regression_loss: 0.9919 - classification_loss: 0.2364
 889/1000 [=========================>....] - ETA: 31s - loss: 1.2287 - regression_loss: 0.9924 - classification_loss: 0.2364
 890/1000 [=========================>....] - ETA: 31s - loss: 1.2286 - regression_loss: 0.9920 - classification_loss: 0.2365
 891/1000 [=========================>....] - ETA: 31s - loss: 1.2295 - regression_loss: 0.9930 - classification_loss: 0.2366
 892/1000 [=========================>....] - ETA: 31s - loss: 1.2295 - regression_loss: 0.9930 - classification_loss: 0.2365
 893/1000 [=========================>....] - ETA: 30s - loss: 1.2298 - regression_loss: 0.9932 - classification_loss: 0.2366
 894/1000 [=========================>....] - ETA: 30s - loss: 1.2291 - regression_loss: 0.9927 - classification_loss: 0.2364
 895/1000 [=========================>....] - ETA: 30s - loss: 1.2287 - regression_loss: 0.9924 - classification_loss: 0.2363
 896/1000 [=========================>....] - ETA: 29s - loss: 1.2294 - regression_loss: 0.9930 - classification_loss: 0.2364
 897/1000 [=========================>....] - ETA: 29s - loss: 1.2296 - regression_loss: 0.9933 - classification_loss: 0.2364
 898/1000 [=========================>....] - ETA: 29s - loss: 1.2293 - regression_loss: 0.9931 - classification_loss: 0.2363
 899/1000 [=========================>....] - ETA: 29s - loss: 1.2299 - regression_loss: 0.9935 - classification_loss: 0.2364
 900/1000 [==========================>...] - ETA: 28s - loss: 1.2308 - regression_loss: 0.9941 - classification_loss: 0.2366
 901/1000 [==========================>...] - ETA: 28s - loss: 1.2309 - regression_loss: 0.9944 - classification_loss: 0.2365
 902/1000 [==========================>...] - ETA: 28s - loss: 1.2306 - regression_loss: 0.9940 - classification_loss: 0.2365
 903/1000 [==========================>...] - ETA: 27s - loss: 1.2304 - regression_loss: 0.9940 - classification_loss: 0.2364
 904/1000 [==========================>...] - ETA: 27s - loss: 1.2298 - regression_loss: 0.9936 - classification_loss: 0.2362
 905/1000 [==========================>...] - ETA: 27s - loss: 1.2292 - regression_loss: 0.9930 - classification_loss: 0.2362
 906/1000 [==========================>...] - ETA: 26s - loss: 1.2301 - regression_loss: 0.9938 - classification_loss: 0.2363
 907/1000 [==========================>...] - ETA: 26s - loss: 1.2305 - regression_loss: 0.9940 - classification_loss: 0.2365
 908/1000 [==========================>...] - ETA: 26s - loss: 1.2301 - regression_loss: 0.9936 - classification_loss: 0.2365
 909/1000 [==========================>...] - ETA: 26s - loss: 1.2297 - regression_loss: 0.9933 - classification_loss: 0.2364
 910/1000 [==========================>...] - ETA: 25s - loss: 1.2294 - regression_loss: 0.9932 - classification_loss: 0.2362
 911/1000 [==========================>...] - ETA: 25s - loss: 1.2295 - regression_loss: 0.9933 - classification_loss: 0.2362
 912/1000 [==========================>...] - ETA: 25s - loss: 1.2287 - regression_loss: 0.9926 - classification_loss: 0.2361
 913/1000 [==========================>...] - ETA: 24s - loss: 1.2290 - regression_loss: 0.9928 - classification_loss: 0.2362
 914/1000 [==========================>...] - ETA: 24s - loss: 1.2280 - regression_loss: 0.9921 - classification_loss: 0.2360
 915/1000 [==========================>...] - ETA: 24s - loss: 1.2271 - regression_loss: 0.9913 - classification_loss: 0.2358
 916/1000 [==========================>...] - ETA: 24s - loss: 1.2272 - regression_loss: 0.9914 - classification_loss: 0.2358
 917/1000 [==========================>...] - ETA: 23s - loss: 1.2270 - regression_loss: 0.9913 - classification_loss: 0.2357
 918/1000 [==========================>...] - ETA: 23s - loss: 1.2266 - regression_loss: 0.9910 - classification_loss: 0.2356
 919/1000 [==========================>...] - ETA: 23s - loss: 1.2262 - regression_loss: 0.9907 - classification_loss: 0.2355
 920/1000 [==========================>...] - ETA: 22s - loss: 1.2255 - regression_loss: 0.9900 - classification_loss: 0.2355
 921/1000 [==========================>...] - ETA: 22s - loss: 1.2249 - regression_loss: 0.9895 - classification_loss: 0.2354
 922/1000 [==========================>...] - ETA: 22s - loss: 1.2261 - regression_loss: 0.9905 - classification_loss: 0.2356
 923/1000 [==========================>...] - ETA: 22s - loss: 1.2269 - regression_loss: 0.9914 - classification_loss: 0.2355
 924/1000 [==========================>...] - ETA: 21s - loss: 1.2270 - regression_loss: 0.9915 - classification_loss: 0.2356
 925/1000 [==========================>...] - ETA: 21s - loss: 1.2265 - regression_loss: 0.9911 - classification_loss: 0.2354
 926/1000 [==========================>...] - ETA: 21s - loss: 1.2260 - regression_loss: 0.9907 - classification_loss: 0.2354
 927/1000 [==========================>...] - ETA: 20s - loss: 1.2260 - regression_loss: 0.9908 - classification_loss: 0.2353
 928/1000 [==========================>...] - ETA: 20s - loss: 1.2262 - regression_loss: 0.9910 - classification_loss: 0.2352
 929/1000 [==========================>...] - ETA: 20s - loss: 1.2259 - regression_loss: 0.9908 - classification_loss: 0.2351
 930/1000 [==========================>...] - ETA: 20s - loss: 1.2262 - regression_loss: 0.9912 - classification_loss: 0.2351
 931/1000 [==========================>...] - ETA: 19s - loss: 1.2255 - regression_loss: 0.9906 - classification_loss: 0.2349
 932/1000 [==========================>...] - ETA: 19s - loss: 1.2248 - regression_loss: 0.9901 - classification_loss: 0.2347
 933/1000 [==========================>...] - ETA: 19s - loss: 1.2239 - regression_loss: 0.9893 - classification_loss: 0.2345
 934/1000 [===========================>..] - ETA: 18s - loss: 1.2230 - regression_loss: 0.9886 - classification_loss: 0.2344
 935/1000 [===========================>..] - ETA: 18s - loss: 1.2236 - regression_loss: 0.9891 - classification_loss: 0.2344
 936/1000 [===========================>..] - ETA: 18s - loss: 1.2236 - regression_loss: 0.9893 - classification_loss: 0.2343
 937/1000 [===========================>..] - ETA: 18s - loss: 1.2238 - regression_loss: 0.9894 - classification_loss: 0.2343
 938/1000 [===========================>..] - ETA: 17s - loss: 1.2235 - regression_loss: 0.9892 - classification_loss: 0.2343
 939/1000 [===========================>..] - ETA: 17s - loss: 1.2242 - regression_loss: 0.9899 - classification_loss: 0.2343
 940/1000 [===========================>..] - ETA: 17s - loss: 1.2257 - regression_loss: 0.9911 - classification_loss: 0.2346
 941/1000 [===========================>..] - ETA: 16s - loss: 1.2263 - regression_loss: 0.9916 - classification_loss: 0.2347
 942/1000 [===========================>..] - ETA: 16s - loss: 1.2258 - regression_loss: 0.9912 - classification_loss: 0.2346
 943/1000 [===========================>..] - ETA: 16s - loss: 1.2255 - regression_loss: 0.9911 - classification_loss: 0.2344
 944/1000 [===========================>..] - ETA: 16s - loss: 1.2248 - regression_loss: 0.9905 - classification_loss: 0.2342
 945/1000 [===========================>..] - ETA: 15s - loss: 1.2250 - regression_loss: 0.9908 - classification_loss: 0.2342
 946/1000 [===========================>..] - ETA: 15s - loss: 1.2266 - regression_loss: 0.9921 - classification_loss: 0.2345
 947/1000 [===========================>..] - ETA: 15s - loss: 1.2271 - regression_loss: 0.9926 - classification_loss: 0.2345
 948/1000 [===========================>..] - ETA: 14s - loss: 1.2279 - regression_loss: 0.9932 - classification_loss: 0.2347
 949/1000 [===========================>..] - ETA: 14s - loss: 1.2283 - regression_loss: 0.9937 - classification_loss: 0.2347
 950/1000 [===========================>..] - ETA: 14s - loss: 1.2282 - regression_loss: 0.9936 - classification_loss: 0.2346
 951/1000 [===========================>..] - ETA: 14s - loss: 1.2280 - regression_loss: 0.9935 - classification_loss: 0.2345
 952/1000 [===========================>..] - ETA: 13s - loss: 1.2286 - regression_loss: 0.9941 - classification_loss: 0.2345
 953/1000 [===========================>..] - ETA: 13s - loss: 1.2283 - regression_loss: 0.9939 - classification_loss: 0.2344
 954/1000 [===========================>..] - ETA: 13s - loss: 1.2284 - regression_loss: 0.9941 - classification_loss: 0.2344
 955/1000 [===========================>..] - ETA: 12s - loss: 1.2283 - regression_loss: 0.9940 - classification_loss: 0.2343
 956/1000 [===========================>..] - ETA: 12s - loss: 1.2286 - regression_loss: 0.9943 - classification_loss: 0.2344
 957/1000 [===========================>..] - ETA: 12s - loss: 1.2287 - regression_loss: 0.9943 - classification_loss: 0.2344
 958/1000 [===========================>..] - ETA: 12s - loss: 1.2283 - regression_loss: 0.9940 - classification_loss: 0.2343
 959/1000 [===========================>..] - ETA: 11s - loss: 1.2283 - regression_loss: 0.9940 - classification_loss: 0.2343
 960/1000 [===========================>..] - ETA: 11s - loss: 1.2278 - regression_loss: 0.9936 - classification_loss: 0.2342
 961/1000 [===========================>..] - ETA: 11s - loss: 1.2284 - regression_loss: 0.9942 - classification_loss: 0.2343
 962/1000 [===========================>..] - ETA: 10s - loss: 1.2283 - regression_loss: 0.9941 - classification_loss: 0.2342
 963/1000 [===========================>..] - ETA: 10s - loss: 1.2286 - regression_loss: 0.9945 - classification_loss: 0.2341
 964/1000 [===========================>..] - ETA: 10s - loss: 1.2287 - regression_loss: 0.9946 - classification_loss: 0.2340
 965/1000 [===========================>..] - ETA: 10s - loss: 1.2283 - regression_loss: 0.9945 - classification_loss: 0.2338
 966/1000 [===========================>..] - ETA: 9s - loss: 1.2288 - regression_loss: 0.9948 - classification_loss: 0.2340 
 967/1000 [============================>.] - ETA: 9s - loss: 1.2287 - regression_loss: 0.9948 - classification_loss: 0.2339
 968/1000 [============================>.] - ETA: 9s - loss: 1.2289 - regression_loss: 0.9949 - classification_loss: 0.2340
 969/1000 [============================>.] - ETA: 8s - loss: 1.2307 - regression_loss: 0.9963 - classification_loss: 0.2344
 970/1000 [============================>.] - ETA: 8s - loss: 1.2300 - regression_loss: 0.9957 - classification_loss: 0.2343
 971/1000 [============================>.] - ETA: 8s - loss: 1.2304 - regression_loss: 0.9962 - classification_loss: 0.2342
 972/1000 [============================>.] - ETA: 8s - loss: 1.2299 - regression_loss: 0.9957 - classification_loss: 0.2341
 973/1000 [============================>.] - ETA: 7s - loss: 1.2300 - regression_loss: 0.9959 - classification_loss: 0.2341
 974/1000 [============================>.] - ETA: 7s - loss: 1.2303 - regression_loss: 0.9962 - classification_loss: 0.2341
 975/1000 [============================>.] - ETA: 7s - loss: 1.2303 - regression_loss: 0.9964 - classification_loss: 0.2340
 976/1000 [============================>.] - ETA: 6s - loss: 1.2298 - regression_loss: 0.9959 - classification_loss: 0.2338
 977/1000 [============================>.] - ETA: 6s - loss: 1.2288 - regression_loss: 0.9952 - classification_loss: 0.2336
 978/1000 [============================>.] - ETA: 6s - loss: 1.2292 - regression_loss: 0.9955 - classification_loss: 0.2337
 979/1000 [============================>.] - ETA: 6s - loss: 1.2290 - regression_loss: 0.9953 - classification_loss: 0.2337
 980/1000 [============================>.] - ETA: 5s - loss: 1.2284 - regression_loss: 0.9949 - classification_loss: 0.2335
 981/1000 [============================>.] - ETA: 5s - loss: 1.2286 - regression_loss: 0.9951 - classification_loss: 0.2335
 982/1000 [============================>.] - ETA: 5s - loss: 1.2288 - regression_loss: 0.9954 - classification_loss: 0.2335
 983/1000 [============================>.] - ETA: 4s - loss: 1.2287 - regression_loss: 0.9953 - classification_loss: 0.2334
 984/1000 [============================>.] - ETA: 4s - loss: 1.2287 - regression_loss: 0.9953 - classification_loss: 0.2334
 985/1000 [============================>.] - ETA: 4s - loss: 1.2292 - regression_loss: 0.9954 - classification_loss: 0.2339
 986/1000 [============================>.] - ETA: 4s - loss: 1.2290 - regression_loss: 0.9951 - classification_loss: 0.2340
 987/1000 [============================>.] - ETA: 3s - loss: 1.2291 - regression_loss: 0.9951 - classification_loss: 0.2339
 988/1000 [============================>.] - ETA: 3s - loss: 1.2289 - regression_loss: 0.9951 - classification_loss: 0.2339
 989/1000 [============================>.] - ETA: 3s - loss: 1.2292 - regression_loss: 0.9953 - classification_loss: 0.2339
 990/1000 [============================>.] - ETA: 2s - loss: 1.2293 - regression_loss: 0.9955 - classification_loss: 0.2339
 991/1000 [============================>.] - ETA: 2s - loss: 1.2298 - regression_loss: 0.9959 - classification_loss: 0.2338
 992/1000 [============================>.] - ETA: 2s - loss: 1.2292 - regression_loss: 0.9955 - classification_loss: 0.2337
 993/1000 [============================>.] - ETA: 2s - loss: 1.2290 - regression_loss: 0.9954 - classification_loss: 0.2336
 994/1000 [============================>.] - ETA: 1s - loss: 1.2292 - regression_loss: 0.9957 - classification_loss: 0.2336
 995/1000 [============================>.] - ETA: 1s - loss: 1.2294 - regression_loss: 0.9959 - classification_loss: 0.2335
 996/1000 [============================>.] - ETA: 1s - loss: 1.2292 - regression_loss: 0.9957 - classification_loss: 0.2335
 997/1000 [============================>.] - ETA: 0s - loss: 1.2289 - regression_loss: 0.9956 - classification_loss: 0.2333
 998/1000 [============================>.] - ETA: 0s - loss: 1.2287 - regression_loss: 0.9955 - classification_loss: 0.2333
 999/1000 [============================>.] - ETA: 0s - loss: 1.2282 - regression_loss: 0.9950 - classification_loss: 0.2332
1000/1000 [==============================] - 287s 287ms/step - loss: 1.2276 - regression_loss: 0.9945 - classification_loss: 0.2331

Epoch 00008: saving model to ./snapshots/resnet50_csv_08.h5
Epoch 9/10

   1/1000 [..............................] - ETA: 4:44 - loss: 1.2814 - regression_loss: 0.6388 - classification_loss: 0.6426
   2/1000 [..............................] - ETA: 4:45 - loss: 1.1807 - regression_loss: 0.7799 - classification_loss: 0.4008
   3/1000 [..............................] - ETA: 4:47 - loss: 1.1355 - regression_loss: 0.7998 - classification_loss: 0.3357
   4/1000 [..............................] - ETA: 4:46 - loss: 1.0379 - regression_loss: 0.7581 - classification_loss: 0.2799
   5/1000 [..............................] - ETA: 4:48 - loss: 1.1552 - regression_loss: 0.8825 - classification_loss: 0.2726
   6/1000 [..............................] - ETA: 4:47 - loss: 1.0769 - regression_loss: 0.8271 - classification_loss: 0.2498
   7/1000 [..............................] - ETA: 4:47 - loss: 1.1412 - regression_loss: 0.8865 - classification_loss: 0.2547
   8/1000 [..............................] - ETA: 4:46 - loss: 1.1135 - regression_loss: 0.8805 - classification_loss: 0.2330
   9/1000 [..............................] - ETA: 4:46 - loss: 1.1784 - regression_loss: 0.9334 - classification_loss: 0.2451
  10/1000 [..............................] - ETA: 4:45 - loss: 1.1527 - regression_loss: 0.9132 - classification_loss: 0.2394
  11/1000 [..............................] - ETA: 4:44 - loss: 1.1225 - regression_loss: 0.8929 - classification_loss: 0.2296
  12/1000 [..............................] - ETA: 4:44 - loss: 1.1581 - regression_loss: 0.9220 - classification_loss: 0.2361
  13/1000 [..............................] - ETA: 4:43 - loss: 1.1322 - regression_loss: 0.9031 - classification_loss: 0.2291
  14/1000 [..............................] - ETA: 4:42 - loss: 1.1122 - regression_loss: 0.8902 - classification_loss: 0.2219
  15/1000 [..............................] - ETA: 4:42 - loss: 1.1308 - regression_loss: 0.9073 - classification_loss: 0.2235
  16/1000 [..............................] - ETA: 4:42 - loss: 1.0930 - regression_loss: 0.8746 - classification_loss: 0.2184
  17/1000 [..............................] - ETA: 4:41 - loss: 1.0417 - regression_loss: 0.8232 - classification_loss: 0.2185
  18/1000 [..............................] - ETA: 4:42 - loss: 1.0290 - regression_loss: 0.8119 - classification_loss: 0.2171
  19/1000 [..............................] - ETA: 4:41 - loss: 1.0096 - regression_loss: 0.7969 - classification_loss: 0.2127
  20/1000 [..............................] - ETA: 4:40 - loss: 0.9945 - regression_loss: 0.7873 - classification_loss: 0.2071
  21/1000 [..............................] - ETA: 4:40 - loss: 0.9977 - regression_loss: 0.7938 - classification_loss: 0.2039
  22/1000 [..............................] - ETA: 4:39 - loss: 0.9864 - regression_loss: 0.7840 - classification_loss: 0.2024
  23/1000 [..............................] - ETA: 4:39 - loss: 1.0002 - regression_loss: 0.7958 - classification_loss: 0.2044
  24/1000 [..............................] - ETA: 4:39 - loss: 0.9795 - regression_loss: 0.7796 - classification_loss: 0.1999
  25/1000 [..............................] - ETA: 4:39 - loss: 0.9848 - regression_loss: 0.7870 - classification_loss: 0.1978
  26/1000 [..............................] - ETA: 4:38 - loss: 0.9601 - regression_loss: 0.7661 - classification_loss: 0.1940
  27/1000 [..............................] - ETA: 4:38 - loss: 0.9717 - regression_loss: 0.7753 - classification_loss: 0.1963
  28/1000 [..............................] - ETA: 4:38 - loss: 0.9709 - regression_loss: 0.7736 - classification_loss: 0.1973
  29/1000 [..............................] - ETA: 4:37 - loss: 0.9629 - regression_loss: 0.7695 - classification_loss: 0.1934
  30/1000 [..............................] - ETA: 4:37 - loss: 0.9970 - regression_loss: 0.7990 - classification_loss: 0.1980
  31/1000 [..............................] - ETA: 4:37 - loss: 0.9849 - regression_loss: 0.7908 - classification_loss: 0.1941
  32/1000 [..............................] - ETA: 4:37 - loss: 0.9851 - regression_loss: 0.7923 - classification_loss: 0.1928
  33/1000 [..............................] - ETA: 4:36 - loss: 0.9652 - regression_loss: 0.7769 - classification_loss: 0.1883
  34/1000 [>.............................] - ETA: 4:36 - loss: 0.9799 - regression_loss: 0.7899 - classification_loss: 0.1900
  35/1000 [>.............................] - ETA: 4:36 - loss: 1.0467 - regression_loss: 0.8407 - classification_loss: 0.2060
  36/1000 [>.............................] - ETA: 4:36 - loss: 1.0603 - regression_loss: 0.8526 - classification_loss: 0.2077
  37/1000 [>.............................] - ETA: 4:35 - loss: 1.0597 - regression_loss: 0.8530 - classification_loss: 0.2066
  38/1000 [>.............................] - ETA: 4:35 - loss: 1.0545 - regression_loss: 0.8510 - classification_loss: 0.2035
  39/1000 [>.............................] - ETA: 4:35 - loss: 1.0462 - regression_loss: 0.8454 - classification_loss: 0.2008
  40/1000 [>.............................] - ETA: 4:35 - loss: 1.0593 - regression_loss: 0.8576 - classification_loss: 0.2016
  41/1000 [>.............................] - ETA: 4:34 - loss: 1.0625 - regression_loss: 0.8611 - classification_loss: 0.2014
  42/1000 [>.............................] - ETA: 4:34 - loss: 1.0633 - regression_loss: 0.8638 - classification_loss: 0.1995
  43/1000 [>.............................] - ETA: 4:34 - loss: 1.0553 - regression_loss: 0.8586 - classification_loss: 0.1967
  44/1000 [>.............................] - ETA: 4:33 - loss: 1.0736 - regression_loss: 0.8735 - classification_loss: 0.2001
  45/1000 [>.............................] - ETA: 4:33 - loss: 1.0742 - regression_loss: 0.8713 - classification_loss: 0.2029
  46/1000 [>.............................] - ETA: 4:33 - loss: 1.0769 - regression_loss: 0.8722 - classification_loss: 0.2047
  47/1000 [>.............................] - ETA: 4:32 - loss: 1.0710 - regression_loss: 0.8686 - classification_loss: 0.2023
  48/1000 [>.............................] - ETA: 4:32 - loss: 1.0744 - regression_loss: 0.8731 - classification_loss: 0.2013
  49/1000 [>.............................] - ETA: 4:32 - loss: 1.0736 - regression_loss: 0.8714 - classification_loss: 0.2022
  50/1000 [>.............................] - ETA: 4:32 - loss: 1.0624 - regression_loss: 0.8631 - classification_loss: 0.1993
  51/1000 [>.............................] - ETA: 4:31 - loss: 1.0718 - regression_loss: 0.8718 - classification_loss: 0.2000
  52/1000 [>.............................] - ETA: 4:31 - loss: 1.0761 - regression_loss: 0.8764 - classification_loss: 0.1997
  53/1000 [>.............................] - ETA: 4:31 - loss: 1.0726 - regression_loss: 0.8739 - classification_loss: 0.1987
  54/1000 [>.............................] - ETA: 4:31 - loss: 1.0652 - regression_loss: 0.8681 - classification_loss: 0.1970
  55/1000 [>.............................] - ETA: 4:30 - loss: 1.0610 - regression_loss: 0.8647 - classification_loss: 0.1963
  56/1000 [>.............................] - ETA: 4:30 - loss: 1.0543 - regression_loss: 0.8598 - classification_loss: 0.1944
  57/1000 [>.............................] - ETA: 4:30 - loss: 1.0439 - regression_loss: 0.8505 - classification_loss: 0.1934
  58/1000 [>.............................] - ETA: 4:30 - loss: 1.0531 - regression_loss: 0.8600 - classification_loss: 0.1931
  59/1000 [>.............................] - ETA: 4:29 - loss: 1.0621 - regression_loss: 0.8678 - classification_loss: 0.1943
  60/1000 [>.............................] - ETA: 4:29 - loss: 1.0552 - regression_loss: 0.8629 - classification_loss: 0.1922
  61/1000 [>.............................] - ETA: 4:29 - loss: 1.0466 - regression_loss: 0.8557 - classification_loss: 0.1908
  62/1000 [>.............................] - ETA: 4:28 - loss: 1.0403 - regression_loss: 0.8510 - classification_loss: 0.1893
  63/1000 [>.............................] - ETA: 4:28 - loss: 1.0409 - regression_loss: 0.8501 - classification_loss: 0.1907
  64/1000 [>.............................] - ETA: 4:28 - loss: 1.0349 - regression_loss: 0.8445 - classification_loss: 0.1904
  65/1000 [>.............................] - ETA: 4:28 - loss: 1.0539 - regression_loss: 0.8611 - classification_loss: 0.1928
  66/1000 [>.............................] - ETA: 4:27 - loss: 1.0473 - regression_loss: 0.8547 - classification_loss: 0.1926
  67/1000 [=>............................] - ETA: 4:27 - loss: 1.0457 - regression_loss: 0.8541 - classification_loss: 0.1916
  68/1000 [=>............................] - ETA: 4:27 - loss: 1.0479 - regression_loss: 0.8530 - classification_loss: 0.1949
  69/1000 [=>............................] - ETA: 4:27 - loss: 1.0520 - regression_loss: 0.8569 - classification_loss: 0.1950
  70/1000 [=>............................] - ETA: 4:26 - loss: 1.0510 - regression_loss: 0.8561 - classification_loss: 0.1950
  71/1000 [=>............................] - ETA: 4:26 - loss: 1.0571 - regression_loss: 0.8623 - classification_loss: 0.1949
  72/1000 [=>............................] - ETA: 4:26 - loss: 1.0670 - regression_loss: 0.8718 - classification_loss: 0.1952
  73/1000 [=>............................] - ETA: 4:26 - loss: 1.0705 - regression_loss: 0.8758 - classification_loss: 0.1947
  74/1000 [=>............................] - ETA: 4:25 - loss: 1.0781 - regression_loss: 0.8827 - classification_loss: 0.1954
  75/1000 [=>............................] - ETA: 4:25 - loss: 1.0841 - regression_loss: 0.8864 - classification_loss: 0.1977
  76/1000 [=>............................] - ETA: 4:25 - loss: 1.0877 - regression_loss: 0.8904 - classification_loss: 0.1974
  77/1000 [=>............................] - ETA: 4:24 - loss: 1.0868 - regression_loss: 0.8902 - classification_loss: 0.1965
  78/1000 [=>............................] - ETA: 4:24 - loss: 1.0955 - regression_loss: 0.8989 - classification_loss: 0.1966
  79/1000 [=>............................] - ETA: 4:24 - loss: 1.0957 - regression_loss: 0.8988 - classification_loss: 0.1969
  80/1000 [=>............................] - ETA: 4:24 - loss: 1.1018 - regression_loss: 0.9045 - classification_loss: 0.1974
  81/1000 [=>............................] - ETA: 4:23 - loss: 1.0953 - regression_loss: 0.8998 - classification_loss: 0.1955
  82/1000 [=>............................] - ETA: 4:23 - loss: 1.0998 - regression_loss: 0.9027 - classification_loss: 0.1971
  83/1000 [=>............................] - ETA: 4:23 - loss: 1.1000 - regression_loss: 0.9036 - classification_loss: 0.1964
  84/1000 [=>............................] - ETA: 4:23 - loss: 1.0944 - regression_loss: 0.8986 - classification_loss: 0.1958
  85/1000 [=>............................] - ETA: 4:22 - loss: 1.0902 - regression_loss: 0.8956 - classification_loss: 0.1946
  86/1000 [=>............................] - ETA: 4:22 - loss: 1.0879 - regression_loss: 0.8942 - classification_loss: 0.1936
  87/1000 [=>............................] - ETA: 4:22 - loss: 1.0875 - regression_loss: 0.8942 - classification_loss: 0.1933
  88/1000 [=>............................] - ETA: 4:21 - loss: 1.0914 - regression_loss: 0.8972 - classification_loss: 0.1942
  89/1000 [=>............................] - ETA: 4:21 - loss: 1.0836 - regression_loss: 0.8911 - classification_loss: 0.1925
  90/1000 [=>............................] - ETA: 4:21 - loss: 1.0840 - regression_loss: 0.8917 - classification_loss: 0.1923
  91/1000 [=>............................] - ETA: 4:20 - loss: 1.0928 - regression_loss: 0.8979 - classification_loss: 0.1949
  92/1000 [=>............................] - ETA: 4:20 - loss: 1.0962 - regression_loss: 0.8971 - classification_loss: 0.1991
  93/1000 [=>............................] - ETA: 4:20 - loss: 1.0926 - regression_loss: 0.8918 - classification_loss: 0.2008
  94/1000 [=>............................] - ETA: 4:20 - loss: 1.0865 - regression_loss: 0.8871 - classification_loss: 0.1994
  95/1000 [=>............................] - ETA: 4:19 - loss: 1.0851 - regression_loss: 0.8857 - classification_loss: 0.1994
  96/1000 [=>............................] - ETA: 4:19 - loss: 1.0926 - regression_loss: 0.8928 - classification_loss: 0.1998
  97/1000 [=>............................] - ETA: 4:19 - loss: 1.0923 - regression_loss: 0.8923 - classification_loss: 0.2000
  98/1000 [=>............................] - ETA: 4:18 - loss: 1.0902 - regression_loss: 0.8912 - classification_loss: 0.1990
  99/1000 [=>............................] - ETA: 4:18 - loss: 1.0934 - regression_loss: 0.8938 - classification_loss: 0.1997
 100/1000 [==>...........................] - ETA: 4:18 - loss: 1.0935 - regression_loss: 0.8939 - classification_loss: 0.1996
 101/1000 [==>...........................] - ETA: 4:18 - loss: 1.0895 - regression_loss: 0.8909 - classification_loss: 0.1987
 102/1000 [==>...........................] - ETA: 4:17 - loss: 1.0885 - regression_loss: 0.8894 - classification_loss: 0.1991
 103/1000 [==>...........................] - ETA: 4:17 - loss: 1.0811 - regression_loss: 0.8834 - classification_loss: 0.1977
 104/1000 [==>...........................] - ETA: 4:17 - loss: 1.0795 - regression_loss: 0.8819 - classification_loss: 0.1976
 105/1000 [==>...........................] - ETA: 4:17 - loss: 1.0725 - regression_loss: 0.8761 - classification_loss: 0.1964
 106/1000 [==>...........................] - ETA: 4:16 - loss: 1.0683 - regression_loss: 0.8725 - classification_loss: 0.1958
 107/1000 [==>...........................] - ETA: 4:16 - loss: 1.0744 - regression_loss: 0.8776 - classification_loss: 0.1968
 108/1000 [==>...........................] - ETA: 4:16 - loss: 1.0768 - regression_loss: 0.8797 - classification_loss: 0.1970
 109/1000 [==>...........................] - ETA: 4:16 - loss: 1.0830 - regression_loss: 0.8838 - classification_loss: 0.1992
 110/1000 [==>...........................] - ETA: 4:15 - loss: 1.0836 - regression_loss: 0.8835 - classification_loss: 0.2001
 111/1000 [==>...........................] - ETA: 4:15 - loss: 1.0851 - regression_loss: 0.8852 - classification_loss: 0.1999
 112/1000 [==>...........................] - ETA: 4:15 - loss: 1.0884 - regression_loss: 0.8869 - classification_loss: 0.2015
 113/1000 [==>...........................] - ETA: 4:15 - loss: 1.0841 - regression_loss: 0.8838 - classification_loss: 0.2003
 114/1000 [==>...........................] - ETA: 4:14 - loss: 1.0842 - regression_loss: 0.8834 - classification_loss: 0.2008
 115/1000 [==>...........................] - ETA: 4:14 - loss: 1.0841 - regression_loss: 0.8831 - classification_loss: 0.2010
 116/1000 [==>...........................] - ETA: 4:14 - loss: 1.0799 - regression_loss: 0.8799 - classification_loss: 0.2000
 117/1000 [==>...........................] - ETA: 4:14 - loss: 1.0760 - regression_loss: 0.8766 - classification_loss: 0.1994
 118/1000 [==>...........................] - ETA: 4:13 - loss: 1.0733 - regression_loss: 0.8748 - classification_loss: 0.1985
 119/1000 [==>...........................] - ETA: 4:13 - loss: 1.0849 - regression_loss: 0.8852 - classification_loss: 0.1997
 120/1000 [==>...........................] - ETA: 4:13 - loss: 1.0832 - regression_loss: 0.8841 - classification_loss: 0.1991
 121/1000 [==>...........................] - ETA: 4:12 - loss: 1.0941 - regression_loss: 0.8934 - classification_loss: 0.2007
 122/1000 [==>...........................] - ETA: 4:12 - loss: 1.0875 - regression_loss: 0.8879 - classification_loss: 0.1996
 123/1000 [==>...........................] - ETA: 4:12 - loss: 1.0896 - regression_loss: 0.8896 - classification_loss: 0.2000
 124/1000 [==>...........................] - ETA: 4:11 - loss: 1.0900 - regression_loss: 0.8903 - classification_loss: 0.1997
 125/1000 [==>...........................] - ETA: 4:11 - loss: 1.0882 - regression_loss: 0.8893 - classification_loss: 0.1989
 126/1000 [==>...........................] - ETA: 4:11 - loss: 1.0848 - regression_loss: 0.8866 - classification_loss: 0.1981
 127/1000 [==>...........................] - ETA: 4:11 - loss: 1.0904 - regression_loss: 0.8906 - classification_loss: 0.1998
 128/1000 [==>...........................] - ETA: 4:10 - loss: 1.0969 - regression_loss: 0.8959 - classification_loss: 0.2010
 129/1000 [==>...........................] - ETA: 4:10 - loss: 1.0950 - regression_loss: 0.8945 - classification_loss: 0.2005
 130/1000 [==>...........................] - ETA: 4:10 - loss: 1.0926 - regression_loss: 0.8919 - classification_loss: 0.2007
 131/1000 [==>...........................] - ETA: 4:09 - loss: 1.0879 - regression_loss: 0.8883 - classification_loss: 0.1996
 132/1000 [==>...........................] - ETA: 4:09 - loss: 1.0925 - regression_loss: 0.8923 - classification_loss: 0.2003
 133/1000 [==>...........................] - ETA: 4:09 - loss: 1.0971 - regression_loss: 0.8962 - classification_loss: 0.2008
 134/1000 [===>..........................] - ETA: 4:09 - loss: 1.0958 - regression_loss: 0.8942 - classification_loss: 0.2016
 135/1000 [===>..........................] - ETA: 4:08 - loss: 1.0943 - regression_loss: 0.8934 - classification_loss: 0.2009
 136/1000 [===>..........................] - ETA: 4:08 - loss: 1.0943 - regression_loss: 0.8933 - classification_loss: 0.2010
 137/1000 [===>..........................] - ETA: 4:08 - loss: 1.0900 - regression_loss: 0.8899 - classification_loss: 0.2001
 138/1000 [===>..........................] - ETA: 4:07 - loss: 1.0952 - regression_loss: 0.8939 - classification_loss: 0.2013
 139/1000 [===>..........................] - ETA: 4:07 - loss: 1.1002 - regression_loss: 0.8984 - classification_loss: 0.2018
 140/1000 [===>..........................] - ETA: 4:07 - loss: 1.1039 - regression_loss: 0.9018 - classification_loss: 0.2021
 141/1000 [===>..........................] - ETA: 4:06 - loss: 1.1044 - regression_loss: 0.9027 - classification_loss: 0.2017
 142/1000 [===>..........................] - ETA: 4:06 - loss: 1.1106 - regression_loss: 0.9071 - classification_loss: 0.2035
 143/1000 [===>..........................] - ETA: 4:06 - loss: 1.1097 - regression_loss: 0.9063 - classification_loss: 0.2034
 144/1000 [===>..........................] - ETA: 4:06 - loss: 1.1069 - regression_loss: 0.9043 - classification_loss: 0.2026
 145/1000 [===>..........................] - ETA: 4:05 - loss: 1.1063 - regression_loss: 0.9042 - classification_loss: 0.2021
 146/1000 [===>..........................] - ETA: 4:05 - loss: 1.1035 - regression_loss: 0.9016 - classification_loss: 0.2018
 147/1000 [===>..........................] - ETA: 4:05 - loss: 1.1020 - regression_loss: 0.9007 - classification_loss: 0.2013
 148/1000 [===>..........................] - ETA: 4:04 - loss: 1.1010 - regression_loss: 0.9003 - classification_loss: 0.2007
 149/1000 [===>..........................] - ETA: 4:04 - loss: 1.0962 - regression_loss: 0.8964 - classification_loss: 0.1997
 150/1000 [===>..........................] - ETA: 4:04 - loss: 1.1000 - regression_loss: 0.9000 - classification_loss: 0.2000
 151/1000 [===>..........................] - ETA: 4:04 - loss: 1.1028 - regression_loss: 0.9026 - classification_loss: 0.2002
 152/1000 [===>..........................] - ETA: 4:03 - loss: 1.1016 - regression_loss: 0.9009 - classification_loss: 0.2007
 153/1000 [===>..........................] - ETA: 4:03 - loss: 1.1050 - regression_loss: 0.9035 - classification_loss: 0.2015
 154/1000 [===>..........................] - ETA: 4:03 - loss: 1.1033 - regression_loss: 0.9023 - classification_loss: 0.2010
 155/1000 [===>..........................] - ETA: 4:02 - loss: 1.1020 - regression_loss: 0.9012 - classification_loss: 0.2008
 156/1000 [===>..........................] - ETA: 4:02 - loss: 1.0987 - regression_loss: 0.8988 - classification_loss: 0.1999
 157/1000 [===>..........................] - ETA: 4:02 - loss: 1.0999 - regression_loss: 0.8994 - classification_loss: 0.2005
 158/1000 [===>..........................] - ETA: 4:02 - loss: 1.0993 - regression_loss: 0.8993 - classification_loss: 0.2000
 159/1000 [===>..........................] - ETA: 4:01 - loss: 1.1019 - regression_loss: 0.9023 - classification_loss: 0.1996
 160/1000 [===>..........................] - ETA: 4:01 - loss: 1.1023 - regression_loss: 0.9030 - classification_loss: 0.1993
 161/1000 [===>..........................] - ETA: 4:01 - loss: 1.1054 - regression_loss: 0.9055 - classification_loss: 0.1999
 162/1000 [===>..........................] - ETA: 4:00 - loss: 1.1043 - regression_loss: 0.9041 - classification_loss: 0.2002
 163/1000 [===>..........................] - ETA: 4:00 - loss: 1.1023 - regression_loss: 0.9028 - classification_loss: 0.1996
 164/1000 [===>..........................] - ETA: 4:00 - loss: 1.1063 - regression_loss: 0.9065 - classification_loss: 0.1998
 165/1000 [===>..........................] - ETA: 3:59 - loss: 1.1137 - regression_loss: 0.9134 - classification_loss: 0.2003
 166/1000 [===>..........................] - ETA: 3:59 - loss: 1.1171 - regression_loss: 0.9162 - classification_loss: 0.2009
 167/1000 [====>.........................] - ETA: 3:59 - loss: 1.1172 - regression_loss: 0.9165 - classification_loss: 0.2007
 168/1000 [====>.........................] - ETA: 3:59 - loss: 1.1126 - regression_loss: 0.9127 - classification_loss: 0.1999
 169/1000 [====>.........................] - ETA: 3:58 - loss: 1.1111 - regression_loss: 0.9109 - classification_loss: 0.2002
 170/1000 [====>.........................] - ETA: 3:58 - loss: 1.1145 - regression_loss: 0.9138 - classification_loss: 0.2007
 171/1000 [====>.........................] - ETA: 3:58 - loss: 1.1144 - regression_loss: 0.9139 - classification_loss: 0.2005
 172/1000 [====>.........................] - ETA: 3:57 - loss: 1.1136 - regression_loss: 0.9137 - classification_loss: 0.1998
 173/1000 [====>.........................] - ETA: 3:57 - loss: 1.1140 - regression_loss: 0.9142 - classification_loss: 0.1998
 174/1000 [====>.........................] - ETA: 3:57 - loss: 1.1152 - regression_loss: 0.9150 - classification_loss: 0.2002
 175/1000 [====>.........................] - ETA: 3:57 - loss: 1.1129 - regression_loss: 0.9132 - classification_loss: 0.1997
 176/1000 [====>.........................] - ETA: 3:56 - loss: 1.1139 - regression_loss: 0.9141 - classification_loss: 0.1998
 177/1000 [====>.........................] - ETA: 3:56 - loss: 1.1130 - regression_loss: 0.9127 - classification_loss: 0.2003
 178/1000 [====>.........................] - ETA: 3:56 - loss: 1.1145 - regression_loss: 0.9142 - classification_loss: 0.2003
 179/1000 [====>.........................] - ETA: 3:55 - loss: 1.1127 - regression_loss: 0.9118 - classification_loss: 0.2009
 180/1000 [====>.........................] - ETA: 3:55 - loss: 1.1175 - regression_loss: 0.9148 - classification_loss: 0.2027
 181/1000 [====>.........................] - ETA: 3:55 - loss: 1.1175 - regression_loss: 0.9144 - classification_loss: 0.2031
 182/1000 [====>.........................] - ETA: 3:55 - loss: 1.1147 - regression_loss: 0.9123 - classification_loss: 0.2025
 183/1000 [====>.........................] - ETA: 3:54 - loss: 1.1157 - regression_loss: 0.9129 - classification_loss: 0.2028
 184/1000 [====>.........................] - ETA: 3:54 - loss: 1.1155 - regression_loss: 0.9129 - classification_loss: 0.2026
 185/1000 [====>.........................] - ETA: 3:54 - loss: 1.1124 - regression_loss: 0.9106 - classification_loss: 0.2018
 186/1000 [====>.........................] - ETA: 3:53 - loss: 1.1098 - regression_loss: 0.9087 - classification_loss: 0.2011
 187/1000 [====>.........................] - ETA: 3:53 - loss: 1.1096 - regression_loss: 0.9081 - classification_loss: 0.2015
 188/1000 [====>.........................] - ETA: 3:53 - loss: 1.1067 - regression_loss: 0.9060 - classification_loss: 0.2007
 189/1000 [====>.........................] - ETA: 3:53 - loss: 1.1088 - regression_loss: 0.9078 - classification_loss: 0.2009
 190/1000 [====>.........................] - ETA: 3:52 - loss: 1.1055 - regression_loss: 0.9048 - classification_loss: 0.2006
 191/1000 [====>.........................] - ETA: 3:52 - loss: 1.1033 - regression_loss: 0.9032 - classification_loss: 0.2001
 192/1000 [====>.........................] - ETA: 3:52 - loss: 1.1060 - regression_loss: 0.9053 - classification_loss: 0.2007
 193/1000 [====>.........................] - ETA: 3:51 - loss: 1.1164 - regression_loss: 0.9123 - classification_loss: 0.2042
 194/1000 [====>.........................] - ETA: 3:51 - loss: 1.1173 - regression_loss: 0.9128 - classification_loss: 0.2045
 195/1000 [====>.........................] - ETA: 3:51 - loss: 1.1141 - regression_loss: 0.9102 - classification_loss: 0.2039
 196/1000 [====>.........................] - ETA: 3:50 - loss: 1.1117 - regression_loss: 0.9082 - classification_loss: 0.2034
 197/1000 [====>.........................] - ETA: 3:50 - loss: 1.1102 - regression_loss: 0.9064 - classification_loss: 0.2038
 198/1000 [====>.........................] - ETA: 3:50 - loss: 1.1096 - regression_loss: 0.9062 - classification_loss: 0.2034
 199/1000 [====>.........................] - ETA: 3:50 - loss: 1.1076 - regression_loss: 0.9047 - classification_loss: 0.2029
 200/1000 [=====>........................] - ETA: 3:49 - loss: 1.1057 - regression_loss: 0.9029 - classification_loss: 0.2028
 201/1000 [=====>........................] - ETA: 3:49 - loss: 1.1054 - regression_loss: 0.9025 - classification_loss: 0.2029
 202/1000 [=====>........................] - ETA: 3:49 - loss: 1.1039 - regression_loss: 0.9016 - classification_loss: 0.2024
 203/1000 [=====>........................] - ETA: 3:48 - loss: 1.1019 - regression_loss: 0.9000 - classification_loss: 0.2018
 204/1000 [=====>........................] - ETA: 3:48 - loss: 1.0999 - regression_loss: 0.8986 - classification_loss: 0.2013
 205/1000 [=====>........................] - ETA: 3:48 - loss: 1.1008 - regression_loss: 0.8994 - classification_loss: 0.2014
 206/1000 [=====>........................] - ETA: 3:47 - loss: 1.1018 - regression_loss: 0.9006 - classification_loss: 0.2012
 207/1000 [=====>........................] - ETA: 3:47 - loss: 1.1020 - regression_loss: 0.9010 - classification_loss: 0.2010
 208/1000 [=====>........................] - ETA: 3:47 - loss: 1.1028 - regression_loss: 0.9022 - classification_loss: 0.2006
 209/1000 [=====>........................] - ETA: 3:47 - loss: 1.1029 - regression_loss: 0.9025 - classification_loss: 0.2004
 210/1000 [=====>........................] - ETA: 3:46 - loss: 1.1001 - regression_loss: 0.9003 - classification_loss: 0.1998
 211/1000 [=====>........................] - ETA: 3:46 - loss: 1.0991 - regression_loss: 0.8984 - classification_loss: 0.2007
 212/1000 [=====>........................] - ETA: 3:46 - loss: 1.1004 - regression_loss: 0.8997 - classification_loss: 0.2006
 213/1000 [=====>........................] - ETA: 3:45 - loss: 1.0998 - regression_loss: 0.8993 - classification_loss: 0.2005
 214/1000 [=====>........................] - ETA: 3:45 - loss: 1.0990 - regression_loss: 0.8984 - classification_loss: 0.2007
 215/1000 [=====>........................] - ETA: 3:45 - loss: 1.0980 - regression_loss: 0.8976 - classification_loss: 0.2004
 216/1000 [=====>........................] - ETA: 3:44 - loss: 1.1025 - regression_loss: 0.9006 - classification_loss: 0.2019
 217/1000 [=====>........................] - ETA: 3:44 - loss: 1.1039 - regression_loss: 0.9020 - classification_loss: 0.2020
 218/1000 [=====>........................] - ETA: 3:44 - loss: 1.1045 - regression_loss: 0.9023 - classification_loss: 0.2022
 219/1000 [=====>........................] - ETA: 3:44 - loss: 1.1014 - regression_loss: 0.8999 - classification_loss: 0.2016
 220/1000 [=====>........................] - ETA: 3:43 - loss: 1.1041 - regression_loss: 0.9018 - classification_loss: 0.2023
 221/1000 [=====>........................] - ETA: 3:43 - loss: 1.1061 - regression_loss: 0.9040 - classification_loss: 0.2021
 222/1000 [=====>........................] - ETA: 3:43 - loss: 1.1076 - regression_loss: 0.9057 - classification_loss: 0.2019
 223/1000 [=====>........................] - ETA: 3:42 - loss: 1.1062 - regression_loss: 0.9045 - classification_loss: 0.2016
 224/1000 [=====>........................] - ETA: 3:42 - loss: 1.1041 - regression_loss: 0.9005 - classification_loss: 0.2036
 225/1000 [=====>........................] - ETA: 3:42 - loss: 1.1056 - regression_loss: 0.9017 - classification_loss: 0.2039
 226/1000 [=====>........................] - ETA: 3:42 - loss: 1.1062 - regression_loss: 0.9024 - classification_loss: 0.2038
 227/1000 [=====>........................] - ETA: 3:41 - loss: 1.1046 - regression_loss: 0.9011 - classification_loss: 0.2034
 228/1000 [=====>........................] - ETA: 3:41 - loss: 1.1031 - regression_loss: 0.9001 - classification_loss: 0.2030
 229/1000 [=====>........................] - ETA: 3:41 - loss: 1.1046 - regression_loss: 0.9013 - classification_loss: 0.2032
 230/1000 [=====>........................] - ETA: 3:40 - loss: 1.1063 - regression_loss: 0.9024 - classification_loss: 0.2039
 231/1000 [=====>........................] - ETA: 3:40 - loss: 1.1134 - regression_loss: 0.9078 - classification_loss: 0.2056
 232/1000 [=====>........................] - ETA: 3:40 - loss: 1.1127 - regression_loss: 0.9073 - classification_loss: 0.2054
 233/1000 [=====>........................] - ETA: 3:40 - loss: 1.1105 - regression_loss: 0.9057 - classification_loss: 0.2048
 234/1000 [======>.......................] - ETA: 3:39 - loss: 1.1086 - regression_loss: 0.9042 - classification_loss: 0.2044
 235/1000 [======>.......................] - ETA: 3:39 - loss: 1.1080 - regression_loss: 0.9039 - classification_loss: 0.2041
 236/1000 [======>.......................] - ETA: 3:39 - loss: 1.1067 - regression_loss: 0.9031 - classification_loss: 0.2037
 237/1000 [======>.......................] - ETA: 3:39 - loss: 1.1116 - regression_loss: 0.9058 - classification_loss: 0.2057
 238/1000 [======>.......................] - ETA: 3:38 - loss: 1.1114 - regression_loss: 0.9057 - classification_loss: 0.2056
 239/1000 [======>.......................] - ETA: 3:38 - loss: 1.1150 - regression_loss: 0.9092 - classification_loss: 0.2058
 240/1000 [======>.......................] - ETA: 3:38 - loss: 1.1156 - regression_loss: 0.9102 - classification_loss: 0.2054
 241/1000 [======>.......................] - ETA: 3:37 - loss: 1.1146 - regression_loss: 0.9081 - classification_loss: 0.2065
 242/1000 [======>.......................] - ETA: 3:37 - loss: 1.1157 - regression_loss: 0.9095 - classification_loss: 0.2062
 243/1000 [======>.......................] - ETA: 3:37 - loss: 1.1155 - regression_loss: 0.9094 - classification_loss: 0.2061
 244/1000 [======>.......................] - ETA: 3:37 - loss: 1.1185 - regression_loss: 0.9119 - classification_loss: 0.2065
 245/1000 [======>.......................] - ETA: 3:36 - loss: 1.1150 - regression_loss: 0.9091 - classification_loss: 0.2059
 246/1000 [======>.......................] - ETA: 3:36 - loss: 1.1204 - regression_loss: 0.9127 - classification_loss: 0.2076
 247/1000 [======>.......................] - ETA: 3:36 - loss: 1.1242 - regression_loss: 0.9162 - classification_loss: 0.2080
 248/1000 [======>.......................] - ETA: 3:35 - loss: 1.1224 - regression_loss: 0.9147 - classification_loss: 0.2077
 249/1000 [======>.......................] - ETA: 3:35 - loss: 1.1205 - regression_loss: 0.9133 - classification_loss: 0.2072
 250/1000 [======>.......................] - ETA: 3:35 - loss: 1.1196 - regression_loss: 0.9128 - classification_loss: 0.2068
 251/1000 [======>.......................] - ETA: 3:34 - loss: 1.1196 - regression_loss: 0.9130 - classification_loss: 0.2065
 252/1000 [======>.......................] - ETA: 3:34 - loss: 1.1204 - regression_loss: 0.9144 - classification_loss: 0.2060
 253/1000 [======>.......................] - ETA: 3:34 - loss: 1.1202 - regression_loss: 0.9144 - classification_loss: 0.2058
 254/1000 [======>.......................] - ETA: 3:34 - loss: 1.1234 - regression_loss: 0.9171 - classification_loss: 0.2064
 255/1000 [======>.......................] - ETA: 3:33 - loss: 1.1212 - regression_loss: 0.9154 - classification_loss: 0.2059
 256/1000 [======>.......................] - ETA: 3:33 - loss: 1.1215 - regression_loss: 0.9158 - classification_loss: 0.2058
 257/1000 [======>.......................] - ETA: 3:33 - loss: 1.1218 - regression_loss: 0.9161 - classification_loss: 0.2057
 258/1000 [======>.......................] - ETA: 3:32 - loss: 1.1193 - regression_loss: 0.9139 - classification_loss: 0.2054
 259/1000 [======>.......................] - ETA: 3:32 - loss: 1.1205 - regression_loss: 0.9154 - classification_loss: 0.2051
 260/1000 [======>.......................] - ETA: 3:32 - loss: 1.1201 - regression_loss: 0.9153 - classification_loss: 0.2048
 261/1000 [======>.......................] - ETA: 3:32 - loss: 1.1211 - regression_loss: 0.9164 - classification_loss: 0.2047
 262/1000 [======>.......................] - ETA: 3:31 - loss: 1.1187 - regression_loss: 0.9144 - classification_loss: 0.2043
 263/1000 [======>.......................] - ETA: 3:31 - loss: 1.1184 - regression_loss: 0.9142 - classification_loss: 0.2042
 264/1000 [======>.......................] - ETA: 3:31 - loss: 1.1167 - regression_loss: 0.9129 - classification_loss: 0.2038
 265/1000 [======>.......................] - ETA: 3:30 - loss: 1.1152 - regression_loss: 0.9114 - classification_loss: 0.2038
 266/1000 [======>.......................] - ETA: 3:30 - loss: 1.1167 - regression_loss: 0.9131 - classification_loss: 0.2036
 267/1000 [=======>......................] - ETA: 3:30 - loss: 1.1172 - regression_loss: 0.9132 - classification_loss: 0.2041
 268/1000 [=======>......................] - ETA: 3:30 - loss: 1.1154 - regression_loss: 0.9118 - classification_loss: 0.2036
 269/1000 [=======>......................] - ETA: 3:29 - loss: 1.1158 - regression_loss: 0.9123 - classification_loss: 0.2036
 270/1000 [=======>......................] - ETA: 3:29 - loss: 1.1170 - regression_loss: 0.9134 - classification_loss: 0.2037
 271/1000 [=======>......................] - ETA: 3:29 - loss: 1.1178 - regression_loss: 0.9142 - classification_loss: 0.2036
 272/1000 [=======>......................] - ETA: 3:28 - loss: 1.1155 - regression_loss: 0.9124 - classification_loss: 0.2031
 273/1000 [=======>......................] - ETA: 3:28 - loss: 1.1156 - regression_loss: 0.9123 - classification_loss: 0.2033
 274/1000 [=======>......................] - ETA: 3:28 - loss: 1.1191 - regression_loss: 0.9150 - classification_loss: 0.2042
 275/1000 [=======>......................] - ETA: 3:28 - loss: 1.1212 - regression_loss: 0.9169 - classification_loss: 0.2043
 276/1000 [=======>......................] - ETA: 3:27 - loss: 1.1202 - regression_loss: 0.9156 - classification_loss: 0.2046
 277/1000 [=======>......................] - ETA: 3:27 - loss: 1.1223 - regression_loss: 0.9174 - classification_loss: 0.2049
 278/1000 [=======>......................] - ETA: 3:27 - loss: 1.1207 - regression_loss: 0.9162 - classification_loss: 0.2044
 279/1000 [=======>......................] - ETA: 3:26 - loss: 1.1219 - regression_loss: 0.9174 - classification_loss: 0.2045
 280/1000 [=======>......................] - ETA: 3:26 - loss: 1.1207 - regression_loss: 0.9166 - classification_loss: 0.2041
 281/1000 [=======>......................] - ETA: 3:26 - loss: 1.1204 - regression_loss: 0.9163 - classification_loss: 0.2041
 282/1000 [=======>......................] - ETA: 3:26 - loss: 1.1214 - regression_loss: 0.9168 - classification_loss: 0.2046
 283/1000 [=======>......................] - ETA: 3:25 - loss: 1.1210 - regression_loss: 0.9168 - classification_loss: 0.2042
 284/1000 [=======>......................] - ETA: 3:25 - loss: 1.1205 - regression_loss: 0.9165 - classification_loss: 0.2040
 285/1000 [=======>......................] - ETA: 3:25 - loss: 1.1213 - regression_loss: 0.9169 - classification_loss: 0.2044
 286/1000 [=======>......................] - ETA: 3:24 - loss: 1.1234 - regression_loss: 0.9185 - classification_loss: 0.2049
 287/1000 [=======>......................] - ETA: 3:24 - loss: 1.1218 - regression_loss: 0.9174 - classification_loss: 0.2044
 288/1000 [=======>......................] - ETA: 3:24 - loss: 1.1218 - regression_loss: 0.9177 - classification_loss: 0.2041
 289/1000 [=======>......................] - ETA: 3:24 - loss: 1.1202 - regression_loss: 0.9165 - classification_loss: 0.2037
 290/1000 [=======>......................] - ETA: 3:23 - loss: 1.1198 - regression_loss: 0.9163 - classification_loss: 0.2035
 291/1000 [=======>......................] - ETA: 3:23 - loss: 1.1181 - regression_loss: 0.9149 - classification_loss: 0.2032
 292/1000 [=======>......................] - ETA: 3:23 - loss: 1.1196 - regression_loss: 0.9164 - classification_loss: 0.2032
 293/1000 [=======>......................] - ETA: 3:22 - loss: 1.1201 - regression_loss: 0.9168 - classification_loss: 0.2034
 294/1000 [=======>......................] - ETA: 3:22 - loss: 1.1216 - regression_loss: 0.9181 - classification_loss: 0.2035
 295/1000 [=======>......................] - ETA: 3:22 - loss: 1.1206 - regression_loss: 0.9175 - classification_loss: 0.2031
 296/1000 [=======>......................] - ETA: 3:22 - loss: 1.1190 - regression_loss: 0.9161 - classification_loss: 0.2029
 297/1000 [=======>......................] - ETA: 3:21 - loss: 1.1184 - regression_loss: 0.9158 - classification_loss: 0.2026
 298/1000 [=======>......................] - ETA: 3:21 - loss: 1.1176 - regression_loss: 0.9152 - classification_loss: 0.2024
 299/1000 [=======>......................] - ETA: 3:21 - loss: 1.1176 - regression_loss: 0.9146 - classification_loss: 0.2030
 300/1000 [========>.....................] - ETA: 3:20 - loss: 1.1171 - regression_loss: 0.9143 - classification_loss: 0.2028
 301/1000 [========>.....................] - ETA: 3:20 - loss: 1.1158 - regression_loss: 0.9133 - classification_loss: 0.2025
 302/1000 [========>.....................] - ETA: 3:20 - loss: 1.1157 - regression_loss: 0.9132 - classification_loss: 0.2025
 303/1000 [========>.....................] - ETA: 3:19 - loss: 1.1145 - regression_loss: 0.9123 - classification_loss: 0.2022
 304/1000 [========>.....................] - ETA: 3:19 - loss: 1.1135 - regression_loss: 0.9116 - classification_loss: 0.2019
 305/1000 [========>.....................] - ETA: 3:19 - loss: 1.1130 - regression_loss: 0.9112 - classification_loss: 0.2018
 306/1000 [========>.....................] - ETA: 3:19 - loss: 1.1129 - regression_loss: 0.9111 - classification_loss: 0.2017
 307/1000 [========>.....................] - ETA: 3:18 - loss: 1.1127 - regression_loss: 0.9110 - classification_loss: 0.2017
 308/1000 [========>.....................] - ETA: 3:18 - loss: 1.1132 - regression_loss: 0.9107 - classification_loss: 0.2025
 309/1000 [========>.....................] - ETA: 3:18 - loss: 1.1113 - regression_loss: 0.9091 - classification_loss: 0.2021
 310/1000 [========>.....................] - ETA: 3:17 - loss: 1.1105 - regression_loss: 0.9086 - classification_loss: 0.2019
 311/1000 [========>.....................] - ETA: 3:17 - loss: 1.1113 - regression_loss: 0.9091 - classification_loss: 0.2022
 312/1000 [========>.....................] - ETA: 3:17 - loss: 1.1118 - regression_loss: 0.9095 - classification_loss: 0.2023
 313/1000 [========>.....................] - ETA: 3:17 - loss: 1.1120 - regression_loss: 0.9096 - classification_loss: 0.2024
 314/1000 [========>.....................] - ETA: 3:16 - loss: 1.1134 - regression_loss: 0.9110 - classification_loss: 0.2024
 315/1000 [========>.....................] - ETA: 3:16 - loss: 1.1129 - regression_loss: 0.9105 - classification_loss: 0.2024
 316/1000 [========>.....................] - ETA: 3:16 - loss: 1.1119 - regression_loss: 0.9095 - classification_loss: 0.2024
 317/1000 [========>.....................] - ETA: 3:15 - loss: 1.1103 - regression_loss: 0.9082 - classification_loss: 0.2021
 318/1000 [========>.....................] - ETA: 3:15 - loss: 1.1085 - regression_loss: 0.9067 - classification_loss: 0.2019
 319/1000 [========>.....................] - ETA: 3:15 - loss: 1.1077 - regression_loss: 0.9061 - classification_loss: 0.2017
 320/1000 [========>.....................] - ETA: 3:15 - loss: 1.1090 - regression_loss: 0.9071 - classification_loss: 0.2018
 321/1000 [========>.....................] - ETA: 3:14 - loss: 1.1083 - regression_loss: 0.9063 - classification_loss: 0.2019
 322/1000 [========>.....................] - ETA: 3:14 - loss: 1.1121 - regression_loss: 0.9100 - classification_loss: 0.2021
 323/1000 [========>.....................] - ETA: 3:14 - loss: 1.1126 - regression_loss: 0.9105 - classification_loss: 0.2021
 324/1000 [========>.....................] - ETA: 3:13 - loss: 1.1119 - regression_loss: 0.9097 - classification_loss: 0.2022
 325/1000 [========>.....................] - ETA: 3:13 - loss: 1.1116 - regression_loss: 0.9097 - classification_loss: 0.2019
 326/1000 [========>.....................] - ETA: 3:13 - loss: 1.1141 - regression_loss: 0.9121 - classification_loss: 0.2020
 327/1000 [========>.....................] - ETA: 3:13 - loss: 1.1132 - regression_loss: 0.9116 - classification_loss: 0.2017
 328/1000 [========>.....................] - ETA: 3:12 - loss: 1.1137 - regression_loss: 0.9122 - classification_loss: 0.2015
 329/1000 [========>.....................] - ETA: 3:12 - loss: 1.1125 - regression_loss: 0.9114 - classification_loss: 0.2011
 330/1000 [========>.....................] - ETA: 3:12 - loss: 1.1117 - regression_loss: 0.9109 - classification_loss: 0.2008
 331/1000 [========>.....................] - ETA: 3:11 - loss: 1.1136 - regression_loss: 0.9125 - classification_loss: 0.2011
 332/1000 [========>.....................] - ETA: 3:11 - loss: 1.1182 - regression_loss: 0.9157 - classification_loss: 0.2025
 333/1000 [========>.....................] - ETA: 3:11 - loss: 1.1224 - regression_loss: 0.9187 - classification_loss: 0.2037
 334/1000 [=========>....................] - ETA: 3:11 - loss: 1.1218 - regression_loss: 0.9182 - classification_loss: 0.2036
 335/1000 [=========>....................] - ETA: 3:10 - loss: 1.1198 - regression_loss: 0.9166 - classification_loss: 0.2032
 336/1000 [=========>....................] - ETA: 3:10 - loss: 1.1197 - regression_loss: 0.9166 - classification_loss: 0.2031
 337/1000 [=========>....................] - ETA: 3:10 - loss: 1.1197 - regression_loss: 0.9167 - classification_loss: 0.2030
 338/1000 [=========>....................] - ETA: 3:09 - loss: 1.1185 - regression_loss: 0.9157 - classification_loss: 0.2028
 339/1000 [=========>....................] - ETA: 3:09 - loss: 1.1162 - regression_loss: 0.9139 - classification_loss: 0.2023
 340/1000 [=========>....................] - ETA: 3:09 - loss: 1.1144 - regression_loss: 0.9126 - classification_loss: 0.2019
 341/1000 [=========>....................] - ETA: 3:09 - loss: 1.1130 - regression_loss: 0.9115 - classification_loss: 0.2015
 342/1000 [=========>....................] - ETA: 3:08 - loss: 1.1113 - regression_loss: 0.9101 - classification_loss: 0.2012
 343/1000 [=========>....................] - ETA: 3:08 - loss: 1.1114 - regression_loss: 0.9103 - classification_loss: 0.2011
 344/1000 [=========>....................] - ETA: 3:08 - loss: 1.1113 - regression_loss: 0.9103 - classification_loss: 0.2011
 345/1000 [=========>....................] - ETA: 3:07 - loss: 1.1157 - regression_loss: 0.9141 - classification_loss: 0.2016
 346/1000 [=========>....................] - ETA: 3:07 - loss: 1.1156 - regression_loss: 0.9143 - classification_loss: 0.2013
 347/1000 [=========>....................] - ETA: 3:07 - loss: 1.1169 - regression_loss: 0.9153 - classification_loss: 0.2015
 348/1000 [=========>....................] - ETA: 3:07 - loss: 1.1184 - regression_loss: 0.9168 - classification_loss: 0.2016
 349/1000 [=========>....................] - ETA: 3:06 - loss: 1.1220 - regression_loss: 0.9194 - classification_loss: 0.2025
 350/1000 [=========>....................] - ETA: 3:06 - loss: 1.1198 - regression_loss: 0.9177 - classification_loss: 0.2021
 351/1000 [=========>....................] - ETA: 3:06 - loss: 1.1218 - regression_loss: 0.9194 - classification_loss: 0.2024
 352/1000 [=========>....................] - ETA: 3:05 - loss: 1.1219 - regression_loss: 0.9195 - classification_loss: 0.2024
 353/1000 [=========>....................] - ETA: 3:05 - loss: 1.1217 - regression_loss: 0.9194 - classification_loss: 0.2023
 354/1000 [=========>....................] - ETA: 3:05 - loss: 1.1203 - regression_loss: 0.9183 - classification_loss: 0.2021
 355/1000 [=========>....................] - ETA: 3:05 - loss: 1.1193 - regression_loss: 0.9175 - classification_loss: 0.2018
 356/1000 [=========>....................] - ETA: 3:04 - loss: 1.1203 - regression_loss: 0.9181 - classification_loss: 0.2022
 357/1000 [=========>....................] - ETA: 3:04 - loss: 1.1184 - regression_loss: 0.9166 - classification_loss: 0.2018
 358/1000 [=========>....................] - ETA: 3:04 - loss: 1.1174 - regression_loss: 0.9157 - classification_loss: 0.2016
 359/1000 [=========>....................] - ETA: 3:03 - loss: 1.1174 - regression_loss: 0.9158 - classification_loss: 0.2017
 360/1000 [=========>....................] - ETA: 3:03 - loss: 1.1178 - regression_loss: 0.9164 - classification_loss: 0.2014
 361/1000 [=========>....................] - ETA: 3:03 - loss: 1.1178 - regression_loss: 0.9165 - classification_loss: 0.2013
 362/1000 [=========>....................] - ETA: 3:03 - loss: 1.1198 - regression_loss: 0.9177 - classification_loss: 0.2021
 363/1000 [=========>....................] - ETA: 3:02 - loss: 1.1186 - regression_loss: 0.9169 - classification_loss: 0.2017
 364/1000 [=========>....................] - ETA: 3:02 - loss: 1.1182 - regression_loss: 0.9167 - classification_loss: 0.2015
 365/1000 [=========>....................] - ETA: 3:02 - loss: 1.1167 - regression_loss: 0.9155 - classification_loss: 0.2012
 366/1000 [=========>....................] - ETA: 3:01 - loss: 1.1168 - regression_loss: 0.9156 - classification_loss: 0.2012
 367/1000 [==========>...................] - ETA: 3:01 - loss: 1.1173 - regression_loss: 0.9160 - classification_loss: 0.2012
 368/1000 [==========>...................] - ETA: 3:01 - loss: 1.1169 - regression_loss: 0.9158 - classification_loss: 0.2011
 369/1000 [==========>...................] - ETA: 3:01 - loss: 1.1162 - regression_loss: 0.9154 - classification_loss: 0.2008
 370/1000 [==========>...................] - ETA: 3:00 - loss: 1.1151 - regression_loss: 0.9145 - classification_loss: 0.2006
 371/1000 [==========>...................] - ETA: 3:00 - loss: 1.1144 - regression_loss: 0.9139 - classification_loss: 0.2005
 372/1000 [==========>...................] - ETA: 3:00 - loss: 1.1142 - regression_loss: 0.9136 - classification_loss: 0.2005
 373/1000 [==========>...................] - ETA: 2:59 - loss: 1.1124 - regression_loss: 0.9121 - classification_loss: 0.2002
 374/1000 [==========>...................] - ETA: 2:59 - loss: 1.1123 - regression_loss: 0.9121 - classification_loss: 0.2002
 375/1000 [==========>...................] - ETA: 2:59 - loss: 1.1123 - regression_loss: 0.9121 - classification_loss: 0.2002
 376/1000 [==========>...................] - ETA: 2:59 - loss: 1.1114 - regression_loss: 0.9114 - classification_loss: 0.2000
 377/1000 [==========>...................] - ETA: 2:58 - loss: 1.1109 - regression_loss: 0.9111 - classification_loss: 0.1998
 378/1000 [==========>...................] - ETA: 2:58 - loss: 1.1098 - regression_loss: 0.9102 - classification_loss: 0.1996
 379/1000 [==========>...................] - ETA: 2:58 - loss: 1.1113 - regression_loss: 0.9116 - classification_loss: 0.1998
 380/1000 [==========>...................] - ETA: 2:57 - loss: 1.1112 - regression_loss: 0.9115 - classification_loss: 0.1997
 381/1000 [==========>...................] - ETA: 2:57 - loss: 1.1135 - regression_loss: 0.9127 - classification_loss: 0.2007
 382/1000 [==========>...................] - ETA: 2:57 - loss: 1.1119 - regression_loss: 0.9115 - classification_loss: 0.2004
 383/1000 [==========>...................] - ETA: 2:57 - loss: 1.1127 - regression_loss: 0.9125 - classification_loss: 0.2002
 384/1000 [==========>...................] - ETA: 2:56 - loss: 1.1134 - regression_loss: 0.9133 - classification_loss: 0.2001
 385/1000 [==========>...................] - ETA: 2:56 - loss: 1.1134 - regression_loss: 0.9132 - classification_loss: 0.2002
 386/1000 [==========>...................] - ETA: 2:56 - loss: 1.1141 - regression_loss: 0.9138 - classification_loss: 0.2003
 387/1000 [==========>...................] - ETA: 2:55 - loss: 1.1126 - regression_loss: 0.9127 - classification_loss: 0.1999
 388/1000 [==========>...................] - ETA: 2:55 - loss: 1.1115 - regression_loss: 0.9118 - classification_loss: 0.1997
 389/1000 [==========>...................] - ETA: 2:55 - loss: 1.1100 - regression_loss: 0.9105 - classification_loss: 0.1995
 390/1000 [==========>...................] - ETA: 2:55 - loss: 1.1103 - regression_loss: 0.9107 - classification_loss: 0.1996
 391/1000 [==========>...................] - ETA: 2:54 - loss: 1.1097 - regression_loss: 0.9103 - classification_loss: 0.1994
 392/1000 [==========>...................] - ETA: 2:54 - loss: 1.1082 - regression_loss: 0.9093 - classification_loss: 0.1990
 393/1000 [==========>...................] - ETA: 2:54 - loss: 1.1109 - regression_loss: 0.9110 - classification_loss: 0.1998
 394/1000 [==========>...................] - ETA: 2:53 - loss: 1.1096 - regression_loss: 0.9099 - classification_loss: 0.1996
 395/1000 [==========>...................] - ETA: 2:53 - loss: 1.1084 - regression_loss: 0.9088 - classification_loss: 0.1996
 396/1000 [==========>...................] - ETA: 2:53 - loss: 1.1082 - regression_loss: 0.9088 - classification_loss: 0.1995
 397/1000 [==========>...................] - ETA: 2:53 - loss: 1.1094 - regression_loss: 0.9094 - classification_loss: 0.2000
 398/1000 [==========>...................] - ETA: 2:52 - loss: 1.1115 - regression_loss: 0.9116 - classification_loss: 0.2000
 399/1000 [==========>...................] - ETA: 2:52 - loss: 1.1125 - regression_loss: 0.9124 - classification_loss: 0.2001
 400/1000 [===========>..................] - ETA: 2:52 - loss: 1.1119 - regression_loss: 0.9119 - classification_loss: 0.2000
 401/1000 [===========>..................] - ETA: 2:51 - loss: 1.1111 - regression_loss: 0.9111 - classification_loss: 0.1999
 402/1000 [===========>..................] - ETA: 2:51 - loss: 1.1125 - regression_loss: 0.9122 - classification_loss: 0.2003
 403/1000 [===========>..................] - ETA: 2:51 - loss: 1.1138 - regression_loss: 0.9129 - classification_loss: 0.2008
 404/1000 [===========>..................] - ETA: 2:51 - loss: 1.1129 - regression_loss: 0.9123 - classification_loss: 0.2005
 405/1000 [===========>..................] - ETA: 2:50 - loss: 1.1157 - regression_loss: 0.9150 - classification_loss: 0.2007
 406/1000 [===========>..................] - ETA: 2:50 - loss: 1.1156 - regression_loss: 0.9148 - classification_loss: 0.2009
 407/1000 [===========>..................] - ETA: 2:50 - loss: 1.1165 - regression_loss: 0.9153 - classification_loss: 0.2011
 408/1000 [===========>..................] - ETA: 2:49 - loss: 1.1147 - regression_loss: 0.9139 - classification_loss: 0.2009
 409/1000 [===========>..................] - ETA: 2:49 - loss: 1.1146 - regression_loss: 0.9133 - classification_loss: 0.2013
 410/1000 [===========>..................] - ETA: 2:49 - loss: 1.1168 - regression_loss: 0.9154 - classification_loss: 0.2014
 411/1000 [===========>..................] - ETA: 2:49 - loss: 1.1176 - regression_loss: 0.9163 - classification_loss: 0.2013
 412/1000 [===========>..................] - ETA: 2:48 - loss: 1.1200 - regression_loss: 0.9184 - classification_loss: 0.2016
 413/1000 [===========>..................] - ETA: 2:48 - loss: 1.1195 - regression_loss: 0.9180 - classification_loss: 0.2015
 414/1000 [===========>..................] - ETA: 2:48 - loss: 1.1188 - regression_loss: 0.9175 - classification_loss: 0.2012
 415/1000 [===========>..................] - ETA: 2:47 - loss: 1.1187 - regression_loss: 0.9176 - classification_loss: 0.2011
 416/1000 [===========>..................] - ETA: 2:47 - loss: 1.1201 - regression_loss: 0.9188 - classification_loss: 0.2013
 417/1000 [===========>..................] - ETA: 2:47 - loss: 1.1183 - regression_loss: 0.9173 - classification_loss: 0.2009
 418/1000 [===========>..................] - ETA: 2:47 - loss: 1.1190 - regression_loss: 0.9170 - classification_loss: 0.2020
 419/1000 [===========>..................] - ETA: 2:46 - loss: 1.1182 - regression_loss: 0.9164 - classification_loss: 0.2018
 420/1000 [===========>..................] - ETA: 2:46 - loss: 1.1185 - regression_loss: 0.9166 - classification_loss: 0.2019
 421/1000 [===========>..................] - ETA: 2:46 - loss: 1.1201 - regression_loss: 0.9174 - classification_loss: 0.2027
 422/1000 [===========>..................] - ETA: 2:45 - loss: 1.1218 - regression_loss: 0.9186 - classification_loss: 0.2032
 423/1000 [===========>..................] - ETA: 2:45 - loss: 1.1216 - regression_loss: 0.9185 - classification_loss: 0.2031
 424/1000 [===========>..................] - ETA: 2:45 - loss: 1.1234 - regression_loss: 0.9199 - classification_loss: 0.2035
 425/1000 [===========>..................] - ETA: 2:45 - loss: 1.1231 - regression_loss: 0.9197 - classification_loss: 0.2034
 426/1000 [===========>..................] - ETA: 2:44 - loss: 1.1219 - regression_loss: 0.9188 - classification_loss: 0.2032
 427/1000 [===========>..................] - ETA: 2:44 - loss: 1.1220 - regression_loss: 0.9189 - classification_loss: 0.2032
 428/1000 [===========>..................] - ETA: 2:44 - loss: 1.1211 - regression_loss: 0.9182 - classification_loss: 0.2029
 429/1000 [===========>..................] - ETA: 2:43 - loss: 1.1221 - regression_loss: 0.9190 - classification_loss: 0.2030
 430/1000 [===========>..................] - ETA: 2:43 - loss: 1.1218 - regression_loss: 0.9189 - classification_loss: 0.2029
 431/1000 [===========>..................] - ETA: 2:43 - loss: 1.1210 - regression_loss: 0.9183 - classification_loss: 0.2028
 432/1000 [===========>..................] - ETA: 2:43 - loss: 1.1225 - regression_loss: 0.9195 - classification_loss: 0.2029
 433/1000 [===========>..................] - ETA: 2:42 - loss: 1.1221 - regression_loss: 0.9193 - classification_loss: 0.2029
 434/1000 [============>.................] - ETA: 2:42 - loss: 1.1229 - regression_loss: 0.9201 - classification_loss: 0.2029
 435/1000 [============>.................] - ETA: 2:42 - loss: 1.1237 - regression_loss: 0.9202 - classification_loss: 0.2035
 436/1000 [============>.................] - ETA: 2:41 - loss: 1.1241 - regression_loss: 0.9203 - classification_loss: 0.2038
 437/1000 [============>.................] - ETA: 2:41 - loss: 1.1229 - regression_loss: 0.9194 - classification_loss: 0.2036
 438/1000 [============>.................] - ETA: 2:41 - loss: 1.1230 - regression_loss: 0.9195 - classification_loss: 0.2035
 439/1000 [============>.................] - ETA: 2:41 - loss: 1.1224 - regression_loss: 0.9192 - classification_loss: 0.2033
 440/1000 [============>.................] - ETA: 2:40 - loss: 1.1219 - regression_loss: 0.9189 - classification_loss: 0.2030
 441/1000 [============>.................] - ETA: 2:40 - loss: 1.1249 - regression_loss: 0.9214 - classification_loss: 0.2035
 442/1000 [============>.................] - ETA: 2:40 - loss: 1.1244 - regression_loss: 0.9210 - classification_loss: 0.2033
 443/1000 [============>.................] - ETA: 2:39 - loss: 1.1249 - regression_loss: 0.9214 - classification_loss: 0.2035
 444/1000 [============>.................] - ETA: 2:39 - loss: 1.1258 - regression_loss: 0.9224 - classification_loss: 0.2035
 445/1000 [============>.................] - ETA: 2:39 - loss: 1.1274 - regression_loss: 0.9240 - classification_loss: 0.2035
 446/1000 [============>.................] - ETA: 2:38 - loss: 1.1272 - regression_loss: 0.9238 - classification_loss: 0.2034
 447/1000 [============>.................] - ETA: 2:38 - loss: 1.1299 - regression_loss: 0.9257 - classification_loss: 0.2042
 448/1000 [============>.................] - ETA: 2:38 - loss: 1.1296 - regression_loss: 0.9252 - classification_loss: 0.2043
 449/1000 [============>.................] - ETA: 2:38 - loss: 1.1309 - regression_loss: 0.9265 - classification_loss: 0.2045
 450/1000 [============>.................] - ETA: 2:37 - loss: 1.1303 - regression_loss: 0.9260 - classification_loss: 0.2043
 451/1000 [============>.................] - ETA: 2:37 - loss: 1.1307 - regression_loss: 0.9265 - classification_loss: 0.2042
 452/1000 [============>.................] - ETA: 2:37 - loss: 1.1331 - regression_loss: 0.9287 - classification_loss: 0.2044
 453/1000 [============>.................] - ETA: 2:36 - loss: 1.1336 - regression_loss: 0.9291 - classification_loss: 0.2045
 454/1000 [============>.................] - ETA: 2:36 - loss: 1.1327 - regression_loss: 0.9284 - classification_loss: 0.2042
 455/1000 [============>.................] - ETA: 2:36 - loss: 1.1329 - regression_loss: 0.9285 - classification_loss: 0.2044
 456/1000 [============>.................] - ETA: 2:36 - loss: 1.1314 - regression_loss: 0.9274 - classification_loss: 0.2041
 457/1000 [============>.................] - ETA: 2:35 - loss: 1.1678 - regression_loss: 0.9253 - classification_loss: 0.2425
 458/1000 [============>.................] - ETA: 2:35 - loss: 1.1671 - regression_loss: 0.9247 - classification_loss: 0.2424
 459/1000 [============>.................] - ETA: 2:35 - loss: 1.1665 - regression_loss: 0.9243 - classification_loss: 0.2422
 460/1000 [============>.................] - ETA: 2:34 - loss: 1.1656 - regression_loss: 0.9237 - classification_loss: 0.2419
 461/1000 [============>.................] - ETA: 2:34 - loss: 1.1662 - regression_loss: 0.9245 - classification_loss: 0.2417
 462/1000 [============>.................] - ETA: 2:34 - loss: 1.1653 - regression_loss: 0.9238 - classification_loss: 0.2416
 463/1000 [============>.................] - ETA: 2:34 - loss: 1.1636 - regression_loss: 0.9223 - classification_loss: 0.2413
 464/1000 [============>.................] - ETA: 2:33 - loss: 1.1630 - regression_loss: 0.9220 - classification_loss: 0.2410
 465/1000 [============>.................] - ETA: 2:33 - loss: 1.1626 - regression_loss: 0.9218 - classification_loss: 0.2408
 466/1000 [============>.................] - ETA: 2:33 - loss: 1.1624 - regression_loss: 0.9215 - classification_loss: 0.2409
 467/1000 [=============>................] - ETA: 2:32 - loss: 1.1610 - regression_loss: 0.9204 - classification_loss: 0.2406
 468/1000 [=============>................] - ETA: 2:32 - loss: 1.1606 - regression_loss: 0.9203 - classification_loss: 0.2403
 469/1000 [=============>................] - ETA: 2:32 - loss: 1.1595 - regression_loss: 0.9196 - classification_loss: 0.2399
 470/1000 [=============>................] - ETA: 2:32 - loss: 1.1581 - regression_loss: 0.9185 - classification_loss: 0.2396
 471/1000 [=============>................] - ETA: 2:31 - loss: 1.1577 - regression_loss: 0.9181 - classification_loss: 0.2396
 472/1000 [=============>................] - ETA: 2:31 - loss: 1.1585 - regression_loss: 0.9187 - classification_loss: 0.2398
 473/1000 [=============>................] - ETA: 2:31 - loss: 1.1572 - regression_loss: 0.9176 - classification_loss: 0.2396
 474/1000 [=============>................] - ETA: 2:30 - loss: 1.1564 - regression_loss: 0.9171 - classification_loss: 0.2393
 475/1000 [=============>................] - ETA: 2:30 - loss: 1.1565 - regression_loss: 0.9173 - classification_loss: 0.2392
 476/1000 [=============>................] - ETA: 2:30 - loss: 1.1561 - regression_loss: 0.9170 - classification_loss: 0.2391
 477/1000 [=============>................] - ETA: 2:30 - loss: 1.1549 - regression_loss: 0.9161 - classification_loss: 0.2389
 478/1000 [=============>................] - ETA: 2:29 - loss: 1.1557 - regression_loss: 0.9168 - classification_loss: 0.2388
 479/1000 [=============>................] - ETA: 2:29 - loss: 1.1557 - regression_loss: 0.9171 - classification_loss: 0.2387
 480/1000 [=============>................] - ETA: 2:29 - loss: 1.1555 - regression_loss: 0.9171 - classification_loss: 0.2384
 481/1000 [=============>................] - ETA: 2:28 - loss: 1.1546 - regression_loss: 0.9164 - classification_loss: 0.2382
 482/1000 [=============>................] - ETA: 2:28 - loss: 1.1545 - regression_loss: 0.9165 - classification_loss: 0.2381
 483/1000 [=============>................] - ETA: 2:28 - loss: 1.1548 - regression_loss: 0.9169 - classification_loss: 0.2378
 484/1000 [=============>................] - ETA: 2:28 - loss: 1.1537 - regression_loss: 0.9158 - classification_loss: 0.2379
 485/1000 [=============>................] - ETA: 2:27 - loss: 1.1531 - regression_loss: 0.9151 - classification_loss: 0.2380
 486/1000 [=============>................] - ETA: 2:27 - loss: 1.1520 - regression_loss: 0.9143 - classification_loss: 0.2377
 487/1000 [=============>................] - ETA: 2:27 - loss: 1.1510 - regression_loss: 0.9136 - classification_loss: 0.2374
 488/1000 [=============>................] - ETA: 2:26 - loss: 1.1512 - regression_loss: 0.9140 - classification_loss: 0.2372
 489/1000 [=============>................] - ETA: 2:26 - loss: 1.1503 - regression_loss: 0.9134 - classification_loss: 0.2369
 490/1000 [=============>................] - ETA: 2:26 - loss: 1.1494 - regression_loss: 0.9128 - classification_loss: 0.2366
 491/1000 [=============>................] - ETA: 2:26 - loss: 1.1490 - regression_loss: 0.9127 - classification_loss: 0.2364
 492/1000 [=============>................] - ETA: 2:25 - loss: 1.1485 - regression_loss: 0.9121 - classification_loss: 0.2364
 493/1000 [=============>................] - ETA: 2:25 - loss: 1.1471 - regression_loss: 0.9110 - classification_loss: 0.2361
 494/1000 [=============>................] - ETA: 2:25 - loss: 1.1476 - regression_loss: 0.9114 - classification_loss: 0.2362
 495/1000 [=============>................] - ETA: 2:24 - loss: 1.1487 - regression_loss: 0.9122 - classification_loss: 0.2365
 496/1000 [=============>................] - ETA: 2:24 - loss: 1.1475 - regression_loss: 0.9114 - classification_loss: 0.2361
 497/1000 [=============>................] - ETA: 2:24 - loss: 1.1491 - regression_loss: 0.9130 - classification_loss: 0.2361
 498/1000 [=============>................] - ETA: 2:24 - loss: 1.1523 - regression_loss: 0.9151 - classification_loss: 0.2372
 499/1000 [=============>................] - ETA: 2:23 - loss: 1.1509 - regression_loss: 0.9139 - classification_loss: 0.2369
 500/1000 [==============>...............] - ETA: 2:23 - loss: 1.1507 - regression_loss: 0.9140 - classification_loss: 0.2368
 501/1000 [==============>...............] - ETA: 2:23 - loss: 1.1509 - regression_loss: 0.9143 - classification_loss: 0.2366
 502/1000 [==============>...............] - ETA: 2:22 - loss: 1.1496 - regression_loss: 0.9132 - classification_loss: 0.2364
 503/1000 [==============>...............] - ETA: 2:22 - loss: 1.1488 - regression_loss: 0.9127 - classification_loss: 0.2361
 504/1000 [==============>...............] - ETA: 2:22 - loss: 1.1481 - regression_loss: 0.9122 - classification_loss: 0.2359
 505/1000 [==============>...............] - ETA: 2:21 - loss: 1.1484 - regression_loss: 0.9124 - classification_loss: 0.2360
 506/1000 [==============>...............] - ETA: 2:21 - loss: 1.1480 - regression_loss: 0.9122 - classification_loss: 0.2358
 507/1000 [==============>...............] - ETA: 2:21 - loss: 1.1467 - regression_loss: 0.9113 - classification_loss: 0.2354
 508/1000 [==============>...............] - ETA: 2:21 - loss: 1.1461 - regression_loss: 0.9109 - classification_loss: 0.2352
 509/1000 [==============>...............] - ETA: 2:20 - loss: 1.1449 - regression_loss: 0.9100 - classification_loss: 0.2349
 510/1000 [==============>...............] - ETA: 2:20 - loss: 1.1442 - regression_loss: 0.9096 - classification_loss: 0.2346
 511/1000 [==============>...............] - ETA: 2:20 - loss: 1.1431 - regression_loss: 0.9087 - classification_loss: 0.2344
 512/1000 [==============>...............] - ETA: 2:19 - loss: 1.1458 - regression_loss: 0.9104 - classification_loss: 0.2354
 513/1000 [==============>...............] - ETA: 2:19 - loss: 1.1451 - regression_loss: 0.9098 - classification_loss: 0.2352
 514/1000 [==============>...............] - ETA: 2:19 - loss: 1.1467 - regression_loss: 0.9112 - classification_loss: 0.2354
 515/1000 [==============>...............] - ETA: 2:19 - loss: 1.1459 - regression_loss: 0.9107 - classification_loss: 0.2352
 516/1000 [==============>...............] - ETA: 2:18 - loss: 1.1455 - regression_loss: 0.9103 - classification_loss: 0.2352
 517/1000 [==============>...............] - ETA: 2:18 - loss: 1.1464 - regression_loss: 0.9112 - classification_loss: 0.2351
 518/1000 [==============>...............] - ETA: 2:18 - loss: 1.1474 - regression_loss: 0.9123 - classification_loss: 0.2351
 519/1000 [==============>...............] - ETA: 2:17 - loss: 1.1473 - regression_loss: 0.9121 - classification_loss: 0.2351
 520/1000 [==============>...............] - ETA: 2:17 - loss: 1.1474 - regression_loss: 0.9123 - classification_loss: 0.2351
 521/1000 [==============>...............] - ETA: 2:17 - loss: 1.1467 - regression_loss: 0.9117 - classification_loss: 0.2350
 522/1000 [==============>...............] - ETA: 2:17 - loss: 1.1452 - regression_loss: 0.9106 - classification_loss: 0.2347
 523/1000 [==============>...............] - ETA: 2:16 - loss: 1.1443 - regression_loss: 0.9099 - classification_loss: 0.2344
 524/1000 [==============>...............] - ETA: 2:16 - loss: 1.1441 - regression_loss: 0.9099 - classification_loss: 0.2342
 525/1000 [==============>...............] - ETA: 2:16 - loss: 1.1462 - regression_loss: 0.9118 - classification_loss: 0.2344
 526/1000 [==============>...............] - ETA: 2:15 - loss: 1.1477 - regression_loss: 0.9132 - classification_loss: 0.2345
 527/1000 [==============>...............] - ETA: 2:15 - loss: 1.1490 - regression_loss: 0.9143 - classification_loss: 0.2346
 528/1000 [==============>...............] - ETA: 2:15 - loss: 1.1483 - regression_loss: 0.9139 - classification_loss: 0.2344
 529/1000 [==============>...............] - ETA: 2:15 - loss: 1.1485 - regression_loss: 0.9143 - classification_loss: 0.2342
 530/1000 [==============>...............] - ETA: 2:14 - loss: 1.1476 - regression_loss: 0.9134 - classification_loss: 0.2342
 531/1000 [==============>...............] - ETA: 2:14 - loss: 1.1478 - regression_loss: 0.9136 - classification_loss: 0.2342
 532/1000 [==============>...............] - ETA: 2:14 - loss: 1.1473 - regression_loss: 0.9134 - classification_loss: 0.2340
 533/1000 [==============>...............] - ETA: 2:13 - loss: 1.1490 - regression_loss: 0.9149 - classification_loss: 0.2341
 534/1000 [===============>..............] - ETA: 2:13 - loss: 1.1484 - regression_loss: 0.9145 - classification_loss: 0.2340
 535/1000 [===============>..............] - ETA: 2:13 - loss: 1.1476 - regression_loss: 0.9138 - classification_loss: 0.2338
 536/1000 [===============>..............] - ETA: 2:13 - loss: 1.1465 - regression_loss: 0.9131 - classification_loss: 0.2335
 537/1000 [===============>..............] - ETA: 2:12 - loss: 1.1478 - regression_loss: 0.9143 - classification_loss: 0.2335
 538/1000 [===============>..............] - ETA: 2:12 - loss: 1.1478 - regression_loss: 0.9145 - classification_loss: 0.2333
 539/1000 [===============>..............] - ETA: 2:12 - loss: 1.1466 - regression_loss: 0.9136 - classification_loss: 0.2331
 540/1000 [===============>..............] - ETA: 2:11 - loss: 1.1472 - regression_loss: 0.9140 - classification_loss: 0.2332
 541/1000 [===============>..............] - ETA: 2:11 - loss: 1.1468 - regression_loss: 0.9139 - classification_loss: 0.2329
 542/1000 [===============>..............] - ETA: 2:11 - loss: 1.1463 - regression_loss: 0.9135 - classification_loss: 0.2328
 543/1000 [===============>..............] - ETA: 2:11 - loss: 1.1463 - regression_loss: 0.9138 - classification_loss: 0.2325
 544/1000 [===============>..............] - ETA: 2:10 - loss: 1.1458 - regression_loss: 0.9135 - classification_loss: 0.2323
 545/1000 [===============>..............] - ETA: 2:10 - loss: 1.1447 - regression_loss: 0.9126 - classification_loss: 0.2321
 546/1000 [===============>..............] - ETA: 2:10 - loss: 1.1434 - regression_loss: 0.9116 - classification_loss: 0.2318
 547/1000 [===============>..............] - ETA: 2:09 - loss: 1.1440 - regression_loss: 0.9120 - classification_loss: 0.2320
 548/1000 [===============>..............] - ETA: 2:09 - loss: 1.1437 - regression_loss: 0.9119 - classification_loss: 0.2318
 549/1000 [===============>..............] - ETA: 2:09 - loss: 1.1423 - regression_loss: 0.9108 - classification_loss: 0.2315
 550/1000 [===============>..............] - ETA: 2:09 - loss: 1.1435 - regression_loss: 0.9116 - classification_loss: 0.2319
 551/1000 [===============>..............] - ETA: 2:08 - loss: 1.1425 - regression_loss: 0.9108 - classification_loss: 0.2316
 552/1000 [===============>..............] - ETA: 2:08 - loss: 1.1440 - regression_loss: 0.9121 - classification_loss: 0.2319
 553/1000 [===============>..............] - ETA: 2:08 - loss: 1.1459 - regression_loss: 0.9138 - classification_loss: 0.2321
 554/1000 [===============>..............] - ETA: 2:07 - loss: 1.1451 - regression_loss: 0.9133 - classification_loss: 0.2318
 555/1000 [===============>..............] - ETA: 2:07 - loss: 1.1475 - regression_loss: 0.9149 - classification_loss: 0.2326
 556/1000 [===============>..............] - ETA: 2:07 - loss: 1.1463 - regression_loss: 0.9140 - classification_loss: 0.2323
 557/1000 [===============>..............] - ETA: 2:06 - loss: 1.1453 - regression_loss: 0.9132 - classification_loss: 0.2321
 558/1000 [===============>..............] - ETA: 2:06 - loss: 1.1456 - regression_loss: 0.9137 - classification_loss: 0.2319
 559/1000 [===============>..............] - ETA: 2:06 - loss: 1.1457 - regression_loss: 0.9138 - classification_loss: 0.2319
 560/1000 [===============>..............] - ETA: 2:06 - loss: 1.1465 - regression_loss: 0.9143 - classification_loss: 0.2321
 561/1000 [===============>..............] - ETA: 2:05 - loss: 1.1458 - regression_loss: 0.9139 - classification_loss: 0.2319
 562/1000 [===============>..............] - ETA: 2:05 - loss: 1.1448 - regression_loss: 0.9129 - classification_loss: 0.2319
 563/1000 [===============>..............] - ETA: 2:05 - loss: 1.1437 - regression_loss: 0.9121 - classification_loss: 0.2317
 564/1000 [===============>..............] - ETA: 2:04 - loss: 1.1443 - regression_loss: 0.9127 - classification_loss: 0.2316
 565/1000 [===============>..............] - ETA: 2:04 - loss: 1.1444 - regression_loss: 0.9129 - classification_loss: 0.2314
 566/1000 [===============>..............] - ETA: 2:04 - loss: 1.1440 - regression_loss: 0.9125 - classification_loss: 0.2315
 567/1000 [================>.............] - ETA: 2:04 - loss: 1.1456 - regression_loss: 0.9136 - classification_loss: 0.2320
 568/1000 [================>.............] - ETA: 2:03 - loss: 1.1444 - regression_loss: 0.9127 - classification_loss: 0.2317
 569/1000 [================>.............] - ETA: 2:03 - loss: 1.1436 - regression_loss: 0.9122 - classification_loss: 0.2315
 570/1000 [================>.............] - ETA: 2:03 - loss: 1.1432 - regression_loss: 0.9119 - classification_loss: 0.2313
 571/1000 [================>.............] - ETA: 2:02 - loss: 1.1423 - regression_loss: 0.9111 - classification_loss: 0.2312
 572/1000 [================>.............] - ETA: 2:02 - loss: 1.1430 - regression_loss: 0.9118 - classification_loss: 0.2312
 573/1000 [================>.............] - ETA: 2:02 - loss: 1.1431 - regression_loss: 0.9119 - classification_loss: 0.2312
 574/1000 [================>.............] - ETA: 2:02 - loss: 1.1432 - regression_loss: 0.9120 - classification_loss: 0.2311
 575/1000 [================>.............] - ETA: 2:01 - loss: 1.1448 - regression_loss: 0.9137 - classification_loss: 0.2312
 576/1000 [================>.............] - ETA: 2:01 - loss: 1.1442 - regression_loss: 0.9132 - classification_loss: 0.2311
 577/1000 [================>.............] - ETA: 2:01 - loss: 1.1431 - regression_loss: 0.9124 - classification_loss: 0.2308
 578/1000 [================>.............] - ETA: 2:00 - loss: 1.1431 - regression_loss: 0.9123 - classification_loss: 0.2308
 579/1000 [================>.............] - ETA: 2:00 - loss: 1.1425 - regression_loss: 0.9119 - classification_loss: 0.2306
 580/1000 [================>.............] - ETA: 2:00 - loss: 1.1426 - regression_loss: 0.9121 - classification_loss: 0.2305
 581/1000 [================>.............] - ETA: 2:00 - loss: 1.1421 - regression_loss: 0.9116 - classification_loss: 0.2305
 582/1000 [================>.............] - ETA: 1:59 - loss: 1.1416 - regression_loss: 0.9114 - classification_loss: 0.2302
 583/1000 [================>.............] - ETA: 1:59 - loss: 1.1413 - regression_loss: 0.9112 - classification_loss: 0.2301
 584/1000 [================>.............] - ETA: 1:59 - loss: 1.1432 - regression_loss: 0.9127 - classification_loss: 0.2305
 585/1000 [================>.............] - ETA: 1:58 - loss: 1.1435 - regression_loss: 0.9130 - classification_loss: 0.2304
 586/1000 [================>.............] - ETA: 1:58 - loss: 1.1436 - regression_loss: 0.9133 - classification_loss: 0.2303
 587/1000 [================>.............] - ETA: 1:58 - loss: 1.1454 - regression_loss: 0.9144 - classification_loss: 0.2310
 588/1000 [================>.............] - ETA: 1:58 - loss: 1.1447 - regression_loss: 0.9139 - classification_loss: 0.2308
 589/1000 [================>.............] - ETA: 1:57 - loss: 1.1456 - regression_loss: 0.9146 - classification_loss: 0.2310
 590/1000 [================>.............] - ETA: 1:57 - loss: 1.1444 - regression_loss: 0.9137 - classification_loss: 0.2307
 591/1000 [================>.............] - ETA: 1:57 - loss: 1.1447 - regression_loss: 0.9140 - classification_loss: 0.2307
 592/1000 [================>.............] - ETA: 1:56 - loss: 1.1467 - regression_loss: 0.9160 - classification_loss: 0.2307
 593/1000 [================>.............] - ETA: 1:56 - loss: 1.1457 - regression_loss: 0.9153 - classification_loss: 0.2304
 594/1000 [================>.............] - ETA: 1:56 - loss: 1.1450 - regression_loss: 0.9148 - classification_loss: 0.2302
 595/1000 [================>.............] - ETA: 1:56 - loss: 1.1446 - regression_loss: 0.9145 - classification_loss: 0.2301
 596/1000 [================>.............] - ETA: 1:55 - loss: 1.1444 - regression_loss: 0.9145 - classification_loss: 0.2300
 597/1000 [================>.............] - ETA: 1:55 - loss: 1.1438 - regression_loss: 0.9140 - classification_loss: 0.2298
 598/1000 [================>.............] - ETA: 1:55 - loss: 1.1451 - regression_loss: 0.9149 - classification_loss: 0.2302
 599/1000 [================>.............] - ETA: 1:54 - loss: 1.1444 - regression_loss: 0.9145 - classification_loss: 0.2299
 600/1000 [=================>............] - ETA: 1:54 - loss: 1.1437 - regression_loss: 0.9139 - classification_loss: 0.2297
 601/1000 [=================>............] - ETA: 1:54 - loss: 1.1430 - regression_loss: 0.9135 - classification_loss: 0.2295
 602/1000 [=================>............] - ETA: 1:54 - loss: 1.1425 - regression_loss: 0.9132 - classification_loss: 0.2293
 603/1000 [=================>............] - ETA: 1:53 - loss: 1.1411 - regression_loss: 0.9121 - classification_loss: 0.2290
 604/1000 [=================>............] - ETA: 1:53 - loss: 1.1406 - regression_loss: 0.9118 - classification_loss: 0.2288
 605/1000 [=================>............] - ETA: 1:53 - loss: 1.1403 - regression_loss: 0.9117 - classification_loss: 0.2286
 606/1000 [=================>............] - ETA: 1:52 - loss: 1.1403 - regression_loss: 0.9118 - classification_loss: 0.2285
 607/1000 [=================>............] - ETA: 1:52 - loss: 1.1401 - regression_loss: 0.9118 - classification_loss: 0.2283
 608/1000 [=================>............] - ETA: 1:52 - loss: 1.1397 - regression_loss: 0.9116 - classification_loss: 0.2281
 609/1000 [=================>............] - ETA: 1:52 - loss: 1.1388 - regression_loss: 0.9109 - classification_loss: 0.2279
 610/1000 [=================>............] - ETA: 1:51 - loss: 1.1386 - regression_loss: 0.9109 - classification_loss: 0.2277
 611/1000 [=================>............] - ETA: 1:51 - loss: 1.1384 - regression_loss: 0.9109 - classification_loss: 0.2275
 612/1000 [=================>............] - ETA: 1:51 - loss: 1.1377 - regression_loss: 0.9105 - classification_loss: 0.2272
 613/1000 [=================>............] - ETA: 1:50 - loss: 1.1364 - regression_loss: 0.9095 - classification_loss: 0.2269
 614/1000 [=================>............] - ETA: 1:50 - loss: 1.1367 - regression_loss: 0.9099 - classification_loss: 0.2268
 615/1000 [=================>............] - ETA: 1:50 - loss: 1.1363 - regression_loss: 0.9097 - classification_loss: 0.2266
 616/1000 [=================>............] - ETA: 1:50 - loss: 1.1365 - regression_loss: 0.9099 - classification_loss: 0.2266
 617/1000 [=================>............] - ETA: 1:49 - loss: 1.1359 - regression_loss: 0.9096 - classification_loss: 0.2264
 618/1000 [=================>............] - ETA: 1:49 - loss: 1.1374 - regression_loss: 0.9108 - classification_loss: 0.2267
 619/1000 [=================>............] - ETA: 1:49 - loss: 1.1360 - regression_loss: 0.9096 - classification_loss: 0.2264
 620/1000 [=================>............] - ETA: 1:48 - loss: 1.1348 - regression_loss: 0.9085 - classification_loss: 0.2263
 621/1000 [=================>............] - ETA: 1:48 - loss: 1.1341 - regression_loss: 0.9079 - classification_loss: 0.2262
 622/1000 [=================>............] - ETA: 1:48 - loss: 1.1353 - regression_loss: 0.9092 - classification_loss: 0.2262
 623/1000 [=================>............] - ETA: 1:48 - loss: 1.1349 - regression_loss: 0.9089 - classification_loss: 0.2260
 624/1000 [=================>............] - ETA: 1:47 - loss: 1.1345 - regression_loss: 0.9087 - classification_loss: 0.2258
 625/1000 [=================>............] - ETA: 1:47 - loss: 1.1339 - regression_loss: 0.9083 - classification_loss: 0.2256
 626/1000 [=================>............] - ETA: 1:47 - loss: 1.1338 - regression_loss: 0.9082 - classification_loss: 0.2255
 627/1000 [=================>............] - ETA: 1:46 - loss: 1.1338 - regression_loss: 0.9083 - classification_loss: 0.2255
 628/1000 [=================>............] - ETA: 1:46 - loss: 1.1331 - regression_loss: 0.9079 - classification_loss: 0.2252
 629/1000 [=================>............] - ETA: 1:46 - loss: 1.1337 - regression_loss: 0.9086 - classification_loss: 0.2252
 630/1000 [=================>............] - ETA: 1:46 - loss: 1.1331 - regression_loss: 0.9081 - classification_loss: 0.2250
 631/1000 [=================>............] - ETA: 1:45 - loss: 1.1324 - regression_loss: 0.9076 - classification_loss: 0.2248
 632/1000 [=================>............] - ETA: 1:45 - loss: 1.1315 - regression_loss: 0.9068 - classification_loss: 0.2247
 633/1000 [=================>............] - ETA: 1:45 - loss: 1.1320 - regression_loss: 0.9073 - classification_loss: 0.2247
 634/1000 [==================>...........] - ETA: 1:44 - loss: 1.1329 - regression_loss: 0.9082 - classification_loss: 0.2247
 635/1000 [==================>...........] - ETA: 1:44 - loss: 1.1332 - regression_loss: 0.9085 - classification_loss: 0.2247
 636/1000 [==================>...........] - ETA: 1:44 - loss: 1.1343 - regression_loss: 0.9092 - classification_loss: 0.2251
 637/1000 [==================>...........] - ETA: 1:44 - loss: 1.1346 - regression_loss: 0.9095 - classification_loss: 0.2251
 638/1000 [==================>...........] - ETA: 1:43 - loss: 1.1348 - regression_loss: 0.9096 - classification_loss: 0.2252
 639/1000 [==================>...........] - ETA: 1:43 - loss: 1.1344 - regression_loss: 0.9093 - classification_loss: 0.2251
 640/1000 [==================>...........] - ETA: 1:43 - loss: 1.1334 - regression_loss: 0.9084 - classification_loss: 0.2249
 641/1000 [==================>...........] - ETA: 1:42 - loss: 1.1330 - regression_loss: 0.9082 - classification_loss: 0.2248
 642/1000 [==================>...........] - ETA: 1:42 - loss: 1.1322 - regression_loss: 0.9076 - classification_loss: 0.2246
 643/1000 [==================>...........] - ETA: 1:42 - loss: 1.1315 - regression_loss: 0.9071 - classification_loss: 0.2244
 644/1000 [==================>...........] - ETA: 1:42 - loss: 1.1309 - regression_loss: 0.9066 - classification_loss: 0.2243
 645/1000 [==================>...........] - ETA: 1:41 - loss: 1.1307 - regression_loss: 0.9065 - classification_loss: 0.2242
 646/1000 [==================>...........] - ETA: 1:41 - loss: 1.1315 - regression_loss: 0.9074 - classification_loss: 0.2241
 647/1000 [==================>...........] - ETA: 1:41 - loss: 1.1304 - regression_loss: 0.9065 - classification_loss: 0.2238
 648/1000 [==================>...........] - ETA: 1:40 - loss: 1.1317 - regression_loss: 0.9079 - classification_loss: 0.2239
 649/1000 [==================>...........] - ETA: 1:40 - loss: 1.1321 - regression_loss: 0.9077 - classification_loss: 0.2244
 650/1000 [==================>...........] - ETA: 1:40 - loss: 1.1319 - regression_loss: 0.9077 - classification_loss: 0.2242
 651/1000 [==================>...........] - ETA: 1:40 - loss: 1.1321 - regression_loss: 0.9075 - classification_loss: 0.2246
 652/1000 [==================>...........] - ETA: 1:39 - loss: 1.1316 - regression_loss: 0.9070 - classification_loss: 0.2245
 653/1000 [==================>...........] - ETA: 1:39 - loss: 1.1317 - regression_loss: 0.9072 - classification_loss: 0.2245
 654/1000 [==================>...........] - ETA: 1:39 - loss: 1.1315 - regression_loss: 0.9072 - classification_loss: 0.2244
 655/1000 [==================>...........] - ETA: 1:38 - loss: 1.1319 - regression_loss: 0.9068 - classification_loss: 0.2251
 656/1000 [==================>...........] - ETA: 1:38 - loss: 1.1320 - regression_loss: 0.9069 - classification_loss: 0.2251
 657/1000 [==================>...........] - ETA: 1:38 - loss: 1.1351 - regression_loss: 0.9093 - classification_loss: 0.2258
 658/1000 [==================>...........] - ETA: 1:38 - loss: 1.1351 - regression_loss: 0.9093 - classification_loss: 0.2258
 659/1000 [==================>...........] - ETA: 1:37 - loss: 1.1366 - regression_loss: 0.9104 - classification_loss: 0.2262
 660/1000 [==================>...........] - ETA: 1:37 - loss: 1.1357 - regression_loss: 0.9096 - classification_loss: 0.2261
 661/1000 [==================>...........] - ETA: 1:37 - loss: 1.1372 - regression_loss: 0.9108 - classification_loss: 0.2264
 662/1000 [==================>...........] - ETA: 1:36 - loss: 1.1369 - regression_loss: 0.9106 - classification_loss: 0.2263
 663/1000 [==================>...........] - ETA: 1:36 - loss: 1.1367 - regression_loss: 0.9105 - classification_loss: 0.2262
 664/1000 [==================>...........] - ETA: 1:36 - loss: 1.1362 - regression_loss: 0.9101 - classification_loss: 0.2261
 665/1000 [==================>...........] - ETA: 1:36 - loss: 1.1383 - regression_loss: 0.9118 - classification_loss: 0.2265
 666/1000 [==================>...........] - ETA: 1:35 - loss: 1.1388 - regression_loss: 0.9123 - classification_loss: 0.2265
 667/1000 [===================>..........] - ETA: 1:35 - loss: 1.1391 - regression_loss: 0.9127 - classification_loss: 0.2265
 668/1000 [===================>..........] - ETA: 1:35 - loss: 1.1399 - regression_loss: 0.9134 - classification_loss: 0.2265
 669/1000 [===================>..........] - ETA: 1:34 - loss: 1.1389 - regression_loss: 0.9126 - classification_loss: 0.2263
 670/1000 [===================>..........] - ETA: 1:34 - loss: 1.1379 - regression_loss: 0.9116 - classification_loss: 0.2262
 671/1000 [===================>..........] - ETA: 1:34 - loss: 1.1388 - regression_loss: 0.9122 - classification_loss: 0.2265
 672/1000 [===================>..........] - ETA: 1:34 - loss: 1.1383 - regression_loss: 0.9119 - classification_loss: 0.2264
 673/1000 [===================>..........] - ETA: 1:33 - loss: 1.1373 - regression_loss: 0.9112 - classification_loss: 0.2261
 674/1000 [===================>..........] - ETA: 1:33 - loss: 1.1370 - regression_loss: 0.9110 - classification_loss: 0.2260
 675/1000 [===================>..........] - ETA: 1:33 - loss: 1.1373 - regression_loss: 0.9113 - classification_loss: 0.2260
 676/1000 [===================>..........] - ETA: 1:32 - loss: 1.1370 - regression_loss: 0.9111 - classification_loss: 0.2259
 677/1000 [===================>..........] - ETA: 1:32 - loss: 1.1375 - regression_loss: 0.9116 - classification_loss: 0.2259
 678/1000 [===================>..........] - ETA: 1:32 - loss: 1.1383 - regression_loss: 0.9125 - classification_loss: 0.2258
 679/1000 [===================>..........] - ETA: 1:32 - loss: 1.1379 - regression_loss: 0.9122 - classification_loss: 0.2257
 680/1000 [===================>..........] - ETA: 1:31 - loss: 1.1373 - regression_loss: 0.9118 - classification_loss: 0.2255
 681/1000 [===================>..........] - ETA: 1:31 - loss: 1.1371 - regression_loss: 0.9117 - classification_loss: 0.2254
 682/1000 [===================>..........] - ETA: 1:31 - loss: 1.1374 - regression_loss: 0.9121 - classification_loss: 0.2253
 683/1000 [===================>..........] - ETA: 1:30 - loss: 1.1393 - regression_loss: 0.9133 - classification_loss: 0.2259
 684/1000 [===================>..........] - ETA: 1:30 - loss: 1.1390 - regression_loss: 0.9132 - classification_loss: 0.2259
 685/1000 [===================>..........] - ETA: 1:30 - loss: 1.1384 - regression_loss: 0.9128 - classification_loss: 0.2256
 686/1000 [===================>..........] - ETA: 1:30 - loss: 1.1383 - regression_loss: 0.9128 - classification_loss: 0.2255
 687/1000 [===================>..........] - ETA: 1:29 - loss: 1.1383 - regression_loss: 0.9128 - classification_loss: 0.2255
 688/1000 [===================>..........] - ETA: 1:29 - loss: 1.1371 - regression_loss: 0.9119 - classification_loss: 0.2253
 689/1000 [===================>..........] - ETA: 1:29 - loss: 1.1384 - regression_loss: 0.9125 - classification_loss: 0.2258
 690/1000 [===================>..........] - ETA: 1:28 - loss: 1.1390 - regression_loss: 0.9129 - classification_loss: 0.2261
 691/1000 [===================>..........] - ETA: 1:28 - loss: 1.1393 - regression_loss: 0.9132 - classification_loss: 0.2261
 692/1000 [===================>..........] - ETA: 1:28 - loss: 1.1393 - regression_loss: 0.9133 - classification_loss: 0.2259
 693/1000 [===================>..........] - ETA: 1:28 - loss: 1.1382 - regression_loss: 0.9126 - classification_loss: 0.2257
 694/1000 [===================>..........] - ETA: 1:27 - loss: 1.1376 - regression_loss: 0.9121 - classification_loss: 0.2255
 695/1000 [===================>..........] - ETA: 1:27 - loss: 1.1376 - regression_loss: 0.9123 - classification_loss: 0.2253
 696/1000 [===================>..........] - ETA: 1:27 - loss: 1.1376 - regression_loss: 0.9123 - classification_loss: 0.2253
 697/1000 [===================>..........] - ETA: 1:26 - loss: 1.1375 - regression_loss: 0.9123 - classification_loss: 0.2252
 698/1000 [===================>..........] - ETA: 1:26 - loss: 1.1372 - regression_loss: 0.9120 - classification_loss: 0.2252
 699/1000 [===================>..........] - ETA: 1:26 - loss: 1.1382 - regression_loss: 0.9128 - classification_loss: 0.2253
 700/1000 [====================>.........] - ETA: 1:26 - loss: 1.1374 - regression_loss: 0.9121 - classification_loss: 0.2253
 701/1000 [====================>.........] - ETA: 1:25 - loss: 1.1365 - regression_loss: 0.9114 - classification_loss: 0.2251
 702/1000 [====================>.........] - ETA: 1:25 - loss: 1.1356 - regression_loss: 0.9107 - classification_loss: 0.2249
 703/1000 [====================>.........] - ETA: 1:25 - loss: 1.1348 - regression_loss: 0.9100 - classification_loss: 0.2248
 704/1000 [====================>.........] - ETA: 1:24 - loss: 1.1348 - regression_loss: 0.9102 - classification_loss: 0.2246
 705/1000 [====================>.........] - ETA: 1:24 - loss: 1.1355 - regression_loss: 0.9108 - classification_loss: 0.2247
 706/1000 [====================>.........] - ETA: 1:24 - loss: 1.1356 - regression_loss: 0.9111 - classification_loss: 0.2246
 707/1000 [====================>.........] - ETA: 1:24 - loss: 1.1366 - regression_loss: 0.9119 - classification_loss: 0.2247
 708/1000 [====================>.........] - ETA: 1:23 - loss: 1.1360 - regression_loss: 0.9115 - classification_loss: 0.2245
 709/1000 [====================>.........] - ETA: 1:23 - loss: 1.1369 - regression_loss: 0.9123 - classification_loss: 0.2247
 710/1000 [====================>.........] - ETA: 1:23 - loss: 1.1363 - regression_loss: 0.9118 - classification_loss: 0.2245
 711/1000 [====================>.........] - ETA: 1:22 - loss: 1.1361 - regression_loss: 0.9115 - classification_loss: 0.2246
 712/1000 [====================>.........] - ETA: 1:22 - loss: 1.1353 - regression_loss: 0.9107 - classification_loss: 0.2245
 713/1000 [====================>.........] - ETA: 1:22 - loss: 1.1348 - regression_loss: 0.9102 - classification_loss: 0.2247
 714/1000 [====================>.........] - ETA: 1:22 - loss: 1.1349 - regression_loss: 0.9104 - classification_loss: 0.2245
 715/1000 [====================>.........] - ETA: 1:21 - loss: 1.1345 - regression_loss: 0.9101 - classification_loss: 0.2244
 716/1000 [====================>.........] - ETA: 1:21 - loss: 1.1349 - regression_loss: 0.9103 - classification_loss: 0.2245
 717/1000 [====================>.........] - ETA: 1:21 - loss: 1.1342 - regression_loss: 0.9099 - classification_loss: 0.2244
 718/1000 [====================>.........] - ETA: 1:20 - loss: 1.1337 - regression_loss: 0.9095 - classification_loss: 0.2242
 719/1000 [====================>.........] - ETA: 1:20 - loss: 1.1340 - regression_loss: 0.9098 - classification_loss: 0.2242
 720/1000 [====================>.........] - ETA: 1:20 - loss: 1.1338 - regression_loss: 0.9097 - classification_loss: 0.2241
 721/1000 [====================>.........] - ETA: 1:19 - loss: 1.1334 - regression_loss: 0.9095 - classification_loss: 0.2239
 722/1000 [====================>.........] - ETA: 1:19 - loss: 1.1338 - regression_loss: 0.9098 - classification_loss: 0.2240
 723/1000 [====================>.........] - ETA: 1:19 - loss: 1.1336 - regression_loss: 0.9096 - classification_loss: 0.2240
 724/1000 [====================>.........] - ETA: 1:19 - loss: 1.1330 - regression_loss: 0.9092 - classification_loss: 0.2238
 725/1000 [====================>.........] - ETA: 1:18 - loss: 1.1320 - regression_loss: 0.9084 - classification_loss: 0.2236
 726/1000 [====================>.........] - ETA: 1:18 - loss: 1.1315 - regression_loss: 0.9081 - classification_loss: 0.2235
 727/1000 [====================>.........] - ETA: 1:18 - loss: 1.1314 - regression_loss: 0.9080 - classification_loss: 0.2234
 728/1000 [====================>.........] - ETA: 1:17 - loss: 1.1303 - regression_loss: 0.9071 - classification_loss: 0.2232
 729/1000 [====================>.........] - ETA: 1:17 - loss: 1.1305 - regression_loss: 0.9073 - classification_loss: 0.2232
 730/1000 [====================>.........] - ETA: 1:17 - loss: 1.1319 - regression_loss: 0.9084 - classification_loss: 0.2235
 731/1000 [====================>.........] - ETA: 1:17 - loss: 1.1315 - regression_loss: 0.9082 - classification_loss: 0.2233
 732/1000 [====================>.........] - ETA: 1:16 - loss: 1.1308 - regression_loss: 0.9074 - classification_loss: 0.2235
 733/1000 [====================>.........] - ETA: 1:16 - loss: 1.1300 - regression_loss: 0.9067 - classification_loss: 0.2232
 734/1000 [=====================>........] - ETA: 1:16 - loss: 1.1314 - regression_loss: 0.9078 - classification_loss: 0.2236
 735/1000 [=====================>........] - ETA: 1:15 - loss: 1.1323 - regression_loss: 0.9084 - classification_loss: 0.2239
 736/1000 [=====================>........] - ETA: 1:15 - loss: 1.1329 - regression_loss: 0.9090 - classification_loss: 0.2239
 737/1000 [=====================>........] - ETA: 1:15 - loss: 1.1348 - regression_loss: 0.9107 - classification_loss: 0.2241
 738/1000 [=====================>........] - ETA: 1:15 - loss: 1.1341 - regression_loss: 0.9099 - classification_loss: 0.2241
 739/1000 [=====================>........] - ETA: 1:14 - loss: 1.1333 - regression_loss: 0.9093 - classification_loss: 0.2240
 740/1000 [=====================>........] - ETA: 1:14 - loss: 1.1347 - regression_loss: 0.9104 - classification_loss: 0.2242
 741/1000 [=====================>........] - ETA: 1:14 - loss: 1.1347 - regression_loss: 0.9104 - classification_loss: 0.2242
 742/1000 [=====================>........] - ETA: 1:13 - loss: 1.1373 - regression_loss: 0.9125 - classification_loss: 0.2248
 743/1000 [=====================>........] - ETA: 1:13 - loss: 1.1372 - regression_loss: 0.9124 - classification_loss: 0.2248
 744/1000 [=====================>........] - ETA: 1:13 - loss: 1.1368 - regression_loss: 0.9120 - classification_loss: 0.2248
 745/1000 [=====================>........] - ETA: 1:13 - loss: 1.1370 - regression_loss: 0.9121 - classification_loss: 0.2249
 746/1000 [=====================>........] - ETA: 1:12 - loss: 1.1361 - regression_loss: 0.9113 - classification_loss: 0.2247
 747/1000 [=====================>........] - ETA: 1:12 - loss: 1.1351 - regression_loss: 0.9106 - classification_loss: 0.2245
 748/1000 [=====================>........] - ETA: 1:12 - loss: 1.1349 - regression_loss: 0.9104 - classification_loss: 0.2245
 749/1000 [=====================>........] - ETA: 1:11 - loss: 1.1355 - regression_loss: 0.9109 - classification_loss: 0.2245
 750/1000 [=====================>........] - ETA: 1:11 - loss: 1.1351 - regression_loss: 0.9107 - classification_loss: 0.2244
 751/1000 [=====================>........] - ETA: 1:11 - loss: 1.1358 - regression_loss: 0.9115 - classification_loss: 0.2243
 752/1000 [=====================>........] - ETA: 1:11 - loss: 1.1361 - regression_loss: 0.9118 - classification_loss: 0.2243
 753/1000 [=====================>........] - ETA: 1:10 - loss: 1.1361 - regression_loss: 0.9119 - classification_loss: 0.2242
 754/1000 [=====================>........] - ETA: 1:10 - loss: 1.1359 - regression_loss: 0.9116 - classification_loss: 0.2243
 755/1000 [=====================>........] - ETA: 1:10 - loss: 1.1364 - regression_loss: 0.9118 - classification_loss: 0.2247
 756/1000 [=====================>........] - ETA: 1:09 - loss: 1.1359 - regression_loss: 0.9113 - classification_loss: 0.2246
 757/1000 [=====================>........] - ETA: 1:09 - loss: 1.1356 - regression_loss: 0.9112 - classification_loss: 0.2244
 758/1000 [=====================>........] - ETA: 1:09 - loss: 1.1350 - regression_loss: 0.9108 - classification_loss: 0.2242
 759/1000 [=====================>........] - ETA: 1:09 - loss: 1.1368 - regression_loss: 0.9122 - classification_loss: 0.2246
 760/1000 [=====================>........] - ETA: 1:08 - loss: 1.1366 - regression_loss: 0.9121 - classification_loss: 0.2244
 761/1000 [=====================>........] - ETA: 1:08 - loss: 1.1373 - regression_loss: 0.9128 - classification_loss: 0.2245
 762/1000 [=====================>........] - ETA: 1:08 - loss: 1.1372 - regression_loss: 0.9127 - classification_loss: 0.2244
 763/1000 [=====================>........] - ETA: 1:07 - loss: 1.1377 - regression_loss: 0.9132 - classification_loss: 0.2245
 764/1000 [=====================>........] - ETA: 1:07 - loss: 1.1364 - regression_loss: 0.9120 - classification_loss: 0.2244
 765/1000 [=====================>........] - ETA: 1:07 - loss: 1.1374 - regression_loss: 0.9128 - classification_loss: 0.2246
 766/1000 [=====================>........] - ETA: 1:07 - loss: 1.1370 - regression_loss: 0.9125 - classification_loss: 0.2245
 767/1000 [======================>.......] - ETA: 1:06 - loss: 1.1369 - regression_loss: 0.9125 - classification_loss: 0.2244
 768/1000 [======================>.......] - ETA: 1:06 - loss: 1.1363 - regression_loss: 0.9120 - classification_loss: 0.2243
 769/1000 [======================>.......] - ETA: 1:06 - loss: 1.1356 - regression_loss: 0.9114 - classification_loss: 0.2241
 770/1000 [======================>.......] - ETA: 1:05 - loss: 1.1363 - regression_loss: 0.9121 - classification_loss: 0.2242
 771/1000 [======================>.......] - ETA: 1:05 - loss: 1.1363 - regression_loss: 0.9122 - classification_loss: 0.2240
 772/1000 [======================>.......] - ETA: 1:05 - loss: 1.1366 - regression_loss: 0.9124 - classification_loss: 0.2242
 773/1000 [======================>.......] - ETA: 1:05 - loss: 1.1368 - regression_loss: 0.9126 - classification_loss: 0.2242
 774/1000 [======================>.......] - ETA: 1:04 - loss: 1.1365 - regression_loss: 0.9124 - classification_loss: 0.2241
 775/1000 [======================>.......] - ETA: 1:04 - loss: 1.1369 - regression_loss: 0.9128 - classification_loss: 0.2241
 776/1000 [======================>.......] - ETA: 1:04 - loss: 1.1362 - regression_loss: 0.9123 - classification_loss: 0.2239
 777/1000 [======================>.......] - ETA: 1:03 - loss: 1.1353 - regression_loss: 0.9116 - classification_loss: 0.2237
 778/1000 [======================>.......] - ETA: 1:03 - loss: 1.1343 - regression_loss: 0.9108 - classification_loss: 0.2235
 779/1000 [======================>.......] - ETA: 1:03 - loss: 1.1342 - regression_loss: 0.9107 - classification_loss: 0.2235
 780/1000 [======================>.......] - ETA: 1:03 - loss: 1.1338 - regression_loss: 0.9104 - classification_loss: 0.2234
 781/1000 [======================>.......] - ETA: 1:02 - loss: 1.1342 - regression_loss: 0.9110 - classification_loss: 0.2233
 782/1000 [======================>.......] - ETA: 1:02 - loss: 1.1340 - regression_loss: 0.9109 - classification_loss: 0.2231
 783/1000 [======================>.......] - ETA: 1:02 - loss: 1.1336 - regression_loss: 0.9106 - classification_loss: 0.2231
 784/1000 [======================>.......] - ETA: 1:01 - loss: 1.1330 - regression_loss: 0.9101 - classification_loss: 0.2229
 785/1000 [======================>.......] - ETA: 1:01 - loss: 1.1326 - regression_loss: 0.9097 - classification_loss: 0.2229
 786/1000 [======================>.......] - ETA: 1:01 - loss: 1.1322 - regression_loss: 0.9094 - classification_loss: 0.2228
 787/1000 [======================>.......] - ETA: 1:01 - loss: 1.1329 - regression_loss: 0.9099 - classification_loss: 0.2230
 788/1000 [======================>.......] - ETA: 1:00 - loss: 1.1324 - regression_loss: 0.9095 - classification_loss: 0.2228
 789/1000 [======================>.......] - ETA: 1:00 - loss: 1.1320 - regression_loss: 0.9093 - classification_loss: 0.2226
 790/1000 [======================>.......] - ETA: 1:00 - loss: 1.1311 - regression_loss: 0.9087 - classification_loss: 0.2225
 791/1000 [======================>.......] - ETA: 59s - loss: 1.1306 - regression_loss: 0.9082 - classification_loss: 0.2223 
 792/1000 [======================>.......] - ETA: 59s - loss: 1.1303 - regression_loss: 0.9082 - classification_loss: 0.2221
 793/1000 [======================>.......] - ETA: 59s - loss: 1.1304 - regression_loss: 0.9082 - classification_loss: 0.2221
 794/1000 [======================>.......] - ETA: 59s - loss: 1.1307 - regression_loss: 0.9085 - classification_loss: 0.2222
 795/1000 [======================>.......] - ETA: 58s - loss: 1.1303 - regression_loss: 0.9083 - classification_loss: 0.2220
 796/1000 [======================>.......] - ETA: 58s - loss: 1.1301 - regression_loss: 0.9081 - classification_loss: 0.2220
 797/1000 [======================>.......] - ETA: 58s - loss: 1.1303 - regression_loss: 0.9083 - classification_loss: 0.2221
 798/1000 [======================>.......] - ETA: 57s - loss: 1.1300 - regression_loss: 0.9079 - classification_loss: 0.2221
 799/1000 [======================>.......] - ETA: 57s - loss: 1.1295 - regression_loss: 0.9076 - classification_loss: 0.2219
 800/1000 [=======================>......] - ETA: 57s - loss: 1.1321 - regression_loss: 0.9100 - classification_loss: 0.2221
 801/1000 [=======================>......] - ETA: 57s - loss: 1.1323 - regression_loss: 0.9101 - classification_loss: 0.2222
 802/1000 [=======================>......] - ETA: 56s - loss: 1.1324 - regression_loss: 0.9102 - classification_loss: 0.2221
 803/1000 [=======================>......] - ETA: 56s - loss: 1.1324 - regression_loss: 0.9103 - classification_loss: 0.2221
 804/1000 [=======================>......] - ETA: 56s - loss: 1.1317 - regression_loss: 0.9098 - classification_loss: 0.2219
 805/1000 [=======================>......] - ETA: 55s - loss: 1.1326 - regression_loss: 0.9105 - classification_loss: 0.2221
 806/1000 [=======================>......] - ETA: 55s - loss: 1.1319 - regression_loss: 0.9099 - classification_loss: 0.2220
 807/1000 [=======================>......] - ETA: 55s - loss: 1.1323 - regression_loss: 0.9103 - classification_loss: 0.2220
 808/1000 [=======================>......] - ETA: 55s - loss: 1.1315 - regression_loss: 0.9096 - classification_loss: 0.2219
 809/1000 [=======================>......] - ETA: 54s - loss: 1.1312 - regression_loss: 0.9094 - classification_loss: 0.2218
 810/1000 [=======================>......] - ETA: 54s - loss: 1.1323 - regression_loss: 0.9102 - classification_loss: 0.2221
 811/1000 [=======================>......] - ETA: 54s - loss: 1.1323 - regression_loss: 0.9102 - classification_loss: 0.2221
 812/1000 [=======================>......] - ETA: 53s - loss: 1.1317 - regression_loss: 0.9096 - classification_loss: 0.2221
 813/1000 [=======================>......] - ETA: 53s - loss: 1.1316 - regression_loss: 0.9097 - classification_loss: 0.2219
 814/1000 [=======================>......] - ETA: 53s - loss: 1.1316 - regression_loss: 0.9098 - classification_loss: 0.2218
 815/1000 [=======================>......] - ETA: 53s - loss: 1.1316 - regression_loss: 0.9099 - classification_loss: 0.2218
 816/1000 [=======================>......] - ETA: 52s - loss: 1.1311 - regression_loss: 0.9092 - classification_loss: 0.2219
 817/1000 [=======================>......] - ETA: 52s - loss: 1.1337 - regression_loss: 0.9111 - classification_loss: 0.2227
 818/1000 [=======================>......] - ETA: 52s - loss: 1.1338 - regression_loss: 0.9112 - classification_loss: 0.2226
 819/1000 [=======================>......] - ETA: 51s - loss: 1.1355 - regression_loss: 0.9123 - classification_loss: 0.2232
 820/1000 [=======================>......] - ETA: 51s - loss: 1.1348 - regression_loss: 0.9118 - classification_loss: 0.2230
 821/1000 [=======================>......] - ETA: 51s - loss: 1.1340 - regression_loss: 0.9111 - classification_loss: 0.2229
 822/1000 [=======================>......] - ETA: 51s - loss: 1.1336 - regression_loss: 0.9108 - classification_loss: 0.2227
 823/1000 [=======================>......] - ETA: 50s - loss: 1.1343 - regression_loss: 0.9114 - classification_loss: 0.2228
 824/1000 [=======================>......] - ETA: 50s - loss: 1.1343 - regression_loss: 0.9115 - classification_loss: 0.2228
 825/1000 [=======================>......] - ETA: 50s - loss: 1.1332 - regression_loss: 0.9106 - classification_loss: 0.2226
 826/1000 [=======================>......] - ETA: 49s - loss: 1.1335 - regression_loss: 0.9108 - classification_loss: 0.2228
 827/1000 [=======================>......] - ETA: 49s - loss: 1.1337 - regression_loss: 0.9109 - classification_loss: 0.2228
 828/1000 [=======================>......] - ETA: 49s - loss: 1.1342 - regression_loss: 0.9114 - classification_loss: 0.2228
 829/1000 [=======================>......] - ETA: 49s - loss: 1.1342 - regression_loss: 0.9113 - classification_loss: 0.2228
 830/1000 [=======================>......] - ETA: 48s - loss: 1.1335 - regression_loss: 0.9108 - classification_loss: 0.2227
 831/1000 [=======================>......] - ETA: 48s - loss: 1.1335 - regression_loss: 0.9108 - classification_loss: 0.2227
 832/1000 [=======================>......] - ETA: 48s - loss: 1.1342 - regression_loss: 0.9114 - classification_loss: 0.2228
 833/1000 [=======================>......] - ETA: 47s - loss: 1.1333 - regression_loss: 0.9106 - classification_loss: 0.2227
 834/1000 [========================>.....] - ETA: 47s - loss: 1.1336 - regression_loss: 0.9108 - classification_loss: 0.2228
 835/1000 [========================>.....] - ETA: 47s - loss: 1.1333 - regression_loss: 0.9106 - classification_loss: 0.2227
 836/1000 [========================>.....] - ETA: 47s - loss: 1.1342 - regression_loss: 0.9114 - classification_loss: 0.2227
 837/1000 [========================>.....] - ETA: 46s - loss: 1.1344 - regression_loss: 0.9118 - classification_loss: 0.2226
 838/1000 [========================>.....] - ETA: 46s - loss: 1.1340 - regression_loss: 0.9115 - classification_loss: 0.2225
 839/1000 [========================>.....] - ETA: 46s - loss: 1.1342 - regression_loss: 0.9117 - classification_loss: 0.2225
 840/1000 [========================>.....] - ETA: 45s - loss: 1.1342 - regression_loss: 0.9116 - classification_loss: 0.2226
 841/1000 [========================>.....] - ETA: 45s - loss: 1.1335 - regression_loss: 0.9111 - classification_loss: 0.2225
 842/1000 [========================>.....] - ETA: 45s - loss: 1.1332 - regression_loss: 0.9108 - classification_loss: 0.2224
 843/1000 [========================>.....] - ETA: 45s - loss: 1.1326 - regression_loss: 0.9103 - classification_loss: 0.2223
 844/1000 [========================>.....] - ETA: 44s - loss: 1.1321 - regression_loss: 0.9100 - classification_loss: 0.2221
 845/1000 [========================>.....] - ETA: 44s - loss: 1.1334 - regression_loss: 0.9112 - classification_loss: 0.2222
 846/1000 [========================>.....] - ETA: 44s - loss: 1.1334 - regression_loss: 0.9111 - classification_loss: 0.2223
 847/1000 [========================>.....] - ETA: 43s - loss: 1.1327 - regression_loss: 0.9107 - classification_loss: 0.2221
 848/1000 [========================>.....] - ETA: 43s - loss: 1.1325 - regression_loss: 0.9106 - classification_loss: 0.2219
 849/1000 [========================>.....] - ETA: 43s - loss: 1.1320 - regression_loss: 0.9102 - classification_loss: 0.2218
 850/1000 [========================>.....] - ETA: 42s - loss: 1.1314 - regression_loss: 0.9098 - classification_loss: 0.2216
 851/1000 [========================>.....] - ETA: 42s - loss: 1.1305 - regression_loss: 0.9091 - classification_loss: 0.2214
 852/1000 [========================>.....] - ETA: 42s - loss: 1.1301 - regression_loss: 0.9088 - classification_loss: 0.2213
 853/1000 [========================>.....] - ETA: 42s - loss: 1.1312 - regression_loss: 0.9100 - classification_loss: 0.2213
 854/1000 [========================>.....] - ETA: 41s - loss: 1.1309 - regression_loss: 0.9098 - classification_loss: 0.2211
 855/1000 [========================>.....] - ETA: 41s - loss: 1.1311 - regression_loss: 0.9100 - classification_loss: 0.2211
 856/1000 [========================>.....] - ETA: 41s - loss: 1.1307 - regression_loss: 0.9097 - classification_loss: 0.2210
 857/1000 [========================>.....] - ETA: 40s - loss: 1.1315 - regression_loss: 0.9103 - classification_loss: 0.2212
 858/1000 [========================>.....] - ETA: 40s - loss: 1.1319 - regression_loss: 0.9107 - classification_loss: 0.2212
 859/1000 [========================>.....] - ETA: 40s - loss: 1.1313 - regression_loss: 0.9102 - classification_loss: 0.2210
 860/1000 [========================>.....] - ETA: 40s - loss: 1.1324 - regression_loss: 0.9112 - classification_loss: 0.2212
 861/1000 [========================>.....] - ETA: 39s - loss: 1.1321 - regression_loss: 0.9111 - classification_loss: 0.2210
 862/1000 [========================>.....] - ETA: 39s - loss: 1.1318 - regression_loss: 0.9109 - classification_loss: 0.2209
 863/1000 [========================>.....] - ETA: 39s - loss: 1.1320 - regression_loss: 0.9109 - classification_loss: 0.2211
 864/1000 [========================>.....] - ETA: 38s - loss: 1.1312 - regression_loss: 0.9103 - classification_loss: 0.2210
 865/1000 [========================>.....] - ETA: 38s - loss: 1.1310 - regression_loss: 0.9101 - classification_loss: 0.2209
 866/1000 [========================>.....] - ETA: 38s - loss: 1.1306 - regression_loss: 0.9099 - classification_loss: 0.2207
 867/1000 [=========================>....] - ETA: 38s - loss: 1.1324 - regression_loss: 0.9114 - classification_loss: 0.2210
 868/1000 [=========================>....] - ETA: 37s - loss: 1.1323 - regression_loss: 0.9113 - classification_loss: 0.2210
 869/1000 [=========================>....] - ETA: 37s - loss: 1.1328 - regression_loss: 0.9116 - classification_loss: 0.2211
 870/1000 [=========================>....] - ETA: 37s - loss: 1.1327 - regression_loss: 0.9117 - classification_loss: 0.2210
 871/1000 [=========================>....] - ETA: 36s - loss: 1.1325 - regression_loss: 0.9116 - classification_loss: 0.2209
 872/1000 [=========================>....] - ETA: 36s - loss: 1.1319 - regression_loss: 0.9111 - classification_loss: 0.2207
 873/1000 [=========================>....] - ETA: 36s - loss: 1.1314 - regression_loss: 0.9108 - classification_loss: 0.2206
 874/1000 [=========================>....] - ETA: 36s - loss: 1.1317 - regression_loss: 0.9111 - classification_loss: 0.2206
 875/1000 [=========================>....] - ETA: 35s - loss: 1.1309 - regression_loss: 0.9104 - classification_loss: 0.2205
 876/1000 [=========================>....] - ETA: 35s - loss: 1.1305 - regression_loss: 0.9101 - classification_loss: 0.2203
 877/1000 [=========================>....] - ETA: 35s - loss: 1.1300 - regression_loss: 0.9098 - classification_loss: 0.2202
 878/1000 [=========================>....] - ETA: 34s - loss: 1.1298 - regression_loss: 0.9098 - classification_loss: 0.2201
 879/1000 [=========================>....] - ETA: 34s - loss: 1.1297 - regression_loss: 0.9097 - classification_loss: 0.2200
 880/1000 [=========================>....] - ETA: 34s - loss: 1.1291 - regression_loss: 0.9093 - classification_loss: 0.2198
 881/1000 [=========================>....] - ETA: 34s - loss: 1.1283 - regression_loss: 0.9087 - classification_loss: 0.2196
 882/1000 [=========================>....] - ETA: 33s - loss: 1.1284 - regression_loss: 0.9088 - classification_loss: 0.2196
 883/1000 [=========================>....] - ETA: 33s - loss: 1.1287 - regression_loss: 0.9091 - classification_loss: 0.2196
 884/1000 [=========================>....] - ETA: 33s - loss: 1.1284 - regression_loss: 0.9089 - classification_loss: 0.2195
 885/1000 [=========================>....] - ETA: 32s - loss: 1.1284 - regression_loss: 0.9088 - classification_loss: 0.2196
 886/1000 [=========================>....] - ETA: 32s - loss: 1.1289 - regression_loss: 0.9092 - classification_loss: 0.2197
 887/1000 [=========================>....] - ETA: 32s - loss: 1.1286 - regression_loss: 0.9090 - classification_loss: 0.2196
 888/1000 [=========================>....] - ETA: 32s - loss: 1.1279 - regression_loss: 0.9084 - classification_loss: 0.2194
 889/1000 [=========================>....] - ETA: 31s - loss: 1.1297 - regression_loss: 0.9096 - classification_loss: 0.2201
 890/1000 [=========================>....] - ETA: 31s - loss: 1.1301 - regression_loss: 0.9099 - classification_loss: 0.2201
 891/1000 [=========================>....] - ETA: 31s - loss: 1.1296 - regression_loss: 0.9095 - classification_loss: 0.2202
 892/1000 [=========================>....] - ETA: 30s - loss: 1.1289 - regression_loss: 0.9089 - classification_loss: 0.2201
 893/1000 [=========================>....] - ETA: 30s - loss: 1.1294 - regression_loss: 0.9094 - classification_loss: 0.2200
 894/1000 [=========================>....] - ETA: 30s - loss: 1.1300 - regression_loss: 0.9101 - classification_loss: 0.2200
 895/1000 [=========================>....] - ETA: 30s - loss: 1.1298 - regression_loss: 0.9098 - classification_loss: 0.2199
 896/1000 [=========================>....] - ETA: 29s - loss: 1.1293 - regression_loss: 0.9096 - classification_loss: 0.2198
 897/1000 [=========================>....] - ETA: 29s - loss: 1.1291 - regression_loss: 0.9093 - classification_loss: 0.2198
 898/1000 [=========================>....] - ETA: 29s - loss: 1.1293 - regression_loss: 0.9095 - classification_loss: 0.2198
 899/1000 [=========================>....] - ETA: 28s - loss: 1.1288 - regression_loss: 0.9091 - classification_loss: 0.2197
 900/1000 [==========================>...] - ETA: 28s - loss: 1.1284 - regression_loss: 0.9088 - classification_loss: 0.2195
 901/1000 [==========================>...] - ETA: 28s - loss: 1.1285 - regression_loss: 0.9090 - classification_loss: 0.2195
 902/1000 [==========================>...] - ETA: 28s - loss: 1.1278 - regression_loss: 0.9085 - classification_loss: 0.2193
 903/1000 [==========================>...] - ETA: 27s - loss: 1.1279 - regression_loss: 0.9086 - classification_loss: 0.2193
 904/1000 [==========================>...] - ETA: 27s - loss: 1.1271 - regression_loss: 0.9080 - classification_loss: 0.2192
 905/1000 [==========================>...] - ETA: 27s - loss: 1.1270 - regression_loss: 0.9080 - classification_loss: 0.2191
 906/1000 [==========================>...] - ETA: 26s - loss: 1.1270 - regression_loss: 0.9081 - classification_loss: 0.2190
 907/1000 [==========================>...] - ETA: 26s - loss: 1.1270 - regression_loss: 0.9081 - classification_loss: 0.2189
 908/1000 [==========================>...] - ETA: 26s - loss: 1.1263 - regression_loss: 0.9076 - classification_loss: 0.2187
 909/1000 [==========================>...] - ETA: 26s - loss: 1.1257 - regression_loss: 0.9071 - classification_loss: 0.2186
 910/1000 [==========================>...] - ETA: 25s - loss: 1.1251 - regression_loss: 0.9066 - classification_loss: 0.2185
 911/1000 [==========================>...] - ETA: 25s - loss: 1.1244 - regression_loss: 0.9060 - classification_loss: 0.2184
 912/1000 [==========================>...] - ETA: 25s - loss: 1.1241 - regression_loss: 0.9058 - classification_loss: 0.2183
 913/1000 [==========================>...] - ETA: 24s - loss: 1.1237 - regression_loss: 0.9056 - classification_loss: 0.2182
 914/1000 [==========================>...] - ETA: 24s - loss: 1.1230 - regression_loss: 0.9050 - classification_loss: 0.2180
 915/1000 [==========================>...] - ETA: 24s - loss: 1.1229 - regression_loss: 0.9049 - classification_loss: 0.2180
 916/1000 [==========================>...] - ETA: 24s - loss: 1.1230 - regression_loss: 0.9050 - classification_loss: 0.2180
 917/1000 [==========================>...] - ETA: 23s - loss: 1.1230 - regression_loss: 0.9051 - classification_loss: 0.2179
 918/1000 [==========================>...] - ETA: 23s - loss: 1.1226 - regression_loss: 0.9047 - classification_loss: 0.2178
 919/1000 [==========================>...] - ETA: 23s - loss: 1.1221 - regression_loss: 0.9044 - classification_loss: 0.2177
 920/1000 [==========================>...] - ETA: 22s - loss: 1.1228 - regression_loss: 0.9050 - classification_loss: 0.2177
 921/1000 [==========================>...] - ETA: 22s - loss: 1.1239 - regression_loss: 0.9060 - classification_loss: 0.2179
 922/1000 [==========================>...] - ETA: 22s - loss: 1.1254 - regression_loss: 0.9071 - classification_loss: 0.2183
 923/1000 [==========================>...] - ETA: 22s - loss: 1.1265 - regression_loss: 0.9081 - classification_loss: 0.2185
 924/1000 [==========================>...] - ETA: 21s - loss: 1.1272 - regression_loss: 0.9087 - classification_loss: 0.2185
 925/1000 [==========================>...] - ETA: 21s - loss: 1.1274 - regression_loss: 0.9088 - classification_loss: 0.2186
 926/1000 [==========================>...] - ETA: 21s - loss: 1.1273 - regression_loss: 0.9087 - classification_loss: 0.2186
 927/1000 [==========================>...] - ETA: 20s - loss: 1.1282 - regression_loss: 0.9094 - classification_loss: 0.2188
 928/1000 [==========================>...] - ETA: 20s - loss: 1.1279 - regression_loss: 0.9091 - classification_loss: 0.2187
 929/1000 [==========================>...] - ETA: 20s - loss: 1.1273 - regression_loss: 0.9087 - classification_loss: 0.2186
 930/1000 [==========================>...] - ETA: 20s - loss: 1.1271 - regression_loss: 0.9084 - classification_loss: 0.2186
 931/1000 [==========================>...] - ETA: 19s - loss: 1.1277 - regression_loss: 0.9089 - classification_loss: 0.2188
 932/1000 [==========================>...] - ETA: 19s - loss: 1.1276 - regression_loss: 0.9090 - classification_loss: 0.2187
 933/1000 [==========================>...] - ETA: 19s - loss: 1.1288 - regression_loss: 0.9099 - classification_loss: 0.2189
 934/1000 [===========================>..] - ETA: 18s - loss: 1.1294 - regression_loss: 0.9104 - classification_loss: 0.2190
 935/1000 [===========================>..] - ETA: 18s - loss: 1.1288 - regression_loss: 0.9100 - classification_loss: 0.2188
 936/1000 [===========================>..] - ETA: 18s - loss: 1.1289 - regression_loss: 0.9101 - classification_loss: 0.2188
 937/1000 [===========================>..] - ETA: 18s - loss: 1.1287 - regression_loss: 0.9100 - classification_loss: 0.2187
 938/1000 [===========================>..] - ETA: 17s - loss: 1.1290 - regression_loss: 0.9103 - classification_loss: 0.2187
 939/1000 [===========================>..] - ETA: 17s - loss: 1.1299 - regression_loss: 0.9107 - classification_loss: 0.2192
 940/1000 [===========================>..] - ETA: 17s - loss: 1.1307 - regression_loss: 0.9115 - classification_loss: 0.2192
 941/1000 [===========================>..] - ETA: 16s - loss: 1.1304 - regression_loss: 0.9109 - classification_loss: 0.2194
 942/1000 [===========================>..] - ETA: 16s - loss: 1.1303 - regression_loss: 0.9107 - classification_loss: 0.2196
 943/1000 [===========================>..] - ETA: 16s - loss: 1.1303 - regression_loss: 0.9108 - classification_loss: 0.2195
 944/1000 [===========================>..] - ETA: 16s - loss: 1.1306 - regression_loss: 0.9111 - classification_loss: 0.2196
 945/1000 [===========================>..] - ETA: 15s - loss: 1.1303 - regression_loss: 0.9109 - classification_loss: 0.2195
 946/1000 [===========================>..] - ETA: 15s - loss: 1.1323 - regression_loss: 0.9122 - classification_loss: 0.2201
 947/1000 [===========================>..] - ETA: 15s - loss: 1.1322 - regression_loss: 0.9121 - classification_loss: 0.2201
 948/1000 [===========================>..] - ETA: 14s - loss: 1.1320 - regression_loss: 0.9121 - classification_loss: 0.2199
 949/1000 [===========================>..] - ETA: 14s - loss: 1.1328 - regression_loss: 0.9128 - classification_loss: 0.2200
 950/1000 [===========================>..] - ETA: 14s - loss: 1.1335 - regression_loss: 0.9133 - classification_loss: 0.2202
 951/1000 [===========================>..] - ETA: 14s - loss: 1.1333 - regression_loss: 0.9131 - classification_loss: 0.2202
 952/1000 [===========================>..] - ETA: 13s - loss: 1.1336 - regression_loss: 0.9133 - classification_loss: 0.2203
 953/1000 [===========================>..] - ETA: 13s - loss: 1.1341 - regression_loss: 0.9137 - classification_loss: 0.2204
 954/1000 [===========================>..] - ETA: 13s - loss: 1.1346 - regression_loss: 0.9141 - classification_loss: 0.2204
 955/1000 [===========================>..] - ETA: 12s - loss: 1.1354 - regression_loss: 0.9148 - classification_loss: 0.2206
 956/1000 [===========================>..] - ETA: 12s - loss: 1.1372 - regression_loss: 0.9153 - classification_loss: 0.2219
 957/1000 [===========================>..] - ETA: 12s - loss: 1.1370 - regression_loss: 0.9152 - classification_loss: 0.2218
 958/1000 [===========================>..] - ETA: 12s - loss: 1.1377 - regression_loss: 0.9159 - classification_loss: 0.2218
 959/1000 [===========================>..] - ETA: 11s - loss: 1.1373 - regression_loss: 0.9155 - classification_loss: 0.2218
 960/1000 [===========================>..] - ETA: 11s - loss: 1.1381 - regression_loss: 0.9161 - classification_loss: 0.2220
 961/1000 [===========================>..] - ETA: 11s - loss: 1.1375 - regression_loss: 0.9156 - classification_loss: 0.2219
 962/1000 [===========================>..] - ETA: 10s - loss: 1.1368 - regression_loss: 0.9150 - classification_loss: 0.2218
 963/1000 [===========================>..] - ETA: 10s - loss: 1.1368 - regression_loss: 0.9151 - classification_loss: 0.2217
 964/1000 [===========================>..] - ETA: 10s - loss: 1.1371 - regression_loss: 0.9155 - classification_loss: 0.2216
 965/1000 [===========================>..] - ETA: 10s - loss: 1.1373 - regression_loss: 0.9157 - classification_loss: 0.2216
 966/1000 [===========================>..] - ETA: 9s - loss: 1.1374 - regression_loss: 0.9159 - classification_loss: 0.2215 
 967/1000 [============================>.] - ETA: 9s - loss: 1.1371 - regression_loss: 0.9156 - classification_loss: 0.2215
 968/1000 [============================>.] - ETA: 9s - loss: 1.1377 - regression_loss: 0.9161 - classification_loss: 0.2216
 969/1000 [============================>.] - ETA: 8s - loss: 1.1390 - regression_loss: 0.9171 - classification_loss: 0.2219
 970/1000 [============================>.] - ETA: 8s - loss: 1.1385 - regression_loss: 0.9167 - classification_loss: 0.2218
 971/1000 [============================>.] - ETA: 8s - loss: 1.1379 - regression_loss: 0.9163 - classification_loss: 0.2216
 972/1000 [============================>.] - ETA: 8s - loss: 1.1375 - regression_loss: 0.9160 - classification_loss: 0.2215
 973/1000 [============================>.] - ETA: 7s - loss: 1.1393 - regression_loss: 0.9174 - classification_loss: 0.2219
 974/1000 [============================>.] - ETA: 7s - loss: 1.1388 - regression_loss: 0.9171 - classification_loss: 0.2218
 975/1000 [============================>.] - ETA: 7s - loss: 1.1387 - regression_loss: 0.9170 - classification_loss: 0.2217
 976/1000 [============================>.] - ETA: 6s - loss: 1.1380 - regression_loss: 0.9164 - classification_loss: 0.2216
 977/1000 [============================>.] - ETA: 6s - loss: 1.1374 - regression_loss: 0.9159 - classification_loss: 0.2214
 978/1000 [============================>.] - ETA: 6s - loss: 1.1375 - regression_loss: 0.9161 - classification_loss: 0.2214
 979/1000 [============================>.] - ETA: 6s - loss: 1.1379 - regression_loss: 0.9163 - classification_loss: 0.2216
 980/1000 [============================>.] - ETA: 5s - loss: 1.1374 - regression_loss: 0.9159 - classification_loss: 0.2215
 981/1000 [============================>.] - ETA: 5s - loss: 1.1376 - regression_loss: 0.9162 - classification_loss: 0.2214
 982/1000 [============================>.] - ETA: 5s - loss: 1.1393 - regression_loss: 0.9175 - classification_loss: 0.2217
 983/1000 [============================>.] - ETA: 4s - loss: 1.1395 - regression_loss: 0.9177 - classification_loss: 0.2218
 984/1000 [============================>.] - ETA: 4s - loss: 1.1391 - regression_loss: 0.9175 - classification_loss: 0.2216
 985/1000 [============================>.] - ETA: 4s - loss: 1.1386 - regression_loss: 0.9171 - classification_loss: 0.2215
 986/1000 [============================>.] - ETA: 4s - loss: 1.1380 - regression_loss: 0.9167 - classification_loss: 0.2213
 987/1000 [============================>.] - ETA: 3s - loss: 1.1378 - regression_loss: 0.9166 - classification_loss: 0.2212
 988/1000 [============================>.] - ETA: 3s - loss: 1.1374 - regression_loss: 0.9161 - classification_loss: 0.2213
 989/1000 [============================>.] - ETA: 3s - loss: 1.1372 - regression_loss: 0.9160 - classification_loss: 0.2212
 990/1000 [============================>.] - ETA: 2s - loss: 1.1370 - regression_loss: 0.9159 - classification_loss: 0.2212
 991/1000 [============================>.] - ETA: 2s - loss: 1.1365 - regression_loss: 0.9155 - classification_loss: 0.2210
 992/1000 [============================>.] - ETA: 2s - loss: 1.1363 - regression_loss: 0.9153 - classification_loss: 0.2210
 993/1000 [============================>.] - ETA: 2s - loss: 1.1375 - regression_loss: 0.9163 - classification_loss: 0.2212
 994/1000 [============================>.] - ETA: 1s - loss: 1.1380 - regression_loss: 0.9168 - classification_loss: 0.2212
 995/1000 [============================>.] - ETA: 1s - loss: 1.1381 - regression_loss: 0.9169 - classification_loss: 0.2212
 996/1000 [============================>.] - ETA: 1s - loss: 1.1384 - regression_loss: 0.9172 - classification_loss: 0.2212
 997/1000 [============================>.] - ETA: 0s - loss: 1.1383 - regression_loss: 0.9172 - classification_loss: 0.2211
 998/1000 [============================>.] - ETA: 0s - loss: 1.1377 - regression_loss: 0.9167 - classification_loss: 0.2210
 999/1000 [============================>.] - ETA: 0s - loss: 1.1381 - regression_loss: 0.9170 - classification_loss: 0.2211
1000/1000 [==============================] - 287s 287ms/step - loss: 1.1378 - regression_loss: 0.9168 - classification_loss: 0.2211

Epoch 00009: saving model to ./snapshots/resnet50_csv_09.h5
Epoch 10/10

   1/1000 [..............................] - ETA: 4:45 - loss: 0.5523 - regression_loss: 0.4324 - classification_loss: 0.1199
   2/1000 [..............................] - ETA: 4:45 - loss: 0.7679 - regression_loss: 0.6432 - classification_loss: 0.1247
   3/1000 [..............................] - ETA: 4:44 - loss: 0.7565 - regression_loss: 0.6499 - classification_loss: 0.1066
   4/1000 [..............................] - ETA: 4:45 - loss: 0.8089 - regression_loss: 0.6927 - classification_loss: 0.1162
   5/1000 [..............................] - ETA: 4:45 - loss: 0.8275 - regression_loss: 0.7141 - classification_loss: 0.1134
   6/1000 [..............................] - ETA: 4:45 - loss: 0.9960 - regression_loss: 0.8569 - classification_loss: 0.1391
   7/1000 [..............................] - ETA: 4:46 - loss: 0.9810 - regression_loss: 0.8401 - classification_loss: 0.1409
   8/1000 [..............................] - ETA: 4:47 - loss: 0.9677 - regression_loss: 0.8311 - classification_loss: 0.1365
   9/1000 [..............................] - ETA: 4:45 - loss: 1.0641 - regression_loss: 0.9106 - classification_loss: 0.1535
  10/1000 [..............................] - ETA: 4:44 - loss: 1.0139 - regression_loss: 0.8618 - classification_loss: 0.1521
  11/1000 [..............................] - ETA: 4:43 - loss: 0.9576 - regression_loss: 0.8128 - classification_loss: 0.1448
  12/1000 [..............................] - ETA: 4:43 - loss: 1.0255 - regression_loss: 0.8690 - classification_loss: 0.1565
  13/1000 [..............................] - ETA: 4:43 - loss: 1.0077 - regression_loss: 0.8598 - classification_loss: 0.1479
  14/1000 [..............................] - ETA: 4:42 - loss: 1.0069 - regression_loss: 0.8546 - classification_loss: 0.1523
  15/1000 [..............................] - ETA: 4:43 - loss: 0.9631 - regression_loss: 0.8171 - classification_loss: 0.1460
  16/1000 [..............................] - ETA: 4:43 - loss: 0.9460 - regression_loss: 0.8062 - classification_loss: 0.1398
  17/1000 [..............................] - ETA: 4:42 - loss: 0.9315 - regression_loss: 0.7938 - classification_loss: 0.1377
  18/1000 [..............................] - ETA: 4:42 - loss: 0.9189 - regression_loss: 0.7736 - classification_loss: 0.1454
  19/1000 [..............................] - ETA: 4:41 - loss: 0.9494 - regression_loss: 0.7844 - classification_loss: 0.1650
  20/1000 [..............................] - ETA: 4:41 - loss: 0.9648 - regression_loss: 0.7847 - classification_loss: 0.1800
  21/1000 [..............................] - ETA: 4:42 - loss: 0.9556 - regression_loss: 0.7796 - classification_loss: 0.1761
  22/1000 [..............................] - ETA: 4:41 - loss: 0.9875 - regression_loss: 0.8096 - classification_loss: 0.1779
  23/1000 [..............................] - ETA: 4:41 - loss: 0.9819 - regression_loss: 0.8039 - classification_loss: 0.1779
  24/1000 [..............................] - ETA: 4:41 - loss: 1.0139 - regression_loss: 0.8298 - classification_loss: 0.1840
  25/1000 [..............................] - ETA: 4:40 - loss: 1.0090 - regression_loss: 0.8236 - classification_loss: 0.1854
  26/1000 [..............................] - ETA: 4:40 - loss: 1.0016 - regression_loss: 0.8184 - classification_loss: 0.1832
  27/1000 [..............................] - ETA: 4:39 - loss: 0.9806 - regression_loss: 0.7994 - classification_loss: 0.1812
  28/1000 [..............................] - ETA: 4:39 - loss: 0.9826 - regression_loss: 0.8007 - classification_loss: 0.1819
  29/1000 [..............................] - ETA: 4:39 - loss: 0.9804 - regression_loss: 0.7976 - classification_loss: 0.1828
  30/1000 [..............................] - ETA: 4:38 - loss: 0.9822 - regression_loss: 0.8004 - classification_loss: 0.1818
  31/1000 [..............................] - ETA: 4:38 - loss: 0.9813 - regression_loss: 0.8012 - classification_loss: 0.1801
  32/1000 [..............................] - ETA: 4:38 - loss: 0.9924 - regression_loss: 0.8117 - classification_loss: 0.1807
  33/1000 [..............................] - ETA: 4:38 - loss: 0.9995 - regression_loss: 0.8200 - classification_loss: 0.1794
  34/1000 [>.............................] - ETA: 4:37 - loss: 1.0136 - regression_loss: 0.8289 - classification_loss: 0.1846
  35/1000 [>.............................] - ETA: 4:37 - loss: 1.0098 - regression_loss: 0.8274 - classification_loss: 0.1824
  36/1000 [>.............................] - ETA: 4:37 - loss: 1.0104 - regression_loss: 0.8265 - classification_loss: 0.1838
  37/1000 [>.............................] - ETA: 4:36 - loss: 1.0365 - regression_loss: 0.8474 - classification_loss: 0.1891
  38/1000 [>.............................] - ETA: 4:36 - loss: 1.0393 - regression_loss: 0.8510 - classification_loss: 0.1882
  39/1000 [>.............................] - ETA: 4:35 - loss: 1.0569 - regression_loss: 0.8675 - classification_loss: 0.1895
  40/1000 [>.............................] - ETA: 4:35 - loss: 1.0521 - regression_loss: 0.8629 - classification_loss: 0.1892
  41/1000 [>.............................] - ETA: 4:35 - loss: 1.1049 - regression_loss: 0.9028 - classification_loss: 0.2022
  42/1000 [>.............................] - ETA: 4:35 - loss: 1.1000 - regression_loss: 0.8999 - classification_loss: 0.2001
  43/1000 [>.............................] - ETA: 4:35 - loss: 1.0939 - regression_loss: 0.8962 - classification_loss: 0.1976
  44/1000 [>.............................] - ETA: 4:34 - loss: 1.1073 - regression_loss: 0.9089 - classification_loss: 0.1985
  45/1000 [>.............................] - ETA: 4:34 - loss: 1.1105 - regression_loss: 0.9120 - classification_loss: 0.1986
  46/1000 [>.............................] - ETA: 4:34 - loss: 1.1164 - regression_loss: 0.9180 - classification_loss: 0.1985
  47/1000 [>.............................] - ETA: 4:33 - loss: 1.1155 - regression_loss: 0.9165 - classification_loss: 0.1991
  48/1000 [>.............................] - ETA: 4:33 - loss: 1.1217 - regression_loss: 0.9233 - classification_loss: 0.1984
  49/1000 [>.............................] - ETA: 4:33 - loss: 1.1240 - regression_loss: 0.9261 - classification_loss: 0.1979
  50/1000 [>.............................] - ETA: 4:32 - loss: 1.1277 - regression_loss: 0.9267 - classification_loss: 0.2009
  51/1000 [>.............................] - ETA: 4:32 - loss: 1.1168 - regression_loss: 0.9176 - classification_loss: 0.1992
  52/1000 [>.............................] - ETA: 4:32 - loss: 1.1181 - regression_loss: 0.9196 - classification_loss: 0.1985
  53/1000 [>.............................] - ETA: 4:31 - loss: 1.1205 - regression_loss: 0.9215 - classification_loss: 0.1991
  54/1000 [>.............................] - ETA: 4:31 - loss: 1.1305 - regression_loss: 0.9304 - classification_loss: 0.2001
  55/1000 [>.............................] - ETA: 4:31 - loss: 1.1249 - regression_loss: 0.9264 - classification_loss: 0.1985
  56/1000 [>.............................] - ETA: 4:30 - loss: 1.1198 - regression_loss: 0.9205 - classification_loss: 0.1994
  57/1000 [>.............................] - ETA: 4:30 - loss: 1.1170 - regression_loss: 0.9186 - classification_loss: 0.1984
  58/1000 [>.............................] - ETA: 4:29 - loss: 1.1166 - regression_loss: 0.9188 - classification_loss: 0.1978
  59/1000 [>.............................] - ETA: 4:29 - loss: 1.1122 - regression_loss: 0.9162 - classification_loss: 0.1960
  60/1000 [>.............................] - ETA: 4:29 - loss: 1.1121 - regression_loss: 0.9166 - classification_loss: 0.1955
  61/1000 [>.............................] - ETA: 4:28 - loss: 1.1235 - regression_loss: 0.9274 - classification_loss: 0.1961
  62/1000 [>.............................] - ETA: 4:28 - loss: 1.1225 - regression_loss: 0.9269 - classification_loss: 0.1955
  63/1000 [>.............................] - ETA: 4:28 - loss: 1.1386 - regression_loss: 0.9398 - classification_loss: 0.1988
  64/1000 [>.............................] - ETA: 4:28 - loss: 1.1347 - regression_loss: 0.9366 - classification_loss: 0.1980
  65/1000 [>.............................] - ETA: 4:27 - loss: 1.1248 - regression_loss: 0.9285 - classification_loss: 0.1962
  66/1000 [>.............................] - ETA: 4:27 - loss: 1.1215 - regression_loss: 0.9258 - classification_loss: 0.1957
  67/1000 [=>............................] - ETA: 4:27 - loss: 1.1291 - regression_loss: 0.9312 - classification_loss: 0.1979
  68/1000 [=>............................] - ETA: 4:26 - loss: 1.1309 - regression_loss: 0.9338 - classification_loss: 0.1971
  69/1000 [=>............................] - ETA: 4:26 - loss: 1.1251 - regression_loss: 0.9273 - classification_loss: 0.1979
  70/1000 [=>............................] - ETA: 4:26 - loss: 1.1159 - regression_loss: 0.9194 - classification_loss: 0.1965
  71/1000 [=>............................] - ETA: 4:25 - loss: 1.1107 - regression_loss: 0.9149 - classification_loss: 0.1958
  72/1000 [=>............................] - ETA: 4:25 - loss: 1.1122 - regression_loss: 0.9167 - classification_loss: 0.1955
  73/1000 [=>............................] - ETA: 4:25 - loss: 1.1017 - regression_loss: 0.9081 - classification_loss: 0.1936
  74/1000 [=>............................] - ETA: 4:25 - loss: 1.0950 - regression_loss: 0.9013 - classification_loss: 0.1937
  75/1000 [=>............................] - ETA: 4:24 - loss: 1.0992 - regression_loss: 0.9056 - classification_loss: 0.1937
  76/1000 [=>............................] - ETA: 4:24 - loss: 1.0982 - regression_loss: 0.9043 - classification_loss: 0.1939
  77/1000 [=>............................] - ETA: 4:24 - loss: 1.0929 - regression_loss: 0.8981 - classification_loss: 0.1949
  78/1000 [=>............................] - ETA: 4:23 - loss: 1.0922 - regression_loss: 0.8930 - classification_loss: 0.1992
  79/1000 [=>............................] - ETA: 4:23 - loss: 1.0961 - regression_loss: 0.8966 - classification_loss: 0.1995
  80/1000 [=>............................] - ETA: 4:23 - loss: 1.0924 - regression_loss: 0.8944 - classification_loss: 0.1980
  81/1000 [=>............................] - ETA: 4:23 - loss: 1.0966 - regression_loss: 0.8982 - classification_loss: 0.1985
  82/1000 [=>............................] - ETA: 4:22 - loss: 1.0909 - regression_loss: 0.8935 - classification_loss: 0.1974
  83/1000 [=>............................] - ETA: 4:22 - loss: 1.0856 - regression_loss: 0.8891 - classification_loss: 0.1965
  84/1000 [=>............................] - ETA: 4:22 - loss: 1.0775 - regression_loss: 0.8822 - classification_loss: 0.1954
  85/1000 [=>............................] - ETA: 4:21 - loss: 1.0743 - regression_loss: 0.8794 - classification_loss: 0.1949
  86/1000 [=>............................] - ETA: 4:21 - loss: 1.0699 - regression_loss: 0.8765 - classification_loss: 0.1934
  87/1000 [=>............................] - ETA: 4:21 - loss: 1.0632 - regression_loss: 0.8709 - classification_loss: 0.1922
  88/1000 [=>............................] - ETA: 4:20 - loss: 1.0589 - regression_loss: 0.8679 - classification_loss: 0.1911
  89/1000 [=>............................] - ETA: 4:20 - loss: 1.0561 - regression_loss: 0.8652 - classification_loss: 0.1909
  90/1000 [=>............................] - ETA: 4:20 - loss: 1.0550 - regression_loss: 0.8627 - classification_loss: 0.1923
  91/1000 [=>............................] - ETA: 4:20 - loss: 1.0696 - regression_loss: 0.8727 - classification_loss: 0.1968
  92/1000 [=>............................] - ETA: 4:19 - loss: 1.0664 - regression_loss: 0.8707 - classification_loss: 0.1957
  93/1000 [=>............................] - ETA: 4:19 - loss: 1.0627 - regression_loss: 0.8676 - classification_loss: 0.1951
  94/1000 [=>............................] - ETA: 4:19 - loss: 1.0588 - regression_loss: 0.8650 - classification_loss: 0.1938
  95/1000 [=>............................] - ETA: 4:18 - loss: 1.0630 - regression_loss: 0.8678 - classification_loss: 0.1952
  96/1000 [=>............................] - ETA: 4:18 - loss: 1.0616 - regression_loss: 0.8669 - classification_loss: 0.1947
  97/1000 [=>............................] - ETA: 4:18 - loss: 1.0626 - regression_loss: 0.8686 - classification_loss: 0.1939
  98/1000 [=>............................] - ETA: 4:17 - loss: 1.0676 - regression_loss: 0.8727 - classification_loss: 0.1949
  99/1000 [=>............................] - ETA: 4:17 - loss: 1.0649 - regression_loss: 0.8711 - classification_loss: 0.1939
 100/1000 [==>...........................] - ETA: 4:17 - loss: 1.0599 - regression_loss: 0.8669 - classification_loss: 0.1930
 101/1000 [==>...........................] - ETA: 4:17 - loss: 1.0616 - regression_loss: 0.8693 - classification_loss: 0.1923
 102/1000 [==>...........................] - ETA: 4:16 - loss: 1.0597 - regression_loss: 0.8684 - classification_loss: 0.1912
 103/1000 [==>...........................] - ETA: 4:16 - loss: 1.0752 - regression_loss: 0.8803 - classification_loss: 0.1949
 104/1000 [==>...........................] - ETA: 4:16 - loss: 1.0703 - regression_loss: 0.8759 - classification_loss: 0.1944
 105/1000 [==>...........................] - ETA: 4:15 - loss: 1.0695 - regression_loss: 0.8753 - classification_loss: 0.1943
 106/1000 [==>...........................] - ETA: 4:15 - loss: 1.0713 - regression_loss: 0.8763 - classification_loss: 0.1951
 107/1000 [==>...........................] - ETA: 4:15 - loss: 1.0775 - regression_loss: 0.8812 - classification_loss: 0.1964
 108/1000 [==>...........................] - ETA: 4:14 - loss: 1.0767 - regression_loss: 0.8808 - classification_loss: 0.1959
 109/1000 [==>...........................] - ETA: 4:14 - loss: 1.0724 - regression_loss: 0.8771 - classification_loss: 0.1954
 110/1000 [==>...........................] - ETA: 4:14 - loss: 1.0691 - regression_loss: 0.8742 - classification_loss: 0.1949
 111/1000 [==>...........................] - ETA: 4:14 - loss: 1.0661 - regression_loss: 0.8710 - classification_loss: 0.1951
 112/1000 [==>...........................] - ETA: 4:13 - loss: 1.0670 - regression_loss: 0.8721 - classification_loss: 0.1949
 113/1000 [==>...........................] - ETA: 4:13 - loss: 1.0721 - regression_loss: 0.8766 - classification_loss: 0.1955
 114/1000 [==>...........................] - ETA: 4:13 - loss: 1.0683 - regression_loss: 0.8734 - classification_loss: 0.1949
 115/1000 [==>...........................] - ETA: 4:13 - loss: 1.0705 - regression_loss: 0.8747 - classification_loss: 0.1958
 116/1000 [==>...........................] - ETA: 4:12 - loss: 1.0697 - regression_loss: 0.8741 - classification_loss: 0.1956
 117/1000 [==>...........................] - ETA: 4:12 - loss: 1.0702 - regression_loss: 0.8748 - classification_loss: 0.1953
 118/1000 [==>...........................] - ETA: 4:12 - loss: 1.0726 - regression_loss: 0.8775 - classification_loss: 0.1951
 119/1000 [==>...........................] - ETA: 4:11 - loss: 1.0722 - regression_loss: 0.8775 - classification_loss: 0.1947
 120/1000 [==>...........................] - ETA: 4:11 - loss: 1.0763 - regression_loss: 0.8814 - classification_loss: 0.1949
 121/1000 [==>...........................] - ETA: 4:11 - loss: 1.0779 - regression_loss: 0.8818 - classification_loss: 0.1961
 122/1000 [==>...........................] - ETA: 4:11 - loss: 1.0754 - regression_loss: 0.8801 - classification_loss: 0.1953
 123/1000 [==>...........................] - ETA: 4:10 - loss: 1.0817 - regression_loss: 0.8841 - classification_loss: 0.1976
 124/1000 [==>...........................] - ETA: 4:10 - loss: 1.0961 - regression_loss: 0.8954 - classification_loss: 0.2007
 125/1000 [==>...........................] - ETA: 4:10 - loss: 1.0942 - regression_loss: 0.8944 - classification_loss: 0.1998
 126/1000 [==>...........................] - ETA: 4:10 - loss: 1.1034 - regression_loss: 0.9014 - classification_loss: 0.2020
 127/1000 [==>...........................] - ETA: 4:09 - loss: 1.1011 - regression_loss: 0.8985 - classification_loss: 0.2026
 128/1000 [==>...........................] - ETA: 4:09 - loss: 1.1020 - regression_loss: 0.8990 - classification_loss: 0.2031
 129/1000 [==>...........................] - ETA: 4:09 - loss: 1.1015 - regression_loss: 0.8985 - classification_loss: 0.2030
 130/1000 [==>...........................] - ETA: 4:08 - loss: 1.1075 - regression_loss: 0.9036 - classification_loss: 0.2039
 131/1000 [==>...........................] - ETA: 4:08 - loss: 1.1080 - regression_loss: 0.9044 - classification_loss: 0.2036
 132/1000 [==>...........................] - ETA: 4:08 - loss: 1.1089 - regression_loss: 0.9054 - classification_loss: 0.2036
 133/1000 [==>...........................] - ETA: 4:08 - loss: 1.1105 - regression_loss: 0.9062 - classification_loss: 0.2043
 134/1000 [===>..........................] - ETA: 4:07 - loss: 1.1070 - regression_loss: 0.9024 - classification_loss: 0.2046
 135/1000 [===>..........................] - ETA: 4:07 - loss: 1.1050 - regression_loss: 0.9006 - classification_loss: 0.2045
 136/1000 [===>..........................] - ETA: 4:07 - loss: 1.1041 - regression_loss: 0.8995 - classification_loss: 0.2046
 137/1000 [===>..........................] - ETA: 4:07 - loss: 1.1019 - regression_loss: 0.8974 - classification_loss: 0.2045
 138/1000 [===>..........................] - ETA: 4:06 - loss: 1.1042 - regression_loss: 0.8996 - classification_loss: 0.2046
 139/1000 [===>..........................] - ETA: 4:06 - loss: 1.1055 - regression_loss: 0.9006 - classification_loss: 0.2049
 140/1000 [===>..........................] - ETA: 4:06 - loss: 1.1038 - regression_loss: 0.8981 - classification_loss: 0.2058
 141/1000 [===>..........................] - ETA: 4:05 - loss: 1.1035 - regression_loss: 0.8986 - classification_loss: 0.2049
 142/1000 [===>..........................] - ETA: 4:05 - loss: 1.1082 - regression_loss: 0.9008 - classification_loss: 0.2074
 143/1000 [===>..........................] - ETA: 4:05 - loss: 1.1073 - regression_loss: 0.9002 - classification_loss: 0.2070
 144/1000 [===>..........................] - ETA: 4:05 - loss: 1.1078 - regression_loss: 0.9002 - classification_loss: 0.2077
 145/1000 [===>..........................] - ETA: 4:04 - loss: 1.1091 - regression_loss: 0.9021 - classification_loss: 0.2070
 146/1000 [===>..........................] - ETA: 4:04 - loss: 1.1120 - regression_loss: 0.9041 - classification_loss: 0.2079
 147/1000 [===>..........................] - ETA: 4:04 - loss: 1.1105 - regression_loss: 0.9033 - classification_loss: 0.2072
 148/1000 [===>..........................] - ETA: 4:03 - loss: 1.1082 - regression_loss: 0.9011 - classification_loss: 0.2071
 149/1000 [===>..........................] - ETA: 4:03 - loss: 1.1080 - regression_loss: 0.9005 - classification_loss: 0.2075
 150/1000 [===>..........................] - ETA: 4:03 - loss: 1.1044 - regression_loss: 0.8978 - classification_loss: 0.2066
 151/1000 [===>..........................] - ETA: 4:03 - loss: 1.1085 - regression_loss: 0.9017 - classification_loss: 0.2069
 152/1000 [===>..........................] - ETA: 4:02 - loss: 1.1069 - regression_loss: 0.9007 - classification_loss: 0.2062
 153/1000 [===>..........................] - ETA: 4:02 - loss: 1.1033 - regression_loss: 0.8979 - classification_loss: 0.2054
 154/1000 [===>..........................] - ETA: 4:02 - loss: 1.1021 - regression_loss: 0.8969 - classification_loss: 0.2052
 155/1000 [===>..........................] - ETA: 4:01 - loss: 1.0981 - regression_loss: 0.8937 - classification_loss: 0.2045
 156/1000 [===>..........................] - ETA: 4:01 - loss: 1.1017 - regression_loss: 0.8956 - classification_loss: 0.2061
 157/1000 [===>..........................] - ETA: 4:01 - loss: 1.0977 - regression_loss: 0.8922 - classification_loss: 0.2054
 158/1000 [===>..........................] - ETA: 4:01 - loss: 1.0955 - regression_loss: 0.8910 - classification_loss: 0.2044
 159/1000 [===>..........................] - ETA: 4:00 - loss: 1.0969 - regression_loss: 0.8926 - classification_loss: 0.2043
 160/1000 [===>..........................] - ETA: 4:00 - loss: 1.0971 - regression_loss: 0.8925 - classification_loss: 0.2047
 161/1000 [===>..........................] - ETA: 4:00 - loss: 1.0945 - regression_loss: 0.8902 - classification_loss: 0.2042
 162/1000 [===>..........................] - ETA: 4:00 - loss: 1.0930 - regression_loss: 0.8886 - classification_loss: 0.2044
 163/1000 [===>..........................] - ETA: 3:59 - loss: 1.1003 - regression_loss: 0.8951 - classification_loss: 0.2052
 164/1000 [===>..........................] - ETA: 3:59 - loss: 1.0982 - regression_loss: 0.8938 - classification_loss: 0.2044
 165/1000 [===>..........................] - ETA: 3:59 - loss: 1.0928 - regression_loss: 0.8893 - classification_loss: 0.2035
 166/1000 [===>..........................] - ETA: 3:58 - loss: 1.0938 - regression_loss: 0.8906 - classification_loss: 0.2032
 167/1000 [====>.........................] - ETA: 3:58 - loss: 1.0979 - regression_loss: 0.8939 - classification_loss: 0.2040
 168/1000 [====>.........................] - ETA: 3:58 - loss: 1.0987 - regression_loss: 0.8951 - classification_loss: 0.2036
 169/1000 [====>.........................] - ETA: 3:58 - loss: 1.1002 - regression_loss: 0.8962 - classification_loss: 0.2040
 170/1000 [====>.........................] - ETA: 3:57 - loss: 1.0967 - regression_loss: 0.8932 - classification_loss: 0.2035
 171/1000 [====>.........................] - ETA: 3:57 - loss: 1.0985 - regression_loss: 0.8944 - classification_loss: 0.2040
 172/1000 [====>.........................] - ETA: 3:57 - loss: 1.1024 - regression_loss: 0.8964 - classification_loss: 0.2060
 173/1000 [====>.........................] - ETA: 3:56 - loss: 1.1011 - regression_loss: 0.8955 - classification_loss: 0.2056
 174/1000 [====>.........................] - ETA: 3:56 - loss: 1.1047 - regression_loss: 0.8995 - classification_loss: 0.2052
 175/1000 [====>.........................] - ETA: 3:56 - loss: 1.1012 - regression_loss: 0.8967 - classification_loss: 0.2044
 176/1000 [====>.........................] - ETA: 3:56 - loss: 1.0983 - regression_loss: 0.8946 - classification_loss: 0.2037
 177/1000 [====>.........................] - ETA: 3:55 - loss: 1.1024 - regression_loss: 0.8986 - classification_loss: 0.2038
 178/1000 [====>.........................] - ETA: 3:55 - loss: 1.1011 - regression_loss: 0.8979 - classification_loss: 0.2031
 179/1000 [====>.........................] - ETA: 3:55 - loss: 1.0977 - regression_loss: 0.8953 - classification_loss: 0.2024
 180/1000 [====>.........................] - ETA: 3:54 - loss: 1.0963 - regression_loss: 0.8941 - classification_loss: 0.2022
 181/1000 [====>.........................] - ETA: 3:54 - loss: 1.0928 - regression_loss: 0.8910 - classification_loss: 0.2018
 182/1000 [====>.........................] - ETA: 3:54 - loss: 1.0992 - regression_loss: 0.8959 - classification_loss: 0.2032
 183/1000 [====>.........................] - ETA: 3:54 - loss: 1.0968 - regression_loss: 0.8941 - classification_loss: 0.2027
 184/1000 [====>.........................] - ETA: 3:53 - loss: 1.0959 - regression_loss: 0.8933 - classification_loss: 0.2026
 185/1000 [====>.........................] - ETA: 3:53 - loss: 1.0982 - regression_loss: 0.8952 - classification_loss: 0.2030
 186/1000 [====>.........................] - ETA: 3:53 - loss: 1.0967 - regression_loss: 0.8938 - classification_loss: 0.2030
 187/1000 [====>.........................] - ETA: 3:52 - loss: 1.0989 - regression_loss: 0.8962 - classification_loss: 0.2027
 188/1000 [====>.........................] - ETA: 3:52 - loss: 1.1027 - regression_loss: 0.8999 - classification_loss: 0.2028
 189/1000 [====>.........................] - ETA: 3:52 - loss: 1.0990 - regression_loss: 0.8968 - classification_loss: 0.2021
 190/1000 [====>.........................] - ETA: 3:51 - loss: 1.0959 - regression_loss: 0.8945 - classification_loss: 0.2015
 191/1000 [====>.........................] - ETA: 3:51 - loss: 1.0964 - regression_loss: 0.8952 - classification_loss: 0.2012
 192/1000 [====>.........................] - ETA: 3:51 - loss: 1.0935 - regression_loss: 0.8930 - classification_loss: 0.2006
 193/1000 [====>.........................] - ETA: 3:51 - loss: 1.0951 - regression_loss: 0.8943 - classification_loss: 0.2008
 194/1000 [====>.........................] - ETA: 3:50 - loss: 1.0944 - regression_loss: 0.8939 - classification_loss: 0.2004
 195/1000 [====>.........................] - ETA: 3:50 - loss: 1.0917 - regression_loss: 0.8918 - classification_loss: 0.1999
 196/1000 [====>.........................] - ETA: 3:50 - loss: 1.0894 - regression_loss: 0.8902 - classification_loss: 0.1992
 197/1000 [====>.........................] - ETA: 3:49 - loss: 1.0868 - regression_loss: 0.8880 - classification_loss: 0.1988
 198/1000 [====>.........................] - ETA: 3:49 - loss: 1.0912 - regression_loss: 0.8910 - classification_loss: 0.2003
 199/1000 [====>.........................] - ETA: 3:49 - loss: 1.0961 - regression_loss: 0.8921 - classification_loss: 0.2041
 200/1000 [=====>........................] - ETA: 3:49 - loss: 1.0945 - regression_loss: 0.8911 - classification_loss: 0.2035
 201/1000 [=====>........................] - ETA: 3:48 - loss: 1.0923 - regression_loss: 0.8897 - classification_loss: 0.2027
 202/1000 [=====>........................] - ETA: 3:48 - loss: 1.0896 - regression_loss: 0.8875 - classification_loss: 0.2022
 203/1000 [=====>........................] - ETA: 3:48 - loss: 1.0952 - regression_loss: 0.8917 - classification_loss: 0.2035
 204/1000 [=====>........................] - ETA: 3:47 - loss: 1.0950 - regression_loss: 0.8913 - classification_loss: 0.2037
 205/1000 [=====>........................] - ETA: 3:47 - loss: 1.0950 - regression_loss: 0.8907 - classification_loss: 0.2043
 206/1000 [=====>........................] - ETA: 3:47 - loss: 1.0935 - regression_loss: 0.8897 - classification_loss: 0.2038
 207/1000 [=====>........................] - ETA: 3:47 - loss: 1.0943 - regression_loss: 0.8900 - classification_loss: 0.2043
 208/1000 [=====>........................] - ETA: 3:46 - loss: 1.0970 - regression_loss: 0.8912 - classification_loss: 0.2058
 209/1000 [=====>........................] - ETA: 3:46 - loss: 1.0953 - regression_loss: 0.8898 - classification_loss: 0.2056
 210/1000 [=====>........................] - ETA: 3:46 - loss: 1.0946 - regression_loss: 0.8884 - classification_loss: 0.2062
 211/1000 [=====>........................] - ETA: 3:45 - loss: 1.0952 - regression_loss: 0.8889 - classification_loss: 0.2063
 212/1000 [=====>........................] - ETA: 3:45 - loss: 1.0971 - regression_loss: 0.8899 - classification_loss: 0.2072
 213/1000 [=====>........................] - ETA: 3:45 - loss: 1.0984 - regression_loss: 0.8908 - classification_loss: 0.2076
 214/1000 [=====>........................] - ETA: 3:45 - loss: 1.1006 - regression_loss: 0.8921 - classification_loss: 0.2085
 215/1000 [=====>........................] - ETA: 3:44 - loss: 1.1019 - regression_loss: 0.8932 - classification_loss: 0.2087
 216/1000 [=====>........................] - ETA: 3:44 - loss: 1.1041 - regression_loss: 0.8953 - classification_loss: 0.2088
 217/1000 [=====>........................] - ETA: 3:44 - loss: 1.1045 - regression_loss: 0.8959 - classification_loss: 0.2085
 218/1000 [=====>........................] - ETA: 3:43 - loss: 1.1043 - regression_loss: 0.8960 - classification_loss: 0.2083
 219/1000 [=====>........................] - ETA: 3:43 - loss: 1.1065 - regression_loss: 0.8965 - classification_loss: 0.2100
 220/1000 [=====>........................] - ETA: 3:43 - loss: 1.1052 - regression_loss: 0.8957 - classification_loss: 0.2095
 221/1000 [=====>........................] - ETA: 3:43 - loss: 1.1037 - regression_loss: 0.8945 - classification_loss: 0.2091
 222/1000 [=====>........................] - ETA: 3:42 - loss: 1.1047 - regression_loss: 0.8956 - classification_loss: 0.2091
 223/1000 [=====>........................] - ETA: 3:42 - loss: 1.1036 - regression_loss: 0.8949 - classification_loss: 0.2087
 224/1000 [=====>........................] - ETA: 3:42 - loss: 1.1021 - regression_loss: 0.8939 - classification_loss: 0.2083
 225/1000 [=====>........................] - ETA: 3:41 - loss: 1.1015 - regression_loss: 0.8933 - classification_loss: 0.2083
 226/1000 [=====>........................] - ETA: 3:41 - loss: 1.1000 - regression_loss: 0.8922 - classification_loss: 0.2078
 227/1000 [=====>........................] - ETA: 3:41 - loss: 1.0984 - regression_loss: 0.8911 - classification_loss: 0.2073
 228/1000 [=====>........................] - ETA: 3:41 - loss: 1.0979 - regression_loss: 0.8911 - classification_loss: 0.2068
 229/1000 [=====>........................] - ETA: 3:40 - loss: 1.0981 - regression_loss: 0.8913 - classification_loss: 0.2068
 230/1000 [=====>........................] - ETA: 3:40 - loss: 1.1067 - regression_loss: 0.8979 - classification_loss: 0.2089
 231/1000 [=====>........................] - ETA: 3:40 - loss: 1.1068 - regression_loss: 0.8981 - classification_loss: 0.2086
 232/1000 [=====>........................] - ETA: 3:39 - loss: 1.1095 - regression_loss: 0.9005 - classification_loss: 0.2090
 233/1000 [=====>........................] - ETA: 3:39 - loss: 1.1130 - regression_loss: 0.9033 - classification_loss: 0.2097
 234/1000 [======>.......................] - ETA: 3:39 - loss: 1.1108 - regression_loss: 0.9015 - classification_loss: 0.2093
 235/1000 [======>.......................] - ETA: 3:38 - loss: 1.1097 - regression_loss: 0.9010 - classification_loss: 0.2087
 236/1000 [======>.......................] - ETA: 3:38 - loss: 1.1068 - regression_loss: 0.8988 - classification_loss: 0.2080
 237/1000 [======>.......................] - ETA: 3:38 - loss: 1.1076 - regression_loss: 0.8998 - classification_loss: 0.2078
 238/1000 [======>.......................] - ETA: 3:38 - loss: 1.1050 - regression_loss: 0.8977 - classification_loss: 0.2073
 239/1000 [======>.......................] - ETA: 3:37 - loss: 1.1039 - regression_loss: 0.8969 - classification_loss: 0.2069
 240/1000 [======>.......................] - ETA: 3:37 - loss: 1.1047 - regression_loss: 0.8976 - classification_loss: 0.2071
 241/1000 [======>.......................] - ETA: 3:37 - loss: 1.1031 - regression_loss: 0.8953 - classification_loss: 0.2078
 242/1000 [======>.......................] - ETA: 3:36 - loss: 1.1014 - regression_loss: 0.8940 - classification_loss: 0.2074
 243/1000 [======>.......................] - ETA: 3:36 - loss: 1.1008 - regression_loss: 0.8938 - classification_loss: 0.2070
 244/1000 [======>.......................] - ETA: 3:36 - loss: 1.0997 - regression_loss: 0.8930 - classification_loss: 0.2067
 245/1000 [======>.......................] - ETA: 3:36 - loss: 1.1000 - regression_loss: 0.8933 - classification_loss: 0.2067
 246/1000 [======>.......................] - ETA: 3:35 - loss: 1.1005 - regression_loss: 0.8935 - classification_loss: 0.2071
 247/1000 [======>.......................] - ETA: 3:35 - loss: 1.1029 - regression_loss: 0.8959 - classification_loss: 0.2069
 248/1000 [======>.......................] - ETA: 3:35 - loss: 1.1032 - regression_loss: 0.8964 - classification_loss: 0.2067
 249/1000 [======>.......................] - ETA: 3:34 - loss: 1.1026 - regression_loss: 0.8962 - classification_loss: 0.2065
 250/1000 [======>.......................] - ETA: 3:34 - loss: 1.1010 - regression_loss: 0.8949 - classification_loss: 0.2061
 251/1000 [======>.......................] - ETA: 3:34 - loss: 1.1008 - regression_loss: 0.8949 - classification_loss: 0.2059
 252/1000 [======>.......................] - ETA: 3:34 - loss: 1.1033 - regression_loss: 0.8972 - classification_loss: 0.2061
 253/1000 [======>.......................] - ETA: 3:33 - loss: 1.1029 - regression_loss: 0.8969 - classification_loss: 0.2059
 254/1000 [======>.......................] - ETA: 3:33 - loss: 1.1011 - regression_loss: 0.8956 - classification_loss: 0.2055
 255/1000 [======>.......................] - ETA: 3:33 - loss: 1.1013 - regression_loss: 0.8961 - classification_loss: 0.2052
 256/1000 [======>.......................] - ETA: 3:32 - loss: 1.1030 - regression_loss: 0.8975 - classification_loss: 0.2055
 257/1000 [======>.......................] - ETA: 3:32 - loss: 1.1024 - regression_loss: 0.8968 - classification_loss: 0.2056
 258/1000 [======>.......................] - ETA: 3:32 - loss: 1.1040 - regression_loss: 0.8985 - classification_loss: 0.2055
 259/1000 [======>.......................] - ETA: 3:32 - loss: 1.1034 - regression_loss: 0.8982 - classification_loss: 0.2051
 260/1000 [======>.......................] - ETA: 3:31 - loss: 1.1016 - regression_loss: 0.8969 - classification_loss: 0.2046
 261/1000 [======>.......................] - ETA: 3:31 - loss: 1.1015 - regression_loss: 0.8958 - classification_loss: 0.2057
 262/1000 [======>.......................] - ETA: 3:31 - loss: 1.0998 - regression_loss: 0.8944 - classification_loss: 0.2054
 263/1000 [======>.......................] - ETA: 3:30 - loss: 1.0988 - regression_loss: 0.8933 - classification_loss: 0.2056
 264/1000 [======>.......................] - ETA: 3:30 - loss: 1.0962 - regression_loss: 0.8911 - classification_loss: 0.2050
 265/1000 [======>.......................] - ETA: 3:30 - loss: 1.0959 - regression_loss: 0.8905 - classification_loss: 0.2054
 266/1000 [======>.......................] - ETA: 3:30 - loss: 1.0945 - regression_loss: 0.8897 - classification_loss: 0.2049
 267/1000 [=======>......................] - ETA: 3:29 - loss: 1.0951 - regression_loss: 0.8902 - classification_loss: 0.2049
 268/1000 [=======>......................] - ETA: 3:29 - loss: 1.0920 - regression_loss: 0.8876 - classification_loss: 0.2044
 269/1000 [=======>......................] - ETA: 3:29 - loss: 1.0941 - regression_loss: 0.8897 - classification_loss: 0.2044
 270/1000 [=======>......................] - ETA: 3:28 - loss: 1.0923 - regression_loss: 0.8883 - classification_loss: 0.2040
 271/1000 [=======>......................] - ETA: 3:28 - loss: 1.0906 - regression_loss: 0.8870 - classification_loss: 0.2036
 272/1000 [=======>......................] - ETA: 3:28 - loss: 1.0899 - regression_loss: 0.8865 - classification_loss: 0.2034
 273/1000 [=======>......................] - ETA: 3:28 - loss: 1.0890 - regression_loss: 0.8861 - classification_loss: 0.2029
 274/1000 [=======>......................] - ETA: 3:27 - loss: 1.0904 - regression_loss: 0.8874 - classification_loss: 0.2030
 275/1000 [=======>......................] - ETA: 3:27 - loss: 1.0887 - regression_loss: 0.8861 - classification_loss: 0.2026
 276/1000 [=======>......................] - ETA: 3:27 - loss: 1.0866 - regression_loss: 0.8846 - classification_loss: 0.2020
 277/1000 [=======>......................] - ETA: 3:26 - loss: 1.0850 - regression_loss: 0.8834 - classification_loss: 0.2016
 278/1000 [=======>......................] - ETA: 3:26 - loss: 1.0874 - regression_loss: 0.8855 - classification_loss: 0.2020
 279/1000 [=======>......................] - ETA: 3:26 - loss: 1.0856 - regression_loss: 0.8838 - classification_loss: 0.2018
 280/1000 [=======>......................] - ETA: 3:26 - loss: 1.0847 - regression_loss: 0.8832 - classification_loss: 0.2015
 281/1000 [=======>......................] - ETA: 3:25 - loss: 1.0856 - regression_loss: 0.8837 - classification_loss: 0.2019
 282/1000 [=======>......................] - ETA: 3:25 - loss: 1.0862 - regression_loss: 0.8839 - classification_loss: 0.2022
 283/1000 [=======>......................] - ETA: 3:25 - loss: 1.0854 - regression_loss: 0.8832 - classification_loss: 0.2022
 284/1000 [=======>......................] - ETA: 3:24 - loss: 1.0852 - regression_loss: 0.8831 - classification_loss: 0.2021
 285/1000 [=======>......................] - ETA: 3:24 - loss: 1.0848 - regression_loss: 0.8830 - classification_loss: 0.2018
 286/1000 [=======>......................] - ETA: 3:24 - loss: 1.0832 - regression_loss: 0.8819 - classification_loss: 0.2013
 287/1000 [=======>......................] - ETA: 3:24 - loss: 1.0811 - regression_loss: 0.8803 - classification_loss: 0.2009
 288/1000 [=======>......................] - ETA: 3:23 - loss: 1.0798 - regression_loss: 0.8792 - classification_loss: 0.2006
 289/1000 [=======>......................] - ETA: 3:23 - loss: 1.0795 - regression_loss: 0.8791 - classification_loss: 0.2004
 290/1000 [=======>......................] - ETA: 3:23 - loss: 1.0792 - regression_loss: 0.8789 - classification_loss: 0.2002
 291/1000 [=======>......................] - ETA: 3:22 - loss: 1.0830 - regression_loss: 0.8815 - classification_loss: 0.2016
 292/1000 [=======>......................] - ETA: 3:22 - loss: 1.0827 - regression_loss: 0.8811 - classification_loss: 0.2015
 293/1000 [=======>......................] - ETA: 3:22 - loss: 1.0830 - regression_loss: 0.8815 - classification_loss: 0.2015
 294/1000 [=======>......................] - ETA: 3:22 - loss: 1.0830 - regression_loss: 0.8816 - classification_loss: 0.2013
 295/1000 [=======>......................] - ETA: 3:21 - loss: 1.0881 - regression_loss: 0.8859 - classification_loss: 0.2022
 296/1000 [=======>......................] - ETA: 3:21 - loss: 1.0869 - regression_loss: 0.8849 - classification_loss: 0.2020
 297/1000 [=======>......................] - ETA: 3:21 - loss: 1.0866 - regression_loss: 0.8850 - classification_loss: 0.2016
 298/1000 [=======>......................] - ETA: 3:20 - loss: 1.0883 - regression_loss: 0.8864 - classification_loss: 0.2019
 299/1000 [=======>......................] - ETA: 3:20 - loss: 1.0872 - regression_loss: 0.8857 - classification_loss: 0.2015
 300/1000 [========>.....................] - ETA: 3:20 - loss: 1.0851 - regression_loss: 0.8841 - classification_loss: 0.2010
 301/1000 [========>.....................] - ETA: 3:20 - loss: 1.0861 - regression_loss: 0.8850 - classification_loss: 0.2012
 302/1000 [========>.....................] - ETA: 3:19 - loss: 1.0840 - regression_loss: 0.8832 - classification_loss: 0.2008
 303/1000 [========>.....................] - ETA: 3:19 - loss: 1.0832 - regression_loss: 0.8829 - classification_loss: 0.2003
 304/1000 [========>.....................] - ETA: 3:19 - loss: 1.0835 - regression_loss: 0.8834 - classification_loss: 0.2001
 305/1000 [========>.....................] - ETA: 3:18 - loss: 1.0814 - regression_loss: 0.8816 - classification_loss: 0.1998
 306/1000 [========>.....................] - ETA: 3:18 - loss: 1.0798 - regression_loss: 0.8803 - classification_loss: 0.1995
 307/1000 [========>.....................] - ETA: 3:18 - loss: 1.0802 - regression_loss: 0.8807 - classification_loss: 0.1995
 308/1000 [========>.....................] - ETA: 3:18 - loss: 1.0821 - regression_loss: 0.8824 - classification_loss: 0.1996
 309/1000 [========>.....................] - ETA: 3:17 - loss: 1.0832 - regression_loss: 0.8831 - classification_loss: 0.2000
 310/1000 [========>.....................] - ETA: 3:17 - loss: 1.0817 - regression_loss: 0.8819 - classification_loss: 0.1997
 311/1000 [========>.....................] - ETA: 3:17 - loss: 1.0804 - regression_loss: 0.8808 - classification_loss: 0.1995
 312/1000 [========>.....................] - ETA: 3:16 - loss: 1.0784 - regression_loss: 0.8793 - classification_loss: 0.1991
 313/1000 [========>.....................] - ETA: 3:16 - loss: 1.0759 - regression_loss: 0.8773 - classification_loss: 0.1986
 314/1000 [========>.....................] - ETA: 3:16 - loss: 1.0746 - regression_loss: 0.8762 - classification_loss: 0.1984
 315/1000 [========>.....................] - ETA: 3:16 - loss: 1.0741 - regression_loss: 0.8758 - classification_loss: 0.1982
 316/1000 [========>.....................] - ETA: 3:15 - loss: 1.0715 - regression_loss: 0.8738 - classification_loss: 0.1977
 317/1000 [========>.....................] - ETA: 3:15 - loss: 1.0713 - regression_loss: 0.8735 - classification_loss: 0.1979
 318/1000 [========>.....................] - ETA: 3:15 - loss: 1.0703 - regression_loss: 0.8726 - classification_loss: 0.1977
 319/1000 [========>.....................] - ETA: 3:14 - loss: 1.0706 - regression_loss: 0.8727 - classification_loss: 0.1980
 320/1000 [========>.....................] - ETA: 3:14 - loss: 1.0693 - regression_loss: 0.8713 - classification_loss: 0.1980
 321/1000 [========>.....................] - ETA: 3:14 - loss: 1.0681 - regression_loss: 0.8704 - classification_loss: 0.1977
 322/1000 [========>.....................] - ETA: 3:14 - loss: 1.0681 - regression_loss: 0.8699 - classification_loss: 0.1982
 323/1000 [========>.....................] - ETA: 3:13 - loss: 1.0680 - regression_loss: 0.8699 - classification_loss: 0.1982
 324/1000 [========>.....................] - ETA: 3:13 - loss: 1.0662 - regression_loss: 0.8684 - classification_loss: 0.1978
 325/1000 [========>.....................] - ETA: 3:13 - loss: 1.0667 - regression_loss: 0.8685 - classification_loss: 0.1982
 326/1000 [========>.....................] - ETA: 3:12 - loss: 1.0656 - regression_loss: 0.8670 - classification_loss: 0.1985
 327/1000 [========>.....................] - ETA: 3:12 - loss: 1.0676 - regression_loss: 0.8688 - classification_loss: 0.1988
 328/1000 [========>.....................] - ETA: 3:12 - loss: 1.0661 - regression_loss: 0.8676 - classification_loss: 0.1985
 329/1000 [========>.....................] - ETA: 3:12 - loss: 1.0643 - regression_loss: 0.8662 - classification_loss: 0.1982
 330/1000 [========>.....................] - ETA: 3:11 - loss: 1.0636 - regression_loss: 0.8656 - classification_loss: 0.1980
 331/1000 [========>.....................] - ETA: 3:11 - loss: 1.0618 - regression_loss: 0.8638 - classification_loss: 0.1980
 332/1000 [========>.....................] - ETA: 3:11 - loss: 1.0607 - regression_loss: 0.8627 - classification_loss: 0.1980
 333/1000 [========>.....................] - ETA: 3:10 - loss: 1.0625 - regression_loss: 0.8637 - classification_loss: 0.1988
 334/1000 [=========>....................] - ETA: 3:10 - loss: 1.0612 - regression_loss: 0.8628 - classification_loss: 0.1984
 335/1000 [=========>....................] - ETA: 3:10 - loss: 1.0633 - regression_loss: 0.8649 - classification_loss: 0.1984
 336/1000 [=========>....................] - ETA: 3:10 - loss: 1.0622 - regression_loss: 0.8633 - classification_loss: 0.1989
 337/1000 [=========>....................] - ETA: 3:09 - loss: 1.0609 - regression_loss: 0.8622 - classification_loss: 0.1987
 338/1000 [=========>....................] - ETA: 3:09 - loss: 1.0633 - regression_loss: 0.8645 - classification_loss: 0.1988
 339/1000 [=========>....................] - ETA: 3:09 - loss: 1.0623 - regression_loss: 0.8638 - classification_loss: 0.1985
 340/1000 [=========>....................] - ETA: 3:09 - loss: 1.0621 - regression_loss: 0.8635 - classification_loss: 0.1986
 341/1000 [=========>....................] - ETA: 3:08 - loss: 1.0640 - regression_loss: 0.8648 - classification_loss: 0.1992
 342/1000 [=========>....................] - ETA: 3:08 - loss: 1.0636 - regression_loss: 0.8646 - classification_loss: 0.1989
 343/1000 [=========>....................] - ETA: 3:08 - loss: 1.0631 - regression_loss: 0.8643 - classification_loss: 0.1988
 344/1000 [=========>....................] - ETA: 3:07 - loss: 1.0624 - regression_loss: 0.8637 - classification_loss: 0.1987
 345/1000 [=========>....................] - ETA: 3:07 - loss: 1.0611 - regression_loss: 0.8628 - classification_loss: 0.1983
 346/1000 [=========>....................] - ETA: 3:07 - loss: 1.0608 - regression_loss: 0.8627 - classification_loss: 0.1982
 347/1000 [=========>....................] - ETA: 3:06 - loss: 1.0616 - regression_loss: 0.8634 - classification_loss: 0.1982
 348/1000 [=========>....................] - ETA: 3:06 - loss: 1.0597 - regression_loss: 0.8618 - classification_loss: 0.1979
 349/1000 [=========>....................] - ETA: 3:06 - loss: 1.0581 - regression_loss: 0.8606 - classification_loss: 0.1975
 350/1000 [=========>....................] - ETA: 3:06 - loss: 1.0582 - regression_loss: 0.8607 - classification_loss: 0.1974
 351/1000 [=========>....................] - ETA: 3:05 - loss: 1.0564 - regression_loss: 0.8594 - classification_loss: 0.1970
 352/1000 [=========>....................] - ETA: 3:05 - loss: 1.0557 - regression_loss: 0.8587 - classification_loss: 0.1970
 353/1000 [=========>....................] - ETA: 3:05 - loss: 1.0552 - regression_loss: 0.8585 - classification_loss: 0.1967
 354/1000 [=========>....................] - ETA: 3:04 - loss: 1.0549 - regression_loss: 0.8583 - classification_loss: 0.1966
 355/1000 [=========>....................] - ETA: 3:04 - loss: 1.0543 - regression_loss: 0.8580 - classification_loss: 0.1963
 356/1000 [=========>....................] - ETA: 3:04 - loss: 1.0521 - regression_loss: 0.8562 - classification_loss: 0.1959
 357/1000 [=========>....................] - ETA: 3:04 - loss: 1.0510 - regression_loss: 0.8553 - classification_loss: 0.1957
 358/1000 [=========>....................] - ETA: 3:03 - loss: 1.0516 - regression_loss: 0.8561 - classification_loss: 0.1956
 359/1000 [=========>....................] - ETA: 3:03 - loss: 1.0501 - regression_loss: 0.8548 - classification_loss: 0.1952
 360/1000 [=========>....................] - ETA: 3:03 - loss: 1.0495 - regression_loss: 0.8538 - classification_loss: 0.1957
 361/1000 [=========>....................] - ETA: 3:02 - loss: 1.0488 - regression_loss: 0.8534 - classification_loss: 0.1954
 362/1000 [=========>....................] - ETA: 3:02 - loss: 1.0482 - regression_loss: 0.8530 - classification_loss: 0.1952
 363/1000 [=========>....................] - ETA: 3:02 - loss: 1.0485 - regression_loss: 0.8534 - classification_loss: 0.1951
 364/1000 [=========>....................] - ETA: 3:02 - loss: 1.0468 - regression_loss: 0.8522 - classification_loss: 0.1947
 365/1000 [=========>....................] - ETA: 3:01 - loss: 1.0475 - regression_loss: 0.8528 - classification_loss: 0.1947
 366/1000 [=========>....................] - ETA: 3:01 - loss: 1.0470 - regression_loss: 0.8522 - classification_loss: 0.1948
 367/1000 [==========>...................] - ETA: 3:01 - loss: 1.0462 - regression_loss: 0.8518 - classification_loss: 0.1944
 368/1000 [==========>...................] - ETA: 3:00 - loss: 1.0456 - regression_loss: 0.8507 - classification_loss: 0.1949
 369/1000 [==========>...................] - ETA: 3:00 - loss: 1.0469 - regression_loss: 0.8518 - classification_loss: 0.1951
 370/1000 [==========>...................] - ETA: 3:00 - loss: 1.0475 - regression_loss: 0.8524 - classification_loss: 0.1951
 371/1000 [==========>...................] - ETA: 3:00 - loss: 1.0469 - regression_loss: 0.8521 - classification_loss: 0.1948
 372/1000 [==========>...................] - ETA: 2:59 - loss: 1.0455 - regression_loss: 0.8512 - classification_loss: 0.1944
 373/1000 [==========>...................] - ETA: 2:59 - loss: 1.0448 - regression_loss: 0.8506 - classification_loss: 0.1942
 374/1000 [==========>...................] - ETA: 2:59 - loss: 1.0472 - regression_loss: 0.8525 - classification_loss: 0.1947
 375/1000 [==========>...................] - ETA: 2:58 - loss: 1.0477 - regression_loss: 0.8529 - classification_loss: 0.1949
 376/1000 [==========>...................] - ETA: 2:58 - loss: 1.0476 - regression_loss: 0.8529 - classification_loss: 0.1947
 377/1000 [==========>...................] - ETA: 2:58 - loss: 1.0488 - regression_loss: 0.8537 - classification_loss: 0.1951
 378/1000 [==========>...................] - ETA: 2:58 - loss: 1.0473 - regression_loss: 0.8525 - classification_loss: 0.1948
 379/1000 [==========>...................] - ETA: 2:57 - loss: 1.0464 - regression_loss: 0.8517 - classification_loss: 0.1946
 380/1000 [==========>...................] - ETA: 2:57 - loss: 1.0460 - regression_loss: 0.8517 - classification_loss: 0.1944
 381/1000 [==========>...................] - ETA: 2:57 - loss: 1.0465 - regression_loss: 0.8521 - classification_loss: 0.1943
 382/1000 [==========>...................] - ETA: 2:56 - loss: 1.0495 - regression_loss: 0.8544 - classification_loss: 0.1950
 383/1000 [==========>...................] - ETA: 2:56 - loss: 1.0488 - regression_loss: 0.8539 - classification_loss: 0.1949
 384/1000 [==========>...................] - ETA: 2:56 - loss: 1.0478 - regression_loss: 0.8531 - classification_loss: 0.1947
 385/1000 [==========>...................] - ETA: 2:56 - loss: 1.0474 - regression_loss: 0.8528 - classification_loss: 0.1946
 386/1000 [==========>...................] - ETA: 2:55 - loss: 1.0462 - regression_loss: 0.8519 - classification_loss: 0.1943
 387/1000 [==========>...................] - ETA: 2:55 - loss: 1.0457 - regression_loss: 0.8516 - classification_loss: 0.1940
 388/1000 [==========>...................] - ETA: 2:55 - loss: 1.0449 - regression_loss: 0.8512 - classification_loss: 0.1936
 389/1000 [==========>...................] - ETA: 2:54 - loss: 1.0435 - regression_loss: 0.8502 - classification_loss: 0.1933
 390/1000 [==========>...................] - ETA: 2:54 - loss: 1.0450 - regression_loss: 0.8515 - classification_loss: 0.1935
 391/1000 [==========>...................] - ETA: 2:54 - loss: 1.0445 - regression_loss: 0.8510 - classification_loss: 0.1935
 392/1000 [==========>...................] - ETA: 2:54 - loss: 1.0492 - regression_loss: 0.8550 - classification_loss: 0.1942
 393/1000 [==========>...................] - ETA: 2:53 - loss: 1.0477 - regression_loss: 0.8536 - classification_loss: 0.1941
 394/1000 [==========>...................] - ETA: 2:53 - loss: 1.0470 - regression_loss: 0.8531 - classification_loss: 0.1939
 395/1000 [==========>...................] - ETA: 2:53 - loss: 1.0495 - regression_loss: 0.8551 - classification_loss: 0.1943
 396/1000 [==========>...................] - ETA: 2:52 - loss: 1.0524 - regression_loss: 0.8577 - classification_loss: 0.1947
 397/1000 [==========>...................] - ETA: 2:52 - loss: 1.0517 - regression_loss: 0.8573 - classification_loss: 0.1945
 398/1000 [==========>...................] - ETA: 2:52 - loss: 1.0532 - regression_loss: 0.8585 - classification_loss: 0.1947
 399/1000 [==========>...................] - ETA: 2:52 - loss: 1.0517 - regression_loss: 0.8574 - classification_loss: 0.1943
 400/1000 [===========>..................] - ETA: 2:51 - loss: 1.0513 - regression_loss: 0.8570 - classification_loss: 0.1943
 401/1000 [===========>..................] - ETA: 2:51 - loss: 1.0558 - regression_loss: 0.8604 - classification_loss: 0.1953
 402/1000 [===========>..................] - ETA: 2:51 - loss: 1.0566 - regression_loss: 0.8611 - classification_loss: 0.1954
 403/1000 [===========>..................] - ETA: 2:50 - loss: 1.0566 - regression_loss: 0.8610 - classification_loss: 0.1956
 404/1000 [===========>..................] - ETA: 2:50 - loss: 1.0565 - regression_loss: 0.8609 - classification_loss: 0.1956
 405/1000 [===========>..................] - ETA: 2:50 - loss: 1.0554 - regression_loss: 0.8602 - classification_loss: 0.1952
 406/1000 [===========>..................] - ETA: 2:50 - loss: 1.0550 - regression_loss: 0.8597 - classification_loss: 0.1953
 407/1000 [===========>..................] - ETA: 2:49 - loss: 1.0548 - regression_loss: 0.8595 - classification_loss: 0.1953
 408/1000 [===========>..................] - ETA: 2:49 - loss: 1.0532 - regression_loss: 0.8583 - classification_loss: 0.1950
 409/1000 [===========>..................] - ETA: 2:49 - loss: 1.0550 - regression_loss: 0.8596 - classification_loss: 0.1954
 410/1000 [===========>..................] - ETA: 2:48 - loss: 1.0540 - regression_loss: 0.8589 - classification_loss: 0.1951
 411/1000 [===========>..................] - ETA: 2:48 - loss: 1.0585 - regression_loss: 0.8611 - classification_loss: 0.1974
 412/1000 [===========>..................] - ETA: 2:48 - loss: 1.0589 - regression_loss: 0.8617 - classification_loss: 0.1973
 413/1000 [===========>..................] - ETA: 2:48 - loss: 1.0598 - regression_loss: 0.8625 - classification_loss: 0.1973
 414/1000 [===========>..................] - ETA: 2:47 - loss: 1.0630 - regression_loss: 0.8649 - classification_loss: 0.1981
 415/1000 [===========>..................] - ETA: 2:47 - loss: 1.0625 - regression_loss: 0.8643 - classification_loss: 0.1982
 416/1000 [===========>..................] - ETA: 2:47 - loss: 1.0622 - regression_loss: 0.8642 - classification_loss: 0.1980
 417/1000 [===========>..................] - ETA: 2:46 - loss: 1.0618 - regression_loss: 0.8639 - classification_loss: 0.1979
 418/1000 [===========>..................] - ETA: 2:46 - loss: 1.0622 - regression_loss: 0.8639 - classification_loss: 0.1983
 419/1000 [===========>..................] - ETA: 2:46 - loss: 1.0620 - regression_loss: 0.8639 - classification_loss: 0.1981
 420/1000 [===========>..................] - ETA: 2:46 - loss: 1.0615 - regression_loss: 0.8637 - classification_loss: 0.1978
 421/1000 [===========>..................] - ETA: 2:45 - loss: 1.0608 - regression_loss: 0.8632 - classification_loss: 0.1976
 422/1000 [===========>..................] - ETA: 2:45 - loss: 1.0606 - regression_loss: 0.8629 - classification_loss: 0.1977
 423/1000 [===========>..................] - ETA: 2:45 - loss: 1.0604 - regression_loss: 0.8626 - classification_loss: 0.1977
 424/1000 [===========>..................] - ETA: 2:44 - loss: 1.0617 - regression_loss: 0.8639 - classification_loss: 0.1979
 425/1000 [===========>..................] - ETA: 2:44 - loss: 1.0629 - regression_loss: 0.8647 - classification_loss: 0.1981
 426/1000 [===========>..................] - ETA: 2:44 - loss: 1.0652 - regression_loss: 0.8669 - classification_loss: 0.1983
 427/1000 [===========>..................] - ETA: 2:44 - loss: 1.0644 - regression_loss: 0.8662 - classification_loss: 0.1982
 428/1000 [===========>..................] - ETA: 2:43 - loss: 1.0645 - regression_loss: 0.8663 - classification_loss: 0.1982
 429/1000 [===========>..................] - ETA: 2:43 - loss: 1.0652 - regression_loss: 0.8665 - classification_loss: 0.1987
 430/1000 [===========>..................] - ETA: 2:43 - loss: 1.0651 - regression_loss: 0.8665 - classification_loss: 0.1986
 431/1000 [===========>..................] - ETA: 2:42 - loss: 1.0636 - regression_loss: 0.8650 - classification_loss: 0.1986
 432/1000 [===========>..................] - ETA: 2:42 - loss: 1.0639 - regression_loss: 0.8652 - classification_loss: 0.1987
 433/1000 [===========>..................] - ETA: 2:42 - loss: 1.0624 - regression_loss: 0.8641 - classification_loss: 0.1984
 434/1000 [============>.................] - ETA: 2:42 - loss: 1.0612 - regression_loss: 0.8631 - classification_loss: 0.1981
 435/1000 [============>.................] - ETA: 2:41 - loss: 1.0604 - regression_loss: 0.8624 - classification_loss: 0.1979
 436/1000 [============>.................] - ETA: 2:41 - loss: 1.0609 - regression_loss: 0.8629 - classification_loss: 0.1979
 437/1000 [============>.................] - ETA: 2:41 - loss: 1.0603 - regression_loss: 0.8627 - classification_loss: 0.1976
 438/1000 [============>.................] - ETA: 2:40 - loss: 1.0599 - regression_loss: 0.8625 - classification_loss: 0.1974
 439/1000 [============>.................] - ETA: 2:40 - loss: 1.0589 - regression_loss: 0.8616 - classification_loss: 0.1973
 440/1000 [============>.................] - ETA: 2:40 - loss: 1.0585 - regression_loss: 0.8613 - classification_loss: 0.1972
 441/1000 [============>.................] - ETA: 2:40 - loss: 1.0583 - regression_loss: 0.8610 - classification_loss: 0.1973
 442/1000 [============>.................] - ETA: 2:39 - loss: 1.0588 - regression_loss: 0.8615 - classification_loss: 0.1973
 443/1000 [============>.................] - ETA: 2:39 - loss: 1.0586 - regression_loss: 0.8615 - classification_loss: 0.1971
 444/1000 [============>.................] - ETA: 2:39 - loss: 1.0588 - regression_loss: 0.8616 - classification_loss: 0.1972
 445/1000 [============>.................] - ETA: 2:38 - loss: 1.0583 - regression_loss: 0.8613 - classification_loss: 0.1970
 446/1000 [============>.................] - ETA: 2:38 - loss: 1.0594 - regression_loss: 0.8622 - classification_loss: 0.1971
 447/1000 [============>.................] - ETA: 2:38 - loss: 1.0607 - regression_loss: 0.8636 - classification_loss: 0.1972
 448/1000 [============>.................] - ETA: 2:38 - loss: 1.0602 - regression_loss: 0.8632 - classification_loss: 0.1970
 449/1000 [============>.................] - ETA: 2:37 - loss: 1.0589 - regression_loss: 0.8622 - classification_loss: 0.1967
 450/1000 [============>.................] - ETA: 2:37 - loss: 1.0578 - regression_loss: 0.8613 - classification_loss: 0.1965
 451/1000 [============>.................] - ETA: 2:37 - loss: 1.0613 - regression_loss: 0.8634 - classification_loss: 0.1978
 452/1000 [============>.................] - ETA: 2:36 - loss: 1.0614 - regression_loss: 0.8634 - classification_loss: 0.1980
 453/1000 [============>.................] - ETA: 2:36 - loss: 1.0625 - regression_loss: 0.8643 - classification_loss: 0.1982
 454/1000 [============>.................] - ETA: 2:36 - loss: 1.0619 - regression_loss: 0.8639 - classification_loss: 0.1980
 455/1000 [============>.................] - ETA: 2:36 - loss: 1.0624 - regression_loss: 0.8645 - classification_loss: 0.1980
 456/1000 [============>.................] - ETA: 2:35 - loss: 1.0619 - regression_loss: 0.8641 - classification_loss: 0.1977
 457/1000 [============>.................] - ETA: 2:35 - loss: 1.0638 - regression_loss: 0.8655 - classification_loss: 0.1983
 458/1000 [============>.................] - ETA: 2:35 - loss: 1.0627 - regression_loss: 0.8646 - classification_loss: 0.1981
 459/1000 [============>.................] - ETA: 2:34 - loss: 1.0628 - regression_loss: 0.8648 - classification_loss: 0.1981
 460/1000 [============>.................] - ETA: 2:34 - loss: 1.0641 - regression_loss: 0.8660 - classification_loss: 0.1981
 461/1000 [============>.................] - ETA: 2:34 - loss: 1.0642 - regression_loss: 0.8660 - classification_loss: 0.1982
 462/1000 [============>.................] - ETA: 2:34 - loss: 1.0671 - regression_loss: 0.8683 - classification_loss: 0.1989
 463/1000 [============>.................] - ETA: 2:33 - loss: 1.0682 - regression_loss: 0.8694 - classification_loss: 0.1989
 464/1000 [============>.................] - ETA: 2:33 - loss: 1.0694 - regression_loss: 0.8705 - classification_loss: 0.1989
 465/1000 [============>.................] - ETA: 2:33 - loss: 1.0690 - regression_loss: 0.8702 - classification_loss: 0.1987
 466/1000 [============>.................] - ETA: 2:32 - loss: 1.0696 - regression_loss: 0.8705 - classification_loss: 0.1991
 467/1000 [=============>................] - ETA: 2:32 - loss: 1.0690 - regression_loss: 0.8701 - classification_loss: 0.1989
 468/1000 [=============>................] - ETA: 2:32 - loss: 1.0678 - regression_loss: 0.8691 - classification_loss: 0.1987
 469/1000 [=============>................] - ETA: 2:32 - loss: 1.0676 - regression_loss: 0.8690 - classification_loss: 0.1986
 470/1000 [=============>................] - ETA: 2:31 - loss: 1.0676 - regression_loss: 0.8686 - classification_loss: 0.1990
 471/1000 [=============>................] - ETA: 2:31 - loss: 1.0693 - regression_loss: 0.8700 - classification_loss: 0.1992
 472/1000 [=============>................] - ETA: 2:31 - loss: 1.0695 - regression_loss: 0.8694 - classification_loss: 0.2001
 473/1000 [=============>................] - ETA: 2:30 - loss: 1.0700 - regression_loss: 0.8697 - classification_loss: 0.2003
 474/1000 [=============>................] - ETA: 2:30 - loss: 1.0697 - regression_loss: 0.8692 - classification_loss: 0.2005
 475/1000 [=============>................] - ETA: 2:30 - loss: 1.0695 - regression_loss: 0.8692 - classification_loss: 0.2003
 476/1000 [=============>................] - ETA: 2:30 - loss: 1.0707 - regression_loss: 0.8701 - classification_loss: 0.2006
 477/1000 [=============>................] - ETA: 2:29 - loss: 1.0702 - regression_loss: 0.8696 - classification_loss: 0.2005
 478/1000 [=============>................] - ETA: 2:29 - loss: 1.0700 - regression_loss: 0.8695 - classification_loss: 0.2005
 479/1000 [=============>................] - ETA: 2:29 - loss: 1.0684 - regression_loss: 0.8681 - classification_loss: 0.2003
 480/1000 [=============>................] - ETA: 2:28 - loss: 1.0678 - regression_loss: 0.8674 - classification_loss: 0.2004
 481/1000 [=============>................] - ETA: 2:28 - loss: 1.0693 - regression_loss: 0.8685 - classification_loss: 0.2007
 482/1000 [=============>................] - ETA: 2:28 - loss: 1.0685 - regression_loss: 0.8677 - classification_loss: 0.2007
 483/1000 [=============>................] - ETA: 2:28 - loss: 1.0688 - regression_loss: 0.8679 - classification_loss: 0.2009
 484/1000 [=============>................] - ETA: 2:27 - loss: 1.0698 - regression_loss: 0.8687 - classification_loss: 0.2012
 485/1000 [=============>................] - ETA: 2:27 - loss: 1.0691 - regression_loss: 0.8679 - classification_loss: 0.2012
 486/1000 [=============>................] - ETA: 2:27 - loss: 1.0682 - regression_loss: 0.8671 - classification_loss: 0.2011
 487/1000 [=============>................] - ETA: 2:26 - loss: 1.0683 - regression_loss: 0.8670 - classification_loss: 0.2013
 488/1000 [=============>................] - ETA: 2:26 - loss: 1.0677 - regression_loss: 0.8666 - classification_loss: 0.2011
 489/1000 [=============>................] - ETA: 2:26 - loss: 1.0671 - regression_loss: 0.8662 - classification_loss: 0.2009
 490/1000 [=============>................] - ETA: 2:26 - loss: 1.0661 - regression_loss: 0.8655 - classification_loss: 0.2007
 491/1000 [=============>................] - ETA: 2:25 - loss: 1.0656 - regression_loss: 0.8652 - classification_loss: 0.2005
 492/1000 [=============>................] - ETA: 2:25 - loss: 1.0660 - regression_loss: 0.8656 - classification_loss: 0.2004
 493/1000 [=============>................] - ETA: 2:25 - loss: 1.0665 - regression_loss: 0.8659 - classification_loss: 0.2006
 494/1000 [=============>................] - ETA: 2:24 - loss: 1.0667 - regression_loss: 0.8662 - classification_loss: 0.2005
 495/1000 [=============>................] - ETA: 2:24 - loss: 1.0665 - regression_loss: 0.8662 - classification_loss: 0.2003
 496/1000 [=============>................] - ETA: 2:24 - loss: 1.0675 - regression_loss: 0.8671 - classification_loss: 0.2004
 497/1000 [=============>................] - ETA: 2:24 - loss: 1.0669 - regression_loss: 0.8665 - classification_loss: 0.2004
 498/1000 [=============>................] - ETA: 2:23 - loss: 1.0661 - regression_loss: 0.8660 - classification_loss: 0.2001
 499/1000 [=============>................] - ETA: 2:23 - loss: 1.0732 - regression_loss: 0.8643 - classification_loss: 0.2089
 500/1000 [==============>...............] - ETA: 2:23 - loss: 1.0733 - regression_loss: 0.8642 - classification_loss: 0.2091
 501/1000 [==============>...............] - ETA: 2:22 - loss: 1.0734 - regression_loss: 0.8643 - classification_loss: 0.2091
 502/1000 [==============>...............] - ETA: 2:22 - loss: 1.0735 - regression_loss: 0.8644 - classification_loss: 0.2092
 503/1000 [==============>...............] - ETA: 2:22 - loss: 1.0742 - regression_loss: 0.8649 - classification_loss: 0.2093
 504/1000 [==============>...............] - ETA: 2:22 - loss: 1.0731 - regression_loss: 0.8641 - classification_loss: 0.2091
 505/1000 [==============>...............] - ETA: 2:21 - loss: 1.0746 - regression_loss: 0.8653 - classification_loss: 0.2093
 506/1000 [==============>...............] - ETA: 2:21 - loss: 1.0736 - regression_loss: 0.8646 - classification_loss: 0.2090
 507/1000 [==============>...............] - ETA: 2:21 - loss: 1.0732 - regression_loss: 0.8642 - classification_loss: 0.2090
 508/1000 [==============>...............] - ETA: 2:20 - loss: 1.0739 - regression_loss: 0.8646 - classification_loss: 0.2093
 509/1000 [==============>...............] - ETA: 2:20 - loss: 1.0730 - regression_loss: 0.8640 - classification_loss: 0.2091
 510/1000 [==============>...............] - ETA: 2:20 - loss: 1.0743 - regression_loss: 0.8651 - classification_loss: 0.2092
 511/1000 [==============>...............] - ETA: 2:20 - loss: 1.0749 - regression_loss: 0.8656 - classification_loss: 0.2093
 512/1000 [==============>...............] - ETA: 2:19 - loss: 1.0754 - regression_loss: 0.8662 - classification_loss: 0.2092
 513/1000 [==============>...............] - ETA: 2:19 - loss: 1.0762 - regression_loss: 0.8671 - classification_loss: 0.2091
 514/1000 [==============>...............] - ETA: 2:19 - loss: 1.0759 - regression_loss: 0.8668 - classification_loss: 0.2091
 515/1000 [==============>...............] - ETA: 2:18 - loss: 1.0749 - regression_loss: 0.8660 - classification_loss: 0.2089
 516/1000 [==============>...............] - ETA: 2:18 - loss: 1.0755 - regression_loss: 0.8667 - classification_loss: 0.2088
 517/1000 [==============>...............] - ETA: 2:18 - loss: 1.0750 - regression_loss: 0.8661 - classification_loss: 0.2089
 518/1000 [==============>...............] - ETA: 2:18 - loss: 1.0738 - regression_loss: 0.8652 - classification_loss: 0.2086
 519/1000 [==============>...............] - ETA: 2:17 - loss: 1.0739 - regression_loss: 0.8654 - classification_loss: 0.2085
 520/1000 [==============>...............] - ETA: 2:17 - loss: 1.0736 - regression_loss: 0.8653 - classification_loss: 0.2084
 521/1000 [==============>...............] - ETA: 2:17 - loss: 1.0727 - regression_loss: 0.8645 - classification_loss: 0.2082
 522/1000 [==============>...............] - ETA: 2:16 - loss: 1.0723 - regression_loss: 0.8643 - classification_loss: 0.2080
 523/1000 [==============>...............] - ETA: 2:16 - loss: 1.0749 - regression_loss: 0.8668 - classification_loss: 0.2081
 524/1000 [==============>...............] - ETA: 2:16 - loss: 1.0739 - regression_loss: 0.8661 - classification_loss: 0.2078
 525/1000 [==============>...............] - ETA: 2:16 - loss: 1.0742 - regression_loss: 0.8662 - classification_loss: 0.2080
 526/1000 [==============>...............] - ETA: 2:15 - loss: 1.0746 - regression_loss: 0.8664 - classification_loss: 0.2082
 527/1000 [==============>...............] - ETA: 2:15 - loss: 1.0736 - regression_loss: 0.8657 - classification_loss: 0.2079
 528/1000 [==============>...............] - ETA: 2:15 - loss: 1.0736 - regression_loss: 0.8658 - classification_loss: 0.2078
 529/1000 [==============>...............] - ETA: 2:14 - loss: 1.0727 - regression_loss: 0.8651 - classification_loss: 0.2076
 530/1000 [==============>...............] - ETA: 2:14 - loss: 1.0716 - regression_loss: 0.8644 - classification_loss: 0.2073
 531/1000 [==============>...............] - ETA: 2:14 - loss: 1.0707 - regression_loss: 0.8637 - classification_loss: 0.2070
 532/1000 [==============>...............] - ETA: 2:14 - loss: 1.0704 - regression_loss: 0.8636 - classification_loss: 0.2068
 533/1000 [==============>...............] - ETA: 2:13 - loss: 1.0709 - regression_loss: 0.8633 - classification_loss: 0.2076
 534/1000 [===============>..............] - ETA: 2:13 - loss: 1.0721 - regression_loss: 0.8644 - classification_loss: 0.2077
 535/1000 [===============>..............] - ETA: 2:13 - loss: 1.0715 - regression_loss: 0.8640 - classification_loss: 0.2076
 536/1000 [===============>..............] - ETA: 2:12 - loss: 1.0713 - regression_loss: 0.8633 - classification_loss: 0.2080
 537/1000 [===============>..............] - ETA: 2:12 - loss: 1.0707 - regression_loss: 0.8629 - classification_loss: 0.2078
 538/1000 [===============>..............] - ETA: 2:12 - loss: 1.0692 - regression_loss: 0.8617 - classification_loss: 0.2075
 539/1000 [===============>..............] - ETA: 2:12 - loss: 1.0684 - regression_loss: 0.8612 - classification_loss: 0.2072
 540/1000 [===============>..............] - ETA: 2:11 - loss: 1.0701 - regression_loss: 0.8626 - classification_loss: 0.2075
 541/1000 [===============>..............] - ETA: 2:11 - loss: 1.0707 - regression_loss: 0.8630 - classification_loss: 0.2077
 542/1000 [===============>..............] - ETA: 2:11 - loss: 1.0709 - regression_loss: 0.8633 - classification_loss: 0.2076
 543/1000 [===============>..............] - ETA: 2:10 - loss: 1.0716 - regression_loss: 0.8639 - classification_loss: 0.2077
 544/1000 [===============>..............] - ETA: 2:10 - loss: 1.0711 - regression_loss: 0.8635 - classification_loss: 0.2076
 545/1000 [===============>..............] - ETA: 2:10 - loss: 1.0710 - regression_loss: 0.8635 - classification_loss: 0.2076
 546/1000 [===============>..............] - ETA: 2:10 - loss: 1.0709 - regression_loss: 0.8635 - classification_loss: 0.2074
 547/1000 [===============>..............] - ETA: 2:09 - loss: 1.0712 - regression_loss: 0.8637 - classification_loss: 0.2075
 548/1000 [===============>..............] - ETA: 2:09 - loss: 1.0723 - regression_loss: 0.8648 - classification_loss: 0.2075
 549/1000 [===============>..............] - ETA: 2:09 - loss: 1.0725 - regression_loss: 0.8650 - classification_loss: 0.2075
 550/1000 [===============>..............] - ETA: 2:08 - loss: 1.0720 - regression_loss: 0.8647 - classification_loss: 0.2073
 551/1000 [===============>..............] - ETA: 2:08 - loss: 1.0720 - regression_loss: 0.8647 - classification_loss: 0.2073
 552/1000 [===============>..............] - ETA: 2:08 - loss: 1.0710 - regression_loss: 0.8639 - classification_loss: 0.2071
 553/1000 [===============>..............] - ETA: 2:08 - loss: 1.0717 - regression_loss: 0.8645 - classification_loss: 0.2072
 554/1000 [===============>..............] - ETA: 2:07 - loss: 1.0713 - regression_loss: 0.8642 - classification_loss: 0.2071
 555/1000 [===============>..............] - ETA: 2:07 - loss: 1.0702 - regression_loss: 0.8633 - classification_loss: 0.2069
 556/1000 [===============>..............] - ETA: 2:07 - loss: 1.0697 - regression_loss: 0.8630 - classification_loss: 0.2067
 557/1000 [===============>..............] - ETA: 2:06 - loss: 1.0690 - regression_loss: 0.8625 - classification_loss: 0.2065
 558/1000 [===============>..............] - ETA: 2:06 - loss: 1.0704 - regression_loss: 0.8637 - classification_loss: 0.2067
 559/1000 [===============>..............] - ETA: 2:06 - loss: 1.0700 - regression_loss: 0.8635 - classification_loss: 0.2065
 560/1000 [===============>..............] - ETA: 2:06 - loss: 1.0699 - regression_loss: 0.8636 - classification_loss: 0.2063
 561/1000 [===============>..............] - ETA: 2:05 - loss: 1.0693 - regression_loss: 0.8632 - classification_loss: 0.2061
 562/1000 [===============>..............] - ETA: 2:05 - loss: 1.0681 - regression_loss: 0.8623 - classification_loss: 0.2059
 563/1000 [===============>..............] - ETA: 2:05 - loss: 1.0673 - regression_loss: 0.8615 - classification_loss: 0.2057
 564/1000 [===============>..............] - ETA: 2:04 - loss: 1.0674 - regression_loss: 0.8619 - classification_loss: 0.2055
 565/1000 [===============>..............] - ETA: 2:04 - loss: 1.0699 - regression_loss: 0.8638 - classification_loss: 0.2061
 566/1000 [===============>..............] - ETA: 2:04 - loss: 1.0697 - regression_loss: 0.8639 - classification_loss: 0.2059
 567/1000 [================>.............] - ETA: 2:04 - loss: 1.0693 - regression_loss: 0.8636 - classification_loss: 0.2057
 568/1000 [================>.............] - ETA: 2:03 - loss: 1.0687 - regression_loss: 0.8632 - classification_loss: 0.2055
 569/1000 [================>.............] - ETA: 2:03 - loss: 1.0697 - regression_loss: 0.8641 - classification_loss: 0.2056
 570/1000 [================>.............] - ETA: 2:03 - loss: 1.0693 - regression_loss: 0.8637 - classification_loss: 0.2056
 571/1000 [================>.............] - ETA: 2:02 - loss: 1.0696 - regression_loss: 0.8640 - classification_loss: 0.2056
 572/1000 [================>.............] - ETA: 2:02 - loss: 1.0690 - regression_loss: 0.8636 - classification_loss: 0.2054
 573/1000 [================>.............] - ETA: 2:02 - loss: 1.0684 - regression_loss: 0.8632 - classification_loss: 0.2052
 574/1000 [================>.............] - ETA: 2:02 - loss: 1.0676 - regression_loss: 0.8625 - classification_loss: 0.2051
 575/1000 [================>.............] - ETA: 2:01 - loss: 1.0673 - regression_loss: 0.8622 - classification_loss: 0.2051
 576/1000 [================>.............] - ETA: 2:01 - loss: 1.0692 - regression_loss: 0.8642 - classification_loss: 0.2051
 577/1000 [================>.............] - ETA: 2:01 - loss: 1.0704 - regression_loss: 0.8653 - classification_loss: 0.2050
 578/1000 [================>.............] - ETA: 2:00 - loss: 1.0705 - regression_loss: 0.8656 - classification_loss: 0.2049
 579/1000 [================>.............] - ETA: 2:00 - loss: 1.0713 - regression_loss: 0.8661 - classification_loss: 0.2052
 580/1000 [================>.............] - ETA: 2:00 - loss: 1.0717 - regression_loss: 0.8666 - classification_loss: 0.2051
 581/1000 [================>.............] - ETA: 2:00 - loss: 1.0708 - regression_loss: 0.8657 - classification_loss: 0.2051
 582/1000 [================>.............] - ETA: 1:59 - loss: 1.0728 - regression_loss: 0.8671 - classification_loss: 0.2057
 583/1000 [================>.............] - ETA: 1:59 - loss: 1.0724 - regression_loss: 0.8668 - classification_loss: 0.2056
 584/1000 [================>.............] - ETA: 1:59 - loss: 1.0731 - regression_loss: 0.8674 - classification_loss: 0.2057
 585/1000 [================>.............] - ETA: 1:58 - loss: 1.0737 - regression_loss: 0.8681 - classification_loss: 0.2056
 586/1000 [================>.............] - ETA: 1:58 - loss: 1.0726 - regression_loss: 0.8673 - classification_loss: 0.2053
 587/1000 [================>.............] - ETA: 1:58 - loss: 1.0733 - regression_loss: 0.8679 - classification_loss: 0.2054
 588/1000 [================>.............] - ETA: 1:58 - loss: 1.0724 - regression_loss: 0.8672 - classification_loss: 0.2051
 589/1000 [================>.............] - ETA: 1:57 - loss: 1.0723 - regression_loss: 0.8671 - classification_loss: 0.2053
 590/1000 [================>.............] - ETA: 1:57 - loss: 1.0711 - regression_loss: 0.8661 - classification_loss: 0.2050
 591/1000 [================>.............] - ETA: 1:57 - loss: 1.0701 - regression_loss: 0.8653 - classification_loss: 0.2048
 592/1000 [================>.............] - ETA: 1:56 - loss: 1.0696 - regression_loss: 0.8650 - classification_loss: 0.2047
 593/1000 [================>.............] - ETA: 1:56 - loss: 1.0695 - regression_loss: 0.8650 - classification_loss: 0.2045
 594/1000 [================>.............] - ETA: 1:56 - loss: 1.0682 - regression_loss: 0.8639 - classification_loss: 0.2043
 595/1000 [================>.............] - ETA: 1:56 - loss: 1.0680 - regression_loss: 0.8639 - classification_loss: 0.2041
 596/1000 [================>.............] - ETA: 1:55 - loss: 1.0701 - regression_loss: 0.8652 - classification_loss: 0.2049
 597/1000 [================>.............] - ETA: 1:55 - loss: 1.0697 - regression_loss: 0.8650 - classification_loss: 0.2047
 598/1000 [================>.............] - ETA: 1:55 - loss: 1.0693 - regression_loss: 0.8648 - classification_loss: 0.2045
 599/1000 [================>.............] - ETA: 1:54 - loss: 1.0685 - regression_loss: 0.8642 - classification_loss: 0.2043
 600/1000 [=================>............] - ETA: 1:54 - loss: 1.0687 - regression_loss: 0.8646 - classification_loss: 0.2041
 601/1000 [=================>............] - ETA: 1:54 - loss: 1.0681 - regression_loss: 0.8640 - classification_loss: 0.2040
 602/1000 [=================>............] - ETA: 1:54 - loss: 1.0675 - regression_loss: 0.8637 - classification_loss: 0.2038
 603/1000 [=================>............] - ETA: 1:53 - loss: 1.0679 - regression_loss: 0.8642 - classification_loss: 0.2037
 604/1000 [=================>............] - ETA: 1:53 - loss: 1.0671 - regression_loss: 0.8635 - classification_loss: 0.2035
 605/1000 [=================>............] - ETA: 1:53 - loss: 1.0673 - regression_loss: 0.8637 - classification_loss: 0.2036
 606/1000 [=================>............] - ETA: 1:52 - loss: 1.0674 - regression_loss: 0.8639 - classification_loss: 0.2035
 607/1000 [=================>............] - ETA: 1:52 - loss: 1.0671 - regression_loss: 0.8639 - classification_loss: 0.2033
 608/1000 [=================>............] - ETA: 1:52 - loss: 1.0659 - regression_loss: 0.8628 - classification_loss: 0.2030
 609/1000 [=================>............] - ETA: 1:51 - loss: 1.0654 - regression_loss: 0.8625 - classification_loss: 0.2029
 610/1000 [=================>............] - ETA: 1:51 - loss: 1.0645 - regression_loss: 0.8618 - classification_loss: 0.2027
 611/1000 [=================>............] - ETA: 1:51 - loss: 1.0647 - regression_loss: 0.8620 - classification_loss: 0.2026
 612/1000 [=================>............] - ETA: 1:51 - loss: 1.0639 - regression_loss: 0.8614 - classification_loss: 0.2026
 613/1000 [=================>............] - ETA: 1:50 - loss: 1.0638 - regression_loss: 0.8612 - classification_loss: 0.2025
 614/1000 [=================>............] - ETA: 1:50 - loss: 1.0632 - regression_loss: 0.8608 - classification_loss: 0.2024
 615/1000 [=================>............] - ETA: 1:50 - loss: 1.0624 - regression_loss: 0.8603 - classification_loss: 0.2022
 616/1000 [=================>............] - ETA: 1:49 - loss: 1.0631 - regression_loss: 0.8609 - classification_loss: 0.2022
 617/1000 [=================>............] - ETA: 1:49 - loss: 1.0621 - regression_loss: 0.8602 - classification_loss: 0.2019
 618/1000 [=================>............] - ETA: 1:49 - loss: 1.0618 - regression_loss: 0.8600 - classification_loss: 0.2019
 619/1000 [=================>............] - ETA: 1:49 - loss: 1.0628 - regression_loss: 0.8607 - classification_loss: 0.2021
 620/1000 [=================>............] - ETA: 1:48 - loss: 1.0619 - regression_loss: 0.8600 - classification_loss: 0.2019
 621/1000 [=================>............] - ETA: 1:48 - loss: 1.0614 - regression_loss: 0.8595 - classification_loss: 0.2019
 622/1000 [=================>............] - ETA: 1:48 - loss: 1.0610 - regression_loss: 0.8593 - classification_loss: 0.2017
 623/1000 [=================>............] - ETA: 1:47 - loss: 1.0615 - regression_loss: 0.8595 - classification_loss: 0.2020
 624/1000 [=================>............] - ETA: 1:47 - loss: 1.0623 - regression_loss: 0.8604 - classification_loss: 0.2020
 625/1000 [=================>............] - ETA: 1:47 - loss: 1.0656 - regression_loss: 0.8631 - classification_loss: 0.2025
 626/1000 [=================>............] - ETA: 1:47 - loss: 1.0668 - regression_loss: 0.8627 - classification_loss: 0.2041
 627/1000 [=================>............] - ETA: 1:46 - loss: 1.0659 - regression_loss: 0.8619 - classification_loss: 0.2040
 628/1000 [=================>............] - ETA: 1:46 - loss: 1.0653 - regression_loss: 0.8615 - classification_loss: 0.2038
 629/1000 [=================>............] - ETA: 1:46 - loss: 1.0656 - regression_loss: 0.8616 - classification_loss: 0.2040
 630/1000 [=================>............] - ETA: 1:45 - loss: 1.0653 - regression_loss: 0.8614 - classification_loss: 0.2039
 631/1000 [=================>............] - ETA: 1:45 - loss: 1.0656 - regression_loss: 0.8615 - classification_loss: 0.2041
 632/1000 [=================>............] - ETA: 1:45 - loss: 1.0661 - regression_loss: 0.8620 - classification_loss: 0.2041
 633/1000 [=================>............] - ETA: 1:45 - loss: 1.0656 - regression_loss: 0.8616 - classification_loss: 0.2039
 634/1000 [==================>...........] - ETA: 1:44 - loss: 1.0654 - regression_loss: 0.8616 - classification_loss: 0.2038
 635/1000 [==================>...........] - ETA: 1:44 - loss: 1.0656 - regression_loss: 0.8618 - classification_loss: 0.2038
 636/1000 [==================>...........] - ETA: 1:44 - loss: 1.0649 - regression_loss: 0.8613 - classification_loss: 0.2036
 637/1000 [==================>...........] - ETA: 1:43 - loss: 1.0669 - regression_loss: 0.8627 - classification_loss: 0.2042
 638/1000 [==================>...........] - ETA: 1:43 - loss: 1.0675 - regression_loss: 0.8634 - classification_loss: 0.2041
 639/1000 [==================>...........] - ETA: 1:43 - loss: 1.0671 - regression_loss: 0.8631 - classification_loss: 0.2040
 640/1000 [==================>...........] - ETA: 1:43 - loss: 1.0673 - regression_loss: 0.8631 - classification_loss: 0.2042
 641/1000 [==================>...........] - ETA: 1:42 - loss: 1.0681 - regression_loss: 0.8638 - classification_loss: 0.2043
 642/1000 [==================>...........] - ETA: 1:42 - loss: 1.0687 - regression_loss: 0.8642 - classification_loss: 0.2045
 643/1000 [==================>...........] - ETA: 1:42 - loss: 1.0694 - regression_loss: 0.8649 - classification_loss: 0.2045
 644/1000 [==================>...........] - ETA: 1:41 - loss: 1.0701 - regression_loss: 0.8657 - classification_loss: 0.2044
 645/1000 [==================>...........] - ETA: 1:41 - loss: 1.0702 - regression_loss: 0.8659 - classification_loss: 0.2044
 646/1000 [==================>...........] - ETA: 1:41 - loss: 1.0695 - regression_loss: 0.8653 - classification_loss: 0.2042
 647/1000 [==================>...........] - ETA: 1:41 - loss: 1.0704 - regression_loss: 0.8660 - classification_loss: 0.2044
 648/1000 [==================>...........] - ETA: 1:40 - loss: 1.0700 - regression_loss: 0.8658 - classification_loss: 0.2042
 649/1000 [==================>...........] - ETA: 1:40 - loss: 1.0693 - regression_loss: 0.8652 - classification_loss: 0.2041
 650/1000 [==================>...........] - ETA: 1:40 - loss: 1.0695 - regression_loss: 0.8653 - classification_loss: 0.2041
 651/1000 [==================>...........] - ETA: 1:39 - loss: 1.0707 - regression_loss: 0.8664 - classification_loss: 0.2043
 652/1000 [==================>...........] - ETA: 1:39 - loss: 1.0719 - regression_loss: 0.8671 - classification_loss: 0.2048
 653/1000 [==================>...........] - ETA: 1:39 - loss: 1.0719 - regression_loss: 0.8672 - classification_loss: 0.2047
 654/1000 [==================>...........] - ETA: 1:39 - loss: 1.0717 - regression_loss: 0.8673 - classification_loss: 0.2045
 655/1000 [==================>...........] - ETA: 1:38 - loss: 1.0715 - regression_loss: 0.8672 - classification_loss: 0.2043
 656/1000 [==================>...........] - ETA: 1:38 - loss: 1.0708 - regression_loss: 0.8667 - classification_loss: 0.2042
 657/1000 [==================>...........] - ETA: 1:38 - loss: 1.0726 - regression_loss: 0.8680 - classification_loss: 0.2047
 658/1000 [==================>...........] - ETA: 1:37 - loss: 1.0749 - regression_loss: 0.8698 - classification_loss: 0.2051
 659/1000 [==================>...........] - ETA: 1:37 - loss: 1.0746 - regression_loss: 0.8697 - classification_loss: 0.2049
 660/1000 [==================>...........] - ETA: 1:37 - loss: 1.0752 - regression_loss: 0.8703 - classification_loss: 0.2050
 661/1000 [==================>...........] - ETA: 1:37 - loss: 1.0755 - regression_loss: 0.8706 - classification_loss: 0.2049
 662/1000 [==================>...........] - ETA: 1:36 - loss: 1.0751 - regression_loss: 0.8702 - classification_loss: 0.2049
 663/1000 [==================>...........] - ETA: 1:36 - loss: 1.0743 - regression_loss: 0.8696 - classification_loss: 0.2047
 664/1000 [==================>...........] - ETA: 1:36 - loss: 1.0735 - regression_loss: 0.8690 - classification_loss: 0.2045
 665/1000 [==================>...........] - ETA: 1:35 - loss: 1.0730 - regression_loss: 0.8685 - classification_loss: 0.2045
 666/1000 [==================>...........] - ETA: 1:35 - loss: 1.0726 - regression_loss: 0.8680 - classification_loss: 0.2046
 667/1000 [===================>..........] - ETA: 1:35 - loss: 1.0717 - regression_loss: 0.8672 - classification_loss: 0.2045
 668/1000 [===================>..........] - ETA: 1:35 - loss: 1.0710 - regression_loss: 0.8667 - classification_loss: 0.2043
 669/1000 [===================>..........] - ETA: 1:34 - loss: 1.0708 - regression_loss: 0.8665 - classification_loss: 0.2043
 670/1000 [===================>..........] - ETA: 1:34 - loss: 1.0706 - regression_loss: 0.8664 - classification_loss: 0.2043
 671/1000 [===================>..........] - ETA: 1:34 - loss: 1.0697 - regression_loss: 0.8657 - classification_loss: 0.2040
 672/1000 [===================>..........] - ETA: 1:33 - loss: 1.0693 - regression_loss: 0.8654 - classification_loss: 0.2039
 673/1000 [===================>..........] - ETA: 1:33 - loss: 1.0698 - regression_loss: 0.8659 - classification_loss: 0.2040
 674/1000 [===================>..........] - ETA: 1:33 - loss: 1.0700 - regression_loss: 0.8662 - classification_loss: 0.2039
 675/1000 [===================>..........] - ETA: 1:33 - loss: 1.0696 - regression_loss: 0.8657 - classification_loss: 0.2039
 676/1000 [===================>..........] - ETA: 1:32 - loss: 1.0687 - regression_loss: 0.8650 - classification_loss: 0.2037
 677/1000 [===================>..........] - ETA: 1:32 - loss: 1.0685 - regression_loss: 0.8649 - classification_loss: 0.2035
 678/1000 [===================>..........] - ETA: 1:32 - loss: 1.0677 - regression_loss: 0.8644 - classification_loss: 0.2033
 679/1000 [===================>..........] - ETA: 1:31 - loss: 1.0674 - regression_loss: 0.8642 - classification_loss: 0.2032
 680/1000 [===================>..........] - ETA: 1:31 - loss: 1.0672 - regression_loss: 0.8641 - classification_loss: 0.2031
 681/1000 [===================>..........] - ETA: 1:31 - loss: 1.0672 - regression_loss: 0.8642 - classification_loss: 0.2030
 682/1000 [===================>..........] - ETA: 1:31 - loss: 1.0676 - regression_loss: 0.8645 - classification_loss: 0.2031
 683/1000 [===================>..........] - ETA: 1:30 - loss: 1.0678 - regression_loss: 0.8646 - classification_loss: 0.2032
 684/1000 [===================>..........] - ETA: 1:30 - loss: 1.0675 - regression_loss: 0.8644 - classification_loss: 0.2031
 685/1000 [===================>..........] - ETA: 1:30 - loss: 1.0681 - regression_loss: 0.8649 - classification_loss: 0.2032
 686/1000 [===================>..........] - ETA: 1:29 - loss: 1.0694 - regression_loss: 0.8659 - classification_loss: 0.2035
 687/1000 [===================>..........] - ETA: 1:29 - loss: 1.0706 - regression_loss: 0.8668 - classification_loss: 0.2039
 688/1000 [===================>..........] - ETA: 1:29 - loss: 1.0705 - regression_loss: 0.8667 - classification_loss: 0.2038
 689/1000 [===================>..........] - ETA: 1:29 - loss: 1.0703 - regression_loss: 0.8666 - classification_loss: 0.2038
 690/1000 [===================>..........] - ETA: 1:28 - loss: 1.0700 - regression_loss: 0.8662 - classification_loss: 0.2038
 691/1000 [===================>..........] - ETA: 1:28 - loss: 1.0699 - regression_loss: 0.8662 - classification_loss: 0.2037
 692/1000 [===================>..........] - ETA: 1:28 - loss: 1.0690 - regression_loss: 0.8654 - classification_loss: 0.2035
 693/1000 [===================>..........] - ETA: 1:27 - loss: 1.0680 - regression_loss: 0.8646 - classification_loss: 0.2034
 694/1000 [===================>..........] - ETA: 1:27 - loss: 1.0693 - regression_loss: 0.8658 - classification_loss: 0.2036
 695/1000 [===================>..........] - ETA: 1:27 - loss: 1.0687 - regression_loss: 0.8653 - classification_loss: 0.2034
 696/1000 [===================>..........] - ETA: 1:27 - loss: 1.0680 - regression_loss: 0.8648 - classification_loss: 0.2032
 697/1000 [===================>..........] - ETA: 1:26 - loss: 1.0675 - regression_loss: 0.8645 - classification_loss: 0.2030
 698/1000 [===================>..........] - ETA: 1:26 - loss: 1.0670 - regression_loss: 0.8642 - classification_loss: 0.2028
 699/1000 [===================>..........] - ETA: 1:26 - loss: 1.0672 - regression_loss: 0.8644 - classification_loss: 0.2028
 700/1000 [====================>.........] - ETA: 1:25 - loss: 1.0675 - regression_loss: 0.8647 - classification_loss: 0.2027
 701/1000 [====================>.........] - ETA: 1:25 - loss: 1.0673 - regression_loss: 0.8647 - classification_loss: 0.2026
 702/1000 [====================>.........] - ETA: 1:25 - loss: 1.0666 - regression_loss: 0.8642 - classification_loss: 0.2025
 703/1000 [====================>.........] - ETA: 1:25 - loss: 1.0668 - regression_loss: 0.8644 - classification_loss: 0.2024
 704/1000 [====================>.........] - ETA: 1:24 - loss: 1.0677 - regression_loss: 0.8651 - classification_loss: 0.2026
 705/1000 [====================>.........] - ETA: 1:24 - loss: 1.0686 - regression_loss: 0.8657 - classification_loss: 0.2028
 706/1000 [====================>.........] - ETA: 1:24 - loss: 1.0694 - regression_loss: 0.8662 - classification_loss: 0.2032
 707/1000 [====================>.........] - ETA: 1:23 - loss: 1.0699 - regression_loss: 0.8667 - classification_loss: 0.2031
 708/1000 [====================>.........] - ETA: 1:23 - loss: 1.0697 - regression_loss: 0.8666 - classification_loss: 0.2030
 709/1000 [====================>.........] - ETA: 1:23 - loss: 1.0696 - regression_loss: 0.8664 - classification_loss: 0.2031
 710/1000 [====================>.........] - ETA: 1:23 - loss: 1.0698 - regression_loss: 0.8666 - classification_loss: 0.2032
 711/1000 [====================>.........] - ETA: 1:22 - loss: 1.0696 - regression_loss: 0.8664 - classification_loss: 0.2032
 712/1000 [====================>.........] - ETA: 1:22 - loss: 1.0689 - regression_loss: 0.8658 - classification_loss: 0.2031
 713/1000 [====================>.........] - ETA: 1:22 - loss: 1.0688 - regression_loss: 0.8657 - classification_loss: 0.2031
 714/1000 [====================>.........] - ETA: 1:21 - loss: 1.0684 - regression_loss: 0.8655 - classification_loss: 0.2029
 715/1000 [====================>.........] - ETA: 1:21 - loss: 1.0692 - regression_loss: 0.8661 - classification_loss: 0.2030
 716/1000 [====================>.........] - ETA: 1:21 - loss: 1.0685 - regression_loss: 0.8657 - classification_loss: 0.2028
 717/1000 [====================>.........] - ETA: 1:21 - loss: 1.0685 - regression_loss: 0.8655 - classification_loss: 0.2029
 718/1000 [====================>.........] - ETA: 1:20 - loss: 1.0684 - regression_loss: 0.8655 - classification_loss: 0.2028
 719/1000 [====================>.........] - ETA: 1:20 - loss: 1.0680 - regression_loss: 0.8652 - classification_loss: 0.2028
 720/1000 [====================>.........] - ETA: 1:20 - loss: 1.0692 - regression_loss: 0.8665 - classification_loss: 0.2027
 721/1000 [====================>.........] - ETA: 1:19 - loss: 1.0699 - regression_loss: 0.8670 - classification_loss: 0.2029
 722/1000 [====================>.........] - ETA: 1:19 - loss: 1.0699 - regression_loss: 0.8670 - classification_loss: 0.2029
 723/1000 [====================>.........] - ETA: 1:19 - loss: 1.0698 - regression_loss: 0.8671 - classification_loss: 0.2028
 724/1000 [====================>.........] - ETA: 1:19 - loss: 1.0693 - regression_loss: 0.8667 - classification_loss: 0.2026
 725/1000 [====================>.........] - ETA: 1:18 - loss: 1.0688 - regression_loss: 0.8662 - classification_loss: 0.2026
 726/1000 [====================>.........] - ETA: 1:18 - loss: 1.0684 - regression_loss: 0.8659 - classification_loss: 0.2025
 727/1000 [====================>.........] - ETA: 1:18 - loss: 1.0679 - regression_loss: 0.8656 - classification_loss: 0.2023
 728/1000 [====================>.........] - ETA: 1:17 - loss: 1.0693 - regression_loss: 0.8668 - classification_loss: 0.2025
 729/1000 [====================>.........] - ETA: 1:17 - loss: 1.0694 - regression_loss: 0.8670 - classification_loss: 0.2024
 730/1000 [====================>.........] - ETA: 1:17 - loss: 1.0685 - regression_loss: 0.8663 - classification_loss: 0.2022
 731/1000 [====================>.........] - ETA: 1:17 - loss: 1.0675 - regression_loss: 0.8655 - classification_loss: 0.2020
 732/1000 [====================>.........] - ETA: 1:16 - loss: 1.0680 - regression_loss: 0.8659 - classification_loss: 0.2021
 733/1000 [====================>.........] - ETA: 1:16 - loss: 1.0687 - regression_loss: 0.8665 - classification_loss: 0.2022
 734/1000 [=====================>........] - ETA: 1:16 - loss: 1.0682 - regression_loss: 0.8661 - classification_loss: 0.2021
 735/1000 [=====================>........] - ETA: 1:15 - loss: 1.0675 - regression_loss: 0.8655 - classification_loss: 0.2019
 736/1000 [=====================>........] - ETA: 1:15 - loss: 1.0677 - regression_loss: 0.8657 - classification_loss: 0.2020
 737/1000 [=====================>........] - ETA: 1:15 - loss: 1.0675 - regression_loss: 0.8656 - classification_loss: 0.2020
 738/1000 [=====================>........] - ETA: 1:15 - loss: 1.0672 - regression_loss: 0.8654 - classification_loss: 0.2018
 739/1000 [=====================>........] - ETA: 1:14 - loss: 1.0671 - regression_loss: 0.8653 - classification_loss: 0.2018
 740/1000 [=====================>........] - ETA: 1:14 - loss: 1.0670 - regression_loss: 0.8653 - classification_loss: 0.2017
 741/1000 [=====================>........] - ETA: 1:14 - loss: 1.0666 - regression_loss: 0.8651 - classification_loss: 0.2016
 742/1000 [=====================>........] - ETA: 1:13 - loss: 1.0661 - regression_loss: 0.8646 - classification_loss: 0.2015
 743/1000 [=====================>........] - ETA: 1:13 - loss: 1.0689 - regression_loss: 0.8666 - classification_loss: 0.2022
 744/1000 [=====================>........] - ETA: 1:13 - loss: 1.0686 - regression_loss: 0.8665 - classification_loss: 0.2021
 745/1000 [=====================>........] - ETA: 1:13 - loss: 1.0685 - regression_loss: 0.8663 - classification_loss: 0.2022
 746/1000 [=====================>........] - ETA: 1:12 - loss: 1.0696 - regression_loss: 0.8672 - classification_loss: 0.2023
 747/1000 [=====================>........] - ETA: 1:12 - loss: 1.0699 - regression_loss: 0.8675 - classification_loss: 0.2025
 748/1000 [=====================>........] - ETA: 1:12 - loss: 1.0697 - regression_loss: 0.8672 - classification_loss: 0.2026
 749/1000 [=====================>........] - ETA: 1:11 - loss: 1.0699 - regression_loss: 0.8673 - classification_loss: 0.2025
 750/1000 [=====================>........] - ETA: 1:11 - loss: 1.0692 - regression_loss: 0.8668 - classification_loss: 0.2024
 751/1000 [=====================>........] - ETA: 1:11 - loss: 1.0687 - regression_loss: 0.8664 - classification_loss: 0.2023
 752/1000 [=====================>........] - ETA: 1:11 - loss: 1.0679 - regression_loss: 0.8658 - classification_loss: 0.2021
 753/1000 [=====================>........] - ETA: 1:10 - loss: 1.0676 - regression_loss: 0.8655 - classification_loss: 0.2021
 754/1000 [=====================>........] - ETA: 1:10 - loss: 1.0687 - regression_loss: 0.8664 - classification_loss: 0.2024
 755/1000 [=====================>........] - ETA: 1:10 - loss: 1.0679 - regression_loss: 0.8658 - classification_loss: 0.2022
 756/1000 [=====================>........] - ETA: 1:09 - loss: 1.0679 - regression_loss: 0.8659 - classification_loss: 0.2020
 757/1000 [=====================>........] - ETA: 1:09 - loss: 1.0679 - regression_loss: 0.8660 - classification_loss: 0.2019
 758/1000 [=====================>........] - ETA: 1:09 - loss: 1.0689 - regression_loss: 0.8666 - classification_loss: 0.2023
 759/1000 [=====================>........] - ETA: 1:09 - loss: 1.0682 - regression_loss: 0.8660 - classification_loss: 0.2022
 760/1000 [=====================>........] - ETA: 1:08 - loss: 1.0674 - regression_loss: 0.8655 - classification_loss: 0.2020
 761/1000 [=====================>........] - ETA: 1:08 - loss: 1.0687 - regression_loss: 0.8667 - classification_loss: 0.2021
 762/1000 [=====================>........] - ETA: 1:08 - loss: 1.0695 - regression_loss: 0.8674 - classification_loss: 0.2021
 763/1000 [=====================>........] - ETA: 1:07 - loss: 1.0693 - regression_loss: 0.8673 - classification_loss: 0.2019
 764/1000 [=====================>........] - ETA: 1:07 - loss: 1.0686 - regression_loss: 0.8668 - classification_loss: 0.2018
 765/1000 [=====================>........] - ETA: 1:07 - loss: 1.0685 - regression_loss: 0.8668 - classification_loss: 0.2016
 766/1000 [=====================>........] - ETA: 1:07 - loss: 1.0680 - regression_loss: 0.8664 - classification_loss: 0.2016
 767/1000 [======================>.......] - ETA: 1:06 - loss: 1.0672 - regression_loss: 0.8657 - classification_loss: 0.2014
 768/1000 [======================>.......] - ETA: 1:06 - loss: 1.0683 - regression_loss: 0.8667 - classification_loss: 0.2016
 769/1000 [======================>.......] - ETA: 1:06 - loss: 1.0673 - regression_loss: 0.8658 - classification_loss: 0.2015
 770/1000 [======================>.......] - ETA: 1:05 - loss: 1.0668 - regression_loss: 0.8655 - classification_loss: 0.2013
 771/1000 [======================>.......] - ETA: 1:05 - loss: 1.0664 - regression_loss: 0.8653 - classification_loss: 0.2012
 772/1000 [======================>.......] - ETA: 1:05 - loss: 1.0668 - regression_loss: 0.8657 - classification_loss: 0.2012
 773/1000 [======================>.......] - ETA: 1:05 - loss: 1.0662 - regression_loss: 0.8652 - classification_loss: 0.2010
 774/1000 [======================>.......] - ETA: 1:04 - loss: 1.0663 - regression_loss: 0.8652 - classification_loss: 0.2011
 775/1000 [======================>.......] - ETA: 1:04 - loss: 1.0663 - regression_loss: 0.8650 - classification_loss: 0.2013
 776/1000 [======================>.......] - ETA: 1:04 - loss: 1.0675 - regression_loss: 0.8660 - classification_loss: 0.2015
 777/1000 [======================>.......] - ETA: 1:03 - loss: 1.0676 - regression_loss: 0.8661 - classification_loss: 0.2014
 778/1000 [======================>.......] - ETA: 1:03 - loss: 1.0675 - regression_loss: 0.8660 - classification_loss: 0.2014
 779/1000 [======================>.......] - ETA: 1:03 - loss: 1.0674 - regression_loss: 0.8660 - classification_loss: 0.2014
 780/1000 [======================>.......] - ETA: 1:03 - loss: 1.0670 - regression_loss: 0.8657 - classification_loss: 0.2013
 781/1000 [======================>.......] - ETA: 1:02 - loss: 1.0668 - regression_loss: 0.8656 - classification_loss: 0.2012
 782/1000 [======================>.......] - ETA: 1:02 - loss: 1.0675 - regression_loss: 0.8663 - classification_loss: 0.2012
 783/1000 [======================>.......] - ETA: 1:02 - loss: 1.0678 - regression_loss: 0.8664 - classification_loss: 0.2014
 784/1000 [======================>.......] - ETA: 1:01 - loss: 1.0681 - regression_loss: 0.8666 - classification_loss: 0.2014
 785/1000 [======================>.......] - ETA: 1:01 - loss: 1.0688 - regression_loss: 0.8673 - classification_loss: 0.2015
 786/1000 [======================>.......] - ETA: 1:01 - loss: 1.0688 - regression_loss: 0.8673 - classification_loss: 0.2014
 787/1000 [======================>.......] - ETA: 1:01 - loss: 1.0685 - regression_loss: 0.8672 - classification_loss: 0.2013
 788/1000 [======================>.......] - ETA: 1:00 - loss: 1.0685 - regression_loss: 0.8671 - classification_loss: 0.2014
 789/1000 [======================>.......] - ETA: 1:00 - loss: 1.0676 - regression_loss: 0.8664 - classification_loss: 0.2012
 790/1000 [======================>.......] - ETA: 1:00 - loss: 1.0679 - regression_loss: 0.8667 - classification_loss: 0.2013
 791/1000 [======================>.......] - ETA: 59s - loss: 1.0677 - regression_loss: 0.8666 - classification_loss: 0.2011 
 792/1000 [======================>.......] - ETA: 59s - loss: 1.0684 - regression_loss: 0.8670 - classification_loss: 0.2015
 793/1000 [======================>.......] - ETA: 59s - loss: 1.0678 - regression_loss: 0.8663 - classification_loss: 0.2015
 794/1000 [======================>.......] - ETA: 59s - loss: 1.0674 - regression_loss: 0.8661 - classification_loss: 0.2013
 795/1000 [======================>.......] - ETA: 58s - loss: 1.0672 - regression_loss: 0.8660 - classification_loss: 0.2013
 796/1000 [======================>.......] - ETA: 58s - loss: 1.0666 - regression_loss: 0.8655 - classification_loss: 0.2011
 797/1000 [======================>.......] - ETA: 58s - loss: 1.0658 - regression_loss: 0.8649 - classification_loss: 0.2009
 798/1000 [======================>.......] - ETA: 57s - loss: 1.0653 - regression_loss: 0.8646 - classification_loss: 0.2007
 799/1000 [======================>.......] - ETA: 57s - loss: 1.0647 - regression_loss: 0.8641 - classification_loss: 0.2006
 800/1000 [=======================>......] - ETA: 57s - loss: 1.0651 - regression_loss: 0.8641 - classification_loss: 0.2010
 801/1000 [=======================>......] - ETA: 57s - loss: 1.0653 - regression_loss: 0.8643 - classification_loss: 0.2010
 802/1000 [=======================>......] - ETA: 56s - loss: 1.0655 - regression_loss: 0.8645 - classification_loss: 0.2010
 803/1000 [=======================>......] - ETA: 56s - loss: 1.0680 - regression_loss: 0.8664 - classification_loss: 0.2016
 804/1000 [=======================>......] - ETA: 56s - loss: 1.0680 - regression_loss: 0.8666 - classification_loss: 0.2015
 805/1000 [=======================>......] - ETA: 55s - loss: 1.0672 - regression_loss: 0.8658 - classification_loss: 0.2013
 806/1000 [=======================>......] - ETA: 55s - loss: 1.0676 - regression_loss: 0.8663 - classification_loss: 0.2013
 807/1000 [=======================>......] - ETA: 55s - loss: 1.0681 - regression_loss: 0.8667 - classification_loss: 0.2013
 808/1000 [=======================>......] - ETA: 55s - loss: 1.0688 - regression_loss: 0.8669 - classification_loss: 0.2020
 809/1000 [=======================>......] - ETA: 54s - loss: 1.0688 - regression_loss: 0.8667 - classification_loss: 0.2022
 810/1000 [=======================>......] - ETA: 54s - loss: 1.0695 - regression_loss: 0.8672 - classification_loss: 0.2023
 811/1000 [=======================>......] - ETA: 54s - loss: 1.0708 - regression_loss: 0.8683 - classification_loss: 0.2025
 812/1000 [=======================>......] - ETA: 53s - loss: 1.0700 - regression_loss: 0.8677 - classification_loss: 0.2023
 813/1000 [=======================>......] - ETA: 53s - loss: 1.0708 - regression_loss: 0.8685 - classification_loss: 0.2023
 814/1000 [=======================>......] - ETA: 53s - loss: 1.0705 - regression_loss: 0.8683 - classification_loss: 0.2022
 815/1000 [=======================>......] - ETA: 52s - loss: 1.0697 - regression_loss: 0.8676 - classification_loss: 0.2021
 816/1000 [=======================>......] - ETA: 52s - loss: 1.0690 - regression_loss: 0.8671 - classification_loss: 0.2019
 817/1000 [=======================>......] - ETA: 52s - loss: 1.0691 - regression_loss: 0.8673 - classification_loss: 0.2017
 818/1000 [=======================>......] - ETA: 52s - loss: 1.0684 - regression_loss: 0.8668 - classification_loss: 0.2016
 819/1000 [=======================>......] - ETA: 51s - loss: 1.0679 - regression_loss: 0.8664 - classification_loss: 0.2015
 820/1000 [=======================>......] - ETA: 51s - loss: 1.0675 - regression_loss: 0.8662 - classification_loss: 0.2014
 821/1000 [=======================>......] - ETA: 51s - loss: 1.0674 - regression_loss: 0.8661 - classification_loss: 0.2013
 822/1000 [=======================>......] - ETA: 50s - loss: 1.0670 - regression_loss: 0.8658 - classification_loss: 0.2012
 823/1000 [=======================>......] - ETA: 50s - loss: 1.0676 - regression_loss: 0.8663 - classification_loss: 0.2014
 824/1000 [=======================>......] - ETA: 50s - loss: 1.0673 - regression_loss: 0.8661 - classification_loss: 0.2012
 825/1000 [=======================>......] - ETA: 50s - loss: 1.0664 - regression_loss: 0.8653 - classification_loss: 0.2011
 826/1000 [=======================>......] - ETA: 49s - loss: 1.0678 - regression_loss: 0.8665 - classification_loss: 0.2013
 827/1000 [=======================>......] - ETA: 49s - loss: 1.0691 - regression_loss: 0.8675 - classification_loss: 0.2015
 828/1000 [=======================>......] - ETA: 49s - loss: 1.0694 - regression_loss: 0.8678 - classification_loss: 0.2015
 829/1000 [=======================>......] - ETA: 48s - loss: 1.0699 - regression_loss: 0.8682 - classification_loss: 0.2018
 830/1000 [=======================>......] - ETA: 48s - loss: 1.0697 - regression_loss: 0.8681 - classification_loss: 0.2016
 831/1000 [=======================>......] - ETA: 48s - loss: 1.0693 - regression_loss: 0.8678 - classification_loss: 0.2015
 832/1000 [=======================>......] - ETA: 48s - loss: 1.0700 - regression_loss: 0.8684 - classification_loss: 0.2016
 833/1000 [=======================>......] - ETA: 47s - loss: 1.0704 - regression_loss: 0.8688 - classification_loss: 0.2015
 834/1000 [========================>.....] - ETA: 47s - loss: 1.0707 - regression_loss: 0.8692 - classification_loss: 0.2015
 835/1000 [========================>.....] - ETA: 47s - loss: 1.0710 - regression_loss: 0.8694 - classification_loss: 0.2015
 836/1000 [========================>.....] - ETA: 46s - loss: 1.0706 - regression_loss: 0.8691 - classification_loss: 0.2015
 837/1000 [========================>.....] - ETA: 46s - loss: 1.0706 - regression_loss: 0.8692 - classification_loss: 0.2015
 838/1000 [========================>.....] - ETA: 46s - loss: 1.0704 - regression_loss: 0.8690 - classification_loss: 0.2014
 839/1000 [========================>.....] - ETA: 46s - loss: 1.0720 - regression_loss: 0.8701 - classification_loss: 0.2020
 840/1000 [========================>.....] - ETA: 45s - loss: 1.0721 - regression_loss: 0.8702 - classification_loss: 0.2019
 841/1000 [========================>.....] - ETA: 45s - loss: 1.0718 - regression_loss: 0.8698 - classification_loss: 0.2020
 842/1000 [========================>.....] - ETA: 45s - loss: 1.0714 - regression_loss: 0.8694 - classification_loss: 0.2020
 843/1000 [========================>.....] - ETA: 44s - loss: 1.0713 - regression_loss: 0.8694 - classification_loss: 0.2019
 844/1000 [========================>.....] - ETA: 44s - loss: 1.0721 - regression_loss: 0.8701 - classification_loss: 0.2020
 845/1000 [========================>.....] - ETA: 44s - loss: 1.0722 - regression_loss: 0.8702 - classification_loss: 0.2019
 846/1000 [========================>.....] - ETA: 44s - loss: 1.0718 - regression_loss: 0.8700 - classification_loss: 0.2018
 847/1000 [========================>.....] - ETA: 43s - loss: 1.0719 - regression_loss: 0.8701 - classification_loss: 0.2018
 848/1000 [========================>.....] - ETA: 43s - loss: 1.0719 - regression_loss: 0.8701 - classification_loss: 0.2018
 849/1000 [========================>.....] - ETA: 43s - loss: 1.0720 - regression_loss: 0.8701 - classification_loss: 0.2019
 850/1000 [========================>.....] - ETA: 42s - loss: 1.0718 - regression_loss: 0.8699 - classification_loss: 0.2019
 851/1000 [========================>.....] - ETA: 42s - loss: 1.0725 - regression_loss: 0.8704 - classification_loss: 0.2021
 852/1000 [========================>.....] - ETA: 42s - loss: 1.0732 - regression_loss: 0.8709 - classification_loss: 0.2024
 853/1000 [========================>.....] - ETA: 42s - loss: 1.0729 - regression_loss: 0.8706 - classification_loss: 0.2023
 854/1000 [========================>.....] - ETA: 41s - loss: 1.0724 - regression_loss: 0.8702 - classification_loss: 0.2022
 855/1000 [========================>.....] - ETA: 41s - loss: 1.0741 - regression_loss: 0.8716 - classification_loss: 0.2024
 856/1000 [========================>.....] - ETA: 41s - loss: 1.0739 - regression_loss: 0.8716 - classification_loss: 0.2023
 857/1000 [========================>.....] - ETA: 40s - loss: 1.0734 - regression_loss: 0.8712 - classification_loss: 0.2022
 858/1000 [========================>.....] - ETA: 40s - loss: 1.0735 - regression_loss: 0.8711 - classification_loss: 0.2024
 859/1000 [========================>.....] - ETA: 40s - loss: 1.0736 - regression_loss: 0.8712 - classification_loss: 0.2024
 860/1000 [========================>.....] - ETA: 40s - loss: 1.0731 - regression_loss: 0.8708 - classification_loss: 0.2023
 861/1000 [========================>.....] - ETA: 39s - loss: 1.0733 - regression_loss: 0.8710 - classification_loss: 0.2024
 862/1000 [========================>.....] - ETA: 39s - loss: 1.0728 - regression_loss: 0.8706 - classification_loss: 0.2022
 863/1000 [========================>.....] - ETA: 39s - loss: 1.0731 - regression_loss: 0.8707 - classification_loss: 0.2023
 864/1000 [========================>.....] - ETA: 38s - loss: 1.0723 - regression_loss: 0.8701 - classification_loss: 0.2022
 865/1000 [========================>.....] - ETA: 38s - loss: 1.0724 - regression_loss: 0.8702 - classification_loss: 0.2022
 866/1000 [========================>.....] - ETA: 38s - loss: 1.0727 - regression_loss: 0.8704 - classification_loss: 0.2023
 867/1000 [=========================>....] - ETA: 38s - loss: 1.0726 - regression_loss: 0.8704 - classification_loss: 0.2022
 868/1000 [=========================>....] - ETA: 37s - loss: 1.0724 - regression_loss: 0.8702 - classification_loss: 0.2023
 869/1000 [=========================>....] - ETA: 37s - loss: 1.0719 - regression_loss: 0.8698 - classification_loss: 0.2022
 870/1000 [=========================>....] - ETA: 37s - loss: 1.0720 - regression_loss: 0.8699 - classification_loss: 0.2021
 871/1000 [=========================>....] - ETA: 36s - loss: 1.0715 - regression_loss: 0.8695 - classification_loss: 0.2020
 872/1000 [=========================>....] - ETA: 36s - loss: 1.0716 - regression_loss: 0.8696 - classification_loss: 0.2020
 873/1000 [=========================>....] - ETA: 36s - loss: 1.0710 - regression_loss: 0.8692 - classification_loss: 0.2019
 874/1000 [=========================>....] - ETA: 36s - loss: 1.0703 - regression_loss: 0.8686 - classification_loss: 0.2017
 875/1000 [=========================>....] - ETA: 35s - loss: 1.0702 - regression_loss: 0.8685 - classification_loss: 0.2017
 876/1000 [=========================>....] - ETA: 35s - loss: 1.0698 - regression_loss: 0.8682 - classification_loss: 0.2016
 877/1000 [=========================>....] - ETA: 35s - loss: 1.0692 - regression_loss: 0.8678 - classification_loss: 0.2015
 878/1000 [=========================>....] - ETA: 34s - loss: 1.0693 - regression_loss: 0.8677 - classification_loss: 0.2016
 879/1000 [=========================>....] - ETA: 34s - loss: 1.0691 - regression_loss: 0.8676 - classification_loss: 0.2015
 880/1000 [=========================>....] - ETA: 34s - loss: 1.0706 - regression_loss: 0.8687 - classification_loss: 0.2019
 881/1000 [=========================>....] - ETA: 34s - loss: 1.0699 - regression_loss: 0.8681 - classification_loss: 0.2018
 882/1000 [=========================>....] - ETA: 33s - loss: 1.0698 - regression_loss: 0.8681 - classification_loss: 0.2017
 883/1000 [=========================>....] - ETA: 33s - loss: 1.0698 - regression_loss: 0.8682 - classification_loss: 0.2016
 884/1000 [=========================>....] - ETA: 33s - loss: 1.0693 - regression_loss: 0.8678 - classification_loss: 0.2015
 885/1000 [=========================>....] - ETA: 32s - loss: 1.0693 - regression_loss: 0.8679 - classification_loss: 0.2015
 886/1000 [=========================>....] - ETA: 32s - loss: 1.0692 - regression_loss: 0.8678 - classification_loss: 0.2014
 887/1000 [=========================>....] - ETA: 32s - loss: 1.0693 - regression_loss: 0.8681 - classification_loss: 0.2013
 888/1000 [=========================>....] - ETA: 32s - loss: 1.0693 - regression_loss: 0.8680 - classification_loss: 0.2013
 889/1000 [=========================>....] - ETA: 31s - loss: 1.0700 - regression_loss: 0.8686 - classification_loss: 0.2014
 890/1000 [=========================>....] - ETA: 31s - loss: 1.0700 - regression_loss: 0.8687 - classification_loss: 0.2013
 891/1000 [=========================>....] - ETA: 31s - loss: 1.0697 - regression_loss: 0.8685 - classification_loss: 0.2012
 892/1000 [=========================>....] - ETA: 30s - loss: 1.0703 - regression_loss: 0.8691 - classification_loss: 0.2012
 893/1000 [=========================>....] - ETA: 30s - loss: 1.0697 - regression_loss: 0.8686 - classification_loss: 0.2011
 894/1000 [=========================>....] - ETA: 30s - loss: 1.0697 - regression_loss: 0.8687 - classification_loss: 0.2011
 895/1000 [=========================>....] - ETA: 30s - loss: 1.0696 - regression_loss: 0.8686 - classification_loss: 0.2010
 896/1000 [=========================>....] - ETA: 29s - loss: 1.0693 - regression_loss: 0.8684 - classification_loss: 0.2010
 897/1000 [=========================>....] - ETA: 29s - loss: 1.0691 - regression_loss: 0.8681 - classification_loss: 0.2010
 898/1000 [=========================>....] - ETA: 29s - loss: 1.0691 - regression_loss: 0.8682 - classification_loss: 0.2009
 899/1000 [=========================>....] - ETA: 28s - loss: 1.0687 - regression_loss: 0.8678 - classification_loss: 0.2009
 900/1000 [==========================>...] - ETA: 28s - loss: 1.0686 - regression_loss: 0.8677 - classification_loss: 0.2009
 901/1000 [==========================>...] - ETA: 28s - loss: 1.0683 - regression_loss: 0.8674 - classification_loss: 0.2009
 902/1000 [==========================>...] - ETA: 28s - loss: 1.0682 - regression_loss: 0.8674 - classification_loss: 0.2008
 903/1000 [==========================>...] - ETA: 27s - loss: 1.0675 - regression_loss: 0.8668 - classification_loss: 0.2008
 904/1000 [==========================>...] - ETA: 27s - loss: 1.0679 - regression_loss: 0.8672 - classification_loss: 0.2007
 905/1000 [==========================>...] - ETA: 27s - loss: 1.0690 - regression_loss: 0.8682 - classification_loss: 0.2008
 906/1000 [==========================>...] - ETA: 26s - loss: 1.0693 - regression_loss: 0.8685 - classification_loss: 0.2008
 907/1000 [==========================>...] - ETA: 26s - loss: 1.0703 - regression_loss: 0.8691 - classification_loss: 0.2012
 908/1000 [==========================>...] - ETA: 26s - loss: 1.0698 - regression_loss: 0.8688 - classification_loss: 0.2011
 909/1000 [==========================>...] - ETA: 26s - loss: 1.0709 - regression_loss: 0.8696 - classification_loss: 0.2013
 910/1000 [==========================>...] - ETA: 25s - loss: 1.0704 - regression_loss: 0.8691 - classification_loss: 0.2013
 911/1000 [==========================>...] - ETA: 25s - loss: 1.0703 - regression_loss: 0.8691 - classification_loss: 0.2012
 912/1000 [==========================>...] - ETA: 25s - loss: 1.0717 - regression_loss: 0.8700 - classification_loss: 0.2017
 913/1000 [==========================>...] - ETA: 24s - loss: 1.0715 - regression_loss: 0.8699 - classification_loss: 0.2015
 914/1000 [==========================>...] - ETA: 24s - loss: 1.0709 - regression_loss: 0.8695 - classification_loss: 0.2014
 915/1000 [==========================>...] - ETA: 24s - loss: 1.0706 - regression_loss: 0.8692 - classification_loss: 0.2013
 916/1000 [==========================>...] - ETA: 24s - loss: 1.0706 - regression_loss: 0.8692 - classification_loss: 0.2014
 917/1000 [==========================>...] - ETA: 23s - loss: 1.0700 - regression_loss: 0.8688 - classification_loss: 0.2012
 918/1000 [==========================>...] - ETA: 23s - loss: 1.0716 - regression_loss: 0.8699 - classification_loss: 0.2017
 919/1000 [==========================>...] - ETA: 23s - loss: 1.0714 - regression_loss: 0.8698 - classification_loss: 0.2016
 920/1000 [==========================>...] - ETA: 22s - loss: 1.0708 - regression_loss: 0.8693 - classification_loss: 0.2015
 921/1000 [==========================>...] - ETA: 22s - loss: 1.0700 - regression_loss: 0.8687 - classification_loss: 0.2013
 922/1000 [==========================>...] - ETA: 22s - loss: 1.0697 - regression_loss: 0.8685 - classification_loss: 0.2012
 923/1000 [==========================>...] - ETA: 22s - loss: 1.0692 - regression_loss: 0.8681 - classification_loss: 0.2011
 924/1000 [==========================>...] - ETA: 21s - loss: 1.0687 - regression_loss: 0.8677 - classification_loss: 0.2010
 925/1000 [==========================>...] - ETA: 21s - loss: 1.0690 - regression_loss: 0.8680 - classification_loss: 0.2010
 926/1000 [==========================>...] - ETA: 21s - loss: 1.0695 - regression_loss: 0.8684 - classification_loss: 0.2010
 927/1000 [==========================>...] - ETA: 20s - loss: 1.0698 - regression_loss: 0.8688 - classification_loss: 0.2010
 928/1000 [==========================>...] - ETA: 20s - loss: 1.0705 - regression_loss: 0.8695 - classification_loss: 0.2010
 929/1000 [==========================>...] - ETA: 20s - loss: 1.0698 - regression_loss: 0.8689 - classification_loss: 0.2009
 930/1000 [==========================>...] - ETA: 20s - loss: 1.0695 - regression_loss: 0.8688 - classification_loss: 0.2007
 931/1000 [==========================>...] - ETA: 19s - loss: 1.0695 - regression_loss: 0.8687 - classification_loss: 0.2008
 932/1000 [==========================>...] - ETA: 19s - loss: 1.0691 - regression_loss: 0.8684 - classification_loss: 0.2007
 933/1000 [==========================>...] - ETA: 19s - loss: 1.0687 - regression_loss: 0.8680 - classification_loss: 0.2007
 934/1000 [===========================>..] - ETA: 18s - loss: 1.0687 - regression_loss: 0.8680 - classification_loss: 0.2007
 935/1000 [===========================>..] - ETA: 18s - loss: 1.0687 - regression_loss: 0.8681 - classification_loss: 0.2006
 936/1000 [===========================>..] - ETA: 18s - loss: 1.0691 - regression_loss: 0.8685 - classification_loss: 0.2006
 937/1000 [===========================>..] - ETA: 18s - loss: 1.0689 - regression_loss: 0.8683 - classification_loss: 0.2005
 938/1000 [===========================>..] - ETA: 17s - loss: 1.0687 - regression_loss: 0.8683 - classification_loss: 0.2004
 939/1000 [===========================>..] - ETA: 17s - loss: 1.0689 - regression_loss: 0.8686 - classification_loss: 0.2004
 940/1000 [===========================>..] - ETA: 17s - loss: 1.0689 - regression_loss: 0.8686 - classification_loss: 0.2003
 941/1000 [===========================>..] - ETA: 16s - loss: 1.0683 - regression_loss: 0.8682 - classification_loss: 0.2001
 942/1000 [===========================>..] - ETA: 16s - loss: 1.0680 - regression_loss: 0.8680 - classification_loss: 0.2000
 943/1000 [===========================>..] - ETA: 16s - loss: 1.0682 - regression_loss: 0.8683 - classification_loss: 0.2000
 944/1000 [===========================>..] - ETA: 16s - loss: 1.0696 - regression_loss: 0.8693 - classification_loss: 0.2003
 945/1000 [===========================>..] - ETA: 15s - loss: 1.0692 - regression_loss: 0.8690 - classification_loss: 0.2001
 946/1000 [===========================>..] - ETA: 15s - loss: 1.0690 - regression_loss: 0.8689 - classification_loss: 0.2001
 947/1000 [===========================>..] - ETA: 15s - loss: 1.0687 - regression_loss: 0.8686 - classification_loss: 0.2001
 948/1000 [===========================>..] - ETA: 14s - loss: 1.0683 - regression_loss: 0.8683 - classification_loss: 0.2000
 949/1000 [===========================>..] - ETA: 14s - loss: 1.0689 - regression_loss: 0.8689 - classification_loss: 0.2000
 950/1000 [===========================>..] - ETA: 14s - loss: 1.0690 - regression_loss: 0.8690 - classification_loss: 0.2000
 951/1000 [===========================>..] - ETA: 14s - loss: 1.0690 - regression_loss: 0.8692 - classification_loss: 0.1999
 952/1000 [===========================>..] - ETA: 13s - loss: 1.0686 - regression_loss: 0.8688 - classification_loss: 0.1997
 953/1000 [===========================>..] - ETA: 13s - loss: 1.0680 - regression_loss: 0.8684 - classification_loss: 0.1996
 954/1000 [===========================>..] - ETA: 13s - loss: 1.0685 - regression_loss: 0.8689 - classification_loss: 0.1996
 955/1000 [===========================>..] - ETA: 12s - loss: 1.0686 - regression_loss: 0.8689 - classification_loss: 0.1997
 956/1000 [===========================>..] - ETA: 12s - loss: 1.0685 - regression_loss: 0.8689 - classification_loss: 0.1996
 957/1000 [===========================>..] - ETA: 12s - loss: 1.0685 - regression_loss: 0.8689 - classification_loss: 0.1996
 958/1000 [===========================>..] - ETA: 12s - loss: 1.0690 - regression_loss: 0.8694 - classification_loss: 0.1996
 959/1000 [===========================>..] - ETA: 11s - loss: 1.0695 - regression_loss: 0.8699 - classification_loss: 0.1996
 960/1000 [===========================>..] - ETA: 11s - loss: 1.0705 - regression_loss: 0.8706 - classification_loss: 0.1999
 961/1000 [===========================>..] - ETA: 11s - loss: 1.0704 - regression_loss: 0.8704 - classification_loss: 0.2000
 962/1000 [===========================>..] - ETA: 10s - loss: 1.0700 - regression_loss: 0.8702 - classification_loss: 0.1998
 963/1000 [===========================>..] - ETA: 10s - loss: 1.0711 - regression_loss: 0.8710 - classification_loss: 0.2002
 964/1000 [===========================>..] - ETA: 10s - loss: 1.0717 - regression_loss: 0.8715 - classification_loss: 0.2002
 965/1000 [===========================>..] - ETA: 10s - loss: 1.0716 - regression_loss: 0.8716 - classification_loss: 0.2001
 966/1000 [===========================>..] - ETA: 9s - loss: 1.0728 - regression_loss: 0.8723 - classification_loss: 0.2004 
 967/1000 [============================>.] - ETA: 9s - loss: 1.0729 - regression_loss: 0.8725 - classification_loss: 0.2005
 968/1000 [============================>.] - ETA: 9s - loss: 1.0732 - regression_loss: 0.8728 - classification_loss: 0.2004
 969/1000 [============================>.] - ETA: 8s - loss: 1.0726 - regression_loss: 0.8722 - classification_loss: 0.2004
 970/1000 [============================>.] - ETA: 8s - loss: 1.0721 - regression_loss: 0.8718 - classification_loss: 0.2003
 971/1000 [============================>.] - ETA: 8s - loss: 1.0720 - regression_loss: 0.8716 - classification_loss: 0.2004
 972/1000 [============================>.] - ETA: 8s - loss: 1.0727 - regression_loss: 0.8721 - classification_loss: 0.2006
 973/1000 [============================>.] - ETA: 7s - loss: 1.0730 - regression_loss: 0.8724 - classification_loss: 0.2006
 974/1000 [============================>.] - ETA: 7s - loss: 1.0726 - regression_loss: 0.8721 - classification_loss: 0.2005
 975/1000 [============================>.] - ETA: 7s - loss: 1.0732 - regression_loss: 0.8726 - classification_loss: 0.2006
 976/1000 [============================>.] - ETA: 6s - loss: 1.0726 - regression_loss: 0.8721 - classification_loss: 0.2004
 977/1000 [============================>.] - ETA: 6s - loss: 1.0725 - regression_loss: 0.8722 - classification_loss: 0.2003
 978/1000 [============================>.] - ETA: 6s - loss: 1.0720 - regression_loss: 0.8717 - classification_loss: 0.2003
 979/1000 [============================>.] - ETA: 6s - loss: 1.0715 - regression_loss: 0.8713 - classification_loss: 0.2002
 980/1000 [============================>.] - ETA: 5s - loss: 1.0711 - regression_loss: 0.8710 - classification_loss: 0.2001
 981/1000 [============================>.] - ETA: 5s - loss: 1.0710 - regression_loss: 0.8708 - classification_loss: 0.2001
 982/1000 [============================>.] - ETA: 5s - loss: 1.0714 - regression_loss: 0.8713 - classification_loss: 0.2001
 983/1000 [============================>.] - ETA: 4s - loss: 1.0711 - regression_loss: 0.8711 - classification_loss: 0.2000
 984/1000 [============================>.] - ETA: 4s - loss: 1.0716 - regression_loss: 0.8716 - classification_loss: 0.2000
 985/1000 [============================>.] - ETA: 4s - loss: 1.0717 - regression_loss: 0.8715 - classification_loss: 0.2002
 986/1000 [============================>.] - ETA: 4s - loss: 1.0714 - regression_loss: 0.8711 - classification_loss: 0.2003
 987/1000 [============================>.] - ETA: 3s - loss: 1.0711 - regression_loss: 0.8708 - classification_loss: 0.2003
 988/1000 [============================>.] - ETA: 3s - loss: 1.0709 - regression_loss: 0.8706 - classification_loss: 0.2002
 989/1000 [============================>.] - ETA: 3s - loss: 1.0709 - regression_loss: 0.8706 - classification_loss: 0.2002
 990/1000 [============================>.] - ETA: 2s - loss: 1.0715 - regression_loss: 0.8711 - classification_loss: 0.2005
 991/1000 [============================>.] - ETA: 2s - loss: 1.0715 - regression_loss: 0.8711 - classification_loss: 0.2005
 992/1000 [============================>.] - ETA: 2s - loss: 1.0717 - regression_loss: 0.8712 - classification_loss: 0.2005
 993/1000 [============================>.] - ETA: 2s - loss: 1.0713 - regression_loss: 0.8709 - classification_loss: 0.2004
 994/1000 [============================>.] - ETA: 1s - loss: 1.0714 - regression_loss: 0.8709 - classification_loss: 0.2005
 995/1000 [============================>.] - ETA: 1s - loss: 1.0715 - regression_loss: 0.8711 - classification_loss: 0.2004
 996/1000 [============================>.] - ETA: 1s - loss: 1.0709 - regression_loss: 0.8706 - classification_loss: 0.2003
 997/1000 [============================>.] - ETA: 0s - loss: 1.0706 - regression_loss: 0.8703 - classification_loss: 0.2003
 998/1000 [============================>.] - ETA: 0s - loss: 1.0707 - regression_loss: 0.8703 - classification_loss: 0.2004
 999/1000 [============================>.] - ETA: 0s - loss: 1.0704 - regression_loss: 0.8702 - classification_loss: 0.2002
1000/1000 [==============================] - 286s 286ms/step - loss: 1.0701 - regression_loss: 0.8700 - classification_loss: 0.2001
Using TensorFlow backend.
/home/mpanoff/.conda/envs/tf-gpu-cuda8/lib/python3.6/site-packages/keras/callbacks.py:1065: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.
  warnings.warn('`epsilon` argument is deprecated and '

Epoch 00010: saving model to ./snapshots/resnet50_csv_10.h5
